{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 5400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 0.0009981481481481482,
      "loss": 1.8568,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0009962962962962963,
      "loss": 1.4763,
      "step": 20
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0009944444444444445,
      "loss": 1.181,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0009925925925925927,
      "loss": 1.0576,
      "step": 40
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0009907407407407408,
      "loss": 0.9188,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000988888888888889,
      "loss": 0.9325,
      "step": 60
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0009870370370370371,
      "loss": 0.8757,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.000985185185185185,
      "loss": 0.8534,
      "step": 80
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0009833333333333332,
      "loss": 0.8053,
      "step": 90
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0009814814814814816,
      "loss": 0.762,
      "step": 100
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0009796296296296296,
      "loss": 0.8505,
      "step": 110
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0009777777777777777,
      "loss": 0.7579,
      "step": 120
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.000975925925925926,
      "loss": 0.7283,
      "step": 130
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0009740740740740741,
      "loss": 0.7835,
      "step": 140
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0009722222222222222,
      "loss": 0.757,
      "step": 150
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0009703703703703704,
      "loss": 0.7025,
      "step": 160
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0009685185185185186,
      "loss": 0.7147,
      "step": 170
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0009666666666666667,
      "loss": 0.746,
      "step": 180
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0009648148148148148,
      "loss": 0.7509,
      "step": 190
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0009629629629629629,
      "loss": 0.7966,
      "step": 200
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0009611111111111112,
      "loss": 0.7143,
      "step": 210
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0009592592592592593,
      "loss": 0.7175,
      "step": 220
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0009574074074074074,
      "loss": 0.7365,
      "step": 230
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0009555555555555556,
      "loss": 0.6986,
      "step": 240
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0009537037037037038,
      "loss": 0.6962,
      "step": 250
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0009518518518518518,
      "loss": 0.7406,
      "step": 260
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00095,
      "loss": 0.763,
      "step": 270
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0009481481481481482,
      "loss": 0.7395,
      "step": 280
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0009462962962962963,
      "loss": 0.7187,
      "step": 290
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0009444444444444445,
      "loss": 0.7103,
      "step": 300
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0009425925925925925,
      "loss": 0.7371,
      "step": 310
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0009407407407407408,
      "loss": 0.6919,
      "step": 320
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.000938888888888889,
      "loss": 0.7209,
      "step": 330
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.000937037037037037,
      "loss": 0.743,
      "step": 340
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0009351851851851853,
      "loss": 0.6923,
      "step": 350
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0009333333333333333,
      "loss": 0.7494,
      "step": 360
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009314814814814815,
      "loss": 0.6967,
      "step": 370
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009296296296296296,
      "loss": 0.7136,
      "step": 380
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0009277777777777778,
      "loss": 0.7065,
      "step": 390
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000925925925925926,
      "loss": 0.696,
      "step": 400
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0009240740740740741,
      "loss": 0.7208,
      "step": 410
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0009222222222222223,
      "loss": 0.6639,
      "step": 420
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0009203703703703704,
      "loss": 0.694,
      "step": 430
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0009185185185185185,
      "loss": 0.6919,
      "step": 440
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0009166666666666666,
      "loss": 0.7325,
      "step": 450
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0009148148148148149,
      "loss": 0.6366,
      "step": 460
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000912962962962963,
      "loss": 0.7238,
      "step": 470
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0009111111111111111,
      "loss": 0.6815,
      "step": 480
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0009092592592592592,
      "loss": 0.6595,
      "step": 490
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0009074074074074074,
      "loss": 0.7445,
      "step": 500
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0009055555555555556,
      "loss": 0.7057,
      "step": 510
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0009037037037037037,
      "loss": 0.6726,
      "step": 520
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0009018518518518519,
      "loss": 0.699,
      "step": 530
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0009000000000000001,
      "loss": 0.6967,
      "step": 540
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0008981481481481481,
      "loss": 0.7226,
      "step": 550
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0008962962962962963,
      "loss": 0.683,
      "step": 560
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0008944444444444445,
      "loss": 0.6666,
      "step": 570
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0008925925925925926,
      "loss": 0.7161,
      "step": 580
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0008907407407407408,
      "loss": 0.7053,
      "step": 590
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0008888888888888888,
      "loss": 0.682,
      "step": 600
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0008870370370370371,
      "loss": 0.6767,
      "step": 610
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0008851851851851853,
      "loss": 0.6866,
      "step": 620
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0008833333333333333,
      "loss": 0.6758,
      "step": 630
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0008814814814814816,
      "loss": 0.6898,
      "step": 640
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0008796296296296296,
      "loss": 0.7167,
      "step": 650
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008777777777777778,
      "loss": 0.736,
      "step": 660
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008759259259259259,
      "loss": 0.6939,
      "step": 670
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008740740740740741,
      "loss": 0.7046,
      "step": 680
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008722222222222223,
      "loss": 0.7361,
      "step": 690
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008703703703703704,
      "loss": 0.7424,
      "step": 700
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008685185185185185,
      "loss": 0.6945,
      "step": 710
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008666666666666667,
      "loss": 0.667,
      "step": 720
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008648148148148148,
      "loss": 0.6878,
      "step": 730
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008629629629629629,
      "loss": 0.6721,
      "step": 740
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0008611111111111112,
      "loss": 0.6478,
      "step": 750
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0008592592592592593,
      "loss": 0.6527,
      "step": 760
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008574074074074074,
      "loss": 0.7062,
      "step": 770
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008555555555555556,
      "loss": 0.6748,
      "step": 780
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008537037037037037,
      "loss": 0.7433,
      "step": 790
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008518518518518519,
      "loss": 0.6676,
      "step": 800
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00085,
      "loss": 0.6992,
      "step": 810
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0008481481481481481,
      "loss": 0.6513,
      "step": 820
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0008462962962962964,
      "loss": 0.6416,
      "step": 830
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0008444444444444444,
      "loss": 0.634,
      "step": 840
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0008425925925925926,
      "loss": 0.7039,
      "step": 850
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0008407407407407409,
      "loss": 0.6376,
      "step": 860
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0008388888888888889,
      "loss": 0.6927,
      "step": 870
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0008370370370370371,
      "loss": 0.7079,
      "step": 880
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0008351851851851851,
      "loss": 0.6767,
      "step": 890
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0008333333333333334,
      "loss": 0.7358,
      "step": 900
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0008314814814814815,
      "loss": 0.6205,
      "step": 910
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0008296296296296296,
      "loss": 0.6855,
      "step": 920
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0008277777777777778,
      "loss": 0.6546,
      "step": 930
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0008259259259259259,
      "loss": 0.7237,
      "step": 940
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0008240740740740741,
      "loss": 0.7119,
      "step": 950
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0008222222222222222,
      "loss": 0.6373,
      "step": 960
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0008203703703703704,
      "loss": 0.6793,
      "step": 970
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0008185185185185186,
      "loss": 0.6843,
      "step": 980
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0008166666666666667,
      "loss": 0.7154,
      "step": 990
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0008148148148148148,
      "loss": 0.7055,
      "step": 1000
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000812962962962963,
      "loss": 0.6612,
      "step": 1010
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0008111111111111111,
      "loss": 0.6386,
      "step": 1020
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0008092592592592592,
      "loss": 0.6724,
      "step": 1030
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0008074074074074075,
      "loss": 0.6909,
      "step": 1040
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0008055555555555556,
      "loss": 0.6954,
      "step": 1050
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0008037037037037037,
      "loss": 0.6985,
      "step": 1060
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0008018518518518519,
      "loss": 0.6814,
      "step": 1070
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0008,
      "loss": 0.6704,
      "step": 1080
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0007981481481481482,
      "loss": 0.6662,
      "step": 1090
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0007962962962962962,
      "loss": 0.7573,
      "step": 1100
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0007944444444444444,
      "loss": 0.6279,
      "step": 1110
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0007925925925925927,
      "loss": 0.669,
      "step": 1120
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0007907407407407407,
      "loss": 0.6626,
      "step": 1130
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0007888888888888889,
      "loss": 0.6477,
      "step": 1140
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0007870370370370372,
      "loss": 0.6789,
      "step": 1150
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0007851851851851852,
      "loss": 0.6214,
      "step": 1160
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0007833333333333334,
      "loss": 0.7112,
      "step": 1170
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0007814814814814814,
      "loss": 0.6498,
      "step": 1180
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0007796296296296297,
      "loss": 0.6623,
      "step": 1190
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0007777777777777778,
      "loss": 0.6626,
      "step": 1200
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0007759259259259259,
      "loss": 0.6679,
      "step": 1210
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.000774074074074074,
      "loss": 0.6626,
      "step": 1220
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0007722222222222223,
      "loss": 0.6709,
      "step": 1230
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0007703703703703704,
      "loss": 0.6409,
      "step": 1240
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0007685185185185185,
      "loss": 0.6665,
      "step": 1250
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0007666666666666667,
      "loss": 0.6417,
      "step": 1260
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0007648148148148148,
      "loss": 0.6608,
      "step": 1270
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.000762962962962963,
      "loss": 0.6979,
      "step": 1280
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0007611111111111111,
      "loss": 0.6366,
      "step": 1290
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0007592592592592593,
      "loss": 0.6612,
      "step": 1300
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0007574074074074075,
      "loss": 0.6593,
      "step": 1310
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0007555555555555555,
      "loss": 0.6359,
      "step": 1320
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0007537037037037037,
      "loss": 0.6735,
      "step": 1330
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0007518518518518519,
      "loss": 0.6659,
      "step": 1340
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00075,
      "loss": 0.7089,
      "step": 1350
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0007481481481481482,
      "loss": 0.6828,
      "step": 1360
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0007462962962962963,
      "loss": 0.6223,
      "step": 1370
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0007444444444444445,
      "loss": 0.6868,
      "step": 1380
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0007425925925925925,
      "loss": 0.718,
      "step": 1390
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0007407407407407407,
      "loss": 0.6597,
      "step": 1400
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.000738888888888889,
      "loss": 0.6554,
      "step": 1410
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.000737037037037037,
      "loss": 0.6494,
      "step": 1420
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0007351851851851852,
      "loss": 0.6238,
      "step": 1430
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0007333333333333333,
      "loss": 0.637,
      "step": 1440
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0007314814814814815,
      "loss": 0.6447,
      "step": 1450
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0007296296296296297,
      "loss": 0.5745,
      "step": 1460
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0007277777777777777,
      "loss": 0.6607,
      "step": 1470
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.000725925925925926,
      "loss": 0.6621,
      "step": 1480
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0007240740740740741,
      "loss": 0.6764,
      "step": 1490
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0007222222222222222,
      "loss": 0.6727,
      "step": 1500
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0007203703703703703,
      "loss": 0.5947,
      "step": 1510
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0007185185185185186,
      "loss": 0.5874,
      "step": 1520
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0007166666666666667,
      "loss": 0.6732,
      "step": 1530
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0007148148148148148,
      "loss": 0.6101,
      "step": 1540
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0007129629629629629,
      "loss": 0.6282,
      "step": 1550
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0007111111111111111,
      "loss": 0.6088,
      "step": 1560
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0007092592592592593,
      "loss": 0.6401,
      "step": 1570
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0007074074074074074,
      "loss": 0.6426,
      "step": 1580
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0007055555555555556,
      "loss": 0.6813,
      "step": 1590
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0007037037037037038,
      "loss": 0.6289,
      "step": 1600
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0007018518518518518,
      "loss": 0.6661,
      "step": 1610
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0007,
      "loss": 0.5802,
      "step": 1620
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0006981481481481482,
      "loss": 0.6032,
      "step": 1630
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0006962962962962963,
      "loss": 0.6339,
      "step": 1640
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0006944444444444445,
      "loss": 0.6288,
      "step": 1650
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0006925925925925925,
      "loss": 0.6413,
      "step": 1660
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0006907407407407408,
      "loss": 0.6402,
      "step": 1670
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.000688888888888889,
      "loss": 0.6293,
      "step": 1680
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.000687037037037037,
      "loss": 0.6349,
      "step": 1690
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0006851851851851853,
      "loss": 0.6357,
      "step": 1700
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0006833333333333333,
      "loss": 0.6134,
      "step": 1710
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0006814814814814815,
      "loss": 0.661,
      "step": 1720
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0006796296296296296,
      "loss": 0.6377,
      "step": 1730
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0006777777777777778,
      "loss": 0.6303,
      "step": 1740
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.000675925925925926,
      "loss": 0.6242,
      "step": 1750
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0006740740740740741,
      "loss": 0.6447,
      "step": 1760
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0006722222222222223,
      "loss": 0.6125,
      "step": 1770
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0006703703703703704,
      "loss": 0.6557,
      "step": 1780
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0006685185185185185,
      "loss": 0.5889,
      "step": 1790
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0006666666666666666,
      "loss": 0.6292,
      "step": 1800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6183516979217529,
      "eval_runtime": 66.1769,
      "eval_samples_per_second": 27.2,
      "eval_steps_per_second": 6.8,
      "step": 1800
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0006648148148148149,
      "loss": 0.6074,
      "step": 1810
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.000662962962962963,
      "loss": 0.6194,
      "step": 1820
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0006611111111111111,
      "loss": 0.6007,
      "step": 1830
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0006592592592592592,
      "loss": 0.5595,
      "step": 1840
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0006574074074074074,
      "loss": 0.62,
      "step": 1850
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0006555555555555556,
      "loss": 0.6479,
      "step": 1860
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0006537037037037037,
      "loss": 0.6282,
      "step": 1870
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0006518518518518519,
      "loss": 0.5909,
      "step": 1880
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.5635,
      "step": 1890
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0006481481481481481,
      "loss": 0.6216,
      "step": 1900
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0006462962962962963,
      "loss": 0.6636,
      "step": 1910
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0006444444444444444,
      "loss": 0.6037,
      "step": 1920
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0006425925925925926,
      "loss": 0.6553,
      "step": 1930
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0006407407407407408,
      "loss": 0.6095,
      "step": 1940
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0006388888888888888,
      "loss": 0.5996,
      "step": 1950
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0006370370370370371,
      "loss": 0.6476,
      "step": 1960
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0006351851851851852,
      "loss": 0.6219,
      "step": 1970
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0006333333333333333,
      "loss": 0.5825,
      "step": 1980
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0006314814814814816,
      "loss": 0.594,
      "step": 1990
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0006296296296296296,
      "loss": 0.6315,
      "step": 2000
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0006277777777777778,
      "loss": 0.6397,
      "step": 2010
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0006259259259259259,
      "loss": 0.6194,
      "step": 2020
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0006240740740740741,
      "loss": 0.6274,
      "step": 2030
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0006222222222222223,
      "loss": 0.6523,
      "step": 2040
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0006203703703703704,
      "loss": 0.6299,
      "step": 2050
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0006185185185185185,
      "loss": 0.6398,
      "step": 2060
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0006166666666666667,
      "loss": 0.6408,
      "step": 2070
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0006148148148148148,
      "loss": 0.5892,
      "step": 2080
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0006129629629629629,
      "loss": 0.5896,
      "step": 2090
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0006111111111111112,
      "loss": 0.6122,
      "step": 2100
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0006092592592592593,
      "loss": 0.6609,
      "step": 2110
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0006074074074074074,
      "loss": 0.6283,
      "step": 2120
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0006055555555555556,
      "loss": 0.6353,
      "step": 2130
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0006037037037037037,
      "loss": 0.6976,
      "step": 2140
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0006018518518518519,
      "loss": 0.6359,
      "step": 2150
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0006,
      "loss": 0.6271,
      "step": 2160
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0005981481481481481,
      "loss": 0.6364,
      "step": 2170
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0005962962962962964,
      "loss": 0.6484,
      "step": 2180
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0005944444444444444,
      "loss": 0.5867,
      "step": 2190
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0005925925925925926,
      "loss": 0.6136,
      "step": 2200
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0005907407407407409,
      "loss": 0.6595,
      "step": 2210
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0005888888888888889,
      "loss": 0.582,
      "step": 2220
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0005870370370370371,
      "loss": 0.6124,
      "step": 2230
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0005851851851851851,
      "loss": 0.6006,
      "step": 2240
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0005833333333333334,
      "loss": 0.6156,
      "step": 2250
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0005814814814814815,
      "loss": 0.5657,
      "step": 2260
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0005796296296296296,
      "loss": 0.6289,
      "step": 2270
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0005777777777777778,
      "loss": 0.5843,
      "step": 2280
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0005759259259259259,
      "loss": 0.6484,
      "step": 2290
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005740740740740741,
      "loss": 0.6166,
      "step": 2300
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0005722222222222222,
      "loss": 0.6644,
      "step": 2310
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005703703703703704,
      "loss": 0.6036,
      "step": 2320
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0005685185185185185,
      "loss": 0.6334,
      "step": 2330
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0005666666666666667,
      "loss": 0.6821,
      "step": 2340
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0005648148148148148,
      "loss": 0.5893,
      "step": 2350
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000562962962962963,
      "loss": 0.6374,
      "step": 2360
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005611111111111111,
      "loss": 0.6528,
      "step": 2370
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005592592592592592,
      "loss": 0.631,
      "step": 2380
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005574074074074075,
      "loss": 0.5974,
      "step": 2390
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0005555555555555556,
      "loss": 0.5854,
      "step": 2400
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005537037037037037,
      "loss": 0.5925,
      "step": 2410
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0005518518518518519,
      "loss": 0.6168,
      "step": 2420
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00055,
      "loss": 0.587,
      "step": 2430
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0005481481481481482,
      "loss": 0.6432,
      "step": 2440
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0005462962962962962,
      "loss": 0.5992,
      "step": 2450
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0005444444444444444,
      "loss": 0.6131,
      "step": 2460
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0005425925925925927,
      "loss": 0.6449,
      "step": 2470
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0005407407407407407,
      "loss": 0.6266,
      "step": 2480
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0005388888888888889,
      "loss": 0.6389,
      "step": 2490
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0005370370370370371,
      "loss": 0.6192,
      "step": 2500
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0005351851851851852,
      "loss": 0.6052,
      "step": 2510
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0005333333333333334,
      "loss": 0.6313,
      "step": 2520
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0005314814814814814,
      "loss": 0.6029,
      "step": 2530
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0005296296296296297,
      "loss": 0.6176,
      "step": 2540
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0005277777777777778,
      "loss": 0.5963,
      "step": 2550
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0005259259259259259,
      "loss": 0.6166,
      "step": 2560
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000524074074074074,
      "loss": 0.6527,
      "step": 2570
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0005222222222222223,
      "loss": 0.5991,
      "step": 2580
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0005203703703703704,
      "loss": 0.5828,
      "step": 2590
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0005185185185185185,
      "loss": 0.6062,
      "step": 2600
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0005166666666666667,
      "loss": 0.5739,
      "step": 2610
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0005148148148148148,
      "loss": 0.6472,
      "step": 2620
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000512962962962963,
      "loss": 0.5786,
      "step": 2630
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0005111111111111111,
      "loss": 0.6311,
      "step": 2640
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0005092592592592593,
      "loss": 0.6222,
      "step": 2650
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0005074074074074075,
      "loss": 0.6137,
      "step": 2660
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0005055555555555555,
      "loss": 0.5961,
      "step": 2670
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0005037037037037037,
      "loss": 0.6042,
      "step": 2680
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0005018518518518519,
      "loss": 0.687,
      "step": 2690
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0005,
      "loss": 0.5918,
      "step": 2700
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0004981481481481482,
      "loss": 0.5721,
      "step": 2710
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0004962962962962963,
      "loss": 0.5849,
      "step": 2720
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0004944444444444445,
      "loss": 0.5819,
      "step": 2730
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0004925925925925925,
      "loss": 0.5872,
      "step": 2740
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0004907407407407408,
      "loss": 0.6055,
      "step": 2750
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0004888888888888889,
      "loss": 0.5858,
      "step": 2760
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00048703703703703707,
      "loss": 0.5921,
      "step": 2770
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0004851851851851852,
      "loss": 0.5824,
      "step": 2780
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00048333333333333334,
      "loss": 0.5848,
      "step": 2790
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00048148148148148144,
      "loss": 0.5877,
      "step": 2800
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00047962962962962965,
      "loss": 0.6364,
      "step": 2810
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0004777777777777778,
      "loss": 0.5448,
      "step": 2820
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0004759259259259259,
      "loss": 0.5469,
      "step": 2830
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0004740740740740741,
      "loss": 0.6263,
      "step": 2840
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00047222222222222224,
      "loss": 0.5713,
      "step": 2850
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0004703703703703704,
      "loss": 0.5761,
      "step": 2860
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0004685185185185185,
      "loss": 0.5828,
      "step": 2870
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00046666666666666666,
      "loss": 0.6688,
      "step": 2880
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0004648148148148148,
      "loss": 0.5212,
      "step": 2890
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.000462962962962963,
      "loss": 0.621,
      "step": 2900
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00046111111111111114,
      "loss": 0.6299,
      "step": 2910
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00045925925925925925,
      "loss": 0.6235,
      "step": 2920
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00045740740740740746,
      "loss": 0.598,
      "step": 2930
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00045555555555555556,
      "loss": 0.6287,
      "step": 2940
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0004537037037037037,
      "loss": 0.5761,
      "step": 2950
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00045185185185185183,
      "loss": 0.6053,
      "step": 2960
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.6011,
      "step": 2970
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00044814814814814815,
      "loss": 0.6245,
      "step": 2980
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0004462962962962963,
      "loss": 0.6179,
      "step": 2990
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0004444444444444444,
      "loss": 0.5783,
      "step": 3000
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0004425925925925926,
      "loss": 0.6439,
      "step": 3010
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0004407407407407408,
      "loss": 0.6401,
      "step": 3020
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0004388888888888889,
      "loss": 0.6148,
      "step": 3030
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00043703703703703705,
      "loss": 0.5553,
      "step": 3040
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0004351851851851852,
      "loss": 0.5755,
      "step": 3050
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00043333333333333337,
      "loss": 0.6449,
      "step": 3060
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00043148148148148147,
      "loss": 0.5754,
      "step": 3070
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00042962962962962963,
      "loss": 0.6304,
      "step": 3080
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0004277777777777778,
      "loss": 0.6301,
      "step": 3090
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00042592592592592595,
      "loss": 0.6914,
      "step": 3100
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00042407407407407406,
      "loss": 0.6061,
      "step": 3110
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0004222222222222222,
      "loss": 0.6014,
      "step": 3120
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00042037037037037043,
      "loss": 0.6201,
      "step": 3130
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00041851851851851853,
      "loss": 0.6114,
      "step": 3140
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0004166666666666667,
      "loss": 0.5963,
      "step": 3150
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0004148148148148148,
      "loss": 0.5698,
      "step": 3160
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00041296296296296296,
      "loss": 0.5949,
      "step": 3170
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0004111111111111111,
      "loss": 0.6285,
      "step": 3180
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0004092592592592593,
      "loss": 0.687,
      "step": 3190
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0004074074074074074,
      "loss": 0.6336,
      "step": 3200
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00040555555555555554,
      "loss": 0.6077,
      "step": 3210
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00040370370370370375,
      "loss": 0.6057,
      "step": 3220
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00040185185185185186,
      "loss": 0.6288,
      "step": 3230
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0004,
      "loss": 0.5987,
      "step": 3240
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0003981481481481481,
      "loss": 0.6201,
      "step": 3250
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00039629629629629634,
      "loss": 0.6285,
      "step": 3260
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00039444444444444444,
      "loss": 0.6201,
      "step": 3270
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0003925925925925926,
      "loss": 0.603,
      "step": 3280
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0003907407407407407,
      "loss": 0.5878,
      "step": 3290
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0003888888888888889,
      "loss": 0.6081,
      "step": 3300
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.000387037037037037,
      "loss": 0.6416,
      "step": 3310
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0003851851851851852,
      "loss": 0.5975,
      "step": 3320
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00038333333333333334,
      "loss": 0.5672,
      "step": 3330
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0003814814814814815,
      "loss": 0.6075,
      "step": 3340
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00037962962962962966,
      "loss": 0.6135,
      "step": 3350
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00037777777777777777,
      "loss": 0.5739,
      "step": 3360
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00037592592592592593,
      "loss": 0.6001,
      "step": 3370
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0003740740740740741,
      "loss": 0.6102,
      "step": 3380
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00037222222222222225,
      "loss": 0.6079,
      "step": 3390
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00037037037037037035,
      "loss": 0.5978,
      "step": 3400
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0003685185185185185,
      "loss": 0.5985,
      "step": 3410
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00036666666666666667,
      "loss": 0.6138,
      "step": 3420
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00036481481481481483,
      "loss": 0.6336,
      "step": 3430
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.000362962962962963,
      "loss": 0.6514,
      "step": 3440
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0003611111111111111,
      "loss": 0.5532,
      "step": 3450
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0003592592592592593,
      "loss": 0.5689,
      "step": 3460
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0003574074074074074,
      "loss": 0.5725,
      "step": 3470
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00035555555555555557,
      "loss": 0.6632,
      "step": 3480
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0003537037037037037,
      "loss": 0.6336,
      "step": 3490
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0003518518518518519,
      "loss": 0.6038,
      "step": 3500
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00035,
      "loss": 0.6528,
      "step": 3510
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00034814814814814816,
      "loss": 0.6047,
      "step": 3520
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00034629629629629626,
      "loss": 0.6355,
      "step": 3530
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0003444444444444445,
      "loss": 0.6238,
      "step": 3540
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00034259259259259263,
      "loss": 0.6228,
      "step": 3550
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00034074074074074074,
      "loss": 0.5831,
      "step": 3560
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0003388888888888889,
      "loss": 0.6476,
      "step": 3570
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00033703703703703706,
      "loss": 0.6343,
      "step": 3580
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0003351851851851852,
      "loss": 0.5921,
      "step": 3590
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.6495,
      "step": 3600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.6063854098320007,
      "eval_runtime": 66.286,
      "eval_samples_per_second": 27.155,
      "eval_steps_per_second": 6.789,
      "step": 3600
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0003314814814814815,
      "loss": 0.598,
      "step": 3610
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0003296296296296296,
      "loss": 0.6037,
      "step": 3620
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0003277777777777778,
      "loss": 0.598,
      "step": 3630
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00032592592592592596,
      "loss": 0.5681,
      "step": 3640
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00032407407407407406,
      "loss": 0.5937,
      "step": 3650
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0003222222222222222,
      "loss": 0.5834,
      "step": 3660
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0003203703703703704,
      "loss": 0.6071,
      "step": 3670
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00031851851851851854,
      "loss": 0.6199,
      "step": 3680
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00031666666666666665,
      "loss": 0.5424,
      "step": 3690
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0003148148148148148,
      "loss": 0.6107,
      "step": 3700
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00031296296296296297,
      "loss": 0.6313,
      "step": 3710
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0003111111111111111,
      "loss": 0.564,
      "step": 3720
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00030925925925925923,
      "loss": 0.6032,
      "step": 3730
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0003074074074074074,
      "loss": 0.6387,
      "step": 3740
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0003055555555555556,
      "loss": 0.5697,
      "step": 3750
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0003037037037037037,
      "loss": 0.5512,
      "step": 3760
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00030185185185185187,
      "loss": 0.6097,
      "step": 3770
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0003,
      "loss": 0.5805,
      "step": 3780
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0002981481481481482,
      "loss": 0.5891,
      "step": 3790
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0002962962962962963,
      "loss": 0.616,
      "step": 3800
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00029444444444444445,
      "loss": 0.583,
      "step": 3810
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00029259259259259256,
      "loss": 0.6202,
      "step": 3820
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00029074074074074077,
      "loss": 0.5959,
      "step": 3830
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0002888888888888889,
      "loss": 0.5836,
      "step": 3840
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00028703703703703703,
      "loss": 0.5693,
      "step": 3850
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0002851851851851852,
      "loss": 0.6519,
      "step": 3860
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00028333333333333335,
      "loss": 0.6297,
      "step": 3870
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0002814814814814815,
      "loss": 0.5976,
      "step": 3880
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0002796296296296296,
      "loss": 0.6041,
      "step": 3890
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0002777777777777778,
      "loss": 0.6059,
      "step": 3900
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.00027592592592592594,
      "loss": 0.6042,
      "step": 3910
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0002740740740740741,
      "loss": 0.6437,
      "step": 3920
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0002722222222222222,
      "loss": 0.6092,
      "step": 3930
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00027037037037037036,
      "loss": 0.579,
      "step": 3940
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0002685185185185186,
      "loss": 0.6208,
      "step": 3950
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0002666666666666667,
      "loss": 0.5911,
      "step": 3960
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00026481481481481484,
      "loss": 0.6487,
      "step": 3970
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00026296296296296294,
      "loss": 0.5757,
      "step": 3980
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00026111111111111116,
      "loss": 0.6105,
      "step": 3990
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00025925925925925926,
      "loss": 0.6074,
      "step": 4000
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0002574074074074074,
      "loss": 0.5451,
      "step": 4010
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00025555555555555553,
      "loss": 0.6475,
      "step": 4020
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00025370370370370374,
      "loss": 0.5955,
      "step": 4030
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00025185185185185185,
      "loss": 0.5873,
      "step": 4040
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00025,
      "loss": 0.5848,
      "step": 4050
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00024814814814814816,
      "loss": 0.5929,
      "step": 4060
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00024629629629629627,
      "loss": 0.5756,
      "step": 4070
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00024444444444444443,
      "loss": 0.6095,
      "step": 4080
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0002425925925925926,
      "loss": 0.6167,
      "step": 4090
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00024074074074074072,
      "loss": 0.5389,
      "step": 4100
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0002388888888888889,
      "loss": 0.6148,
      "step": 4110
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00023703703703703704,
      "loss": 0.5923,
      "step": 4120
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0002351851851851852,
      "loss": 0.6087,
      "step": 4130
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00023333333333333333,
      "loss": 0.5828,
      "step": 4140
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0002314814814814815,
      "loss": 0.6347,
      "step": 4150
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00022962962962962962,
      "loss": 0.6397,
      "step": 4160
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00022777777777777778,
      "loss": 0.5985,
      "step": 4170
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00022592592592592591,
      "loss": 0.5829,
      "step": 4180
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00022407407407407407,
      "loss": 0.6196,
      "step": 4190
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0002222222222222222,
      "loss": 0.5937,
      "step": 4200
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0002203703703703704,
      "loss": 0.6749,
      "step": 4210
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00021851851851851852,
      "loss": 0.5994,
      "step": 4220
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00021666666666666668,
      "loss": 0.5673,
      "step": 4230
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00021481481481481482,
      "loss": 0.5746,
      "step": 4240
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00021296296296296298,
      "loss": 0.5972,
      "step": 4250
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0002111111111111111,
      "loss": 0.5757,
      "step": 4260
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00020925925925925927,
      "loss": 0.6448,
      "step": 4270
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0002074074074074074,
      "loss": 0.5661,
      "step": 4280
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00020555555555555556,
      "loss": 0.5823,
      "step": 4290
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0002037037037037037,
      "loss": 0.5723,
      "step": 4300
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00020185185185185188,
      "loss": 0.6012,
      "step": 4310
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0002,
      "loss": 0.6062,
      "step": 4320
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.00019814814814814817,
      "loss": 0.5823,
      "step": 4330
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0001962962962962963,
      "loss": 0.609,
      "step": 4340
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00019444444444444446,
      "loss": 0.596,
      "step": 4350
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0001925925925925926,
      "loss": 0.5751,
      "step": 4360
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00019074074074074075,
      "loss": 0.5805,
      "step": 4370
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00018888888888888888,
      "loss": 0.5571,
      "step": 4380
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00018703703703703704,
      "loss": 0.5986,
      "step": 4390
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00018518518518518518,
      "loss": 0.5928,
      "step": 4400
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.5916,
      "step": 4410
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0001814814814814815,
      "loss": 0.5731,
      "step": 4420
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00017962962962962965,
      "loss": 0.5929,
      "step": 4430
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00017777777777777779,
      "loss": 0.5511,
      "step": 4440
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.00017592592592592595,
      "loss": 0.5586,
      "step": 4450
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00017407407407407408,
      "loss": 0.6051,
      "step": 4460
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00017222222222222224,
      "loss": 0.5738,
      "step": 4470
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00017037037037037037,
      "loss": 0.596,
      "step": 4480
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00016851851851851853,
      "loss": 0.5862,
      "step": 4490
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.00016666666666666666,
      "loss": 0.5816,
      "step": 4500
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0001648148148148148,
      "loss": 0.6065,
      "step": 4510
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00016296296296296298,
      "loss": 0.6015,
      "step": 4520
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0001611111111111111,
      "loss": 0.6253,
      "step": 4530
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00015925925925925927,
      "loss": 0.5488,
      "step": 4540
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0001574074074074074,
      "loss": 0.5965,
      "step": 4550
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00015555555555555556,
      "loss": 0.5916,
      "step": 4560
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0001537037037037037,
      "loss": 0.6008,
      "step": 4570
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00015185185185185185,
      "loss": 0.649,
      "step": 4580
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00015,
      "loss": 0.5644,
      "step": 4590
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00014814814814814815,
      "loss": 0.6235,
      "step": 4600
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00014629629629629628,
      "loss": 0.6468,
      "step": 4610
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00014444444444444444,
      "loss": 0.6298,
      "step": 4620
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0001425925925925926,
      "loss": 0.6352,
      "step": 4630
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00014074074074074076,
      "loss": 0.6001,
      "step": 4640
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0001388888888888889,
      "loss": 0.6344,
      "step": 4650
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00013703703703703705,
      "loss": 0.6067,
      "step": 4660
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00013518518518518518,
      "loss": 0.5978,
      "step": 4670
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.6111,
      "step": 4680
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00013148148148148147,
      "loss": 0.6212,
      "step": 4690
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00012962962962962963,
      "loss": 0.5693,
      "step": 4700
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00012777777777777776,
      "loss": 0.5706,
      "step": 4710
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00012592592592592592,
      "loss": 0.5998,
      "step": 4720
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00012407407407407408,
      "loss": 0.5849,
      "step": 4730
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00012222222222222221,
      "loss": 0.6074,
      "step": 4740
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00012037037037037036,
      "loss": 0.623,
      "step": 4750
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00011851851851851852,
      "loss": 0.5446,
      "step": 4760
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00011666666666666667,
      "loss": 0.6084,
      "step": 4770
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00011481481481481481,
      "loss": 0.5696,
      "step": 4780
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00011296296296296296,
      "loss": 0.6074,
      "step": 4790
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0001111111111111111,
      "loss": 0.6092,
      "step": 4800
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00010925925925925926,
      "loss": 0.5508,
      "step": 4810
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00010740740740740741,
      "loss": 0.5982,
      "step": 4820
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00010555555555555555,
      "loss": 0.6532,
      "step": 4830
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0001037037037037037,
      "loss": 0.5968,
      "step": 4840
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00010185185185185185,
      "loss": 0.6225,
      "step": 4850
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0001,
      "loss": 0.6383,
      "step": 4860
    },
    {
      "epoch": 2.71,
      "learning_rate": 9.814814814814815e-05,
      "loss": 0.6056,
      "step": 4870
    },
    {
      "epoch": 2.71,
      "learning_rate": 9.62962962962963e-05,
      "loss": 0.5821,
      "step": 4880
    },
    {
      "epoch": 2.72,
      "learning_rate": 9.444444444444444e-05,
      "loss": 0.6474,
      "step": 4890
    },
    {
      "epoch": 2.72,
      "learning_rate": 9.259259259259259e-05,
      "loss": 0.5868,
      "step": 4900
    },
    {
      "epoch": 2.73,
      "learning_rate": 9.074074074074075e-05,
      "loss": 0.5717,
      "step": 4910
    },
    {
      "epoch": 2.73,
      "learning_rate": 8.888888888888889e-05,
      "loss": 0.6345,
      "step": 4920
    },
    {
      "epoch": 2.74,
      "learning_rate": 8.703703703703704e-05,
      "loss": 0.5773,
      "step": 4930
    },
    {
      "epoch": 2.74,
      "learning_rate": 8.518518518518518e-05,
      "loss": 0.5828,
      "step": 4940
    },
    {
      "epoch": 2.75,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.6031,
      "step": 4950
    },
    {
      "epoch": 2.76,
      "learning_rate": 8.148148148148149e-05,
      "loss": 0.6036,
      "step": 4960
    },
    {
      "epoch": 2.76,
      "learning_rate": 7.962962962962964e-05,
      "loss": 0.6086,
      "step": 4970
    },
    {
      "epoch": 2.77,
      "learning_rate": 7.777777777777778e-05,
      "loss": 0.6137,
      "step": 4980
    },
    {
      "epoch": 2.77,
      "learning_rate": 7.592592592592593e-05,
      "loss": 0.5595,
      "step": 4990
    },
    {
      "epoch": 2.78,
      "learning_rate": 7.407407407407407e-05,
      "loss": 0.6347,
      "step": 5000
    },
    {
      "epoch": 2.78,
      "learning_rate": 7.222222222222222e-05,
      "loss": 0.6258,
      "step": 5010
    },
    {
      "epoch": 2.79,
      "learning_rate": 7.037037037037038e-05,
      "loss": 0.5627,
      "step": 5020
    },
    {
      "epoch": 2.79,
      "learning_rate": 6.851851851851852e-05,
      "loss": 0.6223,
      "step": 5030
    },
    {
      "epoch": 2.8,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.6263,
      "step": 5040
    },
    {
      "epoch": 2.81,
      "learning_rate": 6.481481481481482e-05,
      "loss": 0.5773,
      "step": 5050
    },
    {
      "epoch": 2.81,
      "learning_rate": 6.296296296296296e-05,
      "loss": 0.6487,
      "step": 5060
    },
    {
      "epoch": 2.82,
      "learning_rate": 6.111111111111111e-05,
      "loss": 0.6184,
      "step": 5070
    },
    {
      "epoch": 2.82,
      "learning_rate": 5.925925925925926e-05,
      "loss": 0.5614,
      "step": 5080
    },
    {
      "epoch": 2.83,
      "learning_rate": 5.7407407407407406e-05,
      "loss": 0.6065,
      "step": 5090
    },
    {
      "epoch": 2.83,
      "learning_rate": 5.555555555555555e-05,
      "loss": 0.5782,
      "step": 5100
    },
    {
      "epoch": 2.84,
      "learning_rate": 5.3703703703703704e-05,
      "loss": 0.5889,
      "step": 5110
    },
    {
      "epoch": 2.84,
      "learning_rate": 5.185185185185185e-05,
      "loss": 0.5657,
      "step": 5120
    },
    {
      "epoch": 2.85,
      "learning_rate": 5e-05,
      "loss": 0.6118,
      "step": 5130
    },
    {
      "epoch": 2.86,
      "learning_rate": 4.814814814814815e-05,
      "loss": 0.6447,
      "step": 5140
    },
    {
      "epoch": 2.86,
      "learning_rate": 4.6296296296296294e-05,
      "loss": 0.6342,
      "step": 5150
    },
    {
      "epoch": 2.87,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 0.6356,
      "step": 5160
    },
    {
      "epoch": 2.87,
      "learning_rate": 4.259259259259259e-05,
      "loss": 0.6083,
      "step": 5170
    },
    {
      "epoch": 2.88,
      "learning_rate": 4.0740740740740745e-05,
      "loss": 0.5933,
      "step": 5180
    },
    {
      "epoch": 2.88,
      "learning_rate": 3.888888888888889e-05,
      "loss": 0.6115,
      "step": 5190
    },
    {
      "epoch": 2.89,
      "learning_rate": 3.7037037037037037e-05,
      "loss": 0.6154,
      "step": 5200
    },
    {
      "epoch": 2.89,
      "learning_rate": 3.518518518518519e-05,
      "loss": 0.5876,
      "step": 5210
    },
    {
      "epoch": 2.9,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.5599,
      "step": 5220
    },
    {
      "epoch": 2.91,
      "learning_rate": 3.148148148148148e-05,
      "loss": 0.6059,
      "step": 5230
    },
    {
      "epoch": 2.91,
      "learning_rate": 2.962962962962963e-05,
      "loss": 0.5957,
      "step": 5240
    },
    {
      "epoch": 2.92,
      "learning_rate": 2.7777777777777776e-05,
      "loss": 0.5974,
      "step": 5250
    },
    {
      "epoch": 2.92,
      "learning_rate": 2.5925925925925925e-05,
      "loss": 0.5897,
      "step": 5260
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.4074074074074074e-05,
      "loss": 0.6252,
      "step": 5270
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 0.5563,
      "step": 5280
    },
    {
      "epoch": 2.94,
      "learning_rate": 2.0370370370370372e-05,
      "loss": 0.6034,
      "step": 5290
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.8518518518518518e-05,
      "loss": 0.6232,
      "step": 5300
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.5828,
      "step": 5310
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.4814814814814815e-05,
      "loss": 0.6032,
      "step": 5320
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.2962962962962962e-05,
      "loss": 0.6183,
      "step": 5330
    },
    {
      "epoch": 2.97,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 0.6245,
      "step": 5340
    },
    {
      "epoch": 2.97,
      "learning_rate": 9.259259259259259e-06,
      "loss": 0.5475,
      "step": 5350
    },
    {
      "epoch": 2.98,
      "learning_rate": 7.4074074074074075e-06,
      "loss": 0.5926,
      "step": 5360
    },
    {
      "epoch": 2.98,
      "learning_rate": 5.555555555555556e-06,
      "loss": 0.6434,
      "step": 5370
    },
    {
      "epoch": 2.99,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 0.6238,
      "step": 5380
    },
    {
      "epoch": 2.99,
      "learning_rate": 1.8518518518518519e-06,
      "loss": 0.5764,
      "step": 5390
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0,
      "loss": 0.572,
      "step": 5400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.600262463092804,
      "eval_runtime": 66.2453,
      "eval_samples_per_second": 27.172,
      "eval_steps_per_second": 6.793,
      "step": 5400
    }
  ],
  "logging_steps": 10,
  "max_steps": 5400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 2.9274738875900314e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
