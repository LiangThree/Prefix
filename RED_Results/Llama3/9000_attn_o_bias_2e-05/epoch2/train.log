Step 1: {'loss': 15.2473, 'learning_rate': 3.5087719298245616e-07, 'epoch': 0.0}
Step 2: {'loss': 14.5581, 'learning_rate': 7.017543859649123e-07, 'epoch': 0.01}
Step 3: {'loss': 14.7362, 'learning_rate': 1.0526315789473685e-06, 'epoch': 0.01}
Step 4: {'loss': 14.8616, 'learning_rate': 1.4035087719298246e-06, 'epoch': 0.01}
Step 5: {'loss': 14.5458, 'learning_rate': 1.7543859649122807e-06, 'epoch': 0.02}
Step 6: {'loss': 15.7755, 'learning_rate': 2.105263157894737e-06, 'epoch': 0.02}
Step 7: {'loss': 15.2655, 'learning_rate': 2.456140350877193e-06, 'epoch': 0.02}
Step 8: {'loss': 14.7359, 'learning_rate': 2.8070175438596493e-06, 'epoch': 0.03}
Step 9: {'loss': 14.0969, 'learning_rate': 3.157894736842105e-06, 'epoch': 0.03}
Step 10: {'loss': 14.4983, 'learning_rate': 3.5087719298245615e-06, 'epoch': 0.04}
Step 11: {'loss': 14.9153, 'learning_rate': 3.859649122807018e-06, 'epoch': 0.04}
Step 12: {'loss': 14.4595, 'learning_rate': 4.210526315789474e-06, 'epoch': 0.04}
Step 13: {'loss': 14.4963, 'learning_rate': 4.56140350877193e-06, 'epoch': 0.05}
Step 14: {'loss': 15.0064, 'learning_rate': 4.912280701754386e-06, 'epoch': 0.05}
Step 15: {'loss': 14.4514, 'learning_rate': 5.263157894736842e-06, 'epoch': 0.05}
Step 16: {'loss': 14.7364, 'learning_rate': 5.6140350877192985e-06, 'epoch': 0.06}
Step 17: {'loss': 13.9251, 'learning_rate': 5.964912280701755e-06, 'epoch': 0.06}
Step 18: {'loss': 14.3466, 'learning_rate': 6.31578947368421e-06, 'epoch': 0.06}
Step 19: {'loss': 15.5443, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.07}
Step 20: {'loss': 15.7424, 'learning_rate': 7.017543859649123e-06, 'epoch': 0.07}
Step 21: {'loss': 14.7654, 'learning_rate': 7.368421052631579e-06, 'epoch': 0.07}
Step 22: {'loss': 14.0845, 'learning_rate': 7.719298245614036e-06, 'epoch': 0.08}
Step 23: {'loss': 14.6309, 'learning_rate': 8.070175438596492e-06, 'epoch': 0.08}
Step 24: {'loss': 14.1496, 'learning_rate': 8.421052631578948e-06, 'epoch': 0.09}
Step 25: {'loss': 14.0061, 'learning_rate': 8.771929824561405e-06, 'epoch': 0.09}
Step 26: {'loss': 13.347, 'learning_rate': 9.12280701754386e-06, 'epoch': 0.09}
Step 27: {'loss': 14.5956, 'learning_rate': 9.473684210526315e-06, 'epoch': 0.1}
Step 28: {'loss': 13.5951, 'learning_rate': 9.824561403508772e-06, 'epoch': 0.1}
Step 29: {'loss': 14.0197, 'learning_rate': 1.017543859649123e-05, 'epoch': 0.1}
Step 30: {'loss': 12.6742, 'learning_rate': 1.0526315789473684e-05, 'epoch': 0.11}
Step 31: {'loss': 13.5474, 'learning_rate': 1.0877192982456142e-05, 'epoch': 0.11}
Step 32: {'loss': 14.1617, 'learning_rate': 1.1228070175438597e-05, 'epoch': 0.11}
Step 33: {'loss': 14.1049, 'learning_rate': 1.1578947368421053e-05, 'epoch': 0.12}
Step 34: {'loss': 13.4186, 'learning_rate': 1.192982456140351e-05, 'epoch': 0.12}
Step 35: {'loss': 12.6573, 'learning_rate': 1.2280701754385966e-05, 'epoch': 0.12}
Step 36: {'loss': 14.1824, 'learning_rate': 1.263157894736842e-05, 'epoch': 0.13}
Step 37: {'loss': 12.4738, 'learning_rate': 1.2982456140350879e-05, 'epoch': 0.13}
Step 38: {'loss': 13.5847, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.14}
Step 39: {'loss': 12.4618, 'learning_rate': 1.3684210526315791e-05, 'epoch': 0.14}
Step 40: {'loss': 12.8763, 'learning_rate': 1.4035087719298246e-05, 'epoch': 0.14}
Step 41: {'loss': 13.0997, 'learning_rate': 1.4385964912280704e-05, 'epoch': 0.15}
Step 42: {'loss': 12.5827, 'learning_rate': 1.4736842105263159e-05, 'epoch': 0.15}
Step 43: {'loss': 12.1933, 'learning_rate': 1.5087719298245615e-05, 'epoch': 0.15}
Step 44: {'loss': 12.6007, 'learning_rate': 1.543859649122807e-05, 'epoch': 0.16}
Step 45: {'loss': 12.2528, 'learning_rate': 1.578947368421053e-05, 'epoch': 0.16}
Step 46: {'loss': 11.8789, 'learning_rate': 1.6140350877192984e-05, 'epoch': 0.16}
Step 47: {'loss': 11.6213, 'learning_rate': 1.649122807017544e-05, 'epoch': 0.17}
Step 48: {'loss': 12.9288, 'learning_rate': 1.6842105263157896e-05, 'epoch': 0.17}
Step 49: {'loss': 11.802, 'learning_rate': 1.719298245614035e-05, 'epoch': 0.17}
Step 50: {'loss': 11.9676, 'learning_rate': 1.754385964912281e-05, 'epoch': 0.18}
Step 51: {'loss': 12.4871, 'learning_rate': 1.7894736842105264e-05, 'epoch': 0.18}
Step 52: {'loss': 11.541, 'learning_rate': 1.824561403508772e-05, 'epoch': 0.18}
Step 53: {'loss': 11.6032, 'learning_rate': 1.8596491228070176e-05, 'epoch': 0.19}
Step 54: {'loss': 11.528, 'learning_rate': 1.894736842105263e-05, 'epoch': 0.19}
Step 55: {'loss': 11.229, 'learning_rate': 1.929824561403509e-05, 'epoch': 0.2}
Step 56: {'loss': 11.8138, 'learning_rate': 1.9649122807017544e-05, 'epoch': 0.2}
Step 57: {'loss': 11.9331, 'learning_rate': 2e-05, 'epoch': 0.2}
Step 58: {'loss': 11.5496, 'learning_rate': 1.9999806497939984e-05, 'epoch': 0.21}
Step 59: {'loss': 11.3301, 'learning_rate': 1.999922599924854e-05, 'epoch': 0.21}
Step 60: {'loss': 11.596, 'learning_rate': 1.9998258526391207e-05, 'epoch': 0.21}
Step 61: {'loss': 11.8051, 'learning_rate': 1.9996904116809586e-05, 'epoch': 0.22}
Step 62: {'loss': 11.7175, 'learning_rate': 1.999516282291988e-05, 'epoch': 0.22}
Step 63: {'loss': 10.4267, 'learning_rate': 1.9993034712110888e-05, 'epoch': 0.22}
Step 64: {'loss': 10.5477, 'learning_rate': 1.999051986674137e-05, 'epoch': 0.23}
Step 65: {'loss': 11.1899, 'learning_rate': 1.998761838413688e-05, 'epoch': 0.23}
Step 66: {'loss': 10.8887, 'learning_rate': 1.998433037658599e-05, 'epoch': 0.23}
Step 67: {'loss': 10.3834, 'learning_rate': 1.9980655971335944e-05, 'epoch': 0.24}
Step 68: {'loss': 10.873, 'learning_rate': 1.997659531058774e-05, 'epoch': 0.24}
Step 69: {'loss': 10.5944, 'learning_rate': 1.997214855149063e-05, 'epoch': 0.25}
Step 70: {'loss': 10.5821, 'learning_rate': 1.996731586613601e-05, 'epoch': 0.25}
Step 71: {'loss': 10.2646, 'learning_rate': 1.9962097441550803e-05, 'epoch': 0.25}
Step 72: {'loss': 10.4924, 'learning_rate': 1.995649347969019e-05, 'epoch': 0.26}
Step 73: {'loss': 10.2137, 'learning_rate': 1.9950504197429796e-05, 'epoch': 0.26}
Step 74: {'loss': 10.0316, 'learning_rate': 1.9944129826557322e-05, 'epoch': 0.26}
Step 75: {'loss': 10.2059, 'learning_rate': 1.9937370613763544e-05, 'epoch': 0.27}
Step 76: {'loss': 9.6109, 'learning_rate': 1.993022682063278e-05, 'epoch': 0.27}
Step 77: {'loss': 10.0918, 'learning_rate': 1.992269872363277e-05, 'epoch': 0.27}
Step 78: {'loss': 10.3698, 'learning_rate': 1.991478661410396e-05, 'epoch': 0.28}
Step 79: {'loss': 9.9783, 'learning_rate': 1.9906490798248267e-05, 'epoch': 0.28}
Step 80: {'loss': 10.2461, 'learning_rate': 1.9897811597117168e-05, 'epoch': 0.28}
Step 81: {'loss': 9.7497, 'learning_rate': 1.988874934659932e-05, 'epoch': 0.29}
Step 82: {'loss': 9.4894, 'learning_rate': 1.987930439740757e-05, 'epoch': 0.29}
Step 83: {'loss': 9.7212, 'learning_rate': 1.9869477115065327e-05, 'epoch': 0.3}
Step 84: {'loss': 10.1034, 'learning_rate': 1.985926787989247e-05, 'epoch': 0.3}
Step 85: {'loss': 9.4122, 'learning_rate': 1.9848677086990605e-05, 'epoch': 0.3}
Step 86: {'loss': 9.4728, 'learning_rate': 1.9837705146227785e-05, 'epoch': 0.31}
Step 87: {'loss': 9.6274, 'learning_rate': 1.982635248222264e-05, 'epoch': 0.31}
Step 88: {'loss': 8.9713, 'learning_rate': 1.9814619534327936e-05, 'epoch': 0.31}
Step 89: {'loss': 9.3375, 'learning_rate': 1.98025067566136e-05, 'epoch': 0.32}
Step 90: {'loss': 9.0544, 'learning_rate': 1.979001461784911e-05, 'epoch': 0.32}
Step 91: {'loss': 9.0425, 'learning_rate': 1.977714360148539e-05, 'epoch': 0.32}
Step 92: {'loss': 8.7095, 'learning_rate': 1.976389420563607e-05, 'epoch': 0.33}
Step 93: {'loss': 8.8868, 'learning_rate': 1.975026694305824e-05, 'epoch': 0.33}
Step 94: {'loss': 9.1248, 'learning_rate': 1.9736262341132564e-05, 'epoch': 0.33}
Step 95: {'loss': 8.9304, 'learning_rate': 1.9721880941842914e-05, 'epoch': 0.34}
Step 96: {'loss': 8.6901, 'learning_rate': 1.970712330175536e-05, 'epoch': 0.34}
Step 97: {'loss': 9.0565, 'learning_rate': 1.9691989991996663e-05, 'epoch': 0.34}
Step 98: {'loss': 8.6893, 'learning_rate': 1.967648159823214e-05, 'epoch': 0.35}
Step 99: {'loss': 7.9544, 'learning_rate': 1.9660598720643018e-05, 'epoch': 0.35}
Step 100: {'loss': 8.2458, 'learning_rate': 1.964434197390321e-05, 'epoch': 0.36}
Step 101: {'loss': 8.6384, 'learning_rate': 1.9627711987155506e-05, 'epoch': 0.36}
Step 102: {'loss': 8.7198, 'learning_rate': 1.9610709403987248e-05, 'epoch': 0.36}
Step 103: {'loss': 8.1354, 'learning_rate': 1.959333488240541e-05, 'epoch': 0.37}
Step 104: {'loss': 7.8576, 'learning_rate': 1.9575589094811128e-05, 'epoch': 0.37}
Step 105: {'loss': 8.049, 'learning_rate': 1.955747272797371e-05, 'epoch': 0.37}
Step 106: {'loss': 8.4941, 'learning_rate': 1.9538986483004e-05, 'epoch': 0.38}
Step 107: {'loss': 8.341, 'learning_rate': 1.95201310753273e-05, 'epoch': 0.38}
Step 108: {'loss': 7.6731, 'learning_rate': 1.950090723465566e-05, 'epoch': 0.38}
Step 109: {'loss': 7.7285, 'learning_rate': 1.948131570495963e-05, 'epoch': 0.39}
Step 110: {'loss': 7.563, 'learning_rate': 1.946135724443948e-05, 'epoch': 0.39}
Step 111: {'loss': 7.8272, 'learning_rate': 1.944103262549586e-05, 'epoch': 0.39}
Step 112: {'loss': 7.6497, 'learning_rate': 1.9420342634699893e-05, 'epoch': 0.4}
Step 113: {'loss': 7.8768, 'learning_rate': 1.939928807276275e-05, 'epoch': 0.4}
Step 114: {'loss': 7.9688, 'learning_rate': 1.9377869754504645e-05, 'epoch': 0.41}
Step 115: {'loss': 7.7318, 'learning_rate': 1.935608850882333e-05, 'epoch': 0.41}
Step 116: {'loss': 7.2185, 'learning_rate': 1.933394517866198e-05, 'epoch': 0.41}
Step 117: {'loss': 7.3818, 'learning_rate': 1.9311440620976597e-05, 'epoch': 0.42}
Step 118: {'loss': 7.0822, 'learning_rate': 1.9288575706702836e-05, 'epoch': 0.42}
Step 119: {'loss': 7.4028, 'learning_rate': 1.9265351320722296e-05, 'epoch': 0.42}
Step 120: {'loss': 7.1244, 'learning_rate': 1.924176836182829e-05, 'epoch': 0.43}
Step 121: {'loss': 7.2366, 'learning_rate': 1.921782774269104e-05, 'epoch': 0.43}
Step 122: {'loss': 7.6054, 'learning_rate': 1.9193530389822364e-05, 'epoch': 0.43}
Step 123: {'loss': 7.2622, 'learning_rate': 1.916887724353984e-05, 'epoch': 0.44}
Step 124: {'loss': 7.4258, 'learning_rate': 1.914386925793038e-05, 'epoch': 0.44}
Step 125: {'loss': 7.1903, 'learning_rate': 1.9118507400813327e-05, 'epoch': 0.44}
Step 126: {'loss': 7.3545, 'learning_rate': 1.9092792653703006e-05, 'epoch': 0.45}
Step 127: {'loss': 6.9698, 'learning_rate': 1.9066726011770725e-05, 'epoch': 0.45}
Step 128: {'loss': 7.5255, 'learning_rate': 1.9040308483806266e-05, 'epoch': 0.46}
Step 129: {'loss': 6.9447, 'learning_rate': 1.9013541092178844e-05, 'epoch': 0.46}
Step 130: {'loss': 7.2021, 'learning_rate': 1.8986424872797542e-05, 'epoch': 0.46}
Step 131: {'loss': 7.5043, 'learning_rate': 1.8958960875071225e-05, 'epoch': 0.47}
Step 132: {'loss': 7.0611, 'learning_rate': 1.8931150161867917e-05, 'epoch': 0.47}
Step 133: {'loss': 7.0658, 'learning_rate': 1.890299380947368e-05, 'epoch': 0.47}
Step 134: {'loss': 6.7371, 'learning_rate': 1.887449290755095e-05, 'epoch': 0.48}
Step 135: {'loss': 6.5717, 'learning_rate': 1.8845648559096378e-05, 'epoch': 0.48}
Step 136: {'loss': 6.7603, 'learning_rate': 1.8816461880398126e-05, 'epoch': 0.48}
Step 137: {'loss': 7.2652, 'learning_rate': 1.878693400099269e-05, 'epoch': 0.49}
Step 138: {'loss': 7.1015, 'learning_rate': 1.8757066063621167e-05, 'epoch': 0.49}
Step 139: {'loss': 6.9992, 'learning_rate': 1.872685922418504e-05, 'epoch': 0.49}
Step 140: {'loss': 6.6819, 'learning_rate': 1.8696314651701438e-05, 'epoch': 0.5}
Step 141: {'loss': 7.4781, 'learning_rate': 1.8665433528257904e-05, 'epoch': 0.5}
Step 142: {'loss': 6.7977, 'learning_rate': 1.8634217048966638e-05, 'epoch': 0.5}
Step 143: {'loss': 6.9283, 'learning_rate': 1.8602666421918245e-05, 'epoch': 0.51}
Step 144: {'loss': 6.5334, 'learning_rate': 1.8570782868134997e-05, 'epoch': 0.51}
Step 145: {'loss': 6.6397, 'learning_rate': 1.853856762152356e-05, 'epoch': 0.52}
Step 146: {'loss': 6.845, 'learning_rate': 1.8506021928827246e-05, 'epoch': 0.52}
Step 147: {'loss': 6.7123, 'learning_rate': 1.8473147049577777e-05, 'epoch': 0.52}
Step 148: {'loss': 7.0749, 'learning_rate': 1.843994425604652e-05, 'epoch': 0.53}
Step 149: {'loss': 6.564, 'learning_rate': 1.840641483319527e-05, 'epoch': 0.53}
Step 150: {'loss': 6.1386, 'learning_rate': 1.8372560078626502e-05, 'epoch': 0.53}
Step 151: {'loss': 6.8613, 'learning_rate': 1.8338381302533164e-05, 'epoch': 0.54}
Step 152: {'loss': 6.2694, 'learning_rate': 1.8303879827647977e-05, 'epoch': 0.54}
Step 153: {'loss': 6.7243, 'learning_rate': 1.8269056989192232e-05, 'epoch': 0.54}
Step 154: {'loss': 6.8838, 'learning_rate': 1.823391413482412e-05, 'epoch': 0.55}
Step 155: {'loss': 6.6652, 'learning_rate': 1.8198452624586592e-05, 'epoch': 0.55}
Step 156: {'loss': 6.2278, 'learning_rate': 1.81626738308547e-05, 'epoch': 0.55}
Step 157: {'loss': 6.3786, 'learning_rate': 1.8126579138282502e-05, 'epoch': 0.56}
Step 158: {'loss': 6.5189, 'learning_rate': 1.8090169943749477e-05, 'epoch': 0.56}
Step 159: {'loss': 6.8562, 'learning_rate': 1.8053447656306448e-05, 'epoch': 0.57}
Step 160: {'loss': 6.7679, 'learning_rate': 1.8016413697121066e-05, 'epoch': 0.57}
Step 161: {'loss': 6.8912, 'learning_rate': 1.797906949942282e-05, 'epoch': 0.57}
Step 162: {'loss': 6.6792, 'learning_rate': 1.7941416508447537e-05, 'epoch': 0.58}
Step 163: {'loss': 6.8782, 'learning_rate': 1.7903456181381486e-05, 'epoch': 0.58}
Step 164: {'loss': 6.3774, 'learning_rate': 1.7865189987304964e-05, 'epoch': 0.58}
Step 165: {'loss': 7.0335, 'learning_rate': 1.7826619407135444e-05, 'epoch': 0.59}
Step 166: {'loss': 6.2107, 'learning_rate': 1.7787745933570277e-05, 'epoch': 0.59}
Step 167: {'loss': 6.6437, 'learning_rate': 1.77485710710289e-05, 'epoch': 0.59}
Step 168: {'loss': 6.2857, 'learning_rate': 1.7709096335594632e-05, 'epoch': 0.6}
Step 169: {'loss': 6.7688, 'learning_rate': 1.7669323254956006e-05, 'epoch': 0.6}
Step 170: {'loss': 5.8535, 'learning_rate': 1.7629253368347624e-05, 'epoch': 0.6}
Step 171: {'loss': 6.682, 'learning_rate': 1.7588888226490604e-05, 'epoch': 0.61}
Step 172: {'loss': 6.5182, 'learning_rate': 1.7548229391532572e-05, 'epoch': 0.61}
Step 173: {'loss': 6.4192, 'learning_rate': 1.7507278436987188e-05, 'epoch': 0.62}
Step 174: {'loss': 6.3682, 'learning_rate': 1.746603694767327e-05, 'epoch': 0.62}
Step 175: {'loss': 6.1514, 'learning_rate': 1.7424506519653438e-05, 'epoch': 0.62}
Step 176: {'loss': 6.509, 'learning_rate': 1.7382688760172377e-05, 'epoch': 0.63}
Step 177: {'loss': 6.4465, 'learning_rate': 1.7340585287594605e-05, 'epoch': 0.63}
Step 178: {'loss': 6.3226, 'learning_rate': 1.729819773134185e-05, 'epoch': 0.63}
Step 179: {'loss': 6.4805, 'learning_rate': 1.725552773183001e-05, 'epoch': 0.64}
Step 180: {'loss': 6.0208, 'learning_rate': 1.7212576940405647e-05, 'epoch': 0.64}
Step 181: {'loss': 6.4656, 'learning_rate': 1.716934701928208e-05, 'epoch': 0.64}
Step 182: {'loss': 6.3219, 'learning_rate': 1.7125839641475074e-05, 'epoch': 0.65}
Step 183: {'loss': 6.7058, 'learning_rate': 1.7082056490738065e-05, 'epoch': 0.65}
Step 184: {'loss': 6.7647, 'learning_rate': 1.7037999261497037e-05, 'epoch': 0.65}
Step 185: {'loss': 6.4235, 'learning_rate': 1.6993669658784908e-05, 'epoch': 0.66}
Step 186: {'loss': 6.2922, 'learning_rate': 1.6949069398175564e-05, 'epoch': 0.66}
Step 187: {'loss': 6.4918, 'learning_rate': 1.690420020571747e-05, 'epoch': 0.66}
Step 188: {'loss': 6.168, 'learning_rate': 1.685906381786686e-05, 'epoch': 0.67}
Step 189: {'loss': 6.3118, 'learning_rate': 1.681366198142054e-05, 'epoch': 0.67}
Step 190: {'loss': 6.4001, 'learning_rate': 1.6767996453448282e-05, 'epoch': 0.68}
Step 191: {'loss': 6.1512, 'learning_rate': 1.6722069001224842e-05, 'epoch': 0.68}
Step 192: {'loss': 6.5582, 'learning_rate': 1.667588140216154e-05, 'epoch': 0.68}
Step 193: {'loss': 6.6466, 'learning_rate': 1.662943544373748e-05, 'epoch': 0.69}
Step 194: {'loss': 6.4887, 'learning_rate': 1.65827329234304e-05, 'epoch': 0.69}
Step 195: {'loss': 6.55, 'learning_rate': 1.6535775648647074e-05, 'epoch': 0.69}
Step 196: {'loss': 6.1655, 'learning_rate': 1.648856543665338e-05, 'epoch': 0.7}
Step 197: {'loss': 5.9057, 'learning_rate': 1.644110411450398e-05, 'epoch': 0.7}
Step 198: {'loss': 5.904, 'learning_rate': 1.6393393518971587e-05, 'epoch': 0.7}
Step 199: {'loss': 6.3213, 'learning_rate': 1.634543549647591e-05, 'epoch': 0.71}
Step 200: {'loss': 6.6586, 'learning_rate': 1.6297231903012178e-05, 'epoch': 0.71}
Step 201: {'loss': 6.295, 'learning_rate': 1.6248784604079316e-05, 'epoch': 0.71}
Step 202: {'loss': 6.5801, 'learning_rate': 1.6200095474607753e-05, 'epoch': 0.72}
Step 203: {'loss': 6.3485, 'learning_rate': 1.6151166398886862e-05, 'epoch': 0.72}
Step 204: {'loss': 6.2466, 'learning_rate': 1.6101999270492033e-05, 'epoch': 0.73}
Step 205: {'loss': 6.4771, 'learning_rate': 1.6052595992211388e-05, 'epoch': 0.73}
Step 206: {'loss': 6.4406, 'learning_rate': 1.6002958475972158e-05, 'epoch': 0.73}
Step 207: {'loss': 6.1655, 'learning_rate': 1.595308864276666e-05, 'epoch': 0.74}
Step 208: {'loss': 6.2438, 'learning_rate': 1.5902988422578e-05, 'epoch': 0.74}
Step 209: {'loss': 6.1566, 'learning_rate': 1.585265975430533e-05, 'epoch': 0.74}
Step 210: {'loss': 6.475, 'learning_rate': 1.5802104585688853e-05, 'epoch': 0.75}
Step 211: {'loss': 6.391, 'learning_rate': 1.5751324873234422e-05, 'epoch': 0.75}
Step 212: {'loss': 6.0284, 'learning_rate': 1.570032258213783e-05, 'epoch': 0.75}
Step 213: {'loss': 6.2769, 'learning_rate': 1.5649099686208756e-05, 'epoch': 0.76}
Step 214: {'loss': 6.3914, 'learning_rate': 1.5597658167794374e-05, 'epoch': 0.76}
Step 215: {'loss': 6.1381, 'learning_rate': 1.5546000017702646e-05, 'epoch': 0.76}
Step 216: {'loss': 6.1651, 'learning_rate': 1.549412723512526e-05, 'epoch': 0.77}
Step 217: {'loss': 5.8551, 'learning_rate': 1.5442041827560274e-05, 'epoch': 0.77}
Step 218: {'loss': 5.9537, 'learning_rate': 1.538974581073442e-05, 'epoch': 0.78}
Step 219: {'loss': 6.0708, 'learning_rate': 1.5337241208525097e-05, 'epoch': 0.78}
Step 220: {'loss': 6.3172, 'learning_rate': 1.5284530052882043e-05, 'epoch': 0.78}
Step 221: {'loss': 6.4358, 'learning_rate': 1.5231614383748699e-05, 'epoch': 0.79}
Step 222: {'loss': 6.0693, 'learning_rate': 1.5178496248983254e-05, 'epoch': 0.79}
Step 223: {'loss': 6.5165, 'learning_rate': 1.512517770427942e-05, 'epoch': 0.79}
Step 224: {'loss': 6.245, 'learning_rate': 1.5071660813086837e-05, 'epoch': 0.8}
Step 225: {'loss': 5.7738, 'learning_rate': 1.501794764653124e-05, 'epoch': 0.8}
Step 226: {'loss': 6.3477, 'learning_rate': 1.4964040283334315e-05, 'epoch': 0.8}
Step 227: {'loss': 6.1324, 'learning_rate': 1.4909940809733223e-05, 'epoch': 0.81}
Step 228: {'loss': 6.1717, 'learning_rate': 1.4855651319399882e-05, 'epoch': 0.81}
Step 229: {'loss': 5.8476, 'learning_rate': 1.480117391335993e-05, 'epoch': 0.81}
Step 230: {'loss': 5.9082, 'learning_rate': 1.4746510699911431e-05, 'epoch': 0.82}
Step 231: {'loss': 6.0827, 'learning_rate': 1.4691663794543272e-05, 'epoch': 0.82}
Step 232: {'loss': 5.9636, 'learning_rate': 1.4636635319853274e-05, 'epoch': 0.82}
Step 233: {'loss': 6.3223, 'learning_rate': 1.4581427405466091e-05, 'epoch': 0.83}
Step 234: {'loss': 5.9554, 'learning_rate': 1.4526042187950752e-05, 'epoch': 0.83}
Step 235: {'loss': 6.8669, 'learning_rate': 1.4470481810737993e-05, 'epoch': 0.84}
Step 236: {'loss': 5.7462, 'learning_rate': 1.4414748424037303e-05, 'epoch': 0.84}
Step 237: {'loss': 6.1876, 'learning_rate': 1.4358844184753713e-05, 'epoch': 0.84}
Step 238: {'loss': 6.1572, 'learning_rate': 1.4302771256404314e-05, 'epoch': 0.85}
Step 239: {'loss': 5.9221, 'learning_rate': 1.4246531809034529e-05, 'epoch': 0.85}
Step 240: {'loss': 6.421, 'learning_rate': 1.4190128019134156e-05, 'epoch': 0.85}
Step 241: {'loss': 6.0041, 'learning_rate': 1.4133562069553091e-05, 'epoch': 0.86}
Step 242: {'loss': 6.4074, 'learning_rate': 1.4076836149416889e-05, 'epoch': 0.86}
Step 243: {'loss': 6.1941, 'learning_rate': 1.4019952454042037e-05, 'epoch': 0.86}
Step 244: {'loss': 5.7714, 'learning_rate': 1.3962913184850979e-05, 'epoch': 0.87}
Step 245: {'loss': 5.9097, 'learning_rate': 1.3905720549286932e-05, 'epoch': 0.87}
Step 246: {'loss': 5.9534, 'learning_rate': 1.3848376760728454e-05, 'epoch': 0.87}
Step 247: {'loss': 6.0053, 'learning_rate': 1.3790884038403796e-05, 'epoch': 0.88}
Step 248: {'loss': 6.066, 'learning_rate': 1.373324460730499e-05, 'epoch': 0.88}
Step 249: {'loss': 6.0661, 'learning_rate': 1.3675460698101772e-05, 'epoch': 0.89}
Step 250: {'loss': 6.071, 'learning_rate': 1.3617534547055236e-05, 'epoch': 0.89}
Step 251: {'loss': 5.7852, 'learning_rate': 1.3559468395931291e-05, 'epoch': 0.89}
Step 252: {'loss': 6.0777, 'learning_rate': 1.3501264491913909e-05, 'epoch': 0.9}
Step 253: {'loss': 5.7541, 'learning_rate': 1.3442925087518154e-05, 'epoch': 0.9}
Step 254: {'loss': 6.0002, 'learning_rate': 1.338445244050302e-05, 'epoch': 0.9}
Step 255: {'loss': 6.1234, 'learning_rate': 1.3325848813784031e-05, 'epoch': 0.91}
Step 256: {'loss': 6.4632, 'learning_rate': 1.3267116475345682e-05, 'epoch': 0.91}
Step 257: {'loss': 5.8773, 'learning_rate': 1.3208257698153677e-05, 'epoch': 0.91}
Step 258: {'loss': 6.2048, 'learning_rate': 1.3149274760066941e-05, 'epoch': 0.92}
Step 259: {'loss': 5.9859, 'learning_rate': 1.3090169943749475e-05, 'epoch': 0.92}
Step 260: {'loss': 5.7979, 'learning_rate': 1.3030945536582025e-05, 'epoch': 0.92}
Step 261: {'loss': 5.7425, 'learning_rate': 1.2971603830573552e-05, 'epoch': 0.93}
Step 262: {'loss': 5.8987, 'learning_rate': 1.2912147122272523e-05, 'epoch': 0.93}
Step 263: {'loss': 6.1509, 'learning_rate': 1.2852577712678045e-05, 'epoch': 0.94}
Step 264: {'loss': 6.2967, 'learning_rate': 1.2792897907150817e-05, 'epoch': 0.94}
Step 265: {'loss': 5.9546, 'learning_rate': 1.2733110015323897e-05, 'epoch': 0.94}
Step 266: {'loss': 6.168, 'learning_rate': 1.2673216351013331e-05, 'epoch': 0.95}
Step 267: {'loss': 5.619, 'learning_rate': 1.2613219232128608e-05, 'epoch': 0.95}
Step 268: {'loss': 6.0822, 'learning_rate': 1.2553120980582946e-05, 'epoch': 0.95}
Step 269: {'loss': 6.1844, 'learning_rate': 1.2492923922203442e-05, 'epoch': 0.96}
Step 270: {'loss': 5.6519, 'learning_rate': 1.243263038664105e-05, 'epoch': 0.96}
Step 271: {'loss': 6.3077, 'learning_rate': 1.2372242707280446e-05, 'epoch': 0.96}
Step 272: {'loss': 6.1268, 'learning_rate': 1.23117632211497e-05, 'epoch': 0.97}
Step 273: {'loss': 5.94, 'learning_rate': 1.2251194268829839e-05, 'epoch': 0.97}
Step 274: {'loss': 5.7695, 'learning_rate': 1.219053819436427e-05, 'epoch': 0.97}
Step 275: {'loss': 5.8043, 'learning_rate': 1.2129797345168073e-05, 'epoch': 0.98}
Step 276: {'loss': 5.9309, 'learning_rate': 1.2068974071937136e-05, 'epoch': 0.98}
Step 277: {'loss': 5.6838, 'learning_rate': 1.2008070728557186e-05, 'epoch': 0.98}
Step 278: {'loss': 6.1303, 'learning_rate': 1.194708967201271e-05, 'epoch': 0.99}
Step 279: {'loss': 5.5484, 'learning_rate': 1.188603326229572e-05, 'epoch': 0.99}
Step 280: {'loss': 6.054, 'learning_rate': 1.1824903862314427e-05, 'epoch': 1.0}
Step 281: {'loss': 6.1986, 'learning_rate': 1.1763703837801795e-05, 'epoch': 1.0}
Step 282: {'loss': 6.2502, 'learning_rate': 1.1702435557223988e-05, 'epoch': 1.0}
Step 283: {'loss': 5.9777, 'learning_rate': 1.1641101391688708e-05, 'epoch': 1.01}
Step 284: {'loss': 6.1243, 'learning_rate': 1.1579703714853425e-05, 'epoch': 1.01}
Step 285: {'loss': 5.937, 'learning_rate': 1.1518244902833538e-05, 'epoch': 1.01}
Step 286: {'loss': 5.6051, 'learning_rate': 1.145672733411039e-05, 'epoch': 1.02}
Step 287: {'loss': 5.7924, 'learning_rate': 1.1395153389439232e-05, 'epoch': 1.02}
Step 288: {'loss': 6.262, 'learning_rate': 1.1333525451757095e-05, 'epoch': 1.02}
Step 289: {'loss': 5.9276, 'learning_rate': 1.1271845906090557e-05, 'epoch': 1.03}
Step 290: {'loss': 5.8638, 'learning_rate': 1.1210117139463452e-05, 'epoch': 1.03}
Step 291: {'loss': 5.8321, 'learning_rate': 1.1148341540804472e-05, 'epoch': 1.03}
Step 292: {'loss': 5.9041, 'learning_rate': 1.1086521500854746e-05, 'epoch': 1.04}
Step 293: {'loss': 5.8603, 'learning_rate': 1.1024659412075285e-05, 'epoch': 1.04}
Step 294: {'loss': 5.5557, 'learning_rate': 1.0962757668554413e-05, 'epoch': 1.05}
Step 295: {'loss': 5.8715, 'learning_rate': 1.0900818665915109e-05, 'epoch': 1.05}
Step 296: {'loss': 6.051, 'learning_rate': 1.0838844801222294e-05, 'epoch': 1.05}
Step 297: {'loss': 6.3017, 'learning_rate': 1.0776838472890065e-05, 'epoch': 1.06}
Step 298: {'loss': 5.7454, 'learning_rate': 1.0714802080588873e-05, 'epoch': 1.06}
Step 299: {'loss': 5.7349, 'learning_rate': 1.0652738025152663e-05, 'epoch': 1.06}
Step 300: {'loss': 6.1859, 'learning_rate': 1.0590648708485946e-05, 'epoch': 1.07}
Step 301: {'loss': 5.3742, 'learning_rate': 1.0528536533470863e-05, 'epoch': 1.07}
Step 302: {'loss': 5.9536, 'learning_rate': 1.0466403903874176e-05, 'epoch': 1.07}
Step 303: {'loss': 5.9587, 'learning_rate': 1.040425322425425e-05, 'epoch': 1.08}
Step 304: {'loss': 5.8191, 'learning_rate': 1.0342086899867992e-05, 'epoch': 1.08}
Step 305: {'loss': 5.7907, 'learning_rate': 1.0279907336577766e-05, 'epoch': 1.08}
Step 306: {'loss': 6.1415, 'learning_rate': 1.021771694075829e-05, 'epoch': 1.09}
Step 307: {'loss': 5.6196, 'learning_rate': 1.0155518119203511e-05, 'epoch': 1.09}
Step 308: {'loss': 5.9412, 'learning_rate': 1.0093313279033442e-05, 'epoch': 1.1}
Step 309: {'loss': 5.7189, 'learning_rate': 1.0031104827601028e-05, 'epoch': 1.1}
Step 310: {'loss': 5.8675, 'learning_rate': 9.968895172398974e-06, 'epoch': 1.1}
Step 311: {'loss': 5.9883, 'learning_rate': 9.906686720966562e-06, 'epoch': 1.11}
Step 312: {'loss': 5.8828, 'learning_rate': 9.844481880796492e-06, 'epoch': 1.11}
Step 313: {'loss': 5.4968, 'learning_rate': 9.782283059241711e-06, 'epoch': 1.11}
Step 314: {'loss': 5.9297, 'learning_rate': 9.720092663422239e-06, 'epoch': 1.12}
Step 315: {'loss': 5.7875, 'learning_rate': 9.657913100132012e-06, 'epoch': 1.12}
Step 316: {'loss': 6.3642, 'learning_rate': 9.595746775745753e-06, 'epoch': 1.12}
Step 317: {'loss': 5.7799, 'learning_rate': 9.533596096125826e-06, 'epoch': 1.13}
Step 318: {'loss': 5.6883, 'learning_rate': 9.47146346652914e-06, 'epoch': 1.13}
Step 319: {'loss': 5.9152, 'learning_rate': 9.409351291514055e-06, 'epoch': 1.13}
Step 320: {'loss': 5.7985, 'learning_rate': 9.347261974847342e-06, 'epoch': 1.14}
Step 321: {'loss': 5.7813, 'learning_rate': 9.28519791941113e-06, 'epoch': 1.14}
Step 322: {'loss': 5.7228, 'learning_rate': 9.223161527109938e-06, 'epoch': 1.14}
Step 323: {'loss': 6.1595, 'learning_rate': 9.161155198777707e-06, 'epoch': 1.15}
Step 324: {'loss': 5.9524, 'learning_rate': 9.099181334084893e-06, 'epoch': 1.15}
Step 325: {'loss': 5.612, 'learning_rate': 9.037242331445588e-06, 'epoch': 1.16}
Step 326: {'loss': 6.0275, 'learning_rate': 8.975340587924716e-06, 'epoch': 1.16}
Step 327: {'loss': 6.0441, 'learning_rate': 8.913478499145255e-06, 'epoch': 1.16}
Step 328: {'loss': 5.9778, 'learning_rate': 8.851658459195528e-06, 'epoch': 1.17}
Step 329: {'loss': 5.5209, 'learning_rate': 8.78988286053655e-06, 'epoch': 1.17}
Step 330: {'loss': 5.4818, 'learning_rate': 8.728154093909441e-06, 'epoch': 1.17}
Step 331: {'loss': 5.7366, 'learning_rate': 8.666474548242907e-06, 'epoch': 1.18}
Step 332: {'loss': 6.1003, 'learning_rate': 8.604846610560771e-06, 'epoch': 1.18}
Step 333: {'loss': 6.0063, 'learning_rate': 8.543272665889612e-06, 'epoch': 1.18}
Step 334: {'loss': 5.7039, 'learning_rate': 8.481755097166464e-06, 'epoch': 1.19}
Step 335: {'loss': 5.8645, 'learning_rate': 8.420296285146574e-06, 'epoch': 1.19}
Step 336: {'loss': 5.5889, 'learning_rate': 8.358898608311297e-06, 'epoch': 1.19}
Step 337: {'loss': 5.8597, 'learning_rate': 8.297564442776014e-06, 'epoch': 1.2}
Step 338: {'loss': 6.5343, 'learning_rate': 8.236296162198207e-06, 'epoch': 1.2}
Step 339: {'loss': 6.0521, 'learning_rate': 8.175096137685575e-06, 'epoch': 1.21}
Step 340: {'loss': 5.6985, 'learning_rate': 8.11396673770428e-06, 'epoch': 1.21}
Step 341: {'loss': 5.7353, 'learning_rate': 8.05291032798729e-06, 'epoch': 1.21}
Step 342: {'loss': 5.9503, 'learning_rate': 7.991929271442817e-06, 'epoch': 1.22}
Step 343: {'loss': 6.0526, 'learning_rate': 7.93102592806287e-06, 'epoch': 1.22}
Step 344: {'loss': 6.025, 'learning_rate': 7.87020265483193e-06, 'epoch': 1.22}
Step 345: {'loss': 5.5535, 'learning_rate': 7.809461805635734e-06, 'epoch': 1.23}
Step 346: {'loss': 6.178, 'learning_rate': 7.748805731170168e-06, 'epoch': 1.23}
Step 347: {'loss': 5.6523, 'learning_rate': 7.688236778850307e-06, 'epoch': 1.23}
Step 348: {'loss': 5.9684, 'learning_rate': 7.6277572927195584e-06, 'epoch': 1.24}
Step 349: {'loss': 5.9676, 'learning_rate': 7.567369613358953e-06, 'epoch': 1.24}
Step 350: {'loss': 5.7096, 'learning_rate': 7.507076077796564e-06, 'epoch': 1.24}
Step 351: {'loss': 5.5438, 'learning_rate': 7.4468790194170596e-06, 'epoch': 1.25}
Step 352: {'loss': 5.8839, 'learning_rate': 7.3867807678713965e-06, 'epoch': 1.25}
Step 353: {'loss': 6.0732, 'learning_rate': 7.326783648986672e-06, 'epoch': 1.26}
Step 354: {'loss': 5.6878, 'learning_rate': 7.266889984676108e-06, 'epoch': 1.26}
Step 355: {'loss': 5.9461, 'learning_rate': 7.207102092849187e-06, 'epoch': 1.26}
Step 356: {'loss': 5.9701, 'learning_rate': 7.147422287321957e-06, 'epoch': 1.27}
Step 357: {'loss': 5.9961, 'learning_rate': 7.0878528777274814e-06, 'epoch': 1.27}
Step 358: {'loss': 5.8036, 'learning_rate': 7.028396169426453e-06, 'epoch': 1.27}
Step 359: {'loss': 5.5321, 'learning_rate': 6.9690544634179764e-06, 'epoch': 1.28}
Step 360: {'loss': 6.0376, 'learning_rate': 6.909830056250527e-06, 'epoch': 1.28}
Step 361: {'loss': 5.9406, 'learning_rate': 6.850725239933063e-06, 'epoch': 1.28}
Step 362: {'loss': 6.0723, 'learning_rate': 6.791742301846325e-06, 'epoch': 1.29}
Step 363: {'loss': 5.8043, 'learning_rate': 6.732883524654319e-06, 'epoch': 1.29}
Step 364: {'loss': 5.5057, 'learning_rate': 6.674151186215973e-06, 'epoch': 1.29}
Step 365: {'loss': 6.2706, 'learning_rate': 6.6155475594969846e-06, 'epoch': 1.3}
Step 366: {'loss': 6.0296, 'learning_rate': 6.5570749124818465e-06, 'epoch': 1.3}
Step 367: {'loss': 5.6827, 'learning_rate': 6.498735508086094e-06, 'epoch': 1.3}
Step 368: {'loss': 5.821, 'learning_rate': 6.4405316040687125e-06, 'epoch': 1.31}
Step 369: {'loss': 6.134, 'learning_rate': 6.382465452944769e-06, 'epoch': 1.31}
Step 370: {'loss': 5.9568, 'learning_rate': 6.32453930189823e-06, 'epoch': 1.32}
Step 371: {'loss': 5.8087, 'learning_rate': 6.266755392695012e-06, 'epoch': 1.32}
Step 372: {'loss': 5.2219, 'learning_rate': 6.209115961596208e-06, 'epoch': 1.32}
Step 373: {'loss': 5.6086, 'learning_rate': 6.151623239271548e-06, 'epoch': 1.33}
Step 374: {'loss': 5.7775, 'learning_rate': 6.094279450713071e-06, 'epoch': 1.33}
Step 375: {'loss': 5.8893, 'learning_rate': 6.037086815149025e-06, 'epoch': 1.33}
Step 376: {'loss': 5.5107, 'learning_rate': 5.980047545957966e-06, 'epoch': 1.34}
Step 377: {'loss': 5.9768, 'learning_rate': 5.923163850583114e-06, 'epoch': 1.34}
Step 378: {'loss': 5.8501, 'learning_rate': 5.866437930446913e-06, 'epoch': 1.34}
Step 379: {'loss': 5.6498, 'learning_rate': 5.809871980865847e-06, 'epoch': 1.35}
Step 380: {'loss': 6.1022, 'learning_rate': 5.75346819096547e-06, 'epoch': 1.35}
Step 381: {'loss': 6.122, 'learning_rate': 5.6972287435956895e-06, 'epoch': 1.35}
Step 382: {'loss': 5.9498, 'learning_rate': 5.64115581524629e-06, 'epoch': 1.36}
Step 383: {'loss': 5.3375, 'learning_rate': 5.585251575962698e-06, 'epoch': 1.36}
Step 384: {'loss': 5.5973, 'learning_rate': 5.529518189262011e-06, 'epoch': 1.37}
Step 385: {'loss': 5.3969, 'learning_rate': 5.473957812049252e-06, 'epoch': 1.37}
Step 386: {'loss': 6.0016, 'learning_rate': 5.418572594533908e-06, 'epoch': 1.37}
Step 387: {'loss': 6.4004, 'learning_rate': 5.3633646801467255e-06, 'epoch': 1.38}
Step 388: {'loss': 5.7077, 'learning_rate': 5.3083362054567325e-06, 'epoch': 1.38}
Step 389: {'loss': 5.8306, 'learning_rate': 5.253489300088568e-06, 'epoch': 1.38}
Step 390: {'loss': 5.417, 'learning_rate': 5.1988260866400715e-06, 'epoch': 1.39}
Step 391: {'loss': 5.7396, 'learning_rate': 5.144348680600122e-06, 'epoch': 1.39}
Step 392: {'loss': 5.7453, 'learning_rate': 5.090059190266779e-06, 'epoch': 1.39}
Step 393: {'loss': 5.9507, 'learning_rate': 5.035959716665683e-06, 'epoch': 1.4}
Step 394: {'loss': 5.7554, 'learning_rate': 4.982052353468757e-06, 'epoch': 1.4}
Step 395: {'loss': 6.0333, 'learning_rate': 4.928339186913165e-06, 'epoch': 1.4}
Step 396: {'loss': 5.6431, 'learning_rate': 4.8748222957205815e-06, 'epoch': 1.41}
Step 397: {'loss': 5.9535, 'learning_rate': 4.821503751016746e-06, 'epoch': 1.41}
Step 398: {'loss': 5.7884, 'learning_rate': 4.768385616251304e-06, 'epoch': 1.42}
Step 399: {'loss': 6.0349, 'learning_rate': 4.715469947117957e-06, 'epoch': 1.42}
Step 400: {'loss': 5.9052, 'learning_rate': 4.662758791474904e-06, 'epoch': 1.42}
Step 401: {'loss': 5.582, 'learning_rate': 4.610254189265577e-06, 'epoch': 1.43}
Step 402: {'loss': 5.2954, 'learning_rate': 4.557958172439726e-06, 'epoch': 1.43}
Step 403: {'loss': 5.5856, 'learning_rate': 4.505872764874741e-06, 'epoch': 1.43}
Step 404: {'loss': 5.7821, 'learning_rate': 4.453999982297355e-06, 'epoch': 1.44}
Step 405: {'loss': 5.7737, 'learning_rate': 4.402341832205631e-06, 'epoch': 1.44}
Step 406: {'loss': 5.4986, 'learning_rate': 4.350900313791247e-06, 'epoch': 1.44}
Step 407: {'loss': 5.7407, 'learning_rate': 4.299677417862174e-06, 'epoch': 1.45}
Step 408: {'loss': 5.8069, 'learning_rate': 4.2486751267655825e-06, 'epoch': 1.45}
Step 409: {'loss': 5.9583, 'learning_rate': 4.197895414311151e-06, 'epoch': 1.45}
Step 410: {'loss': 5.8261, 'learning_rate': 4.147340245694674e-06, 'epoch': 1.46}
Step 411: {'loss': 5.576, 'learning_rate': 4.097011577422005e-06, 'epoch': 1.46}
Step 412: {'loss': 5.7302, 'learning_rate': 4.046911357233343e-06, 'epoch': 1.46}
Step 413: {'loss': 5.4267, 'learning_rate': 3.997041524027846e-06, 'epoch': 1.47}
Step 414: {'loss': 5.786, 'learning_rate': 3.9474040077886134e-06, 'epoch': 1.47}
Step 415: {'loss': 5.604, 'learning_rate': 3.89800072950797e-06, 'epoch': 1.48}
Step 416: {'loss': 5.6889, 'learning_rate': 3.848833601113141e-06, 'epoch': 1.48}
Step 417: {'loss': 5.6198, 'learning_rate': 3.799904525392251e-06, 'epoch': 1.48}
Step 418: {'loss': 5.7732, 'learning_rate': 3.75121539592069e-06, 'epoch': 1.49}
Step 419: {'loss': 5.5088, 'learning_rate': 3.702768096987828e-06, 'epoch': 1.49}
Step 420: {'loss': 5.6869, 'learning_rate': 3.6545645035240917e-06, 'epoch': 1.49}
Step 421: {'loss': 5.8262, 'learning_rate': 3.606606481028415e-06, 'epoch': 1.5}
Step 422: {'loss': 5.7584, 'learning_rate': 3.558895885496023e-06, 'epoch': 1.5}
Step 423: {'loss': 5.6961, 'learning_rate': 3.5114345633466208e-06, 'epoch': 1.5}
Step 424: {'loss': 5.9811, 'learning_rate': 3.4642243513529296e-06, 'epoch': 1.51}
Step 425: {'loss': 6.0185, 'learning_rate': 3.4172670765696024e-06, 'epoch': 1.51}
Step 426: {'loss': 5.7571, 'learning_rate': 3.370564556262523e-06, 'epoch': 1.51}
Step 427: {'loss': 6.1883, 'learning_rate': 3.3241185978384636e-06, 'epoch': 1.52}
Step 428: {'loss': 5.7782, 'learning_rate': 3.2779309987751584e-06, 'epoch': 1.52}
Step 429: {'loss': 5.78, 'learning_rate': 3.2320035465517175e-06, 'epoch': 1.53}
Step 430: {'loss': 5.8434, 'learning_rate': 3.1863380185794636e-06, 'epoch': 1.53}
Step 431: {'loss': 5.8399, 'learning_rate': 3.1409361821331443e-06, 'epoch': 1.53}
Step 432: {'loss': 6.2112, 'learning_rate': 3.0957997942825337e-06, 'epoch': 1.54}
Step 433: {'loss': 5.7645, 'learning_rate': 3.050930601824441e-06, 'epoch': 1.54}
Step 434: {'loss': 5.6513, 'learning_rate': 3.0063303412150957e-06, 'epoch': 1.54}
Step 435: {'loss': 6.0107, 'learning_rate': 2.9620007385029657e-06, 'epoch': 1.55}
Step 436: {'loss': 5.9459, 'learning_rate': 2.9179435092619367e-06, 'epoch': 1.55}
Step 437: {'loss': 6.1405, 'learning_rate': 2.8741603585249312e-06, 'epoch': 1.55}
Step 438: {'loss': 5.6738, 'learning_rate': 2.8306529807179226e-06, 'epoch': 1.56}
Step 439: {'loss': 5.6523, 'learning_rate': 2.7874230595943576e-06, 'epoch': 1.56}
Step 440: {'loss': 5.8942, 'learning_rate': 2.744472268169993e-06, 'epoch': 1.56}
Step 441: {'loss': 5.6359, 'learning_rate': 2.7018022686581534e-06, 'epoch': 1.57}
Step 442: {'loss': 5.7511, 'learning_rate': 2.6594147124053983e-06, 'epoch': 1.57}
Step 443: {'loss': 5.994, 'learning_rate': 2.6173112398276233e-06, 'epoch': 1.58}
Step 444: {'loss': 6.1482, 'learning_rate': 2.5754934803465616e-06, 'epoch': 1.58}
Step 445: {'loss': 5.8682, 'learning_rate': 2.5339630523267332e-06, 'epoch': 1.58}
Step 446: {'loss': 5.5978, 'learning_rate': 2.4927215630128133e-06, 'epoch': 1.59}
Step 447: {'loss': 5.7734, 'learning_rate': 2.451770608467432e-06, 'epoch': 1.59}
Step 448: {'loss': 5.6562, 'learning_rate': 2.411111773509399e-06, 'epoch': 1.59}
Step 449: {'loss': 6.0323, 'learning_rate': 2.3707466316523787e-06, 'epoch': 1.6}
Step 450: {'loss': 5.5699, 'learning_rate': 2.3306767450439947e-06, 'epoch': 1.6}
Step 451: {'loss': 5.7628, 'learning_rate': 2.2909036644053672e-06, 'epoch': 1.6}
Step 452: {'loss': 5.5486, 'learning_rate': 2.251428928971102e-06, 'epoch': 1.61}
Step 453: {'loss': 5.6304, 'learning_rate': 2.2122540664297252e-06, 'epoch': 1.61}
Step 454: {'loss': 6.2589, 'learning_rate': 2.173380592864557e-06, 'epoch': 1.61}
Step 455: {'loss': 5.8869, 'learning_rate': 2.13481001269504e-06, 'epoch': 1.62}
Step 456: {'loss': 5.8995, 'learning_rate': 2.096543818618515e-06, 'epoch': 1.62}
Step 457: {'loss': 5.5057, 'learning_rate': 2.058583491552465e-06, 'epoch': 1.62}
Step 458: {'loss': 5.6258, 'learning_rate': 2.020930500577184e-06, 'epoch': 1.63}
Step 459: {'loss': 5.735, 'learning_rate': 1.9835863028789348e-06, 'epoch': 1.63}
Step 460: {'loss': 5.9135, 'learning_rate': 1.9465523436935562e-06, 'epoch': 1.64}
Step 461: {'loss': 5.6903, 'learning_rate': 1.9098300562505266e-06, 'epoch': 1.64}
Step 462: {'loss': 5.6638, 'learning_rate': 1.8734208617174986e-06, 'epoch': 1.64}
Step 463: {'loss': 5.6264, 'learning_rate': 1.8373261691452993e-06, 'epoch': 1.65}
Step 464: {'loss': 5.9517, 'learning_rate': 1.8015473754134072e-06, 'epoch': 1.65}
Step 465: {'loss': 5.647, 'learning_rate': 1.7660858651758794e-06, 'epoch': 1.65}
Step 466: {'loss': 5.7976, 'learning_rate': 1.7309430108077706e-06, 'epoch': 1.66}
Step 467: {'loss': 5.756, 'learning_rate': 1.6961201723520248e-06, 'epoch': 1.66}
Step 468: {'loss': 5.8802, 'learning_rate': 1.661618697466838e-06, 'epoch': 1.66}
Step 469: {'loss': 5.4568, 'learning_rate': 1.6274399213735015e-06, 'epoch': 1.67}
Step 470: {'loss': 5.8744, 'learning_rate': 1.593585166804732e-06, 'epoch': 1.67}
Step 471: {'loss': 5.5306, 'learning_rate': 1.5600557439534815e-06, 'epoch': 1.67}
Step 472: {'loss': 5.5758, 'learning_rate': 1.5268529504222262e-06, 'epoch': 1.68}
Step 473: {'loss': 5.4775, 'learning_rate': 1.493978071172757e-06, 'epoch': 1.68}
Step 474: {'loss': 5.8864, 'learning_rate': 1.461432378476445e-06, 'epoch': 1.69}
Step 475: {'loss': 5.8822, 'learning_rate': 1.429217131865005e-06, 'epoch': 1.69}
Step 476: {'loss': 5.7786, 'learning_rate': 1.3973335780817565e-06, 'epoch': 1.69}
Step 477: {'loss': 5.9668, 'learning_rate': 1.3657829510333653e-06, 'epoch': 1.7}
Step 478: {'loss': 5.7913, 'learning_rate': 1.334566471742098e-06, 'epoch': 1.7}
Step 479: {'loss': 5.5894, 'learning_rate': 1.3036853482985646e-06, 'epoch': 1.7}
Step 480: {'loss': 5.5923, 'learning_rate': 1.2731407758149638e-06, 'epoch': 1.71}
Step 481: {'loss': 6.0906, 'learning_rate': 1.2429339363788362e-06, 'epoch': 1.71}
Step 482: {'loss': 5.5018, 'learning_rate': 1.2130659990073146e-06, 'epoch': 1.71}
Step 483: {'loss': 5.705, 'learning_rate': 1.183538119601877e-06, 'epoch': 1.72}
Step 484: {'loss': 5.8364, 'learning_rate': 1.1543514409036261e-06, 'epoch': 1.72}
Step 485: {'loss': 5.9326, 'learning_rate': 1.125507092449052e-06, 'epoch': 1.72}
Step 486: {'loss': 5.671, 'learning_rate': 1.097006190526323e-06, 'epoch': 1.73}
Step 487: {'loss': 6.0036, 'learning_rate': 1.0688498381320855e-06, 'epoch': 1.73}
Step 488: {'loss': 6.0323, 'learning_rate': 1.0410391249287787e-06, 'epoch': 1.74}
Step 489: {'loss': 5.8557, 'learning_rate': 1.0135751272024608e-06, 'epoch': 1.74}
Step 490: {'loss': 5.8037, 'learning_rate': 9.864589078211573e-07, 'epoch': 1.74}
Step 491: {'loss': 5.5369, 'learning_rate': 9.596915161937349e-07, 'epoch': 1.75}
Step 492: {'loss': 5.3711, 'learning_rate': 9.332739882292752e-07, 'epoch': 1.75}
Step 493: {'loss': 5.6491, 'learning_rate': 9.072073462969944e-07, 'epoch': 1.75}
Step 494: {'loss': 5.6341, 'learning_rate': 8.814925991866751e-07, 'epoch': 1.76}
Step 495: {'loss': 5.7689, 'learning_rate': 8.561307420696252e-07, 'epoch': 1.76}
Step 496: {'loss': 5.5, 'learning_rate': 8.311227564601642e-07, 'epoch': 1.76}
Step 497: {'loss': 5.892, 'learning_rate': 8.06469610177636e-07, 'epoch': 1.77}
Step 498: {'loss': 5.3182, 'learning_rate': 7.821722573089641e-07, 'epoch': 1.77}
Step 499: {'loss': 5.3276, 'learning_rate': 7.582316381717125e-07, 'epoch': 1.77}
Step 500: {'loss': 5.764, 'learning_rate': 7.346486792777053e-07, 'epoch': 1.78}
Step 501: {'loss': 5.5326, 'learning_rate': 7.114242932971671e-07, 'epoch': 1.78}
Step 502: {'loss': 5.9106, 'learning_rate': 6.885593790234057e-07, 'epoch': 1.78}
Step 503: {'loss': 5.9602, 'learning_rate': 6.660548213380225e-07, 'epoch': 1.79}
Step 504: {'loss': 6.0408, 'learning_rate': 6.439114911766708e-07, 'epoch': 1.79}
Step 505: {'loss': 5.9801, 'learning_rate': 6.221302454953548e-07, 'epoch': 1.8}
Step 506: {'loss': 5.6049, 'learning_rate': 6.007119272372541e-07, 'epoch': 1.8}
Step 507: {'loss': 5.4717, 'learning_rate': 5.796573653001091e-07, 'epoch': 1.8}
Step 508: {'loss': 5.9901, 'learning_rate': 5.589673745041423e-07, 'epoch': 1.81}
Step 509: {'loss': 5.7695, 'learning_rate': 5.386427555605212e-07, 'epoch': 1.81}
Step 510: {'loss': 5.7265, 'learning_rate': 5.186842950403736e-07, 'epoch': 1.81}
Step 511: {'loss': 6.1213, 'learning_rate': 4.990927653443422e-07, 'epoch': 1.82}
Step 512: {'loss': 6.0168, 'learning_rate': 4.798689246727006e-07, 'epoch': 1.82}
Step 513: {'loss': 5.4322, 'learning_rate': 4.610135169960028e-07, 'epoch': 1.82}
Step 514: {'loss': 5.7192, 'learning_rate': 4.425272720262941e-07, 'epoch': 1.83}
Step 515: {'loss': 5.9394, 'learning_rate': 4.2441090518887117e-07, 'epoch': 1.83}
Step 516: {'loss': 5.509, 'learning_rate': 4.0666511759459457e-07, 'epoch': 1.83}
Step 517: {'loss': 5.9964, 'learning_rate': 3.8929059601275463e-07, 'epoch': 1.84}
Step 518: {'loss': 6.3937, 'learning_rate': 3.72288012844495e-07, 'epoch': 1.84}
Step 519: {'loss': 5.6197, 'learning_rate': 3.5565802609679234e-07, 'epoch': 1.85}
Step 520: {'loss': 5.9363, 'learning_rate': 3.394012793569823e-07, 'epoch': 1.85}
Step 521: {'loss': 5.9767, 'learning_rate': 3.235184017678616e-07, 'epoch': 1.85}
Step 522: {'loss': 6.0036, 'learning_rate': 3.080100080033388e-07, 'epoch': 1.86}
Step 523: {'loss': 6.0899, 'learning_rate': 2.928766982446407e-07, 'epoch': 1.86}
Step 524: {'loss': 5.6742, 'learning_rate': 2.781190581570903e-07, 'epoch': 1.86}
Step 525: {'loss': 6.1053, 'learning_rate': 2.6373765886743784e-07, 'epoch': 1.87}
Step 526: {'loss': 5.8931, 'learning_rate': 2.4973305694176333e-07, 'epoch': 1.87}
Step 527: {'loss': 5.8615, 'learning_rate': 2.3610579436392999e-07, 'epoch': 1.87}
Step 528: {'loss': 6.0367, 'learning_rate': 2.228563985146137e-07, 'epoch': 1.88}
Step 529: {'loss': 6.1537, 'learning_rate': 2.0998538215089349e-07, 'epoch': 1.88}
Step 530: {'loss': 5.9099, 'learning_rate': 1.974932433864052e-07, 'epoch': 1.88}
Step 531: {'loss': 5.9594, 'learning_rate': 1.853804656720659e-07, 'epoch': 1.89}
Step 532: {'loss': 5.6305, 'learning_rate': 1.7364751777736334e-07, 'epoch': 1.89}
Step 533: {'loss': 5.592, 'learning_rate': 1.6229485377221578e-07, 'epoch': 1.9}
Step 534: {'loss': 6.1108, 'learning_rate': 1.5132291300939628e-07, 'epoch': 1.9}
Step 535: {'loss': 5.7249, 'learning_rate': 1.4073212010753401e-07, 'epoch': 1.9}
Step 536: {'loss': 5.6097, 'learning_rate': 1.3052288493467736e-07, 'epoch': 1.91}
Step 537: {'loss': 5.6871, 'learning_rate': 1.206956025924333e-07, 'epoch': 1.91}
Step 538: {'loss': 5.7703, 'learning_rate': 1.1125065340067743e-07, 'epoch': 1.91}
Step 539: {'loss': 5.6353, 'learning_rate': 1.0218840288283571e-07, 'epoch': 1.92}
Step 540: {'loss': 5.7617, 'learning_rate': 9.350920175173694e-08, 'epoch': 1.92}
Step 541: {'loss': 6.0055, 'learning_rate': 8.521338589603911e-08, 'epoch': 1.92}
Step 542: {'loss': 5.7566, 'learning_rate': 7.730127636723539e-08, 'epoch': 1.93}
Step 543: {'loss': 5.5262, 'learning_rate': 6.977317936722294e-08, 'epoch': 1.93}
Step 544: {'loss': 5.9384, 'learning_rate': 6.262938623645909e-08, 'epoch': 1.93}
Step 545: {'loss': 5.8606, 'learning_rate': 5.58701734426792e-08, 'epoch': 1.94}
Step 546: {'loss': 5.6237, 'learning_rate': 4.9495802570205254e-08, 'epoch': 1.94}
Step 547: {'loss': 5.5693, 'learning_rate': 4.350652030981395e-08, 'epoch': 1.94}
Step 548: {'loss': 5.2768, 'learning_rate': 3.790255844919877e-08, 'epoch': 1.95}
Step 549: {'loss': 5.7313, 'learning_rate': 3.268413386399161e-08, 'epoch': 1.95}
Step 550: {'loss': 5.8448, 'learning_rate': 2.7851448509372825e-08, 'epoch': 1.96}
Step 551: {'loss': 6.0904, 'learning_rate': 2.3404689412258595e-08, 'epoch': 1.96}
Step 552: {'loss': 5.9546, 'learning_rate': 1.9344028664056715e-08, 'epoch': 1.96}
Step 553: {'loss': 5.6347, 'learning_rate': 1.5669623414011903e-08, 'epoch': 1.97}
Step 554: {'loss': 5.4508, 'learning_rate': 1.23816158631207e-08, 'epoch': 1.97}
Step 555: {'loss': 5.4977, 'learning_rate': 9.480133258630286e-09, 'epoch': 1.97}
Step 556: {'loss': 5.543, 'learning_rate': 6.965287889112438e-09, 'epoch': 1.98}
Step 557: {'loss': 5.7413, 'learning_rate': 4.837177080119215e-09, 'epoch': 1.98}
Step 558: {'loss': 5.6207, 'learning_rate': 3.095883190417093e-09, 'epoch': 1.98}
Step 559: {'loss': 6.0236, 'learning_rate': 1.7414736087950635e-09, 'epoch': 1.99}
Step 560: {'loss': 5.3571, 'learning_rate': 7.740007514622783e-10, 'epoch': 1.99}
Step 561: {'loss': 5.7748, 'learning_rate': 1.9350206001744754e-10, 'epoch': 1.99}
Step 562: {'loss': 5.4815, 'learning_rate': 0.0, 'epoch': 2.0}
Step 562: {'train_runtime': 1240.8645, 'train_samples_per_second': 14.506, 'train_steps_per_second': 0.453, 'total_flos': 0.0, 'train_loss': 7.147552234846502, 'epoch': 2.0}
