Step 1: {'loss': 1.9269, 'learning_rate': 2.3809523809523808e-06, 'epoch': 0.0}
Step 2: {'loss': 1.8845, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.01}
Step 3: {'loss': 1.7426, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.01}
Step 4: {'loss': 1.8432, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.01}
Step 5: {'loss': 1.8978, 'learning_rate': 1.1904761904761905e-05, 'epoch': 0.02}
Step 6: {'loss': 1.8124, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.02}
Step 7: {'loss': 1.7754, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
Step 8: {'loss': 1.9504, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.03}
Step 9: {'loss': 1.7948, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.03}
Step 10: {'loss': 1.7188, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.04}
Step 11: {'loss': 1.6496, 'learning_rate': 2.6190476190476192e-05, 'epoch': 0.04}
Step 12: {'loss': 1.7628, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.04}
Step 13: {'loss': 1.8999, 'learning_rate': 3.095238095238095e-05, 'epoch': 0.05}
Step 14: {'loss': 1.6578, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.05}
Step 15: {'loss': 1.7673, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.05}
Step 16: {'loss': 1.6446, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.06}
Step 17: {'loss': 1.4915, 'learning_rate': 4.047619047619048e-05, 'epoch': 0.06}
Step 18: {'loss': 1.5841, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.06}
Step 19: {'loss': 1.5253, 'learning_rate': 4.523809523809524e-05, 'epoch': 0.07}
Step 20: {'loss': 1.4436, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.07}
Step 21: {'loss': 1.499, 'learning_rate': 5e-05, 'epoch': 0.08}
Step 22: {'loss': 1.4151, 'learning_rate': 5.2380952380952384e-05, 'epoch': 0.08}
Step 23: {'loss': 1.4157, 'learning_rate': 5.4761904761904766e-05, 'epoch': 0.08}
Step 24: {'loss': 1.4109, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.09}
Step 25: {'loss': 1.4293, 'learning_rate': 5.9523809523809524e-05, 'epoch': 0.09}
Step 26: {'loss': 1.46, 'learning_rate': 6.19047619047619e-05, 'epoch': 0.09}
Step 27: {'loss': 1.4206, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.1}
Step 28: {'loss': 1.2116, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.1}
Step 29: {'loss': 1.4321, 'learning_rate': 6.904761904761905e-05, 'epoch': 0.1}
Step 30: {'loss': 1.3182, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.11}
Step 31: {'loss': 1.4011, 'learning_rate': 7.380952380952382e-05, 'epoch': 0.11}
Step 32: {'loss': 1.3421, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.11}
Step 33: {'loss': 1.2624, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.12}
Step 34: {'loss': 1.3295, 'learning_rate': 8.095238095238096e-05, 'epoch': 0.12}
Step 35: {'loss': 1.1962, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.13}
Step 36: {'loss': 1.1535, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.13}
Step 37: {'loss': 1.1928, 'learning_rate': 8.80952380952381e-05, 'epoch': 0.13}
Step 38: {'loss': 1.2164, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.14}
Step 39: {'loss': 1.1464, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.14}
Step 40: {'loss': 1.1069, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.14}
Step 41: {'loss': 1.1722, 'learning_rate': 9.761904761904762e-05, 'epoch': 0.15}
Step 42: {'loss': 1.0611, 'learning_rate': 0.0001, 'epoch': 0.15}
Step 43: {'loss': 0.9642, 'learning_rate': 0.00010238095238095237, 'epoch': 0.15}
Step 44: {'loss': 0.9902, 'learning_rate': 0.00010476190476190477, 'epoch': 0.16}
Step 45: {'loss': 0.9878, 'learning_rate': 0.00010714285714285715, 'epoch': 0.16}
Step 46: {'loss': 0.9461, 'learning_rate': 0.00010952380952380953, 'epoch': 0.16}
Step 47: {'loss': 0.9639, 'learning_rate': 0.00011190476190476191, 'epoch': 0.17}
Step 48: {'loss': 0.9297, 'learning_rate': 0.00011428571428571428, 'epoch': 0.17}
Step 49: {'loss': 0.9385, 'learning_rate': 0.00011666666666666668, 'epoch': 0.18}
Step 50: {'loss': 0.9186, 'learning_rate': 0.00011904761904761905, 'epoch': 0.18}
Step 51: {'loss': 0.8685, 'learning_rate': 0.00012142857142857143, 'epoch': 0.18}
Step 52: {'loss': 0.8424, 'learning_rate': 0.0001238095238095238, 'epoch': 0.19}
Step 53: {'loss': 0.8473, 'learning_rate': 0.0001261904761904762, 'epoch': 0.19}
Step 54: {'loss': 0.8727, 'learning_rate': 0.00012857142857142858, 'epoch': 0.19}
Step 55: {'loss': 0.8396, 'learning_rate': 0.00013095238095238096, 'epoch': 0.2}
Step 56: {'loss': 0.8019, 'learning_rate': 0.00013333333333333334, 'epoch': 0.2}
Step 57: {'loss': 0.7993, 'learning_rate': 0.00013571428571428572, 'epoch': 0.2}
Step 58: {'loss': 0.814, 'learning_rate': 0.0001380952380952381, 'epoch': 0.21}
Step 59: {'loss': 0.8017, 'learning_rate': 0.00014047619047619049, 'epoch': 0.21}
Step 60: {'loss': 0.8322, 'learning_rate': 0.00014285714285714287, 'epoch': 0.21}
Step 61: {'loss': 0.8206, 'learning_rate': 0.00014523809523809525, 'epoch': 0.22}
Step 62: {'loss': 0.7892, 'learning_rate': 0.00014761904761904763, 'epoch': 0.22}
Step 63: {'loss': 0.8027, 'learning_rate': 0.00015000000000000001, 'epoch': 0.23}
Step 64: {'loss': 0.771, 'learning_rate': 0.00015238095238095237, 'epoch': 0.23}
Step 65: {'loss': 0.8147, 'learning_rate': 0.00015476190476190478, 'epoch': 0.23}
Step 66: {'loss': 0.7954, 'learning_rate': 0.00015714285714285716, 'epoch': 0.24}
Step 67: {'loss': 0.7616, 'learning_rate': 0.00015952380952380954, 'epoch': 0.24}
Step 68: {'loss': 0.7291, 'learning_rate': 0.00016190476190476192, 'epoch': 0.24}
Step 69: {'loss': 0.7311, 'learning_rate': 0.00016428571428571428, 'epoch': 0.25}
Step 70: {'loss': 0.766, 'learning_rate': 0.0001666666666666667, 'epoch': 0.25}
Step 71: {'loss': 0.7711, 'learning_rate': 0.00016904761904761904, 'epoch': 0.25}
Step 72: {'loss': 0.7699, 'learning_rate': 0.00017142857142857143, 'epoch': 0.26}
Step 73: {'loss': 0.689, 'learning_rate': 0.00017380952380952383, 'epoch': 0.26}
Step 74: {'loss': 0.7525, 'learning_rate': 0.0001761904761904762, 'epoch': 0.26}
Step 75: {'loss': 0.7239, 'learning_rate': 0.0001785714285714286, 'epoch': 0.27}
Step 76: {'loss': 0.6952, 'learning_rate': 0.00018095238095238095, 'epoch': 0.27}
Step 77: {'loss': 0.8018, 'learning_rate': 0.00018333333333333334, 'epoch': 0.28}
Step 78: {'loss': 0.7073, 'learning_rate': 0.00018571428571428572, 'epoch': 0.28}
Step 79: {'loss': 0.724, 'learning_rate': 0.0001880952380952381, 'epoch': 0.28}
Step 80: {'loss': 0.7052, 'learning_rate': 0.00019047619047619048, 'epoch': 0.29}
Step 81: {'loss': 0.714, 'learning_rate': 0.00019285714285714286, 'epoch': 0.29}
Step 82: {'loss': 0.7177, 'learning_rate': 0.00019523809523809525, 'epoch': 0.29}
Step 83: {'loss': 0.6822, 'learning_rate': 0.00019761904761904763, 'epoch': 0.3}
Step 84: {'loss': 0.6967, 'learning_rate': 0.0002, 'epoch': 0.3}
Step 85: {'loss': 0.7004, 'learning_rate': 0.00019999912967959196, 'epoch': 0.3}
Step 86: {'loss': 0.6629, 'learning_rate': 0.000199996518733517, 'epoch': 0.31}
Step 87: {'loss': 0.6887, 'learning_rate': 0.00019999216720722226, 'epoch': 0.31}
Step 88: {'loss': 0.6751, 'learning_rate': 0.00019998607517645228, 'epoch': 0.31}
Step 89: {'loss': 0.7268, 'learning_rate': 0.0001999782427472473, 'epoch': 0.32}
Step 90: {'loss': 0.7009, 'learning_rate': 0.0001999686700559419, 'epoch': 0.32}
Step 91: {'loss': 0.6585, 'learning_rate': 0.00019995735726916224, 'epoch': 0.33}
Step 92: {'loss': 0.6585, 'learning_rate': 0.00019994430458382322, 'epoch': 0.33}
Step 93: {'loss': 0.7171, 'learning_rate': 0.00019992951222712527, 'epoch': 0.33}
Step 94: {'loss': 0.6533, 'learning_rate': 0.0001999129804565502, 'epoch': 0.34}
Step 95: {'loss': 0.6701, 'learning_rate': 0.00019989470955985672, 'epoch': 0.34}
Step 96: {'loss': 0.6533, 'learning_rate': 0.00019987469985507553, 'epoch': 0.34}
Step 97: {'loss': 0.6913, 'learning_rate': 0.00019985295169050373, 'epoch': 0.35}
Step 98: {'loss': 0.6372, 'learning_rate': 0.00019982946544469873, 'epoch': 0.35}
Step 99: {'loss': 0.6795, 'learning_rate': 0.00019980424152647171, 'epoch': 0.35}
Step 100: {'loss': 0.6413, 'learning_rate': 0.00019977728037488053, 'epoch': 0.36}
Step 101: {'loss': 0.6882, 'learning_rate': 0.0001997485824592219, 'epoch': 0.36}
Step 102: {'loss': 0.6488, 'learning_rate': 0.0001997181482790236, 'epoch': 0.36}
Step 103: {'loss': 0.7293, 'learning_rate': 0.00019968597836403528, 'epoch': 0.37}
Step 104: {'loss': 0.6636, 'learning_rate': 0.00019965207327421962, 'epoch': 0.37}
Step 105: {'loss': 0.7121, 'learning_rate': 0.0001996164335997425, 'epoch': 0.38}
Step 106: {'loss': 0.6636, 'learning_rate': 0.00019957905996096257, 'epoch': 0.38}
Step 107: {'loss': 0.6881, 'learning_rate': 0.00019953995300842073, 'epoch': 0.38}
Step 108: {'loss': 0.6637, 'learning_rate': 0.00019949911342282848, 'epoch': 0.39}
Step 109: {'loss': 0.6922, 'learning_rate': 0.00019945654191505638, 'epoch': 0.39}
Step 110: {'loss': 0.7032, 'learning_rate': 0.0001994122392261214, 'epoch': 0.39}
Step 111: {'loss': 0.656, 'learning_rate': 0.0001993662061271743, 'epoch': 0.4}
Step 112: {'loss': 0.6499, 'learning_rate': 0.00019931844341948595, 'epoch': 0.4}
Step 113: {'loss': 0.6607, 'learning_rate': 0.00019926895193443352, 'epoch': 0.4}
Step 114: {'loss': 0.7138, 'learning_rate': 0.00019921773253348603, 'epoch': 0.41}
Step 115: {'loss': 0.6543, 'learning_rate': 0.00019916478610818928, 'epoch': 0.41}
Step 116: {'loss': 0.671, 'learning_rate': 0.0001991101135801503, 'epoch': 0.41}
Step 117: {'loss': 0.6391, 'learning_rate': 0.00019905371590102155, 'epoch': 0.42}
Step 118: {'loss': 0.6379, 'learning_rate': 0.00019899559405248392, 'epoch': 0.42}
Step 119: {'loss': 0.6845, 'learning_rate': 0.00019893574904623012, 'epoch': 0.43}
Step 120: {'loss': 0.6867, 'learning_rate': 0.0001988741819239467, 'epoch': 0.43}
Step 121: {'loss': 0.6801, 'learning_rate': 0.00019881089375729615, 'epoch': 0.43}
Step 122: {'loss': 0.6758, 'learning_rate': 0.0001987458856478981, 'epoch': 0.44}
Step 123: {'loss': 0.7034, 'learning_rate': 0.0001986791587273103, 'epoch': 0.44}
Step 124: {'loss': 0.6611, 'learning_rate': 0.00019861071415700867, 'epoch': 0.44}
Step 125: {'loss': 0.6565, 'learning_rate': 0.00019854055312836742, 'epoch': 0.45}
Step 126: {'loss': 0.6446, 'learning_rate': 0.00019846867686263803, 'epoch': 0.45}
Step 127: {'loss': 0.7377, 'learning_rate': 0.0001983950866109281, 'epoch': 0.45}
Step 128: {'loss': 0.6704, 'learning_rate': 0.00019831978365417955, 'epoch': 0.46}
Step 129: {'loss': 0.654, 'learning_rate': 0.0001982427693031465, 'epoch': 0.46}
Step 130: {'loss': 0.6475, 'learning_rate': 0.00019816404489837207, 'epoch': 0.46}
Step 131: {'loss': 0.6925, 'learning_rate': 0.00019808361181016543, 'epoch': 0.47}
Step 132: {'loss': 0.7009, 'learning_rate': 0.00019800147143857771, 'epoch': 0.47}
Step 133: {'loss': 0.6427, 'learning_rate': 0.00019791762521337777, 'epoch': 0.48}
Step 134: {'loss': 0.6733, 'learning_rate': 0.00019783207459402727, 'epoch': 0.48}
Step 135: {'loss': 0.7062, 'learning_rate': 0.00019774482106965513, 'epoch': 0.48}
Step 136: {'loss': 0.6414, 'learning_rate': 0.00019765586615903182, 'epoch': 0.49}
Step 137: {'loss': 0.6631, 'learning_rate': 0.00019756521141054288, 'epoch': 0.49}
Step 138: {'loss': 0.679, 'learning_rate': 0.00019747285840216182, 'epoch': 0.49}
Step 139: {'loss': 0.6772, 'learning_rate': 0.0001973788087414228, 'epoch': 0.5}
Step 140: {'loss': 0.6589, 'learning_rate': 0.0001972830640653926, 'epoch': 0.5}
Step 141: {'loss': 0.6662, 'learning_rate': 0.00019718562604064213, 'epoch': 0.5}
Step 142: {'loss': 0.644, 'learning_rate': 0.00019708649636321744, 'epoch': 0.51}
Step 143: {'loss': 0.6098, 'learning_rate': 0.00019698567675861014, 'epoch': 0.51}
Step 144: {'loss': 0.6496, 'learning_rate': 0.00019688316898172742, 'epoch': 0.51}
Step 145: {'loss': 0.6631, 'learning_rate': 0.00019677897481686153, 'epoch': 0.52}
Step 146: {'loss': 0.7022, 'learning_rate': 0.00019667309607765857, 'epoch': 0.52}
Step 147: {'loss': 0.6253, 'learning_rate': 0.00019656553460708706, 'epoch': 0.53}
Step 148: {'loss': 0.6688, 'learning_rate': 0.00019645629227740594, 'epoch': 0.53}
Step 149: {'loss': 0.6692, 'learning_rate': 0.00019634537099013177, 'epoch': 0.53}
Step 150: {'loss': 0.6372, 'learning_rate': 0.00019623277267600574, 'epoch': 0.54}
Step 151: {'loss': 0.6507, 'learning_rate': 0.00019611849929496, 'epoch': 0.54}
Step 152: {'loss': 0.649, 'learning_rate': 0.00019600255283608377, 'epoch': 0.54}
Step 153: {'loss': 0.6462, 'learning_rate': 0.0001958849353175884, 'epoch': 0.55}
Step 154: {'loss': 0.6102, 'learning_rate': 0.00019576564878677241, 'epoch': 0.55}
Step 155: {'loss': 0.6871, 'learning_rate': 0.00019564469531998583, 'epoch': 0.55}
Step 156: {'loss': 0.6327, 'learning_rate': 0.00019552207702259412, 'epoch': 0.56}
Step 157: {'loss': 0.6422, 'learning_rate': 0.00019539779602894134, 'epoch': 0.56}
Step 158: {'loss': 0.69, 'learning_rate': 0.00019527185450231326, 'epoch': 0.56}
Step 159: {'loss': 0.6099, 'learning_rate': 0.00019514425463489947, 'epoch': 0.57}
Step 160: {'loss': 0.6836, 'learning_rate': 0.00019501499864775534, 'epoch': 0.57}
Step 161: {'loss': 0.6414, 'learning_rate': 0.00019488408879076333, 'epoch': 0.58}
Step 162: {'loss': 0.7113, 'learning_rate': 0.0001947515273425939, 'epoch': 0.58}
Step 163: {'loss': 0.6815, 'learning_rate': 0.00019461731661066565, 'epoch': 0.58}
Step 164: {'loss': 0.647, 'learning_rate': 0.0001944814589311054, 'epoch': 0.59}
Step 165: {'loss': 0.6208, 'learning_rate': 0.00019434395666870734, 'epoch': 0.59}
Step 166: {'loss': 0.6045, 'learning_rate': 0.000194204812216892, 'epoch': 0.59}
Step 167: {'loss': 0.6461, 'learning_rate': 0.00019406402799766452, 'epoch': 0.6}
Step 168: {'loss': 0.6458, 'learning_rate': 0.00019392160646157242, 'epoch': 0.6}
Step 169: {'loss': 0.697, 'learning_rate': 0.00019377755008766315, 'epoch': 0.6}
Step 170: {'loss': 0.6664, 'learning_rate': 0.00019363186138344075, 'epoch': 0.61}
Step 171: {'loss': 0.6735, 'learning_rate': 0.0001934845428848222, 'epoch': 0.61}
Step 172: {'loss': 0.6561, 'learning_rate': 0.0001933355971560935, 'epoch': 0.61}
Step 173: {'loss': 0.6299, 'learning_rate': 0.00019318502678986477, 'epoch': 0.62}
Step 174: {'loss': 0.6838, 'learning_rate': 0.0001930328344070252, 'epoch': 0.62}
Step 175: {'loss': 0.6415, 'learning_rate': 0.00019287902265669764, 'epoch': 0.63}
Step 176: {'loss': 0.6482, 'learning_rate': 0.0001927235942161921, 'epoch': 0.63}
Step 177: {'loss': 0.6503, 'learning_rate': 0.00019256655179095952, 'epoch': 0.63}
Step 178: {'loss': 0.6576, 'learning_rate': 0.00019240789811454442, 'epoch': 0.64}
Step 179: {'loss': 0.6541, 'learning_rate': 0.00019224763594853745, 'epoch': 0.64}
Step 180: {'loss': 0.645, 'learning_rate': 0.00019208576808252726, 'epoch': 0.64}
Step 181: {'loss': 0.6099, 'learning_rate': 0.00019192229733405202, 'epoch': 0.65}
Step 182: {'loss': 0.6274, 'learning_rate': 0.00019175722654855032, 'epoch': 0.65}
Step 183: {'loss': 0.6514, 'learning_rate': 0.00019159055859931164, 'epoch': 0.65}
Step 184: {'loss': 0.6032, 'learning_rate': 0.00019142229638742622, 'epoch': 0.66}
Step 185: {'loss': 0.6493, 'learning_rate': 0.00019125244284173495, 'epoch': 0.66}
Step 186: {'loss': 0.7217, 'learning_rate': 0.00019108100091877787, 'epoch': 0.66}
Step 187: {'loss': 0.6328, 'learning_rate': 0.00019090797360274308, 'epoch': 0.67}
Step 188: {'loss': 0.6742, 'learning_rate': 0.00019073336390541473, 'epoch': 0.67}
Step 189: {'loss': 0.6526, 'learning_rate': 0.0001905571748661204, 'epoch': 0.68}
Step 190: {'loss': 0.6427, 'learning_rate': 0.00019037940955167845, 'epoch': 0.68}
Step 191: {'loss': 0.7108, 'learning_rate': 0.00019020007105634453, 'epoch': 0.68}
Step 192: {'loss': 0.6193, 'learning_rate': 0.00019001916250175764, 'epoch': 0.69}
Step 193: {'loss': 0.6744, 'learning_rate': 0.00018983668703688596, 'epoch': 0.69}
Step 194: {'loss': 0.6317, 'learning_rate': 0.0001896526478379719, 'epoch': 0.69}
Step 195: {'loss': 0.6855, 'learning_rate': 0.00018946704810847689, 'epoch': 0.7}
Step 196: {'loss': 0.729, 'learning_rate': 0.00018927989107902552, 'epoch': 0.7}
Step 197: {'loss': 0.6044, 'learning_rate': 0.0001890911800073495, 'epoch': 0.7}
Step 198: {'loss': 0.6566, 'learning_rate': 0.00018890091817823072, 'epoch': 0.71}
Step 199: {'loss': 0.6136, 'learning_rate': 0.00018870910890344427, 'epoch': 0.71}
Step 200: {'loss': 0.6598, 'learning_rate': 0.00018851575552170064, 'epoch': 0.71}
Step 201: {'loss': 0.6403, 'learning_rate': 0.00018832086139858775, 'epoch': 0.72}
Step 202: {'loss': 0.6764, 'learning_rate': 0.00018812442992651221, 'epoch': 0.72}
Step 203: {'loss': 0.6687, 'learning_rate': 0.00018792646452464048, 'epoch': 0.73}
Step 204: {'loss': 0.6372, 'learning_rate': 0.00018772696863883904, 'epoch': 0.73}
Step 205: {'loss': 0.6272, 'learning_rate': 0.0001875259457416148, 'epoch': 0.73}
Step 206: {'loss': 0.6208, 'learning_rate': 0.0001873233993320543, 'epoch': 0.74}
Step 207: {'loss': 0.6667, 'learning_rate': 0.00018711933293576302, 'epoch': 0.74}
Step 208: {'loss': 0.6222, 'learning_rate': 0.00018691375010480396, 'epoch': 0.74}
Step 209: {'loss': 0.6207, 'learning_rate': 0.0001867066544176358, 'epoch': 0.75}
Step 210: {'loss': 0.66, 'learning_rate': 0.00018649804947905055, 'epoch': 0.75}
Step 211: {'loss': 0.6746, 'learning_rate': 0.000186287938920111, 'epoch': 0.75}
Step 212: {'loss': 0.6534, 'learning_rate': 0.00018607632639808724, 'epoch': 0.76}
Step 213: {'loss': 0.6379, 'learning_rate': 0.00018586321559639317, 'epoch': 0.76}
Step 214: {'loss': 0.7047, 'learning_rate': 0.00018564861022452242, 'epoch': 0.76}
Step 215: {'loss': 0.6631, 'learning_rate': 0.00018543251401798374, 'epoch': 0.77}
Step 216: {'loss': 0.6609, 'learning_rate': 0.0001852149307382358, 'epoch': 0.77}
Step 217: {'loss': 0.6781, 'learning_rate': 0.00018499586417262208, 'epoch': 0.78}
Step 218: {'loss': 0.5989, 'learning_rate': 0.0001847753181343046, 'epoch': 0.78}
Step 219: {'loss': 0.703, 'learning_rate': 0.00018455329646219765, 'epoch': 0.78}
Step 220: {'loss': 0.6056, 'learning_rate': 0.00018432980302090116, 'epoch': 0.79}
Step 221: {'loss': 0.5783, 'learning_rate': 0.00018410484170063317, 'epoch': 0.79}
Step 222: {'loss': 0.6527, 'learning_rate': 0.00018387841641716223, 'epoch': 0.79}
Step 223: {'loss': 0.671, 'learning_rate': 0.00018365053111173924, 'epoch': 0.8}
Step 224: {'loss': 0.6705, 'learning_rate': 0.00018342118975102887, 'epoch': 0.8}
Step 225: {'loss': 0.6953, 'learning_rate': 0.0001831903963270404, 'epoch': 0.8}
Step 226: {'loss': 0.6881, 'learning_rate': 0.0001829581548570584, 'epoch': 0.81}
Step 227: {'loss': 0.596, 'learning_rate': 0.0001827244693835727, 'epoch': 0.81}
Step 228: {'loss': 0.6682, 'learning_rate': 0.000182489343974208, 'epoch': 0.82}
Step 229: {'loss': 0.624, 'learning_rate': 0.0001822527827216532, 'epoch': 0.82}
Step 230: {'loss': 0.6618, 'learning_rate': 0.00018201478974358995, 'epoch': 0.82}
Step 231: {'loss': 0.658, 'learning_rate': 0.0001817753691826212, 'epoch': 0.83}
Step 232: {'loss': 0.6212, 'learning_rate': 0.00018153452520619897, 'epoch': 0.83}
Step 233: {'loss': 0.6675, 'learning_rate': 0.00018129226200655176, 'epoch': 0.83}
Step 234: {'loss': 0.656, 'learning_rate': 0.00018104858380061178, 'epoch': 0.84}
Step 235: {'loss': 0.6784, 'learning_rate': 0.0001808034948299413, 'epoch': 0.84}
Step 236: {'loss': 0.6521, 'learning_rate': 0.00018055699936065896, 'epoch': 0.84}
Step 237: {'loss': 0.6222, 'learning_rate': 0.00018030910168336556, 'epoch': 0.85}
Step 238: {'loss': 0.6592, 'learning_rate': 0.00018005980611306925, 'epoch': 0.85}
Step 239: {'loss': 0.6064, 'learning_rate': 0.00017980911698911041, 'epoch': 0.85}
Step 240: {'loss': 0.6408, 'learning_rate': 0.00017955703867508633, 'epoch': 0.86}
Step 241: {'loss': 0.6947, 'learning_rate': 0.000179303575558775, 'epoch': 0.86}
Step 242: {'loss': 0.6326, 'learning_rate': 0.00017904873205205885, 'epoch': 0.87}
Step 243: {'loss': 0.6537, 'learning_rate': 0.00017879251259084804, 'epoch': 0.87}
Step 244: {'loss': 0.6318, 'learning_rate': 0.00017853492163500304, 'epoch': 0.87}
Step 245: {'loss': 0.6644, 'learning_rate': 0.00017827596366825718, 'epoch': 0.88}
Step 246: {'loss': 0.6521, 'learning_rate': 0.00017801564319813853, 'epoch': 0.88}
Step 247: {'loss': 0.6225, 'learning_rate': 0.00017775396475589144, 'epoch': 0.88}
Step 248: {'loss': 0.632, 'learning_rate': 0.00017749093289639767, 'epoch': 0.89}
Step 249: {'loss': 0.6803, 'learning_rate': 0.00017722655219809717, 'epoch': 0.89}
Step 250: {'loss': 0.6516, 'learning_rate': 0.00017696082726290823, 'epoch': 0.89}
Step 251: {'loss': 0.6075, 'learning_rate': 0.00017669376271614755, 'epoch': 0.9}
Step 252: {'loss': 0.6732, 'learning_rate': 0.00017642536320644964, 'epoch': 0.9}
Step 253: {'loss': 0.6585, 'learning_rate': 0.00017615563340568592, 'epoch': 0.9}
Step 254: {'loss': 0.6132, 'learning_rate': 0.00017588457800888342, 'epoch': 0.91}
Step 255: {'loss': 0.6065, 'learning_rate': 0.00017561220173414297, 'epoch': 0.91}
Step 256: {'loss': 0.5964, 'learning_rate': 0.00017533850932255717, 'epoch': 0.92}
Step 257: {'loss': 0.6693, 'learning_rate': 0.0001750635055381279, 'epoch': 0.92}
Step 258: {'loss': 0.6569, 'learning_rate': 0.00017478719516768324, 'epoch': 0.92}
Step 259: {'loss': 0.6271, 'learning_rate': 0.0001745095830207943, 'epoch': 0.93}
Step 260: {'loss': 0.6325, 'learning_rate': 0.00017423067392969137, 'epoch': 0.93}
Step 261: {'loss': 0.6664, 'learning_rate': 0.00017395047274917994, 'epoch': 0.93}
Step 262: {'loss': 0.6086, 'learning_rate': 0.0001736689843565562, 'epoch': 0.94}
Step 263: {'loss': 0.6406, 'learning_rate': 0.00017338621365152194, 'epoch': 0.94}
Step 264: {'loss': 0.6941, 'learning_rate': 0.0001731021655560995, 'epoch': 0.94}
Step 265: {'loss': 0.6213, 'learning_rate': 0.00017281684501454595, 'epoch': 0.95}
Step 266: {'loss': 0.6701, 'learning_rate': 0.00017253025699326706, 'epoch': 0.95}
Step 267: {'loss': 0.6585, 'learning_rate': 0.00017224240648073096, 'epoch': 0.95}
Step 268: {'loss': 0.6076, 'learning_rate': 0.0001719532984873811, 'epoch': 0.96}
Step 269: {'loss': 0.5908, 'learning_rate': 0.00017166293804554927, 'epoch': 0.96}
Step 270: {'loss': 0.5612, 'learning_rate': 0.00017137133020936782, 'epoch': 0.97}
Step 271: {'loss': 0.6233, 'learning_rate': 0.00017107848005468176, 'epoch': 0.97}
Step 272: {'loss': 0.6508, 'learning_rate': 0.00017078439267896042, 'epoch': 0.97}
Step 273: {'loss': 0.6529, 'learning_rate': 0.00017048907320120867, 'epoch': 0.98}
Step 274: {'loss': 0.6715, 'learning_rate': 0.00017019252676187788, 'epoch': 0.98}
Step 275: {'loss': 0.6232, 'learning_rate': 0.0001698947585227765, 'epoch': 0.98}
Step 276: {'loss': 0.6445, 'learning_rate': 0.0001695957736669799, 'epoch': 0.99}
Step 277: {'loss': 0.6548, 'learning_rate': 0.00016929557739874063, 'epoch': 0.99}
Step 278: {'loss': 0.6295, 'learning_rate': 0.0001689941749433974, 'epoch': 0.99}
Step 279: {'loss': 0.6554, 'learning_rate': 0.00016869157154728436, 'epoch': 1.0}
Step 280: {'loss': 0.6187, 'learning_rate': 0.00016838777247763978, 'epoch': 1.0}
Step 281: {'loss': 0.5866, 'learning_rate': 0.00016808278302251424, 'epoch': 1.0}
Step 282: {'loss': 0.6393, 'learning_rate': 0.00016777660849067868, 'epoch': 1.01}
Step 283: {'loss': 0.6018, 'learning_rate': 0.00016746925421153196, 'epoch': 1.01}
Step 284: {'loss': 0.6324, 'learning_rate': 0.00016716072553500815, 'epoch': 1.02}
Step 285: {'loss': 0.621, 'learning_rate': 0.0001668510278314833, 'epoch': 1.02}
Step 286: {'loss': 0.6698, 'learning_rate': 0.00016654016649168203, 'epoch': 1.02}
Step 287: {'loss': 0.5715, 'learning_rate': 0.0001662281469265837, 'epoch': 1.03}
Step 288: {'loss': 0.6322, 'learning_rate': 0.00016591497456732826, 'epoch': 1.03}
Step 289: {'loss': 0.6389, 'learning_rate': 0.00016560065486512156, 'epoch': 1.03}
Step 290: {'loss': 0.6332, 'learning_rate': 0.0001652851932911407, 'epoch': 1.04}
Step 291: {'loss': 0.6741, 'learning_rate': 0.00016496859533643852, 'epoch': 1.04}
Step 292: {'loss': 0.6232, 'learning_rate': 0.00016465086651184827, 'epoch': 1.04}
Step 293: {'loss': 0.6388, 'learning_rate': 0.00016433201234788758, 'epoch': 1.05}
Step 294: {'loss': 0.6062, 'learning_rate': 0.00016401203839466213, 'epoch': 1.05}
Step 295: {'loss': 0.6291, 'learning_rate': 0.0001636909502217692, 'epoch': 1.05}
Step 296: {'loss': 0.6403, 'learning_rate': 0.0001633687534182005, 'epoch': 1.06}
Step 297: {'loss': 0.5744, 'learning_rate': 0.0001630454535922452, 'epoch': 1.06}
Step 298: {'loss': 0.6373, 'learning_rate': 0.00016272105637139204, 'epoch': 1.07}
Step 299: {'loss': 0.6273, 'learning_rate': 0.0001623955674022313, 'epoch': 1.07}
Step 300: {'loss': 0.6799, 'learning_rate': 0.00016206899235035702, 'epoch': 1.07}
Step 301: {'loss': 0.6718, 'learning_rate': 0.0001617413369002677, 'epoch': 1.08}
Step 302: {'loss': 0.6368, 'learning_rate': 0.00016141260675526793, 'epoch': 1.08}
Step 303: {'loss': 0.6801, 'learning_rate': 0.0001610828076373687, 'epoch': 1.08}
Step 304: {'loss': 0.6339, 'learning_rate': 0.00016075194528718817, 'epoch': 1.09}
Step 305: {'loss': 0.6022, 'learning_rate': 0.0001604200254638514, 'epoch': 1.09}
Step 306: {'loss': 0.615, 'learning_rate': 0.00016008705394489033, 'epoch': 1.09}
Step 307: {'loss': 0.6802, 'learning_rate': 0.00015975303652614309, 'epoch': 1.1}
Step 308: {'loss': 0.5846, 'learning_rate': 0.00015941797902165324, 'epoch': 1.1}
Step 309: {'loss': 0.6419, 'learning_rate': 0.00015908188726356843, 'epoch': 1.1}
Step 310: {'loss': 0.6442, 'learning_rate': 0.000158744767102039, 'epoch': 1.11}
Step 311: {'loss': 0.639, 'learning_rate': 0.00015840662440511606, 'epoch': 1.11}
Step 312: {'loss': 0.6393, 'learning_rate': 0.00015806746505864946, 'epoch': 1.12}
Step 313: {'loss': 0.6547, 'learning_rate': 0.00015772729496618516, 'epoch': 1.12}
Step 314: {'loss': 0.6431, 'learning_rate': 0.00015738612004886267, 'epoch': 1.12}
Step 315: {'loss': 0.6642, 'learning_rate': 0.00015704394624531184, 'epoch': 1.13}
Step 316: {'loss': 0.6425, 'learning_rate': 0.00015670077951154956, 'epoch': 1.13}
Step 317: {'loss': 0.5865, 'learning_rate': 0.00015635662582087604, 'epoch': 1.13}
Step 318: {'loss': 0.6687, 'learning_rate': 0.00015601149116377093, 'epoch': 1.14}
Step 319: {'loss': 0.6258, 'learning_rate': 0.00015566538154778892, 'epoch': 1.14}
Step 320: {'loss': 0.6425, 'learning_rate': 0.0001553183029974553, 'epoch': 1.14}
Step 321: {'loss': 0.6482, 'learning_rate': 0.00015497026155416089, 'epoch': 1.15}
Step 322: {'loss': 0.6065, 'learning_rate': 0.00015462126327605717, 'epoch': 1.15}
Step 323: {'loss': 0.6179, 'learning_rate': 0.00015427131423795062, 'epoch': 1.15}
Step 324: {'loss': 0.6475, 'learning_rate': 0.00015392042053119699, 'epoch': 1.16}
Step 325: {'loss': 0.6248, 'learning_rate': 0.00015356858826359542, 'epoch': 1.16}
Step 326: {'loss': 0.6178, 'learning_rate': 0.0001532158235592819, 'epoch': 1.17}
Step 327: {'loss': 0.6407, 'learning_rate': 0.00015286213255862293, 'epoch': 1.17}
Step 328: {'loss': 0.6214, 'learning_rate': 0.0001525075214181084, 'epoch': 1.17}
Step 329: {'loss': 0.582, 'learning_rate': 0.0001521519963102445, 'epoch': 1.18}
Step 330: {'loss': 0.661, 'learning_rate': 0.00015179556342344644, 'epoch': 1.18}
Step 331: {'loss': 0.6615, 'learning_rate': 0.0001514382289619305, 'epoch': 1.18}
Step 332: {'loss': 0.6402, 'learning_rate': 0.00015107999914560618, 'epoch': 1.19}
Step 333: {'loss': 0.6675, 'learning_rate': 0.0001507208802099679, 'epoch': 1.19}
Step 334: {'loss': 0.607, 'learning_rate': 0.0001503608784059864, 'epoch': 1.19}
Step 335: {'loss': 0.6319, 'learning_rate': 0.00015000000000000001, 'epoch': 1.2}
Step 336: {'loss': 0.6521, 'learning_rate': 0.0001496382512736056, 'epoch': 1.2}
Step 337: {'loss': 0.6187, 'learning_rate': 0.00014927563852354912, 'epoch': 1.2}
Step 338: {'loss': 0.6431, 'learning_rate': 0.00014891216806161612, 'epoch': 1.21}
Step 339: {'loss': 0.6323, 'learning_rate': 0.00014854784621452175, 'epoch': 1.21}
Step 340: {'loss': 0.642, 'learning_rate': 0.0001481826793238009, 'epoch': 1.22}
Step 341: {'loss': 0.6277, 'learning_rate': 0.00014781667374569747, 'epoch': 1.22}
Step 342: {'loss': 0.6013, 'learning_rate': 0.00014744983585105386, 'epoch': 1.22}
Step 343: {'loss': 0.612, 'learning_rate': 0.0001470821720252003, 'epoch': 1.23}
Step 344: {'loss': 0.6273, 'learning_rate': 0.00014671368866784338, 'epoch': 1.23}
Step 345: {'loss': 0.659, 'learning_rate': 0.00014634439219295478, 'epoch': 1.23}
Step 346: {'loss': 0.6402, 'learning_rate': 0.00014597428902865972, 'epoch': 1.24}
Step 347: {'loss': 0.6527, 'learning_rate': 0.00014560338561712494, 'epoch': 1.24}
Step 348: {'loss': 0.5956, 'learning_rate': 0.00014523168841444657, 'epoch': 1.24}
Step 349: {'loss': 0.6303, 'learning_rate': 0.00014485920389053784, 'epoch': 1.25}
Step 350: {'loss': 0.6525, 'learning_rate': 0.00014448593852901644, 'epoch': 1.25}
Step 351: {'loss': 0.646, 'learning_rate': 0.0001441118988270916, 'epoch': 1.25}
Step 352: {'loss': 0.6285, 'learning_rate': 0.000143737091295451, 'epoch': 1.26}
Step 353: {'loss': 0.6328, 'learning_rate': 0.00014336152245814754, 'epoch': 1.26}
Step 354: {'loss': 0.5793, 'learning_rate': 0.00014298519885248573, 'epoch': 1.27}
Step 355: {'loss': 0.5991, 'learning_rate': 0.00014260812702890778, 'epoch': 1.27}
Step 356: {'loss': 0.6285, 'learning_rate': 0.0001422303135508798, 'epoch': 1.27}
Step 357: {'loss': 0.6469, 'learning_rate': 0.00014185176499477743, 'epoch': 1.28}
Step 358: {'loss': 0.6047, 'learning_rate': 0.00014147248794977126, 'epoch': 1.28}
Step 359: {'loss': 0.6166, 'learning_rate': 0.00014109248901771242, 'epoch': 1.28}
Step 360: {'loss': 0.6059, 'learning_rate': 0.0001407117748130174, 'epoch': 1.29}
Step 361: {'loss': 0.6422, 'learning_rate': 0.000140330351962553, 'epoch': 1.29}
Step 362: {'loss': 0.6449, 'learning_rate': 0.00013994822710552106, 'epoch': 1.29}
Step 363: {'loss': 0.614, 'learning_rate': 0.00013956540689334285, 'epoch': 1.3}
Step 364: {'loss': 0.62, 'learning_rate': 0.0001391818979895432, 'epoch': 1.3}
Step 365: {'loss': 0.6119, 'learning_rate': 0.00013879770706963463, 'epoch': 1.3}
Step 366: {'loss': 0.6735, 'learning_rate': 0.0001384128408210011, 'epoch': 1.31}
Step 367: {'loss': 0.5889, 'learning_rate': 0.00013802730594278162, 'epoch': 1.31}
Step 368: {'loss': 0.6861, 'learning_rate': 0.00013764110914575364, 'epoch': 1.32}
Step 369: {'loss': 0.5982, 'learning_rate': 0.00013725425715221625, 'epoch': 1.32}
Step 370: {'loss': 0.6754, 'learning_rate': 0.0001368667566958731, 'epoch': 1.32}
Step 371: {'loss': 0.6074, 'learning_rate': 0.00013647861452171535, 'epoch': 1.33}
Step 372: {'loss': 0.5928, 'learning_rate': 0.00013608983738590413, 'epoch': 1.33}
Step 373: {'loss': 0.6463, 'learning_rate': 0.00013570043205565288, 'epoch': 1.33}
Step 374: {'loss': 0.6226, 'learning_rate': 0.00013531040530910976, 'epoch': 1.34}
Step 375: {'loss': 0.6599, 'learning_rate': 0.0001349197639352395, 'epoch': 1.34}
Step 376: {'loss': 0.6419, 'learning_rate': 0.0001345285147337053, 'epoch': 1.34}
Step 377: {'loss': 0.6243, 'learning_rate': 0.00013413666451475047, 'epoch': 1.35}
Step 378: {'loss': 0.6479, 'learning_rate': 0.00013374422009907984, 'epoch': 1.35}
Step 379: {'loss': 0.6262, 'learning_rate': 0.0001333511883177411, 'epoch': 1.35}
Step 380: {'loss': 0.6516, 'learning_rate': 0.00013295757601200581, 'epoch': 1.36}
Step 381: {'loss': 0.6473, 'learning_rate': 0.00013256339003325053, 'epoch': 1.36}
Step 382: {'loss': 0.6541, 'learning_rate': 0.0001321686372428372, 'epoch': 1.37}
Step 383: {'loss': 0.6274, 'learning_rate': 0.00013177332451199403, 'epoch': 1.37}
Step 384: {'loss': 0.6313, 'learning_rate': 0.0001313774587216958, 'epoch': 1.37}
Step 385: {'loss': 0.6631, 'learning_rate': 0.00013098104676254396, 'epoch': 1.38}
Step 386: {'loss': 0.6517, 'learning_rate': 0.00013058409553464697, 'epoch': 1.38}
Step 387: {'loss': 0.654, 'learning_rate': 0.00013018661194749985, 'epoch': 1.38}
Step 388: {'loss': 0.6197, 'learning_rate': 0.00012978860291986422, 'epoch': 1.39}
Step 389: {'loss': 0.6359, 'learning_rate': 0.00012939007537964757, 'epoch': 1.39}
Step 390: {'loss': 0.6628, 'learning_rate': 0.000128991036263783, 'epoch': 1.39}
Step 391: {'loss': 0.5997, 'learning_rate': 0.00012859149251810822, 'epoch': 1.4}
Step 392: {'loss': 0.608, 'learning_rate': 0.00012819145109724476, 'epoch': 1.4}
Step 393: {'loss': 0.605, 'learning_rate': 0.0001277909189644768, 'epoch': 1.4}
Step 394: {'loss': 0.6257, 'learning_rate': 0.00012738990309163023, 'epoch': 1.41}
Step 395: {'loss': 0.6403, 'learning_rate': 0.00012698841045895095, 'epoch': 1.41}
Step 396: {'loss': 0.6049, 'learning_rate': 0.00012658644805498362, 'epoch': 1.42}
Step 397: {'loss': 0.6398, 'learning_rate': 0.0001261840228764499, 'epoch': 1.42}
Step 398: {'loss': 0.6456, 'learning_rate': 0.0001257811419281267, 'epoch': 1.42}
Step 399: {'loss': 0.6574, 'learning_rate': 0.00012537781222272422, 'epoch': 1.43}
Step 400: {'loss': 0.6317, 'learning_rate': 0.00012497404078076397, 'epoch': 1.43}
Step 401: {'loss': 0.7044, 'learning_rate': 0.00012456983463045643, 'epoch': 1.43}
Step 402: {'loss': 0.6175, 'learning_rate': 0.00012416520080757893, 'epoch': 1.44}
Step 403: {'loss': 0.6594, 'learning_rate': 0.00012376014635535285, 'epoch': 1.44}
Step 404: {'loss': 0.605, 'learning_rate': 0.00012335467832432135, 'epoch': 1.44}
Step 405: {'loss': 0.5775, 'learning_rate': 0.00012294880377222649, 'epoch': 1.45}
Step 406: {'loss': 0.6484, 'learning_rate': 0.00012254252976388636, 'epoch': 1.45}
Step 407: {'loss': 0.6191, 'learning_rate': 0.00012213586337107217, 'epoch': 1.45}
Step 408: {'loss': 0.625, 'learning_rate': 0.00012172881167238514, 'epoch': 1.46}
Step 409: {'loss': 0.6575, 'learning_rate': 0.0001213213817531333, 'epoch': 1.46}
Step 410: {'loss': 0.6408, 'learning_rate': 0.00012091358070520813, 'epoch': 1.47}
Step 411: {'loss': 0.6265, 'learning_rate': 0.0001205054156269611, 'epoch': 1.47}
Step 412: {'loss': 0.6757, 'learning_rate': 0.00012009689362308014, 'epoch': 1.47}
Step 413: {'loss': 0.627, 'learning_rate': 0.00011968802180446601, 'epoch': 1.48}
Step 414: {'loss': 0.6018, 'learning_rate': 0.00011927880728810849, 'epoch': 1.48}
Step 415: {'loss': 0.5871, 'learning_rate': 0.00011886925719696242, 'epoch': 1.48}
Step 416: {'loss': 0.6595, 'learning_rate': 0.00011845937865982393, 'epoch': 1.49}
Step 417: {'loss': 0.5872, 'learning_rate': 0.00011804917881120607, 'epoch': 1.49}
Step 418: {'loss': 0.657, 'learning_rate': 0.00011763866479121486, 'epoch': 1.49}
Step 419: {'loss': 0.648, 'learning_rate': 0.00011722784374542488, 'epoch': 1.5}
Step 420: {'loss': 0.6286, 'learning_rate': 0.00011681672282475495, 'epoch': 1.5}
Step 421: {'loss': 0.5621, 'learning_rate': 0.00011640530918534361, 'epoch': 1.5}
Step 422: {'loss': 0.6333, 'learning_rate': 0.00011599360998842454, 'epoch': 1.51}
Step 423: {'loss': 0.6658, 'learning_rate': 0.00011558163240020207, 'epoch': 1.51}
Step 424: {'loss': 0.692, 'learning_rate': 0.00011516938359172625, 'epoch': 1.52}
Step 425: {'loss': 0.6429, 'learning_rate': 0.00011475687073876806, 'epoch': 1.52}
Step 426: {'loss': 0.6137, 'learning_rate': 0.00011434410102169462, 'epoch': 1.52}
Step 427: {'loss': 0.6074, 'learning_rate': 0.00011393108162534409, 'epoch': 1.53}
Step 428: {'loss': 0.611, 'learning_rate': 0.00011351781973890068, 'epoch': 1.53}
Step 429: {'loss': 0.642, 'learning_rate': 0.00011310432255576944, 'epoch': 1.53}
Step 430: {'loss': 0.6424, 'learning_rate': 0.00011269059727345111, 'epoch': 1.54}
Step 431: {'loss': 0.6408, 'learning_rate': 0.00011227665109341685, 'epoch': 1.54}
Step 432: {'loss': 0.66, 'learning_rate': 0.00011186249122098283, 'epoch': 1.54}
Step 433: {'loss': 0.602, 'learning_rate': 0.00011144812486518477, 'epoch': 1.55}
Step 434: {'loss': 0.6008, 'learning_rate': 0.00011103355923865267, 'epoch': 1.55}
Step 435: {'loss': 0.6139, 'learning_rate': 0.00011061880155748497, 'epoch': 1.55}
Step 436: {'loss': 0.6534, 'learning_rate': 0.00011020385904112318, 'epoch': 1.56}
Step 437: {'loss': 0.5948, 'learning_rate': 0.0001097887389122261, 'epoch': 1.56}
Step 438: {'loss': 0.6574, 'learning_rate': 0.00010937344839654415, 'epoch': 1.57}
Step 439: {'loss': 0.6222, 'learning_rate': 0.00010895799472279351, 'epoch': 1.57}
Step 440: {'loss': 0.6007, 'learning_rate': 0.00010854238512253046, 'epoch': 1.57}
Step 441: {'loss': 0.6221, 'learning_rate': 0.00010812662683002528, 'epoch': 1.58}
Step 442: {'loss': 0.6262, 'learning_rate': 0.00010771072708213652, 'epoch': 1.58}
Step 443: {'loss': 0.682, 'learning_rate': 0.00010729469311818496, 'epoch': 1.58}
Step 444: {'loss': 0.6076, 'learning_rate': 0.00010687853217982759, 'epoch': 1.59}
Step 445: {'loss': 0.6379, 'learning_rate': 0.00010646225151093155, 'epoch': 1.59}
Step 446: {'loss': 0.6773, 'learning_rate': 0.00010604585835744802, 'epoch': 1.59}
Step 447: {'loss': 0.6564, 'learning_rate': 0.00010562935996728629, 'epoch': 1.6}
Step 448: {'loss': 0.5992, 'learning_rate': 0.00010521276359018728, 'epoch': 1.6}
Step 449: {'loss': 0.6296, 'learning_rate': 0.00010479607647759755, 'epoch': 1.61}
Step 450: {'loss': 0.6198, 'learning_rate': 0.0001043793058825431, 'epoch': 1.61}
Step 451: {'loss': 0.6516, 'learning_rate': 0.000103962459059503, 'epoch': 1.61}
Step 452: {'loss': 0.6233, 'learning_rate': 0.00010354554326428318, 'epoch': 1.62}
Step 453: {'loss': 0.6704, 'learning_rate': 0.00010312856575389017, 'epoch': 1.62}
Step 454: {'loss': 0.6023, 'learning_rate': 0.00010271153378640463, 'epoch': 1.62}
Step 455: {'loss': 0.6255, 'learning_rate': 0.00010229445462085532, 'epoch': 1.63}
Step 456: {'loss': 0.6744, 'learning_rate': 0.00010187733551709235, 'epoch': 1.63}
Step 457: {'loss': 0.594, 'learning_rate': 0.00010146018373566113, 'epoch': 1.63}
Step 458: {'loss': 0.6184, 'learning_rate': 0.00010104300653767582, 'epoch': 1.64}
Step 459: {'loss': 0.6214, 'learning_rate': 0.00010062581118469299, 'epoch': 1.64}
Step 460: {'loss': 0.6464, 'learning_rate': 0.00010020860493858524, 'epoch': 1.64}
Step 461: {'loss': 0.5954, 'learning_rate': 9.979139506141477e-05, 'epoch': 1.65}
Step 462: {'loss': 0.6141, 'learning_rate': 9.937418881530703e-05, 'epoch': 1.65}
Step 463: {'loss': 0.6283, 'learning_rate': 9.895699346232421e-05, 'epoch': 1.66}
Step 464: {'loss': 0.6224, 'learning_rate': 9.853981626433889e-05, 'epoch': 1.66}
Step 465: {'loss': 0.6547, 'learning_rate': 9.812266448290767e-05, 'epoch': 1.66}
Step 466: {'loss': 0.61, 'learning_rate': 9.77055453791447e-05, 'epoch': 1.67}
Step 467: {'loss': 0.5985, 'learning_rate': 9.728846621359538e-05, 'epoch': 1.67}
Step 468: {'loss': 0.6373, 'learning_rate': 9.687143424610986e-05, 'epoch': 1.67}
Step 469: {'loss': 0.6173, 'learning_rate': 9.645445673571684e-05, 'epoch': 1.68}
Step 470: {'loss': 0.6567, 'learning_rate': 9.603754094049702e-05, 'epoch': 1.68}
Step 471: {'loss': 0.6242, 'learning_rate': 9.562069411745691e-05, 'epoch': 1.68}
Step 472: {'loss': 0.6344, 'learning_rate': 9.520392352240246e-05, 'epoch': 1.69}
Step 473: {'loss': 0.6371, 'learning_rate': 9.478723640981275e-05, 'epoch': 1.69}
Step 474: {'loss': 0.6228, 'learning_rate': 9.437064003271374e-05, 'epoch': 1.69}
Step 475: {'loss': 0.6419, 'learning_rate': 9.395414164255199e-05, 'epoch': 1.7}
Step 476: {'loss': 0.6206, 'learning_rate': 9.353774848906849e-05, 'epoch': 1.7}
Step 477: {'loss': 0.6404, 'learning_rate': 9.312146782017243e-05, 'epoch': 1.71}
Step 478: {'loss': 0.623, 'learning_rate': 9.270530688181506e-05, 'epoch': 1.71}
Step 479: {'loss': 0.6437, 'learning_rate': 9.22892729178635e-05, 'epoch': 1.71}
Step 480: {'loss': 0.6535, 'learning_rate': 9.187337316997476e-05, 'epoch': 1.72}
Step 481: {'loss': 0.5956, 'learning_rate': 9.145761487746958e-05, 'epoch': 1.72}
Step 482: {'loss': 0.6524, 'learning_rate': 9.104200527720651e-05, 'epoch': 1.72}
Step 483: {'loss': 0.6269, 'learning_rate': 9.062655160345587e-05, 'epoch': 1.73}
Step 484: {'loss': 0.5732, 'learning_rate': 9.021126108777391e-05, 'epoch': 1.73}
Step 485: {'loss': 0.6303, 'learning_rate': 8.979614095887685e-05, 'epoch': 1.73}
Step 486: {'loss': 0.6645, 'learning_rate': 8.938119844251507e-05, 'epoch': 1.74}
Step 487: {'loss': 0.6198, 'learning_rate': 8.896644076134738e-05, 'epoch': 1.74}
Step 488: {'loss': 0.619, 'learning_rate': 8.855187513481527e-05, 'epoch': 1.74}
Step 489: {'loss': 0.6094, 'learning_rate': 8.813750877901723e-05, 'epoch': 1.75}
Step 490: {'loss': 0.6138, 'learning_rate': 8.772334890658316e-05, 'epoch': 1.75}
Step 491: {'loss': 0.6335, 'learning_rate': 8.73094027265489e-05, 'epoch': 1.76}
Step 492: {'loss': 0.6432, 'learning_rate': 8.68956774442306e-05, 'epoch': 1.76}
Step 493: {'loss': 0.6294, 'learning_rate': 8.648218026109937e-05, 'epoch': 1.76}
Step 494: {'loss': 0.6086, 'learning_rate': 8.606891837465595e-05, 'epoch': 1.77}
Step 495: {'loss': 0.6004, 'learning_rate': 8.565589897830543e-05, 'epoch': 1.77}
Step 496: {'loss': 0.6304, 'learning_rate': 8.524312926123199e-05, 'epoch': 1.77}
Step 497: {'loss': 0.6196, 'learning_rate': 8.483061640827382e-05, 'epoch': 1.78}
Step 498: {'loss': 0.5772, 'learning_rate': 8.441836759979795e-05, 'epoch': 1.78}
Step 499: {'loss': 0.6877, 'learning_rate': 8.400639001157549e-05, 'epoch': 1.78}
Step 500: {'loss': 0.6697, 'learning_rate': 8.359469081465645e-05, 'epoch': 1.79}
Step 501: {'loss': 0.6765, 'learning_rate': 8.318327717524508e-05, 'epoch': 1.79}
Step 502: {'loss': 0.6203, 'learning_rate': 8.277215625457516e-05, 'epoch': 1.79}
Step 503: {'loss': 0.6196, 'learning_rate': 8.236133520878517e-05, 'epoch': 1.8}
Step 504: {'loss': 0.5842, 'learning_rate': 8.195082118879397e-05, 'epoch': 1.8}
Step 505: {'loss': 0.6474, 'learning_rate': 8.15406213401761e-05, 'epoch': 1.81}
Step 506: {'loss': 0.6683, 'learning_rate': 8.11307428030376e-05, 'epoch': 1.81}
Step 507: {'loss': 0.6466, 'learning_rate': 8.072119271189156e-05, 'epoch': 1.81}
Step 508: {'loss': 0.6293, 'learning_rate': 8.031197819553397e-05, 'epoch': 1.82}
Step 509: {'loss': 0.6253, 'learning_rate': 7.990310637691987e-05, 'epoch': 1.82}
Step 510: {'loss': 0.6298, 'learning_rate': 7.949458437303891e-05, 'epoch': 1.82}
Step 511: {'loss': 0.6363, 'learning_rate': 7.908641929479187e-05, 'epoch': 1.83}
Step 512: {'loss': 0.5858, 'learning_rate': 7.867861824686669e-05, 'epoch': 1.83}
Step 513: {'loss': 0.6466, 'learning_rate': 7.827118832761487e-05, 'epoch': 1.83}
Step 514: {'loss': 0.6132, 'learning_rate': 7.786413662892784e-05, 'epoch': 1.84}
Step 515: {'loss': 0.6368, 'learning_rate': 7.745747023611367e-05, 'epoch': 1.84}
Step 516: {'loss': 0.6066, 'learning_rate': 7.705119622777351e-05, 'epoch': 1.84}
Step 517: {'loss': 0.6105, 'learning_rate': 7.664532167567864e-05, 'epoch': 1.85}
Step 518: {'loss': 0.6341, 'learning_rate': 7.623985364464716e-05, 'epoch': 1.85}
Step 519: {'loss': 0.6086, 'learning_rate': 7.583479919242108e-05, 'epoch': 1.86}
Step 520: {'loss': 0.6194, 'learning_rate': 7.543016536954355e-05, 'epoch': 1.86}
Step 521: {'loss': 0.6298, 'learning_rate': 7.502595921923606e-05, 'epoch': 1.86}
Step 522: {'loss': 0.6089, 'learning_rate': 7.46221877772758e-05, 'epoch': 1.87}
Step 523: {'loss': 0.6357, 'learning_rate': 7.421885807187332e-05, 'epoch': 1.87}
Step 524: {'loss': 0.6457, 'learning_rate': 7.38159771235501e-05, 'epoch': 1.87}
Step 525: {'loss': 0.63, 'learning_rate': 7.341355194501638e-05, 'epoch': 1.88}
Step 526: {'loss': 0.6477, 'learning_rate': 7.301158954104904e-05, 'epoch': 1.88}
Step 527: {'loss': 0.6791, 'learning_rate': 7.261009690836977e-05, 'epoch': 1.88}
Step 528: {'loss': 0.6111, 'learning_rate': 7.220908103552318e-05, 'epoch': 1.89}
Step 529: {'loss': 0.674, 'learning_rate': 7.180854890275527e-05, 'epoch': 1.89}
Step 530: {'loss': 0.6086, 'learning_rate': 7.140850748189177e-05, 'epoch': 1.89}
Step 531: {'loss': 0.6183, 'learning_rate': 7.100896373621699e-05, 'epoch': 1.9}
Step 532: {'loss': 0.6572, 'learning_rate': 7.060992462035242e-05, 'epoch': 1.9}
Step 533: {'loss': 0.6596, 'learning_rate': 7.021139708013582e-05, 'epoch': 1.91}
Step 534: {'loss': 0.6316, 'learning_rate': 6.981338805250014e-05, 'epoch': 1.91}
Step 535: {'loss': 0.5973, 'learning_rate': 6.941590446535305e-05, 'epoch': 1.91}
Step 536: {'loss': 0.5968, 'learning_rate': 6.901895323745605e-05, 'epoch': 1.92}
Step 537: {'loss': 0.6034, 'learning_rate': 6.862254127830425e-05, 'epoch': 1.92}
Step 538: {'loss': 0.5962, 'learning_rate': 6.822667548800599e-05, 'epoch': 1.92}
Step 539: {'loss': 0.6363, 'learning_rate': 6.783136275716283e-05, 'epoch': 1.93}
Step 540: {'loss': 0.6232, 'learning_rate': 6.74366099667495e-05, 'epoch': 1.93}
Step 541: {'loss': 0.6096, 'learning_rate': 6.704242398799418e-05, 'epoch': 1.93}
Step 542: {'loss': 0.6529, 'learning_rate': 6.664881168225894e-05, 'epoch': 1.94}
Step 543: {'loss': 0.6539, 'learning_rate': 6.62557799009202e-05, 'epoch': 1.94}
Step 544: {'loss': 0.6523, 'learning_rate': 6.586333548524957e-05, 'epoch': 1.94}
Step 545: {'loss': 0.6191, 'learning_rate': 6.54714852662947e-05, 'epoch': 1.95}
Step 546: {'loss': 0.5852, 'learning_rate': 6.508023606476052e-05, 'epoch': 1.95}
Step 547: {'loss': 0.6233, 'learning_rate': 6.468959469089026e-05, 'epoch': 1.96}
Step 548: {'loss': 0.6049, 'learning_rate': 6.429956794434714e-05, 'epoch': 1.96}
Step 549: {'loss': 0.5723, 'learning_rate': 6.39101626140959e-05, 'epoch': 1.96}
Step 550: {'loss': 0.625, 'learning_rate': 6.352138547828466e-05, 'epoch': 1.97}
Step 551: {'loss': 0.6381, 'learning_rate': 6.313324330412692e-05, 'epoch': 1.97}
Step 552: {'loss': 0.6227, 'learning_rate': 6.274574284778378e-05, 'epoch': 1.97}
Step 553: {'loss': 0.6147, 'learning_rate': 6.235889085424637e-05, 'epoch': 1.98}
Step 554: {'loss': 0.64, 'learning_rate': 6.19726940572184e-05, 'epoch': 1.98}
Step 555: {'loss': 0.6263, 'learning_rate': 6.158715917899893e-05, 'epoch': 1.98}
Step 556: {'loss': 0.6496, 'learning_rate': 6.120229293036539e-05, 'epoch': 1.99}
Step 557: {'loss': 0.6264, 'learning_rate': 6.081810201045681e-05, 'epoch': 1.99}
Step 558: {'loss': 0.6464, 'learning_rate': 6.0434593106657155e-05, 'epoch': 1.99}
Step 559: {'loss': 0.625, 'learning_rate': 6.005177289447894e-05, 'epoch': 2.0}
Step 560: {'loss': 0.644, 'learning_rate': 5.9669648037447015e-05, 'epoch': 2.0}
Step 561: {'loss': 0.6209, 'learning_rate': 5.9288225186982626e-05, 'epoch': 2.01}
Step 562: {'loss': 0.6474, 'learning_rate': 5.8907510982287594e-05, 'epoch': 2.01}
Step 563: {'loss': 0.6295, 'learning_rate': 5.8527512050228747e-05, 'epoch': 2.01}
Step 564: {'loss': 0.6456, 'learning_rate': 5.81482350052226e-05, 'epoch': 2.02}
Step 565: {'loss': 0.6365, 'learning_rate': 5.776968644912022e-05, 'epoch': 2.02}
Step 566: {'loss': 0.6276, 'learning_rate': 5.739187297109223e-05, 'epoch': 2.02}
Step 567: {'loss': 0.597, 'learning_rate': 5.7014801147514316e-05, 'epoch': 2.03}
Step 568: {'loss': 0.6574, 'learning_rate': 5.6638477541852465e-05, 'epoch': 2.03}
Step 569: {'loss': 0.6728, 'learning_rate': 5.6262908704549044e-05, 'epoch': 2.03}
Step 570: {'loss': 0.6053, 'learning_rate': 5.588810117290843e-05, 'epoch': 2.04}
Step 571: {'loss': 0.5832, 'learning_rate': 5.551406147098355e-05, 'epoch': 2.04}
Step 572: {'loss': 0.6065, 'learning_rate': 5.5140796109462164e-05, 'epoch': 2.04}
Step 573: {'loss': 0.6154, 'learning_rate': 5.476831158555344e-05, 'epoch': 2.05}
Step 574: {'loss': 0.6285, 'learning_rate': 5.43966143828751e-05, 'epoch': 2.05}
Step 575: {'loss': 0.6511, 'learning_rate': 5.4025710971340285e-05, 'epoch': 2.06}
Step 576: {'loss': 0.6589, 'learning_rate': 5.365560780704524e-05, 'epoch': 2.06}
Step 577: {'loss': 0.6334, 'learning_rate': 5.328631133215665e-05, 'epoch': 2.06}
Step 578: {'loss': 0.5951, 'learning_rate': 5.291782797479969e-05, 'epoch': 2.07}
Step 579: {'loss': 0.6006, 'learning_rate': 5.2550164148946155e-05, 'epoch': 2.07}
Step 580: {'loss': 0.6507, 'learning_rate': 5.218332625430258e-05, 'epoch': 2.07}
Step 581: {'loss': 0.6115, 'learning_rate': 5.181732067619913e-05, 'epoch': 2.08}
Step 582: {'loss': 0.5839, 'learning_rate': 5.145215378547825e-05, 'epoch': 2.08}
Step 583: {'loss': 0.6127, 'learning_rate': 5.1087831938383954e-05, 'epoch': 2.08}
Step 584: {'loss': 0.6195, 'learning_rate': 5.072436147645092e-05, 'epoch': 2.09}
Step 585: {'loss': 0.5923, 'learning_rate': 5.036174872639443e-05, 'epoch': 2.09}
Step 586: {'loss': 0.661, 'learning_rate': 5.000000000000002e-05, 'epoch': 2.09}
Step 587: {'loss': 0.6349, 'learning_rate': 4.963912159401363e-05, 'epoch': 2.1}
Step 588: {'loss': 0.661, 'learning_rate': 4.9279119790032135e-05, 'epoch': 2.1}
Step 589: {'loss': 0.6363, 'learning_rate': 4.892000085439383e-05, 'epoch': 2.11}
Step 590: {'loss': 0.6755, 'learning_rate': 4.856177103806954e-05, 'epoch': 2.11}
Step 591: {'loss': 0.6491, 'learning_rate': 4.82044365765536e-05, 'epoch': 2.11}
Step 592: {'loss': 0.5818, 'learning_rate': 4.784800368975556e-05, 'epoch': 2.12}
Step 593: {'loss': 0.6029, 'learning_rate': 4.7492478581891665e-05, 'epoch': 2.12}
Step 594: {'loss': 0.6441, 'learning_rate': 4.713786744137709e-05, 'epoch': 2.12}
Step 595: {'loss': 0.5643, 'learning_rate': 4.678417644071813e-05, 'epoch': 2.13}
Step 596: {'loss': 0.6212, 'learning_rate': 4.6431411736404604e-05, 'epoch': 2.13}
Step 597: {'loss': 0.635, 'learning_rate': 4.6079579468803044e-05, 'epoch': 2.13}
Step 598: {'loss': 0.624, 'learning_rate': 4.5728685762049414e-05, 'epoch': 2.14}
Step 599: {'loss': 0.6266, 'learning_rate': 4.537873672394288e-05, 'epoch': 2.14}
Step 600: {'loss': 0.6767, 'learning_rate': 4.5029738445839143e-05, 'epoch': 2.14}
Step 601: {'loss': 0.6059, 'learning_rate': 4.468169700254474e-05, 'epoch': 2.15}
Step 602: {'loss': 0.6093, 'learning_rate': 4.433461845221106e-05, 'epoch': 2.15}
Step 603: {'loss': 0.621, 'learning_rate': 4.3988508836229045e-05, 'epoch': 2.16}
Step 604: {'loss': 0.6571, 'learning_rate': 4.364337417912395e-05, 'epoch': 2.16}
Step 605: {'loss': 0.5765, 'learning_rate': 4.329922048845044e-05, 'epoch': 2.16}
Step 606: {'loss': 0.5924, 'learning_rate': 4.2956053754688174e-05, 'epoch': 2.17}
Step 607: {'loss': 0.6324, 'learning_rate': 4.2613879951137326e-05, 'epoch': 2.17}
Step 608: {'loss': 0.6639, 'learning_rate': 4.227270503381485e-05, 'epoch': 2.17}
Step 609: {'loss': 0.5987, 'learning_rate': 4.1932534941350545e-05, 'epoch': 2.18}
Step 610: {'loss': 0.6012, 'learning_rate': 4.159337559488396e-05, 'epoch': 2.18}
Step 611: {'loss': 0.6051, 'learning_rate': 4.125523289796102e-05, 'epoch': 2.18}
Step 612: {'loss': 0.6215, 'learning_rate': 4.091811273643157e-05, 'epoch': 2.19}
Step 613: {'loss': 0.6243, 'learning_rate': 4.058202097834679e-05, 'epoch': 2.19}
Step 614: {'loss': 0.6589, 'learning_rate': 4.024696347385691e-05, 'epoch': 2.19}
Step 615: {'loss': 0.6095, 'learning_rate': 3.991294605510969e-05, 'epoch': 2.2}
Step 616: {'loss': 0.638, 'learning_rate': 3.957997453614859e-05, 'epoch': 2.2}
Step 617: {'loss': 0.5978, 'learning_rate': 3.924805471281183e-05, 'epoch': 2.21}
Step 618: {'loss': 0.6072, 'learning_rate': 3.891719236263128e-05, 'epoch': 2.21}
Step 619: {'loss': 0.5484, 'learning_rate': 3.8587393244732074e-05, 'epoch': 2.21}
Step 620: {'loss': 0.6503, 'learning_rate': 3.825866309973231e-05, 'epoch': 2.22}
Step 621: {'loss': 0.6173, 'learning_rate': 3.793100764964299e-05, 'epoch': 2.22}
Step 622: {'loss': 0.6791, 'learning_rate': 3.760443259776869e-05, 'epoch': 2.22}
Step 623: {'loss': 0.6148, 'learning_rate': 3.727894362860799e-05, 'epoch': 2.23}
Step 624: {'loss': 0.6049, 'learning_rate': 3.6954546407754796e-05, 'epoch': 2.23}
Step 625: {'loss': 0.6213, 'learning_rate': 3.663124658179948e-05, 'epoch': 2.23}
Step 626: {'loss': 0.6651, 'learning_rate': 3.630904977823082e-05, 'epoch': 2.24}
Step 627: {'loss': 0.6164, 'learning_rate': 3.598796160533789e-05, 'epoch': 2.24}
Step 628: {'loss': 0.6428, 'learning_rate': 3.566798765211245e-05, 'epoch': 2.24}
Step 629: {'loss': 0.6021, 'learning_rate': 3.534913348815176e-05, 'epoch': 2.25}
Step 630: {'loss': 0.6582, 'learning_rate': 3.503140466356151e-05, 'epoch': 2.25}
Step 631: {'loss': 0.6547, 'learning_rate': 3.471480670885935e-05, 'epoch': 2.26}
Step 632: {'loss': 0.6139, 'learning_rate': 3.439934513487845e-05, 'epoch': 2.26}
Step 633: {'loss': 0.5855, 'learning_rate': 3.4085025432671746e-05, 'epoch': 2.26}
Step 634: {'loss': 0.5984, 'learning_rate': 3.37718530734163e-05, 'epoch': 2.27}
Step 635: {'loss': 0.6091, 'learning_rate': 3.345983350831798e-05, 'epoch': 2.27}
Step 636: {'loss': 0.6261, 'learning_rate': 3.314897216851673e-05, 'epoch': 2.27}
Step 637: {'loss': 0.6204, 'learning_rate': 3.283927446499185e-05, 'epoch': 2.28}
Step 638: {'loss': 0.6272, 'learning_rate': 3.253074578846805e-05, 'epoch': 2.28}
Step 639: {'loss': 0.63, 'learning_rate': 3.2223391509321334e-05, 'epoch': 2.28}
Step 640: {'loss': 0.6288, 'learning_rate': 3.191721697748576e-05, 'epoch': 2.29}
Step 641: {'loss': 0.5818, 'learning_rate': 3.161222752236024e-05, 'epoch': 2.29}
Step 642: {'loss': 0.6192, 'learning_rate': 3.130842845271564e-05, 'epoch': 2.29}
Step 643: {'loss': 0.6277, 'learning_rate': 3.100582505660263e-05, 'epoch': 2.3}
Step 644: {'loss': 0.6102, 'learning_rate': 3.070442260125939e-05, 'epoch': 2.3}
Step 645: {'loss': 0.6822, 'learning_rate': 3.0404226333020114e-05, 'epoch': 2.31}
Step 646: {'loss': 0.6215, 'learning_rate': 3.0105241477223533e-05, 'epoch': 2.31}
Step 647: {'loss': 0.6115, 'learning_rate': 2.9807473238122098e-05, 'epoch': 2.31}
Step 648: {'loss': 0.6494, 'learning_rate': 2.951092679879136e-05, 'epoch': 2.32}
Step 649: {'loss': 0.6719, 'learning_rate': 2.9215607321039606e-05, 'epoch': 2.32}
Step 650: {'loss': 0.6311, 'learning_rate': 2.8921519945318276e-05, 'epoch': 2.32}
Step 651: {'loss': 0.6214, 'learning_rate': 2.862866979063219e-05, 'epoch': 2.33}
Step 652: {'loss': 0.6413, 'learning_rate': 2.833706195445075e-05, 'epoch': 2.33}
Step 653: {'loss': 0.6408, 'learning_rate': 2.804670151261891e-05, 'epoch': 2.33}
Step 654: {'loss': 0.6384, 'learning_rate': 2.7757593519269087e-05, 'epoch': 2.34}
Step 655: {'loss': 0.627, 'learning_rate': 2.7469743006732963e-05, 'epoch': 2.34}
Step 656: {'loss': 0.6488, 'learning_rate': 2.7183154985454074e-05, 'epoch': 2.34}
Step 657: {'loss': 0.5999, 'learning_rate': 2.6897834443900526e-05, 'epoch': 2.35}
Step 658: {'loss': 0.6205, 'learning_rate': 2.6613786348478053e-05, 'epoch': 2.35}
Step 659: {'loss': 0.6635, 'learning_rate': 2.633101564344381e-05, 'epoch': 2.36}
Step 660: {'loss': 0.6319, 'learning_rate': 2.6049527250820048e-05, 'epoch': 2.36}
Step 661: {'loss': 0.5946, 'learning_rate': 2.5769326070308676e-05, 'epoch': 2.36}
Step 662: {'loss': 0.5806, 'learning_rate': 2.5490416979205757e-05, 'epoch': 2.37}
Step 663: {'loss': 0.619, 'learning_rate': 2.5212804832316784e-05, 'epoch': 2.37}
Step 664: {'loss': 0.5806, 'learning_rate': 2.493649446187213e-05, 'epoch': 2.37}
Step 665: {'loss': 0.6599, 'learning_rate': 2.4661490677442833e-05, 'epoch': 2.38}
Step 666: {'loss': 0.6168, 'learning_rate': 2.4387798265857074e-05, 'epoch': 2.38}
Step 667: {'loss': 0.6241, 'learning_rate': 2.4115421991116606e-05, 'epoch': 2.38}
Step 668: {'loss': 0.5966, 'learning_rate': 2.3844366594314093e-05, 'epoch': 2.39}
Step 669: {'loss': 0.5702, 'learning_rate': 2.3574636793550377e-05, 'epoch': 2.39}
Step 670: {'loss': 0.55, 'learning_rate': 2.3306237283852462e-05, 'epoch': 2.39}
Step 671: {'loss': 0.6139, 'learning_rate': 2.303917273709181e-05, 'epoch': 2.4}
Step 672: {'loss': 0.5863, 'learning_rate': 2.277344780190286e-05, 'epoch': 2.4}
Step 673: {'loss': 0.5881, 'learning_rate': 2.2509067103602356e-05, 'epoch': 2.41}
Step 674: {'loss': 0.6378, 'learning_rate': 2.2246035244108586e-05, 'epoch': 2.41}
Step 675: {'loss': 0.5925, 'learning_rate': 2.1984356801861506e-05, 'epoch': 2.41}
Step 676: {'loss': 0.5963, 'learning_rate': 2.1724036331742835e-05, 'epoch': 2.42}
Step 677: {'loss': 0.6519, 'learning_rate': 2.1465078364996972e-05, 'epoch': 2.42}
Step 678: {'loss': 0.6195, 'learning_rate': 2.120748740915198e-05, 'epoch': 2.42}
Step 679: {'loss': 0.5991, 'learning_rate': 2.0951267947941145e-05, 'epoch': 2.43}
Step 680: {'loss': 0.5837, 'learning_rate': 2.069642444122504e-05, 'epoch': 2.43}
Step 681: {'loss': 0.6049, 'learning_rate': 2.044296132491369e-05, 'epoch': 2.43}
Step 682: {'loss': 0.5912, 'learning_rate': 2.0190883010889615e-05, 'epoch': 2.44}
Step 683: {'loss': 0.583, 'learning_rate': 1.994019388693078e-05, 'epoch': 2.44}
Step 684: {'loss': 0.628, 'learning_rate': 1.969089831663443e-05, 'epoch': 2.45}
Step 685: {'loss': 0.578, 'learning_rate': 1.9443000639341048e-05, 'epoch': 2.45}
Step 686: {'loss': 0.6477, 'learning_rate': 1.9196505170058722e-05, 'epoch': 2.45}
Step 687: {'loss': 0.5991, 'learning_rate': 1.895141619938825e-05, 'epoch': 2.46}
Step 688: {'loss': 0.6403, 'learning_rate': 1.870773799344825e-05, 'epoch': 2.46}
Step 689: {'loss': 0.6044, 'learning_rate': 1.8465474793801084e-05, 'epoch': 2.46}
Step 690: {'loss': 0.6303, 'learning_rate': 1.822463081737883e-05, 'epoch': 2.47}
Step 691: {'loss': 0.6281, 'learning_rate': 1.798521025641009e-05, 'epoch': 2.47}
Step 692: {'loss': 0.5853, 'learning_rate': 1.774721727834684e-05, 'epoch': 2.47}
Step 693: {'loss': 0.6081, 'learning_rate': 1.7510656025792005e-05, 'epoch': 2.48}
Step 694: {'loss': 0.6488, 'learning_rate': 1.727553061642734e-05, 'epoch': 2.48}
Step 695: {'loss': 0.5608, 'learning_rate': 1.7041845142941614e-05, 'epoch': 2.48}
Step 696: {'loss': 0.6265, 'learning_rate': 1.6809603672959617e-05, 'epoch': 2.49}
Step 697: {'loss': 0.6036, 'learning_rate': 1.6578810248971144e-05, 'epoch': 2.49}
Step 698: {'loss': 0.5594, 'learning_rate': 1.6349468888260767e-05, 'epoch': 2.5}
Step 699: {'loss': 0.6214, 'learning_rate': 1.6121583582837772e-05, 'epoch': 2.5}
Step 700: {'loss': 0.6277, 'learning_rate': 1.5895158299366843e-05, 'epoch': 2.5}
Step 701: {'loss': 0.6059, 'learning_rate': 1.5670196979098838e-05, 'epoch': 2.51}
Step 702: {'loss': 0.7147, 'learning_rate': 1.5446703537802344e-05, 'epoch': 2.51}
Step 703: {'loss': 0.6332, 'learning_rate': 1.5224681865695422e-05, 'epoch': 2.51}
Step 704: {'loss': 0.6488, 'learning_rate': 1.5004135827377907e-05, 'epoch': 2.52}
Step 705: {'loss': 0.6394, 'learning_rate': 1.4785069261764184e-05, 'epoch': 2.52}
Step 706: {'loss': 0.6761, 'learning_rate': 1.456748598201626e-05, 'epoch': 2.52}
Step 707: {'loss': 0.5954, 'learning_rate': 1.4351389775477575e-05, 'epoch': 2.53}
Step 708: {'loss': 0.638, 'learning_rate': 1.413678440360684e-05, 'epoch': 2.53}
Step 709: {'loss': 0.6145, 'learning_rate': 1.392367360191278e-05, 'epoch': 2.53}
Step 710: {'loss': 0.6575, 'learning_rate': 1.3712061079889016e-05, 'epoch': 2.54}
Step 711: {'loss': 0.6087, 'learning_rate': 1.3501950520949436e-05, 'epoch': 2.54}
Step 712: {'loss': 0.6399, 'learning_rate': 1.3293345582364225e-05, 'epoch': 2.55}
Step 713: {'loss': 0.6417, 'learning_rate': 1.3086249895196046e-05, 'epoch': 2.55}
Step 714: {'loss': 0.6144, 'learning_rate': 1.2880667064237007e-05, 'epoch': 2.55}
Step 715: {'loss': 0.6312, 'learning_rate': 1.2676600667945715e-05, 'epoch': 2.56}
Step 716: {'loss': 0.6078, 'learning_rate': 1.2474054258385226e-05, 'epoch': 2.56}
Step 717: {'loss': 0.6296, 'learning_rate': 1.2273031361160958e-05, 'epoch': 2.56}
Step 718: {'loss': 0.5947, 'learning_rate': 1.2073535475359531e-05, 'epoch': 2.57}
Step 719: {'loss': 0.5893, 'learning_rate': 1.1875570073487786e-05, 'epoch': 2.57}
Step 720: {'loss': 0.6022, 'learning_rate': 1.1679138601412255e-05, 'epoch': 2.57}
Step 721: {'loss': 0.6198, 'learning_rate': 1.1484244478299366e-05, 'epoch': 2.58}
Step 722: {'loss': 0.6372, 'learning_rate': 1.1290891096555745e-05, 'epoch': 2.58}
Step 723: {'loss': 0.6657, 'learning_rate': 1.1099081821769297e-05, 'epoch': 2.58}
Step 724: {'loss': 0.64, 'learning_rate': 1.090881999265051e-05, 'epoch': 2.59}
Step 725: {'loss': 0.6589, 'learning_rate': 1.072010892097447e-05, 'epoch': 2.59}
Step 726: {'loss': 0.64, 'learning_rate': 1.0532951891523124e-05, 'epoch': 2.6}
Step 727: {'loss': 0.6485, 'learning_rate': 1.034735216202809e-05, 'epoch': 2.6}
Step 728: {'loss': 0.6354, 'learning_rate': 1.0163312963114036e-05, 'epoch': 2.6}
Step 729: {'loss': 0.606, 'learning_rate': 9.980837498242356e-06, 'epoch': 2.61}
Step 730: {'loss': 0.6436, 'learning_rate': 9.79992894365549e-06, 'epoch': 2.61}
Step 731: {'loss': 0.5672, 'learning_rate': 9.620590448321554e-06, 'epoch': 2.61}
Step 732: {'loss': 0.6235, 'learning_rate': 9.442825133879607e-06, 'epoch': 2.62}
Step 733: {'loss': 0.5757, 'learning_rate': 9.266636094585302e-06, 'epoch': 2.62}
Step 734: {'loss': 0.6195, 'learning_rate': 9.092026397256914e-06, 'epoch': 2.62}
Step 735: {'loss': 0.6492, 'learning_rate': 8.918999081222156e-06, 'epoch': 2.63}
Step 736: {'loss': 0.654, 'learning_rate': 8.747557158265074e-06, 'epoch': 2.63}
Step 737: {'loss': 0.5944, 'learning_rate': 8.577703612573784e-06, 'epoch': 2.63}
Step 738: {'loss': 0.6367, 'learning_rate': 8.4094414006884e-06, 'epoch': 2.64}
Step 739: {'loss': 0.6105, 'learning_rate': 8.24277345144967e-06, 'epoch': 2.64}
Step 740: {'loss': 0.5987, 'learning_rate': 8.077702665947973e-06, 'epoch': 2.65}
Step 741: {'loss': 0.6199, 'learning_rate': 7.914231917472747e-06, 'epoch': 2.65}
Step 742: {'loss': 0.6094, 'learning_rate': 7.75236405146258e-06, 'epoch': 2.65}
Step 743: {'loss': 0.6301, 'learning_rate': 7.592101885455593e-06, 'epoch': 2.66}
Step 744: {'loss': 0.608, 'learning_rate': 7.433448209040495e-06, 'epoch': 2.66}
Step 745: {'loss': 0.5986, 'learning_rate': 7.276405783807894e-06, 'epoch': 2.66}
Step 746: {'loss': 0.6394, 'learning_rate': 7.12097734330236e-06, 'epoch': 2.67}
Step 747: {'loss': 0.5977, 'learning_rate': 6.967165592974789e-06, 'epoch': 2.67}
Step 748: {'loss': 0.6205, 'learning_rate': 6.814973210135256e-06, 'epoch': 2.67}
Step 749: {'loss': 0.6438, 'learning_rate': 6.6644028439065145e-06, 'epoch': 2.68}
Step 750: {'loss': 0.6049, 'learning_rate': 6.515457115177803e-06, 'epoch': 2.68}
Step 751: {'loss': 0.6082, 'learning_rate': 6.368138616559283e-06, 'epoch': 2.68}
Step 752: {'loss': 0.6427, 'learning_rate': 6.222449912336859e-06, 'epoch': 2.69}
Step 753: {'loss': 0.6131, 'learning_rate': 6.078393538427574e-06, 'epoch': 2.69}
Step 754: {'loss': 0.6313, 'learning_rate': 5.93597200233551e-06, 'epoch': 2.7}
Step 755: {'loss': 0.5847, 'learning_rate': 5.795187783108003e-06, 'epoch': 2.7}
Step 756: {'loss': 0.6481, 'learning_rate': 5.6560433312926815e-06, 'epoch': 2.7}
Step 757: {'loss': 0.6119, 'learning_rate': 5.518541068894623e-06, 'epoch': 2.71}
Step 758: {'loss': 0.7053, 'learning_rate': 5.3826833893343755e-06, 'epoch': 2.71}
Step 759: {'loss': 0.6381, 'learning_rate': 5.248472657406123e-06, 'epoch': 2.71}
Step 760: {'loss': 0.6825, 'learning_rate': 5.115911209236668e-06, 'epoch': 2.72}
Step 761: {'loss': 0.6502, 'learning_rate': 4.985001352244667e-06, 'epoch': 2.72}
Step 762: {'loss': 0.6497, 'learning_rate': 4.8557453651005395e-06, 'epoch': 2.72}
Step 763: {'loss': 0.5696, 'learning_rate': 4.728145497686753e-06, 'epoch': 2.73}
Step 764: {'loss': 0.6559, 'learning_rate': 4.60220397105866e-06, 'epoch': 2.73}
Step 765: {'loss': 0.6216, 'learning_rate': 4.477922977405913e-06, 'epoch': 2.73}
Step 766: {'loss': 0.5874, 'learning_rate': 4.355304680014171e-06, 'epoch': 2.74}
Step 767: {'loss': 0.608, 'learning_rate': 4.234351213227605e-06, 'epoch': 2.74}
Step 768: {'loss': 0.6242, 'learning_rate': 4.1150646824116065e-06, 'epoch': 2.75}
Step 769: {'loss': 0.652, 'learning_rate': 3.997447163916224e-06, 'epoch': 2.75}
Step 770: {'loss': 0.6572, 'learning_rate': 3.881500705039997e-06, 'epoch': 2.75}
Step 771: {'loss': 0.6308, 'learning_rate': 3.7672273239942932e-06, 'epoch': 2.76}
Step 772: {'loss': 0.6317, 'learning_rate': 3.654629009868249e-06, 'epoch': 2.76}
Step 773: {'loss': 0.6061, 'learning_rate': 3.5437077225940694e-06, 'epoch': 2.76}
Step 774: {'loss': 0.6426, 'learning_rate': 3.4344653929129555e-06, 'epoch': 2.77}
Step 775: {'loss': 0.6412, 'learning_rate': 3.326903922341473e-06, 'epoch': 2.77}
Step 776: {'loss': 0.6174, 'learning_rate': 3.221025183138493e-06, 'epoch': 2.77}
Step 777: {'loss': 0.6366, 'learning_rate': 3.116831018272581e-06, 'epoch': 2.78}
Step 778: {'loss': 0.6046, 'learning_rate': 3.0143232413898605e-06, 'epoch': 2.78}
Step 779: {'loss': 0.5527, 'learning_rate': 2.9135036367825773e-06, 'epoch': 2.78}
Step 780: {'loss': 0.6179, 'learning_rate': 2.8143739593578856e-06, 'epoch': 2.79}
Step 781: {'loss': 0.6199, 'learning_rate': 2.7169359346074343e-06, 'epoch': 2.79}
Step 782: {'loss': 0.606, 'learning_rate': 2.621191258577238e-06, 'epoch': 2.8}
Step 783: {'loss': 0.5913, 'learning_rate': 2.527141597838212e-06, 'epoch': 2.8}
Step 784: {'loss': 0.5956, 'learning_rate': 2.4347885894571487e-06, 'epoch': 2.8}
Step 785: {'loss': 0.6507, 'learning_rate': 2.344133840968188e-06, 'epoch': 2.81}
Step 786: {'loss': 0.6588, 'learning_rate': 2.2551789303449034e-06, 'epoch': 2.81}
Step 787: {'loss': 0.6022, 'learning_rate': 2.1679254059727595e-06, 'epoch': 2.81}
Step 788: {'loss': 0.6015, 'learning_rate': 2.082374786622232e-06, 'epoch': 2.82}
Step 789: {'loss': 0.5789, 'learning_rate': 1.998528561422297e-06, 'epoch': 2.82}
Step 790: {'loss': 0.6359, 'learning_rate': 1.9163881898345835e-06, 'epoch': 2.82}
Step 791: {'loss': 0.5791, 'learning_rate': 1.8359551016279398e-06, 'epoch': 2.83}
Step 792: {'loss': 0.636, 'learning_rate': 1.7572306968535179e-06, 'epoch': 2.83}
Step 793: {'loss': 0.6144, 'learning_rate': 1.68021634582044e-06, 'epoch': 2.83}
Step 794: {'loss': 0.6267, 'learning_rate': 1.604913389071927e-06, 'epoch': 2.84}
Step 795: {'loss': 0.5844, 'learning_rate': 1.5313231373619952e-06, 'epoch': 2.84}
Step 796: {'loss': 0.6276, 'learning_rate': 1.459446871632586e-06, 'epoch': 2.85}
Step 797: {'loss': 0.6205, 'learning_rate': 1.389285842991339e-06, 'epoch': 2.85}
Step 798: {'loss': 0.5974, 'learning_rate': 1.3208412726897323e-06, 'epoch': 2.85}
Step 799: {'loss': 0.6187, 'learning_rate': 1.2541143521019095e-06, 'epoch': 2.86}
Step 800: {'loss': 0.567, 'learning_rate': 1.1891062427038746e-06, 'epoch': 2.86}
Step 801: {'loss': 0.6322, 'learning_rate': 1.1258180760533089e-06, 'epoch': 2.86}
Step 802: {'loss': 0.5941, 'learning_rate': 1.0642509537698964e-06, 'epoch': 2.87}
Step 803: {'loss': 0.609, 'learning_rate': 1.004405947516085e-06, 'epoch': 2.87}
Step 804: {'loss': 0.6045, 'learning_rate': 9.462840989784671e-07, 'epoch': 2.87}
Step 805: {'loss': 0.6104, 'learning_rate': 8.898864198496836e-07, 'epoch': 2.88}
Step 806: {'loss': 0.6249, 'learning_rate': 8.352138918107377e-07, 'epoch': 2.88}
Step 807: {'loss': 0.6144, 'learning_rate': 7.822674665139751e-07, 'epoch': 2.88}
Step 808: {'loss': 0.6128, 'learning_rate': 7.310480655664865e-07, 'epoch': 2.89}
Step 809: {'loss': 0.6209, 'learning_rate': 6.815565805140644e-07, 'epoch': 2.89}
Step 810: {'loss': 0.5661, 'learning_rate': 6.337938728257054e-07, 'epoch': 2.9}
Step 811: {'loss': 0.6453, 'learning_rate': 5.877607738785984e-07, 'epoch': 2.9}
Step 812: {'loss': 0.612, 'learning_rate': 5.434580849436378e-07, 'epoch': 2.9}
Step 813: {'loss': 0.6282, 'learning_rate': 5.008865771715221e-07, 'epoch': 2.91}
Step 814: {'loss': 0.624, 'learning_rate': 4.600469915792882e-07, 'epoch': 2.91}
Step 815: {'loss': 0.6834, 'learning_rate': 4.2094003903743186e-07, 'epoch': 2.91}
Step 816: {'loss': 0.6097, 'learning_rate': 3.83566400257529e-07, 'epoch': 2.92}
Step 817: {'loss': 0.6352, 'learning_rate': 3.4792672578038977e-07, 'epoch': 2.92}
Step 818: {'loss': 0.6286, 'learning_rate': 3.140216359647452e-07, 'epoch': 2.92}
Step 819: {'loss': 0.5819, 'learning_rate': 2.8185172097641156e-07, 'epoch': 2.93}
Step 820: {'loss': 0.6057, 'learning_rate': 2.5141754077807613e-07, 'epoch': 2.93}
Step 821: {'loss': 0.6557, 'learning_rate': 2.2271962511948296e-07, 'epoch': 2.93}
Step 822: {'loss': 0.5974, 'learning_rate': 1.957584735282847e-07, 'epoch': 2.94}
Step 823: {'loss': 0.6271, 'learning_rate': 1.705345553012716e-07, 'epoch': 2.94}
Step 824: {'loss': 0.6415, 'learning_rate': 1.4704830949627824e-07, 'epoch': 2.95}
Step 825: {'loss': 0.5958, 'learning_rate': 1.2530014492446728e-07, 'epoch': 2.95}
Step 826: {'loss': 0.6315, 'learning_rate': 1.0529044014329081e-07, 'epoch': 2.95}
Step 827: {'loss': 0.6627, 'learning_rate': 8.701954344980667e-08, 'epoch': 2.96}
Step 828: {'loss': 0.6161, 'learning_rate': 7.048777287472774e-08, 'epoch': 2.96}
Step 829: {'loss': 0.5863, 'learning_rate': 5.569541617679308e-08, 'epoch': 2.96}
Step 830: {'loss': 0.5971, 'learning_rate': 4.264273083778303e-08, 'epoch': 2.97}
Step 831: {'loss': 0.639, 'learning_rate': 3.132994405808942e-08, 'epoch': 2.97}
Step 832: {'loss': 0.6287, 'learning_rate': 2.1757252752685476e-08, 'epoch': 2.97}
Step 833: {'loss': 0.5972, 'learning_rate': 1.3924823547750709e-08, 'epoch': 2.98}
Step 834: {'loss': 0.5374, 'learning_rate': 7.83279277773996e-09, 'epoch': 2.98}
Step 835: {'loss': 0.6091, 'learning_rate': 3.4812664830186082e-09, 'epoch': 2.98}
Step 836: {'loss': 0.6287, 'learning_rate': 8.703204080418026e-10, 'epoch': 2.99}
Step 837: {'loss': 0.6107, 'learning_rate': 0.0, 'epoch': 2.99}
Step 837: {'train_runtime': 1755.6035, 'train_samples_per_second': 15.289, 'train_steps_per_second': 0.477, 'total_flos': 0.0, 'train_loss': 0.6861013972346216, 'epoch': 2.99}
