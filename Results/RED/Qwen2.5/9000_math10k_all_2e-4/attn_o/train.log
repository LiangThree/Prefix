Step 1: {'loss': 1.7278, 'learning_rate': 2.3809523809523808e-06, 'epoch': 0.0}
Step 2: {'loss': 1.7246, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.01}
Step 3: {'loss': 1.6422, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.01}
Step 4: {'loss': 1.7968, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.01}
Step 5: {'loss': 1.6011, 'learning_rate': 1.1904761904761905e-05, 'epoch': 0.02}
Step 6: {'loss': 1.6807, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.02}
Step 7: {'loss': 1.6351, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}
Step 8: {'loss': 1.657, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.03}
Step 9: {'loss': 1.625, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.03}
Step 10: {'loss': 1.8368, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.04}
Step 11: {'loss': 1.6635, 'learning_rate': 2.6190476190476192e-05, 'epoch': 0.04}
Step 12: {'loss': 1.6438, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.04}
Step 13: {'loss': 1.6613, 'learning_rate': 3.095238095238095e-05, 'epoch': 0.05}
Step 14: {'loss': 1.6157, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.05}
Step 15: {'loss': 1.7134, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.05}
Step 16: {'loss': 1.7576, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.06}
Step 17: {'loss': 1.7461, 'learning_rate': 4.047619047619048e-05, 'epoch': 0.06}
Step 18: {'loss': 1.7507, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.06}
Step 19: {'loss': 1.6057, 'learning_rate': 4.523809523809524e-05, 'epoch': 0.07}
Step 20: {'loss': 1.5354, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.07}
Step 21: {'loss': 1.5323, 'learning_rate': 5e-05, 'epoch': 0.08}
Step 22: {'loss': 1.5348, 'learning_rate': 5.2380952380952384e-05, 'epoch': 0.08}
Step 23: {'loss': 1.5902, 'learning_rate': 5.4761904761904766e-05, 'epoch': 0.08}
Step 24: {'loss': 1.7106, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.09}
Step 25: {'loss': 1.4624, 'learning_rate': 5.9523809523809524e-05, 'epoch': 0.09}
Step 26: {'loss': 1.6394, 'learning_rate': 6.19047619047619e-05, 'epoch': 0.09}
Step 27: {'loss': 1.4354, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.1}
Step 28: {'loss': 1.4738, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.1}
Step 29: {'loss': 1.4524, 'learning_rate': 6.904761904761905e-05, 'epoch': 0.1}
Step 30: {'loss': 1.4501, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.11}
Step 31: {'loss': 1.4682, 'learning_rate': 7.380952380952382e-05, 'epoch': 0.11}
Step 32: {'loss': 1.4962, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.11}
Step 33: {'loss': 1.4883, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.12}
Step 34: {'loss': 1.6152, 'learning_rate': 8.095238095238096e-05, 'epoch': 0.12}
Step 35: {'loss': 1.4976, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.13}
Step 36: {'loss': 1.4734, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.13}
Step 37: {'loss': 1.6423, 'learning_rate': 8.80952380952381e-05, 'epoch': 0.13}
Step 38: {'loss': 1.3407, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.14}
Step 39: {'loss': 1.4445, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.14}
Step 40: {'loss': 1.4448, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.14}
Step 41: {'loss': 1.4617, 'learning_rate': 9.761904761904762e-05, 'epoch': 0.15}
Step 42: {'loss': 1.4642, 'learning_rate': 0.0001, 'epoch': 0.15}
Step 43: {'loss': 1.4822, 'learning_rate': 0.00010238095238095237, 'epoch': 0.15}
Step 44: {'loss': 1.4233, 'learning_rate': 0.00010476190476190477, 'epoch': 0.16}
Step 45: {'loss': 1.2669, 'learning_rate': 0.00010714285714285715, 'epoch': 0.16}
Step 46: {'loss': 1.3994, 'learning_rate': 0.00010952380952380953, 'epoch': 0.16}
Step 47: {'loss': 1.214, 'learning_rate': 0.00011190476190476191, 'epoch': 0.17}
Step 48: {'loss': 1.3176, 'learning_rate': 0.00011428571428571428, 'epoch': 0.17}
Step 49: {'loss': 1.5124, 'learning_rate': 0.00011666666666666668, 'epoch': 0.18}
Step 50: {'loss': 1.2709, 'learning_rate': 0.00011904761904761905, 'epoch': 0.18}
Step 51: {'loss': 1.2812, 'learning_rate': 0.00012142857142857143, 'epoch': 0.18}
Step 52: {'loss': 1.4339, 'learning_rate': 0.0001238095238095238, 'epoch': 0.19}
Step 53: {'loss': 1.1978, 'learning_rate': 0.0001261904761904762, 'epoch': 0.19}
Step 54: {'loss': 1.1611, 'learning_rate': 0.00012857142857142858, 'epoch': 0.19}
Step 55: {'loss': 1.357, 'learning_rate': 0.00013095238095238096, 'epoch': 0.2}
Step 56: {'loss': 1.2793, 'learning_rate': 0.00013333333333333334, 'epoch': 0.2}
Step 57: {'loss': 1.2676, 'learning_rate': 0.00013571428571428572, 'epoch': 0.2}
Step 58: {'loss': 1.2581, 'learning_rate': 0.0001380952380952381, 'epoch': 0.21}
Step 59: {'loss': 1.2878, 'learning_rate': 0.00014047619047619049, 'epoch': 0.21}
Step 60: {'loss': 1.2358, 'learning_rate': 0.00014285714285714287, 'epoch': 0.22}
Step 61: {'loss': 1.254, 'learning_rate': 0.00014523809523809525, 'epoch': 0.22}
Step 62: {'loss': 1.1911, 'learning_rate': 0.00014761904761904763, 'epoch': 0.22}
Step 63: {'loss': 1.1154, 'learning_rate': 0.00015000000000000001, 'epoch': 0.23}
Step 64: {'loss': 1.2586, 'learning_rate': 0.00015238095238095237, 'epoch': 0.23}
Step 65: {'loss': 1.1403, 'learning_rate': 0.00015476190476190478, 'epoch': 0.23}
Step 66: {'loss': 1.144, 'learning_rate': 0.00015714285714285716, 'epoch': 0.24}
Step 67: {'loss': 1.0872, 'learning_rate': 0.00015952380952380954, 'epoch': 0.24}
Step 68: {'loss': 1.1154, 'learning_rate': 0.00016190476190476192, 'epoch': 0.24}
Step 69: {'loss': 1.1322, 'learning_rate': 0.00016428571428571428, 'epoch': 0.25}
Step 70: {'loss': 1.0801, 'learning_rate': 0.0001666666666666667, 'epoch': 0.25}
Step 71: {'loss': 1.0813, 'learning_rate': 0.00016904761904761904, 'epoch': 0.25}
Step 72: {'loss': 1.0729, 'learning_rate': 0.00017142857142857143, 'epoch': 0.26}
Step 73: {'loss': 1.0579, 'learning_rate': 0.00017380952380952383, 'epoch': 0.26}
Step 74: {'loss': 0.9906, 'learning_rate': 0.0001761904761904762, 'epoch': 0.27}
Step 75: {'loss': 1.0469, 'learning_rate': 0.0001785714285714286, 'epoch': 0.27}
Step 76: {'loss': 0.9859, 'learning_rate': 0.00018095238095238095, 'epoch': 0.27}
Step 77: {'loss': 0.9541, 'learning_rate': 0.00018333333333333334, 'epoch': 0.28}
Step 78: {'loss': 1.0503, 'learning_rate': 0.00018571428571428572, 'epoch': 0.28}
Step 79: {'loss': 1.0421, 'learning_rate': 0.0001880952380952381, 'epoch': 0.28}
Step 80: {'loss': 0.9481, 'learning_rate': 0.00019047619047619048, 'epoch': 0.29}
Step 81: {'loss': 0.984, 'learning_rate': 0.00019285714285714286, 'epoch': 0.29}
Step 82: {'loss': 1.0054, 'learning_rate': 0.00019523809523809525, 'epoch': 0.29}
Step 83: {'loss': 0.9253, 'learning_rate': 0.00019761904761904763, 'epoch': 0.3}
Step 84: {'loss': 0.9054, 'learning_rate': 0.0002, 'epoch': 0.3}
Step 85: {'loss': 0.9258, 'learning_rate': 0.00019999912967959196, 'epoch': 0.3}
Step 86: {'loss': 0.8804, 'learning_rate': 0.000199996518733517, 'epoch': 0.31}
Step 87: {'loss': 0.9267, 'learning_rate': 0.00019999216720722226, 'epoch': 0.31}
Step 88: {'loss': 0.8404, 'learning_rate': 0.00019998607517645228, 'epoch': 0.32}
Step 89: {'loss': 0.8372, 'learning_rate': 0.0001999782427472473, 'epoch': 0.32}
Step 90: {'loss': 0.8684, 'learning_rate': 0.0001999686700559419, 'epoch': 0.32}
Step 91: {'loss': 0.845, 'learning_rate': 0.00019995735726916224, 'epoch': 0.33}
Step 92: {'loss': 0.9473, 'learning_rate': 0.00019994430458382322, 'epoch': 0.33}
Step 93: {'loss': 0.87, 'learning_rate': 0.00019992951222712527, 'epoch': 0.33}
Step 94: {'loss': 0.9596, 'learning_rate': 0.0001999129804565502, 'epoch': 0.34}
Step 95: {'loss': 0.8197, 'learning_rate': 0.00019989470955985672, 'epoch': 0.34}
Step 96: {'loss': 0.7546, 'learning_rate': 0.00019987469985507553, 'epoch': 0.34}
Step 97: {'loss': 0.7334, 'learning_rate': 0.00019985295169050373, 'epoch': 0.35}
Step 98: {'loss': 0.812, 'learning_rate': 0.00019982946544469873, 'epoch': 0.35}
Step 99: {'loss': 0.8194, 'learning_rate': 0.00019980424152647171, 'epoch': 0.35}
Step 100: {'loss': 0.7178, 'learning_rate': 0.00019977728037488053, 'epoch': 0.36}
Step 101: {'loss': 0.7731, 'learning_rate': 0.0001997485824592219, 'epoch': 0.36}
Step 102: {'loss': 0.7607, 'learning_rate': 0.0001997181482790236, 'epoch': 0.37}
Step 103: {'loss': 0.7778, 'learning_rate': 0.00019968597836403528, 'epoch': 0.37}
Step 104: {'loss': 0.7796, 'learning_rate': 0.00019965207327421962, 'epoch': 0.37}
Step 105: {'loss': 0.829, 'learning_rate': 0.0001996164335997425, 'epoch': 0.38}
Step 106: {'loss': 0.6995, 'learning_rate': 0.00019957905996096257, 'epoch': 0.38}
Step 107: {'loss': 0.802, 'learning_rate': 0.00019953995300842073, 'epoch': 0.38}
Step 108: {'loss': 0.7658, 'learning_rate': 0.00019949911342282848, 'epoch': 0.39}
Step 109: {'loss': 0.7737, 'learning_rate': 0.00019945654191505638, 'epoch': 0.39}
Step 110: {'loss': 0.8119, 'learning_rate': 0.0001994122392261214, 'epoch': 0.39}
Step 111: {'loss': 0.702, 'learning_rate': 0.0001993662061271743, 'epoch': 0.4}
Step 112: {'loss': 0.6699, 'learning_rate': 0.00019931844341948595, 'epoch': 0.4}
Step 113: {'loss': 0.7024, 'learning_rate': 0.00019926895193443352, 'epoch': 0.41}
Step 114: {'loss': 0.6973, 'learning_rate': 0.00019921773253348603, 'epoch': 0.41}
Step 115: {'loss': 0.7192, 'learning_rate': 0.00019916478610818928, 'epoch': 0.41}
Step 116: {'loss': 0.7412, 'learning_rate': 0.0001991101135801503, 'epoch': 0.42}
Step 117: {'loss': 0.6597, 'learning_rate': 0.00019905371590102155, 'epoch': 0.42}
Step 118: {'loss': 0.7474, 'learning_rate': 0.00019899559405248392, 'epoch': 0.42}
Step 119: {'loss': 0.6926, 'learning_rate': 0.00019893574904623012, 'epoch': 0.43}
Step 120: {'loss': 0.6762, 'learning_rate': 0.0001988741819239467, 'epoch': 0.43}
Step 121: {'loss': 0.697, 'learning_rate': 0.00019881089375729615, 'epoch': 0.43}
Step 122: {'loss': 0.7009, 'learning_rate': 0.0001987458856478981, 'epoch': 0.44}
Step 123: {'loss': 0.6368, 'learning_rate': 0.0001986791587273103, 'epoch': 0.44}
Step 124: {'loss': 0.7132, 'learning_rate': 0.00019861071415700867, 'epoch': 0.44}
Step 125: {'loss': 0.657, 'learning_rate': 0.00019854055312836742, 'epoch': 0.45}
Step 126: {'loss': 0.6558, 'learning_rate': 0.00019846867686263803, 'epoch': 0.45}
Step 127: {'loss': 0.6441, 'learning_rate': 0.0001983950866109281, 'epoch': 0.46}
Step 128: {'loss': 0.6171, 'learning_rate': 0.00019831978365417955, 'epoch': 0.46}
Step 129: {'loss': 0.5882, 'learning_rate': 0.0001982427693031465, 'epoch': 0.46}
Step 130: {'loss': 0.5721, 'learning_rate': 0.00019816404489837207, 'epoch': 0.47}
Step 131: {'loss': 0.6725, 'learning_rate': 0.00019808361181016543, 'epoch': 0.47}
Step 132: {'loss': 0.6663, 'learning_rate': 0.00019800147143857771, 'epoch': 0.47}
Step 133: {'loss': 0.6104, 'learning_rate': 0.00019791762521337777, 'epoch': 0.48}
Step 134: {'loss': 0.6023, 'learning_rate': 0.00019783207459402727, 'epoch': 0.48}
Step 135: {'loss': 0.6317, 'learning_rate': 0.00019774482106965513, 'epoch': 0.48}
Step 136: {'loss': 0.6727, 'learning_rate': 0.00019765586615903182, 'epoch': 0.49}
Step 137: {'loss': 0.6242, 'learning_rate': 0.00019756521141054288, 'epoch': 0.49}
Step 138: {'loss': 0.5897, 'learning_rate': 0.00019747285840216182, 'epoch': 0.49}
Step 139: {'loss': 0.577, 'learning_rate': 0.0001973788087414228, 'epoch': 0.5}
Step 140: {'loss': 0.6652, 'learning_rate': 0.0001972830640653926, 'epoch': 0.5}
Step 141: {'loss': 0.6275, 'learning_rate': 0.00019718562604064213, 'epoch': 0.51}
Step 142: {'loss': 0.6369, 'learning_rate': 0.00019708649636321744, 'epoch': 0.51}
Step 143: {'loss': 0.584, 'learning_rate': 0.00019698567675861014, 'epoch': 0.51}
Step 144: {'loss': 0.6109, 'learning_rate': 0.00019688316898172742, 'epoch': 0.52}
Step 145: {'loss': 0.6574, 'learning_rate': 0.00019677897481686153, 'epoch': 0.52}
Step 146: {'loss': 0.584, 'learning_rate': 0.00019667309607765857, 'epoch': 0.52}
Step 147: {'loss': 0.5976, 'learning_rate': 0.00019656553460708706, 'epoch': 0.53}
Step 148: {'loss': 0.5549, 'learning_rate': 0.00019645629227740594, 'epoch': 0.53}
Step 149: {'loss': 0.6116, 'learning_rate': 0.00019634537099013177, 'epoch': 0.53}
Step 150: {'loss': 0.5492, 'learning_rate': 0.00019623277267600574, 'epoch': 0.54}
Step 151: {'loss': 0.5811, 'learning_rate': 0.00019611849929496, 'epoch': 0.54}
Step 152: {'loss': 0.5849, 'learning_rate': 0.00019600255283608377, 'epoch': 0.54}
Step 153: {'loss': 0.5553, 'learning_rate': 0.0001958849353175884, 'epoch': 0.55}
Step 154: {'loss': 0.552, 'learning_rate': 0.00019576564878677241, 'epoch': 0.55}
Step 155: {'loss': 0.5242, 'learning_rate': 0.00019564469531998583, 'epoch': 0.56}
Step 156: {'loss': 0.6346, 'learning_rate': 0.00019552207702259412, 'epoch': 0.56}
Step 157: {'loss': 0.5696, 'learning_rate': 0.00019539779602894134, 'epoch': 0.56}
Step 158: {'loss': 0.5532, 'learning_rate': 0.00019527185450231326, 'epoch': 0.57}
Step 159: {'loss': 0.5625, 'learning_rate': 0.00019514425463489947, 'epoch': 0.57}
Step 160: {'loss': 0.5346, 'learning_rate': 0.00019501499864775534, 'epoch': 0.57}
Step 161: {'loss': 0.5967, 'learning_rate': 0.00019488408879076333, 'epoch': 0.58}
Step 162: {'loss': 0.5661, 'learning_rate': 0.0001947515273425939, 'epoch': 0.58}
Step 163: {'loss': 0.6431, 'learning_rate': 0.00019461731661066565, 'epoch': 0.58}
Step 164: {'loss': 0.5442, 'learning_rate': 0.0001944814589311054, 'epoch': 0.59}
Step 165: {'loss': 0.5055, 'learning_rate': 0.00019434395666870734, 'epoch': 0.59}
Step 166: {'loss': 0.5677, 'learning_rate': 0.000194204812216892, 'epoch': 0.59}
Step 167: {'loss': 0.504, 'learning_rate': 0.00019406402799766452, 'epoch': 0.6}
Step 168: {'loss': 0.534, 'learning_rate': 0.00019392160646157242, 'epoch': 0.6}
Step 169: {'loss': 0.495, 'learning_rate': 0.00019377755008766315, 'epoch': 0.61}
Step 170: {'loss': 0.5684, 'learning_rate': 0.00019363186138344075, 'epoch': 0.61}
Step 171: {'loss': 0.517, 'learning_rate': 0.0001934845428848222, 'epoch': 0.61}
Step 172: {'loss': 0.4878, 'learning_rate': 0.0001933355971560935, 'epoch': 0.62}
Step 173: {'loss': 0.5627, 'learning_rate': 0.00019318502678986477, 'epoch': 0.62}
Step 174: {'loss': 0.606, 'learning_rate': 0.0001930328344070252, 'epoch': 0.62}
Step 175: {'loss': 0.5791, 'learning_rate': 0.00019287902265669764, 'epoch': 0.63}
Step 176: {'loss': 0.4998, 'learning_rate': 0.0001927235942161921, 'epoch': 0.63}
Step 177: {'loss': 0.5293, 'learning_rate': 0.00019256655179095952, 'epoch': 0.63}
Step 178: {'loss': 0.4912, 'learning_rate': 0.00019240789811454442, 'epoch': 0.64}
Step 179: {'loss': 0.513, 'learning_rate': 0.00019224763594853745, 'epoch': 0.64}
Step 180: {'loss': 0.5556, 'learning_rate': 0.00019208576808252726, 'epoch': 0.65}
Step 181: {'loss': 0.5521, 'learning_rate': 0.00019192229733405202, 'epoch': 0.65}
Step 182: {'loss': 0.4683, 'learning_rate': 0.00019175722654855032, 'epoch': 0.65}
Step 183: {'loss': 0.4727, 'learning_rate': 0.00019159055859931164, 'epoch': 0.66}
Step 184: {'loss': 0.5776, 'learning_rate': 0.00019142229638742622, 'epoch': 0.66}
Step 185: {'loss': 0.5175, 'learning_rate': 0.00019125244284173495, 'epoch': 0.66}
Step 186: {'loss': 0.4316, 'learning_rate': 0.00019108100091877787, 'epoch': 0.67}
Step 187: {'loss': 0.5062, 'learning_rate': 0.00019090797360274308, 'epoch': 0.67}
Step 188: {'loss': 0.5274, 'learning_rate': 0.00019073336390541473, 'epoch': 0.67}
Step 189: {'loss': 0.543, 'learning_rate': 0.0001905571748661204, 'epoch': 0.68}
Step 190: {'loss': 0.4731, 'learning_rate': 0.00019037940955167845, 'epoch': 0.68}
Step 191: {'loss': 0.4727, 'learning_rate': 0.00019020007105634453, 'epoch': 0.68}
Step 192: {'loss': 0.5429, 'learning_rate': 0.00019001916250175764, 'epoch': 0.69}
Step 193: {'loss': 0.4796, 'learning_rate': 0.00018983668703688596, 'epoch': 0.69}
Step 194: {'loss': 0.4772, 'learning_rate': 0.0001896526478379719, 'epoch': 0.7}
Step 195: {'loss': 0.474, 'learning_rate': 0.00018946704810847689, 'epoch': 0.7}
Step 196: {'loss': 0.4693, 'learning_rate': 0.00018927989107902552, 'epoch': 0.7}
Step 197: {'loss': 0.5252, 'learning_rate': 0.0001890911800073495, 'epoch': 0.71}
Step 198: {'loss': 0.5198, 'learning_rate': 0.00018890091817823072, 'epoch': 0.71}
Step 199: {'loss': 0.4766, 'learning_rate': 0.00018870910890344427, 'epoch': 0.71}
Step 200: {'loss': 0.5005, 'learning_rate': 0.00018851575552170064, 'epoch': 0.72}
Step 201: {'loss': 0.505, 'learning_rate': 0.00018832086139858775, 'epoch': 0.72}
Step 202: {'loss': 0.4731, 'learning_rate': 0.00018812442992651221, 'epoch': 0.72}
Step 203: {'loss': 0.511, 'learning_rate': 0.00018792646452464048, 'epoch': 0.73}
Step 204: {'loss': 0.4945, 'learning_rate': 0.00018772696863883904, 'epoch': 0.73}
Step 205: {'loss': 0.4864, 'learning_rate': 0.0001875259457416148, 'epoch': 0.73}
Step 206: {'loss': 0.504, 'learning_rate': 0.0001873233993320543, 'epoch': 0.74}
Step 207: {'loss': 0.474, 'learning_rate': 0.00018711933293576302, 'epoch': 0.74}
Step 208: {'loss': 0.4766, 'learning_rate': 0.00018691375010480396, 'epoch': 0.75}
Step 209: {'loss': 0.4892, 'learning_rate': 0.0001867066544176358, 'epoch': 0.75}
Step 210: {'loss': 0.4628, 'learning_rate': 0.00018649804947905055, 'epoch': 0.75}
Step 211: {'loss': 0.5235, 'learning_rate': 0.000186287938920111, 'epoch': 0.76}
Step 212: {'loss': 0.4694, 'learning_rate': 0.00018607632639808724, 'epoch': 0.76}
Step 213: {'loss': 0.4846, 'learning_rate': 0.00018586321559639317, 'epoch': 0.76}
Step 214: {'loss': 0.4651, 'learning_rate': 0.00018564861022452242, 'epoch': 0.77}
Step 215: {'loss': 0.5008, 'learning_rate': 0.00018543251401798374, 'epoch': 0.77}
Step 216: {'loss': 0.4842, 'learning_rate': 0.0001852149307382358, 'epoch': 0.77}
Step 217: {'loss': 0.4867, 'learning_rate': 0.00018499586417262208, 'epoch': 0.78}
Step 218: {'loss': 0.5046, 'learning_rate': 0.0001847753181343046, 'epoch': 0.78}
Step 219: {'loss': 0.4845, 'learning_rate': 0.00018455329646219765, 'epoch': 0.78}
Step 220: {'loss': 0.523, 'learning_rate': 0.00018432980302090116, 'epoch': 0.79}
Step 221: {'loss': 0.5309, 'learning_rate': 0.00018410484170063317, 'epoch': 0.79}
Step 222: {'loss': 0.5126, 'learning_rate': 0.00018387841641716223, 'epoch': 0.8}
Step 223: {'loss': 0.4918, 'learning_rate': 0.00018365053111173924, 'epoch': 0.8}
Step 224: {'loss': 0.4849, 'learning_rate': 0.00018342118975102887, 'epoch': 0.8}
Step 225: {'loss': 0.4773, 'learning_rate': 0.0001831903963270404, 'epoch': 0.81}
Step 226: {'loss': 0.4488, 'learning_rate': 0.0001829581548570584, 'epoch': 0.81}
Step 227: {'loss': 0.4445, 'learning_rate': 0.0001827244693835727, 'epoch': 0.81}
Step 228: {'loss': 0.5057, 'learning_rate': 0.000182489343974208, 'epoch': 0.82}
Step 229: {'loss': 0.4475, 'learning_rate': 0.0001822527827216532, 'epoch': 0.82}
Step 230: {'loss': 0.4416, 'learning_rate': 0.00018201478974358995, 'epoch': 0.82}
Step 231: {'loss': 0.4523, 'learning_rate': 0.0001817753691826212, 'epoch': 0.83}
Step 232: {'loss': 0.4372, 'learning_rate': 0.00018153452520619897, 'epoch': 0.83}
Step 233: {'loss': 0.456, 'learning_rate': 0.00018129226200655176, 'epoch': 0.84}
Step 234: {'loss': 0.4685, 'learning_rate': 0.00018104858380061178, 'epoch': 0.84}
Step 235: {'loss': 0.4413, 'learning_rate': 0.0001808034948299413, 'epoch': 0.84}
Step 236: {'loss': 0.4588, 'learning_rate': 0.00018055699936065896, 'epoch': 0.85}
Step 237: {'loss': 0.4818, 'learning_rate': 0.00018030910168336556, 'epoch': 0.85}
Step 238: {'loss': 0.4422, 'learning_rate': 0.00018005980611306925, 'epoch': 0.85}
Step 239: {'loss': 0.4619, 'learning_rate': 0.00017980911698911041, 'epoch': 0.86}
Step 240: {'loss': 0.4429, 'learning_rate': 0.00017955703867508633, 'epoch': 0.86}
Step 241: {'loss': 0.4688, 'learning_rate': 0.000179303575558775, 'epoch': 0.86}
Step 242: {'loss': 0.4587, 'learning_rate': 0.00017904873205205885, 'epoch': 0.87}
Step 243: {'loss': 0.4819, 'learning_rate': 0.00017879251259084804, 'epoch': 0.87}
Step 244: {'loss': 0.4333, 'learning_rate': 0.00017853492163500304, 'epoch': 0.87}
Step 245: {'loss': 0.4283, 'learning_rate': 0.00017827596366825718, 'epoch': 0.88}
Step 246: {'loss': 0.4595, 'learning_rate': 0.00017801564319813853, 'epoch': 0.88}
Step 247: {'loss': 0.4633, 'learning_rate': 0.00017775396475589144, 'epoch': 0.89}
Step 248: {'loss': 0.4557, 'learning_rate': 0.00017749093289639767, 'epoch': 0.89}
Step 249: {'loss': 0.4745, 'learning_rate': 0.00017722655219809717, 'epoch': 0.89}
Step 250: {'loss': 0.4647, 'learning_rate': 0.00017696082726290823, 'epoch': 0.9}
Step 251: {'loss': 0.421, 'learning_rate': 0.00017669376271614755, 'epoch': 0.9}
Step 252: {'loss': 0.4207, 'learning_rate': 0.00017642536320644964, 'epoch': 0.9}
Step 253: {'loss': 0.4501, 'learning_rate': 0.00017615563340568592, 'epoch': 0.91}
Step 254: {'loss': 0.4707, 'learning_rate': 0.00017588457800888342, 'epoch': 0.91}
Step 255: {'loss': 0.4095, 'learning_rate': 0.00017561220173414297, 'epoch': 0.91}
Step 256: {'loss': 0.3791, 'learning_rate': 0.00017533850932255717, 'epoch': 0.92}
Step 257: {'loss': 0.4723, 'learning_rate': 0.0001750635055381279, 'epoch': 0.92}
Step 258: {'loss': 0.4501, 'learning_rate': 0.00017478719516768324, 'epoch': 0.92}
Step 259: {'loss': 0.4628, 'learning_rate': 0.0001745095830207943, 'epoch': 0.93}
Step 260: {'loss': 0.4733, 'learning_rate': 0.00017423067392969137, 'epoch': 0.93}
Step 261: {'loss': 0.3982, 'learning_rate': 0.00017395047274917994, 'epoch': 0.94}
Step 262: {'loss': 0.4685, 'learning_rate': 0.0001736689843565562, 'epoch': 0.94}
Step 263: {'loss': 0.4748, 'learning_rate': 0.00017338621365152194, 'epoch': 0.94}
Step 264: {'loss': 0.4714, 'learning_rate': 0.0001731021655560995, 'epoch': 0.95}
Step 265: {'loss': 0.4283, 'learning_rate': 0.00017281684501454595, 'epoch': 0.95}
Step 266: {'loss': 0.432, 'learning_rate': 0.00017253025699326706, 'epoch': 0.95}
Step 267: {'loss': 0.4164, 'learning_rate': 0.00017224240648073096, 'epoch': 0.96}
Step 268: {'loss': 0.4339, 'learning_rate': 0.0001719532984873811, 'epoch': 0.96}
Step 269: {'loss': 0.4328, 'learning_rate': 0.00017166293804554927, 'epoch': 0.96}
Step 270: {'loss': 0.4349, 'learning_rate': 0.00017137133020936782, 'epoch': 0.97}
Step 271: {'loss': 0.4509, 'learning_rate': 0.00017107848005468176, 'epoch': 0.97}
Step 272: {'loss': 0.4761, 'learning_rate': 0.00017078439267896042, 'epoch': 0.97}
Step 273: {'loss': 0.4472, 'learning_rate': 0.00017048907320120867, 'epoch': 0.98}
Step 274: {'loss': 0.4834, 'learning_rate': 0.00017019252676187788, 'epoch': 0.98}
Step 275: {'loss': 0.4777, 'learning_rate': 0.0001698947585227765, 'epoch': 0.99}
Step 276: {'loss': 0.3849, 'learning_rate': 0.0001695957736669799, 'epoch': 0.99}
Step 277: {'loss': 0.464, 'learning_rate': 0.00016929557739874063, 'epoch': 0.99}
Step 278: {'loss': 0.4511, 'learning_rate': 0.0001689941749433974, 'epoch': 1.0}
Step 279: {'loss': 0.442, 'learning_rate': 0.00016869157154728436, 'epoch': 1.0}
Step 280: {'loss': 0.4614, 'learning_rate': 0.00016838777247763978, 'epoch': 1.0}
Step 281: {'loss': 0.4542, 'learning_rate': 0.00016808278302251424, 'epoch': 1.01}
Step 282: {'loss': 0.4424, 'learning_rate': 0.00016777660849067868, 'epoch': 1.01}
Step 283: {'loss': 0.4599, 'learning_rate': 0.00016746925421153196, 'epoch': 1.01}
Step 284: {'loss': 0.4373, 'learning_rate': 0.00016716072553500815, 'epoch': 1.02}
Step 285: {'loss': 0.4026, 'learning_rate': 0.0001668510278314833, 'epoch': 1.02}
Step 286: {'loss': 0.4133, 'learning_rate': 0.00016654016649168203, 'epoch': 1.03}
Step 287: {'loss': 0.4077, 'learning_rate': 0.0001662281469265837, 'epoch': 1.03}
Step 288: {'loss': 0.4026, 'learning_rate': 0.00016591497456732826, 'epoch': 1.03}
Step 289: {'loss': 0.3938, 'learning_rate': 0.00016560065486512156, 'epoch': 1.04}
Step 290: {'loss': 0.4326, 'learning_rate': 0.0001652851932911407, 'epoch': 1.04}
Step 291: {'loss': 0.4208, 'learning_rate': 0.00016496859533643852, 'epoch': 1.04}
Step 292: {'loss': 0.4936, 'learning_rate': 0.00016465086651184827, 'epoch': 1.05}
Step 293: {'loss': 0.4489, 'learning_rate': 0.00016433201234788758, 'epoch': 1.05}
Step 294: {'loss': 0.4314, 'learning_rate': 0.00016401203839466213, 'epoch': 1.05}
Step 295: {'loss': 0.4003, 'learning_rate': 0.0001636909502217692, 'epoch': 1.06}
Step 296: {'loss': 0.3767, 'learning_rate': 0.0001633687534182005, 'epoch': 1.06}
Step 297: {'loss': 0.3962, 'learning_rate': 0.0001630454535922452, 'epoch': 1.06}
Step 298: {'loss': 0.4769, 'learning_rate': 0.00016272105637139204, 'epoch': 1.07}
Step 299: {'loss': 0.4446, 'learning_rate': 0.0001623955674022313, 'epoch': 1.07}
Step 300: {'loss': 0.4375, 'learning_rate': 0.00016206899235035702, 'epoch': 1.08}
Step 301: {'loss': 0.3743, 'learning_rate': 0.0001617413369002677, 'epoch': 1.08}
Step 302: {'loss': 0.4069, 'learning_rate': 0.00016141260675526793, 'epoch': 1.08}
Step 303: {'loss': 0.4604, 'learning_rate': 0.0001610828076373687, 'epoch': 1.09}
Step 304: {'loss': 0.4096, 'learning_rate': 0.00016075194528718817, 'epoch': 1.09}
Step 305: {'loss': 0.4206, 'learning_rate': 0.0001604200254638514, 'epoch': 1.09}
Step 306: {'loss': 0.3934, 'learning_rate': 0.00016008705394489033, 'epoch': 1.1}
Step 307: {'loss': 0.4406, 'learning_rate': 0.00015975303652614309, 'epoch': 1.1}
Step 308: {'loss': 0.4249, 'learning_rate': 0.00015941797902165324, 'epoch': 1.1}
Step 309: {'loss': 0.429, 'learning_rate': 0.00015908188726356843, 'epoch': 1.11}
Step 310: {'loss': 0.4653, 'learning_rate': 0.000158744767102039, 'epoch': 1.11}
Step 311: {'loss': 0.4435, 'learning_rate': 0.00015840662440511606, 'epoch': 1.11}
Step 312: {'loss': 0.4066, 'learning_rate': 0.00015806746505864946, 'epoch': 1.12}
Step 313: {'loss': 0.4164, 'learning_rate': 0.00015772729496618516, 'epoch': 1.12}
Step 314: {'loss': 0.4472, 'learning_rate': 0.00015738612004886267, 'epoch': 1.13}
Step 315: {'loss': 0.3886, 'learning_rate': 0.00015704394624531184, 'epoch': 1.13}
Step 316: {'loss': 0.379, 'learning_rate': 0.00015670077951154956, 'epoch': 1.13}
Step 317: {'loss': 0.4809, 'learning_rate': 0.00015635662582087604, 'epoch': 1.14}
Step 318: {'loss': 0.3863, 'learning_rate': 0.00015601149116377093, 'epoch': 1.14}
Step 319: {'loss': 0.4103, 'learning_rate': 0.00015566538154778892, 'epoch': 1.14}
Step 320: {'loss': 0.4249, 'learning_rate': 0.0001553183029974553, 'epoch': 1.15}
Step 321: {'loss': 0.4376, 'learning_rate': 0.00015497026155416089, 'epoch': 1.15}
Step 322: {'loss': 0.4069, 'learning_rate': 0.00015462126327605717, 'epoch': 1.15}
Step 323: {'loss': 0.4371, 'learning_rate': 0.00015427131423795062, 'epoch': 1.16}
Step 324: {'loss': 0.4101, 'learning_rate': 0.00015392042053119699, 'epoch': 1.16}
Step 325: {'loss': 0.376, 'learning_rate': 0.00015356858826359542, 'epoch': 1.16}
Step 326: {'loss': 0.4519, 'learning_rate': 0.0001532158235592819, 'epoch': 1.17}
Step 327: {'loss': 0.3992, 'learning_rate': 0.00015286213255862293, 'epoch': 1.17}
Step 328: {'loss': 0.4167, 'learning_rate': 0.0001525075214181084, 'epoch': 1.18}
Step 329: {'loss': 0.411, 'learning_rate': 0.0001521519963102445, 'epoch': 1.18}
Step 330: {'loss': 0.4456, 'learning_rate': 0.00015179556342344644, 'epoch': 1.18}
Step 331: {'loss': 0.4445, 'learning_rate': 0.0001514382289619305, 'epoch': 1.19}
Step 332: {'loss': 0.447, 'learning_rate': 0.00015107999914560618, 'epoch': 1.19}
Step 333: {'loss': 0.4747, 'learning_rate': 0.0001507208802099679, 'epoch': 1.19}
Step 334: {'loss': 0.4282, 'learning_rate': 0.0001503608784059864, 'epoch': 1.2}
Step 335: {'loss': 0.5061, 'learning_rate': 0.00015000000000000001, 'epoch': 1.2}
Step 336: {'loss': 0.4726, 'learning_rate': 0.0001496382512736056, 'epoch': 1.2}
Step 337: {'loss': 0.429, 'learning_rate': 0.00014927563852354912, 'epoch': 1.21}
Step 338: {'loss': 0.4345, 'learning_rate': 0.00014891216806161612, 'epoch': 1.21}
Step 339: {'loss': 0.453, 'learning_rate': 0.00014854784621452175, 'epoch': 1.22}
Step 340: {'loss': 0.4123, 'learning_rate': 0.0001481826793238009, 'epoch': 1.22}
Step 341: {'loss': 0.4008, 'learning_rate': 0.00014781667374569747, 'epoch': 1.22}
Step 342: {'loss': 0.3939, 'learning_rate': 0.00014744983585105386, 'epoch': 1.23}
Step 343: {'loss': 0.4229, 'learning_rate': 0.0001470821720252003, 'epoch': 1.23}
Step 344: {'loss': 0.3823, 'learning_rate': 0.00014671368866784338, 'epoch': 1.23}
Step 345: {'loss': 0.3747, 'learning_rate': 0.00014634439219295478, 'epoch': 1.24}
Step 346: {'loss': 0.4078, 'learning_rate': 0.00014597428902865972, 'epoch': 1.24}
Step 347: {'loss': 0.389, 'learning_rate': 0.00014560338561712494, 'epoch': 1.24}
Step 348: {'loss': 0.4157, 'learning_rate': 0.00014523168841444657, 'epoch': 1.25}
Step 349: {'loss': 0.4697, 'learning_rate': 0.00014485920389053784, 'epoch': 1.25}
Step 350: {'loss': 0.4155, 'learning_rate': 0.00014448593852901644, 'epoch': 1.25}
Step 351: {'loss': 0.4612, 'learning_rate': 0.0001441118988270916, 'epoch': 1.26}
Step 352: {'loss': 0.4504, 'learning_rate': 0.000143737091295451, 'epoch': 1.26}
Step 353: {'loss': 0.4083, 'learning_rate': 0.00014336152245814754, 'epoch': 1.27}
Step 354: {'loss': 0.4373, 'learning_rate': 0.00014298519885248573, 'epoch': 1.27}
Step 355: {'loss': 0.3762, 'learning_rate': 0.00014260812702890778, 'epoch': 1.27}
Step 356: {'loss': 0.3815, 'learning_rate': 0.0001422303135508798, 'epoch': 1.28}
Step 357: {'loss': 0.4579, 'learning_rate': 0.00014185176499477743, 'epoch': 1.28}
Step 358: {'loss': 0.395, 'learning_rate': 0.00014147248794977126, 'epoch': 1.28}
Step 359: {'loss': 0.3924, 'learning_rate': 0.00014109248901771242, 'epoch': 1.29}
Step 360: {'loss': 0.4833, 'learning_rate': 0.0001407117748130174, 'epoch': 1.29}
Step 361: {'loss': 0.4284, 'learning_rate': 0.000140330351962553, 'epoch': 1.29}
Step 362: {'loss': 0.4278, 'learning_rate': 0.00013994822710552106, 'epoch': 1.3}
Step 363: {'loss': 0.4252, 'learning_rate': 0.00013956540689334285, 'epoch': 1.3}
Step 364: {'loss': 0.4611, 'learning_rate': 0.0001391818979895432, 'epoch': 1.3}
Step 365: {'loss': 0.4117, 'learning_rate': 0.00013879770706963463, 'epoch': 1.31}
Step 366: {'loss': 0.4621, 'learning_rate': 0.0001384128408210011, 'epoch': 1.31}
Step 367: {'loss': 0.4313, 'learning_rate': 0.00013802730594278162, 'epoch': 1.32}
Step 368: {'loss': 0.3527, 'learning_rate': 0.00013764110914575364, 'epoch': 1.32}
Step 369: {'loss': 0.4375, 'learning_rate': 0.00013725425715221625, 'epoch': 1.32}
Step 370: {'loss': 0.3837, 'learning_rate': 0.0001368667566958731, 'epoch': 1.33}
Step 371: {'loss': 0.4024, 'learning_rate': 0.00013647861452171535, 'epoch': 1.33}
Step 372: {'loss': 0.4131, 'learning_rate': 0.00013608983738590413, 'epoch': 1.33}
Step 373: {'loss': 0.3808, 'learning_rate': 0.00013570043205565288, 'epoch': 1.34}
Step 374: {'loss': 0.4228, 'learning_rate': 0.00013531040530910976, 'epoch': 1.34}
Step 375: {'loss': 0.4112, 'learning_rate': 0.0001349197639352395, 'epoch': 1.34}
Step 376: {'loss': 0.3705, 'learning_rate': 0.0001345285147337053, 'epoch': 1.35}
Step 377: {'loss': 0.4188, 'learning_rate': 0.00013413666451475047, 'epoch': 1.35}
Step 378: {'loss': 0.4167, 'learning_rate': 0.00013374422009907984, 'epoch': 1.35}
Step 379: {'loss': 0.4146, 'learning_rate': 0.0001333511883177411, 'epoch': 1.36}
Step 380: {'loss': 0.3996, 'learning_rate': 0.00013295757601200581, 'epoch': 1.36}
Step 381: {'loss': 0.437, 'learning_rate': 0.00013256339003325053, 'epoch': 1.37}
Step 382: {'loss': 0.3779, 'learning_rate': 0.0001321686372428372, 'epoch': 1.37}
Step 383: {'loss': 0.4108, 'learning_rate': 0.00013177332451199403, 'epoch': 1.37}
Step 384: {'loss': 0.4056, 'learning_rate': 0.0001313774587216958, 'epoch': 1.38}
Step 385: {'loss': 0.4439, 'learning_rate': 0.00013098104676254396, 'epoch': 1.38}
Step 386: {'loss': 0.4431, 'learning_rate': 0.00013058409553464697, 'epoch': 1.38}
Step 387: {'loss': 0.4673, 'learning_rate': 0.00013018661194749985, 'epoch': 1.39}
Step 388: {'loss': 0.4281, 'learning_rate': 0.00012978860291986422, 'epoch': 1.39}
Step 389: {'loss': 0.5084, 'learning_rate': 0.00012939007537964757, 'epoch': 1.39}
Step 390: {'loss': 0.3909, 'learning_rate': 0.000128991036263783, 'epoch': 1.4}
Step 391: {'loss': 0.3617, 'learning_rate': 0.00012859149251810822, 'epoch': 1.4}
Step 392: {'loss': 0.3851, 'learning_rate': 0.00012819145109724476, 'epoch': 1.41}
Step 393: {'loss': 0.4131, 'learning_rate': 0.0001277909189644768, 'epoch': 1.41}
Step 394: {'loss': 0.4338, 'learning_rate': 0.00012738990309163023, 'epoch': 1.41}
Step 395: {'loss': 0.4358, 'learning_rate': 0.00012698841045895095, 'epoch': 1.42}
Step 396: {'loss': 0.4367, 'learning_rate': 0.00012658644805498362, 'epoch': 1.42}
Step 397: {'loss': 0.4309, 'learning_rate': 0.0001261840228764499, 'epoch': 1.42}
Step 398: {'loss': 0.3676, 'learning_rate': 0.0001257811419281267, 'epoch': 1.43}
Step 399: {'loss': 0.4146, 'learning_rate': 0.00012537781222272422, 'epoch': 1.43}
Step 400: {'loss': 0.4334, 'learning_rate': 0.00012497404078076397, 'epoch': 1.43}
Step 401: {'loss': 0.462, 'learning_rate': 0.00012456983463045643, 'epoch': 1.44}
Step 402: {'loss': 0.4446, 'learning_rate': 0.00012416520080757893, 'epoch': 1.44}
Step 403: {'loss': 0.4408, 'learning_rate': 0.00012376014635535285, 'epoch': 1.44}
Step 404: {'loss': 0.4367, 'learning_rate': 0.00012335467832432135, 'epoch': 1.45}
Step 405: {'loss': 0.4562, 'learning_rate': 0.00012294880377222649, 'epoch': 1.45}
Step 406: {'loss': 0.4292, 'learning_rate': 0.00012254252976388636, 'epoch': 1.46}
Step 407: {'loss': 0.3855, 'learning_rate': 0.00012213586337107217, 'epoch': 1.46}
Step 408: {'loss': 0.4242, 'learning_rate': 0.00012172881167238514, 'epoch': 1.46}
Step 409: {'loss': 0.3997, 'learning_rate': 0.0001213213817531333, 'epoch': 1.47}
Step 410: {'loss': 0.3643, 'learning_rate': 0.00012091358070520813, 'epoch': 1.47}
Step 411: {'loss': 0.4812, 'learning_rate': 0.0001205054156269611, 'epoch': 1.47}
Step 412: {'loss': 0.4206, 'learning_rate': 0.00012009689362308014, 'epoch': 1.48}
Step 413: {'loss': 0.3814, 'learning_rate': 0.00011968802180446601, 'epoch': 1.48}
Step 414: {'loss': 0.4455, 'learning_rate': 0.00011927880728810849, 'epoch': 1.48}
Step 415: {'loss': 0.434, 'learning_rate': 0.00011886925719696242, 'epoch': 1.49}
Step 416: {'loss': 0.4344, 'learning_rate': 0.00011845937865982393, 'epoch': 1.49}
Step 417: {'loss': 0.3963, 'learning_rate': 0.00011804917881120607, 'epoch': 1.49}
Step 418: {'loss': 0.3836, 'learning_rate': 0.00011763866479121486, 'epoch': 1.5}
Step 419: {'loss': 0.3919, 'learning_rate': 0.00011722784374542488, 'epoch': 1.5}
Step 420: {'loss': 0.4232, 'learning_rate': 0.00011681672282475495, 'epoch': 1.51}
Step 421: {'loss': 0.4459, 'learning_rate': 0.00011640530918534361, 'epoch': 1.51}
Step 422: {'loss': 0.3801, 'learning_rate': 0.00011599360998842454, 'epoch': 1.51}
Step 423: {'loss': 0.4331, 'learning_rate': 0.00011558163240020207, 'epoch': 1.52}
Step 424: {'loss': 0.4086, 'learning_rate': 0.00011516938359172625, 'epoch': 1.52}
Step 425: {'loss': 0.3877, 'learning_rate': 0.00011475687073876806, 'epoch': 1.52}
Step 426: {'loss': 0.4271, 'learning_rate': 0.00011434410102169462, 'epoch': 1.53}
Step 427: {'loss': 0.4913, 'learning_rate': 0.00011393108162534409, 'epoch': 1.53}
Step 428: {'loss': 0.3959, 'learning_rate': 0.00011351781973890068, 'epoch': 1.53}
Step 429: {'loss': 0.4209, 'learning_rate': 0.00011310432255576944, 'epoch': 1.54}
Step 430: {'loss': 0.45, 'learning_rate': 0.00011269059727345111, 'epoch': 1.54}
Step 431: {'loss': 0.4268, 'learning_rate': 0.00011227665109341685, 'epoch': 1.54}
Step 432: {'loss': 0.414, 'learning_rate': 0.00011186249122098283, 'epoch': 1.55}
Step 433: {'loss': 0.4077, 'learning_rate': 0.00011144812486518477, 'epoch': 1.55}
Step 434: {'loss': 0.4242, 'learning_rate': 0.00011103355923865267, 'epoch': 1.56}
Step 435: {'loss': 0.3783, 'learning_rate': 0.00011061880155748497, 'epoch': 1.56}
Step 436: {'loss': 0.3678, 'learning_rate': 0.00011020385904112318, 'epoch': 1.56}
Step 437: {'loss': 0.4039, 'learning_rate': 0.0001097887389122261, 'epoch': 1.57}
Step 438: {'loss': 0.4255, 'learning_rate': 0.00010937344839654415, 'epoch': 1.57}
Step 439: {'loss': 0.4044, 'learning_rate': 0.00010895799472279351, 'epoch': 1.57}
Step 440: {'loss': 0.47, 'learning_rate': 0.00010854238512253046, 'epoch': 1.58}
Step 441: {'loss': 0.4417, 'learning_rate': 0.00010812662683002528, 'epoch': 1.58}
Step 442: {'loss': 0.3993, 'learning_rate': 0.00010771072708213652, 'epoch': 1.58}
Step 443: {'loss': 0.4403, 'learning_rate': 0.00010729469311818496, 'epoch': 1.59}
Step 444: {'loss': 0.4153, 'learning_rate': 0.00010687853217982759, 'epoch': 1.59}
Step 445: {'loss': 0.3687, 'learning_rate': 0.00010646225151093155, 'epoch': 1.59}
Step 446: {'loss': 0.3904, 'learning_rate': 0.00010604585835744802, 'epoch': 1.6}
Step 447: {'loss': 0.412, 'learning_rate': 0.00010562935996728629, 'epoch': 1.6}
Step 448: {'loss': 0.4177, 'learning_rate': 0.00010521276359018728, 'epoch': 1.61}
Step 449: {'loss': 0.3987, 'learning_rate': 0.00010479607647759755, 'epoch': 1.61}
Step 450: {'loss': 0.3958, 'learning_rate': 0.0001043793058825431, 'epoch': 1.61}
Step 451: {'loss': 0.3835, 'learning_rate': 0.000103962459059503, 'epoch': 1.62}
Step 452: {'loss': 0.4184, 'learning_rate': 0.00010354554326428318, 'epoch': 1.62}
Step 453: {'loss': 0.4154, 'learning_rate': 0.00010312856575389017, 'epoch': 1.62}
Step 454: {'loss': 0.4749, 'learning_rate': 0.00010271153378640463, 'epoch': 1.63}
Step 455: {'loss': 0.4215, 'learning_rate': 0.00010229445462085532, 'epoch': 1.63}
Step 456: {'loss': 0.4274, 'learning_rate': 0.00010187733551709235, 'epoch': 1.63}
Step 457: {'loss': 0.4341, 'learning_rate': 0.00010146018373566113, 'epoch': 1.64}
Step 458: {'loss': 0.4293, 'learning_rate': 0.00010104300653767582, 'epoch': 1.64}
Step 459: {'loss': 0.4719, 'learning_rate': 0.00010062581118469299, 'epoch': 1.65}
Step 460: {'loss': 0.3911, 'learning_rate': 0.00010020860493858524, 'epoch': 1.65}
Step 461: {'loss': 0.3847, 'learning_rate': 9.979139506141477e-05, 'epoch': 1.65}
Step 462: {'loss': 0.4011, 'learning_rate': 9.937418881530703e-05, 'epoch': 1.66}
Step 463: {'loss': 0.4157, 'learning_rate': 9.895699346232421e-05, 'epoch': 1.66}
Step 464: {'loss': 0.3791, 'learning_rate': 9.853981626433889e-05, 'epoch': 1.66}
Step 465: {'loss': 0.3978, 'learning_rate': 9.812266448290767e-05, 'epoch': 1.67}
Step 466: {'loss': 0.437, 'learning_rate': 9.77055453791447e-05, 'epoch': 1.67}
Step 467: {'loss': 0.4176, 'learning_rate': 9.728846621359538e-05, 'epoch': 1.67}
Step 468: {'loss': 0.4309, 'learning_rate': 9.687143424610986e-05, 'epoch': 1.68}
Step 469: {'loss': 0.4085, 'learning_rate': 9.645445673571684e-05, 'epoch': 1.68}
Step 470: {'loss': 0.4083, 'learning_rate': 9.603754094049702e-05, 'epoch': 1.68}
Step 471: {'loss': 0.4463, 'learning_rate': 9.562069411745691e-05, 'epoch': 1.69}
Step 472: {'loss': 0.3856, 'learning_rate': 9.520392352240246e-05, 'epoch': 1.69}
Step 473: {'loss': 0.416, 'learning_rate': 9.478723640981275e-05, 'epoch': 1.7}
Step 474: {'loss': 0.4242, 'learning_rate': 9.437064003271374e-05, 'epoch': 1.7}
Step 475: {'loss': 0.4113, 'learning_rate': 9.395414164255199e-05, 'epoch': 1.7}
Step 476: {'loss': 0.4221, 'learning_rate': 9.353774848906849e-05, 'epoch': 1.71}
Step 477: {'loss': 0.4388, 'learning_rate': 9.312146782017243e-05, 'epoch': 1.71}
Step 478: {'loss': 0.3881, 'learning_rate': 9.270530688181506e-05, 'epoch': 1.71}
Step 479: {'loss': 0.4009, 'learning_rate': 9.22892729178635e-05, 'epoch': 1.72}
Step 480: {'loss': 0.418, 'learning_rate': 9.187337316997476e-05, 'epoch': 1.72}
Step 481: {'loss': 0.3994, 'learning_rate': 9.145761487746958e-05, 'epoch': 1.72}
Step 482: {'loss': 0.3658, 'learning_rate': 9.104200527720651e-05, 'epoch': 1.73}
Step 483: {'loss': 0.4119, 'learning_rate': 9.062655160345587e-05, 'epoch': 1.73}
Step 484: {'loss': 0.3688, 'learning_rate': 9.021126108777391e-05, 'epoch': 1.73}
Step 485: {'loss': 0.4437, 'learning_rate': 8.979614095887685e-05, 'epoch': 1.74}
Step 486: {'loss': 0.4212, 'learning_rate': 8.938119844251507e-05, 'epoch': 1.74}
Step 487: {'loss': 0.4117, 'learning_rate': 8.896644076134738e-05, 'epoch': 1.75}
Step 488: {'loss': 0.4227, 'learning_rate': 8.855187513481527e-05, 'epoch': 1.75}
Step 489: {'loss': 0.3831, 'learning_rate': 8.813750877901723e-05, 'epoch': 1.75}
Step 490: {'loss': 0.4148, 'learning_rate': 8.772334890658316e-05, 'epoch': 1.76}
Step 491: {'loss': 0.3909, 'learning_rate': 8.73094027265489e-05, 'epoch': 1.76}
Step 492: {'loss': 0.3976, 'learning_rate': 8.68956774442306e-05, 'epoch': 1.76}
Step 493: {'loss': 0.4154, 'learning_rate': 8.648218026109937e-05, 'epoch': 1.77}
Step 494: {'loss': 0.3866, 'learning_rate': 8.606891837465595e-05, 'epoch': 1.77}
Step 495: {'loss': 0.4302, 'learning_rate': 8.565589897830543e-05, 'epoch': 1.77}
Step 496: {'loss': 0.4125, 'learning_rate': 8.524312926123199e-05, 'epoch': 1.78}
Step 497: {'loss': 0.4397, 'learning_rate': 8.483061640827382e-05, 'epoch': 1.78}
Step 498: {'loss': 0.4073, 'learning_rate': 8.441836759979795e-05, 'epoch': 1.78}
Step 499: {'loss': 0.4087, 'learning_rate': 8.400639001157549e-05, 'epoch': 1.79}
Step 500: {'loss': 0.3499, 'learning_rate': 8.359469081465645e-05, 'epoch': 1.79}
Step 501: {'loss': 0.4026, 'learning_rate': 8.318327717524508e-05, 'epoch': 1.8}
Step 502: {'loss': 0.42, 'learning_rate': 8.277215625457516e-05, 'epoch': 1.8}
Step 503: {'loss': 0.3705, 'learning_rate': 8.236133520878517e-05, 'epoch': 1.8}
Step 504: {'loss': 0.407, 'learning_rate': 8.195082118879397e-05, 'epoch': 1.81}
Step 505: {'loss': 0.3405, 'learning_rate': 8.15406213401761e-05, 'epoch': 1.81}
Step 506: {'loss': 0.387, 'learning_rate': 8.11307428030376e-05, 'epoch': 1.81}
Step 507: {'loss': 0.4295, 'learning_rate': 8.072119271189156e-05, 'epoch': 1.82}
Step 508: {'loss': 0.4119, 'learning_rate': 8.031197819553397e-05, 'epoch': 1.82}
Step 509: {'loss': 0.4008, 'learning_rate': 7.990310637691987e-05, 'epoch': 1.82}
Step 510: {'loss': 0.4225, 'learning_rate': 7.949458437303891e-05, 'epoch': 1.83}
Step 511: {'loss': 0.4276, 'learning_rate': 7.908641929479187e-05, 'epoch': 1.83}
Step 512: {'loss': 0.4196, 'learning_rate': 7.867861824686669e-05, 'epoch': 1.84}
Step 513: {'loss': 0.4308, 'learning_rate': 7.827118832761487e-05, 'epoch': 1.84}
Step 514: {'loss': 0.4058, 'learning_rate': 7.786413662892784e-05, 'epoch': 1.84}
Step 515: {'loss': 0.4319, 'learning_rate': 7.745747023611367e-05, 'epoch': 1.85}
Step 516: {'loss': 0.392, 'learning_rate': 7.705119622777351e-05, 'epoch': 1.85}
Step 517: {'loss': 0.415, 'learning_rate': 7.664532167567864e-05, 'epoch': 1.85}
Step 518: {'loss': 0.4008, 'learning_rate': 7.623985364464716e-05, 'epoch': 1.86}
Step 519: {'loss': 0.4561, 'learning_rate': 7.583479919242108e-05, 'epoch': 1.86}
Step 520: {'loss': 0.3691, 'learning_rate': 7.543016536954355e-05, 'epoch': 1.86}
Step 521: {'loss': 0.3608, 'learning_rate': 7.502595921923606e-05, 'epoch': 1.87}
Step 522: {'loss': 0.3888, 'learning_rate': 7.46221877772758e-05, 'epoch': 1.87}
Step 523: {'loss': 0.3965, 'learning_rate': 7.421885807187332e-05, 'epoch': 1.87}
Step 524: {'loss': 0.3927, 'learning_rate': 7.38159771235501e-05, 'epoch': 1.88}
Step 525: {'loss': 0.4274, 'learning_rate': 7.341355194501638e-05, 'epoch': 1.88}
Step 526: {'loss': 0.4101, 'learning_rate': 7.301158954104904e-05, 'epoch': 1.89}
Step 527: {'loss': 0.3875, 'learning_rate': 7.261009690836977e-05, 'epoch': 1.89}
Step 528: {'loss': 0.4099, 'learning_rate': 7.220908103552318e-05, 'epoch': 1.89}
Step 529: {'loss': 0.3866, 'learning_rate': 7.180854890275527e-05, 'epoch': 1.9}
Step 530: {'loss': 0.3963, 'learning_rate': 7.140850748189177e-05, 'epoch': 1.9}
Step 531: {'loss': 0.3861, 'learning_rate': 7.100896373621699e-05, 'epoch': 1.9}
Step 532: {'loss': 0.4147, 'learning_rate': 7.060992462035242e-05, 'epoch': 1.91}
Step 533: {'loss': 0.3906, 'learning_rate': 7.021139708013582e-05, 'epoch': 1.91}
Step 534: {'loss': 0.4013, 'learning_rate': 6.981338805250014e-05, 'epoch': 1.91}
Step 535: {'loss': 0.3897, 'learning_rate': 6.941590446535305e-05, 'epoch': 1.92}
Step 536: {'loss': 0.415, 'learning_rate': 6.901895323745605e-05, 'epoch': 1.92}
Step 537: {'loss': 0.4236, 'learning_rate': 6.862254127830425e-05, 'epoch': 1.92}
Step 538: {'loss': 0.3768, 'learning_rate': 6.822667548800599e-05, 'epoch': 1.93}
Step 539: {'loss': 0.3985, 'learning_rate': 6.783136275716283e-05, 'epoch': 1.93}
Step 540: {'loss': 0.3989, 'learning_rate': 6.74366099667495e-05, 'epoch': 1.94}
Step 541: {'loss': 0.4497, 'learning_rate': 6.704242398799418e-05, 'epoch': 1.94}
Step 542: {'loss': 0.3925, 'learning_rate': 6.664881168225894e-05, 'epoch': 1.94}
Step 543: {'loss': 0.4375, 'learning_rate': 6.62557799009202e-05, 'epoch': 1.95}
Step 544: {'loss': 0.3618, 'learning_rate': 6.586333548524957e-05, 'epoch': 1.95}
Step 545: {'loss': 0.362, 'learning_rate': 6.54714852662947e-05, 'epoch': 1.95}
Step 546: {'loss': 0.3774, 'learning_rate': 6.508023606476052e-05, 'epoch': 1.96}
Step 547: {'loss': 0.3778, 'learning_rate': 6.468959469089026e-05, 'epoch': 1.96}
Step 548: {'loss': 0.3996, 'learning_rate': 6.429956794434714e-05, 'epoch': 1.96}
Step 549: {'loss': 0.4064, 'learning_rate': 6.39101626140959e-05, 'epoch': 1.97}
Step 550: {'loss': 0.405, 'learning_rate': 6.352138547828466e-05, 'epoch': 1.97}
Step 551: {'loss': 0.4301, 'learning_rate': 6.313324330412692e-05, 'epoch': 1.97}
Step 552: {'loss': 0.4269, 'learning_rate': 6.274574284778378e-05, 'epoch': 1.98}
Step 553: {'loss': 0.4072, 'learning_rate': 6.235889085424637e-05, 'epoch': 1.98}
Step 554: {'loss': 0.4261, 'learning_rate': 6.19726940572184e-05, 'epoch': 1.99}
Step 555: {'loss': 0.4197, 'learning_rate': 6.158715917899893e-05, 'epoch': 1.99}
Step 556: {'loss': 0.4325, 'learning_rate': 6.120229293036539e-05, 'epoch': 1.99}
Step 557: {'loss': 0.3838, 'learning_rate': 6.081810201045681e-05, 'epoch': 2.0}
Step 558: {'loss': 0.4189, 'learning_rate': 6.0434593106657155e-05, 'epoch': 2.0}
Step 559: {'loss': 0.3873, 'learning_rate': 6.005177289447894e-05, 'epoch': 2.0}
Step 560: {'loss': 0.4267, 'learning_rate': 5.9669648037447015e-05, 'epoch': 2.01}
Step 561: {'loss': 0.4304, 'learning_rate': 5.9288225186982626e-05, 'epoch': 2.01}
Step 562: {'loss': 0.42, 'learning_rate': 5.8907510982287594e-05, 'epoch': 2.01}
Step 563: {'loss': 0.4211, 'learning_rate': 5.8527512050228747e-05, 'epoch': 2.02}
Step 564: {'loss': 0.3861, 'learning_rate': 5.81482350052226e-05, 'epoch': 2.02}
Step 565: {'loss': 0.3808, 'learning_rate': 5.776968644912022e-05, 'epoch': 2.03}
Step 566: {'loss': 0.4139, 'learning_rate': 5.739187297109223e-05, 'epoch': 2.03}
Step 567: {'loss': 0.4028, 'learning_rate': 5.7014801147514316e-05, 'epoch': 2.03}
Step 568: {'loss': 0.414, 'learning_rate': 5.6638477541852465e-05, 'epoch': 2.04}
Step 569: {'loss': 0.4232, 'learning_rate': 5.6262908704549044e-05, 'epoch': 2.04}
Step 570: {'loss': 0.4029, 'learning_rate': 5.588810117290843e-05, 'epoch': 2.04}
Step 571: {'loss': 0.4145, 'learning_rate': 5.551406147098355e-05, 'epoch': 2.05}
Step 572: {'loss': 0.4045, 'learning_rate': 5.5140796109462164e-05, 'epoch': 2.05}
Step 573: {'loss': 0.3568, 'learning_rate': 5.476831158555344e-05, 'epoch': 2.05}
Step 574: {'loss': 0.3866, 'learning_rate': 5.43966143828751e-05, 'epoch': 2.06}
Step 575: {'loss': 0.3975, 'learning_rate': 5.4025710971340285e-05, 'epoch': 2.06}
Step 576: {'loss': 0.4414, 'learning_rate': 5.365560780704524e-05, 'epoch': 2.06}
Step 577: {'loss': 0.398, 'learning_rate': 5.328631133215665e-05, 'epoch': 2.07}
Step 578: {'loss': 0.4184, 'learning_rate': 5.291782797479969e-05, 'epoch': 2.07}
Step 579: {'loss': 0.3899, 'learning_rate': 5.2550164148946155e-05, 'epoch': 2.08}
Step 580: {'loss': 0.4167, 'learning_rate': 5.218332625430258e-05, 'epoch': 2.08}
Step 581: {'loss': 0.4312, 'learning_rate': 5.181732067619913e-05, 'epoch': 2.08}
Step 582: {'loss': 0.4123, 'learning_rate': 5.145215378547825e-05, 'epoch': 2.09}
Step 583: {'loss': 0.4381, 'learning_rate': 5.1087831938383954e-05, 'epoch': 2.09}
Step 584: {'loss': 0.3814, 'learning_rate': 5.072436147645092e-05, 'epoch': 2.09}
Step 585: {'loss': 0.3833, 'learning_rate': 5.036174872639443e-05, 'epoch': 2.1}
Step 586: {'loss': 0.4386, 'learning_rate': 5.000000000000002e-05, 'epoch': 2.1}
Step 587: {'loss': 0.4147, 'learning_rate': 4.963912159401363e-05, 'epoch': 2.1}
Step 588: {'loss': 0.4434, 'learning_rate': 4.9279119790032135e-05, 'epoch': 2.11}
Step 589: {'loss': 0.3841, 'learning_rate': 4.892000085439383e-05, 'epoch': 2.11}
Step 590: {'loss': 0.3895, 'learning_rate': 4.856177103806954e-05, 'epoch': 2.11}
Step 591: {'loss': 0.3699, 'learning_rate': 4.82044365765536e-05, 'epoch': 2.12}
Step 592: {'loss': 0.419, 'learning_rate': 4.784800368975556e-05, 'epoch': 2.12}
Step 593: {'loss': 0.3944, 'learning_rate': 4.7492478581891665e-05, 'epoch': 2.13}
Step 594: {'loss': 0.3661, 'learning_rate': 4.713786744137709e-05, 'epoch': 2.13}
Step 595: {'loss': 0.4203, 'learning_rate': 4.678417644071813e-05, 'epoch': 2.13}
Step 596: {'loss': 0.3965, 'learning_rate': 4.6431411736404604e-05, 'epoch': 2.14}
Step 597: {'loss': 0.3552, 'learning_rate': 4.6079579468803044e-05, 'epoch': 2.14}
Step 598: {'loss': 0.4299, 'learning_rate': 4.5728685762049414e-05, 'epoch': 2.14}
Step 599: {'loss': 0.419, 'learning_rate': 4.537873672394288e-05, 'epoch': 2.15}
Step 600: {'loss': 0.4226, 'learning_rate': 4.5029738445839143e-05, 'epoch': 2.15}
Step 601: {'loss': 0.3859, 'learning_rate': 4.468169700254474e-05, 'epoch': 2.15}
Step 602: {'loss': 0.3963, 'learning_rate': 4.433461845221106e-05, 'epoch': 2.16}
Step 603: {'loss': 0.4029, 'learning_rate': 4.3988508836229045e-05, 'epoch': 2.16}
Step 604: {'loss': 0.3928, 'learning_rate': 4.364337417912395e-05, 'epoch': 2.16}
Step 605: {'loss': 0.4187, 'learning_rate': 4.329922048845044e-05, 'epoch': 2.17}
Step 606: {'loss': 0.3831, 'learning_rate': 4.2956053754688174e-05, 'epoch': 2.17}
Step 607: {'loss': 0.3868, 'learning_rate': 4.2613879951137326e-05, 'epoch': 2.18}
Step 608: {'loss': 0.4145, 'learning_rate': 4.227270503381485e-05, 'epoch': 2.18}
Step 609: {'loss': 0.4496, 'learning_rate': 4.1932534941350545e-05, 'epoch': 2.18}
Step 610: {'loss': 0.3742, 'learning_rate': 4.159337559488396e-05, 'epoch': 2.19}
Step 611: {'loss': 0.4219, 'learning_rate': 4.125523289796102e-05, 'epoch': 2.19}
Step 612: {'loss': 0.4234, 'learning_rate': 4.091811273643157e-05, 'epoch': 2.19}
Step 613: {'loss': 0.3719, 'learning_rate': 4.058202097834679e-05, 'epoch': 2.2}
Step 614: {'loss': 0.3736, 'learning_rate': 4.024696347385691e-05, 'epoch': 2.2}
Step 615: {'loss': 0.4634, 'learning_rate': 3.991294605510969e-05, 'epoch': 2.2}
Step 616: {'loss': 0.4193, 'learning_rate': 3.957997453614859e-05, 'epoch': 2.21}
Step 617: {'loss': 0.3453, 'learning_rate': 3.924805471281183e-05, 'epoch': 2.21}
Step 618: {'loss': 0.413, 'learning_rate': 3.891719236263128e-05, 'epoch': 2.22}
Step 619: {'loss': 0.4172, 'learning_rate': 3.8587393244732074e-05, 'epoch': 2.22}
Step 620: {'loss': 0.4097, 'learning_rate': 3.825866309973231e-05, 'epoch': 2.22}
Step 621: {'loss': 0.4494, 'learning_rate': 3.793100764964299e-05, 'epoch': 2.23}
Step 622: {'loss': 0.4286, 'learning_rate': 3.760443259776869e-05, 'epoch': 2.23}
Step 623: {'loss': 0.3991, 'learning_rate': 3.727894362860799e-05, 'epoch': 2.23}
Step 624: {'loss': 0.4214, 'learning_rate': 3.6954546407754796e-05, 'epoch': 2.24}
Step 625: {'loss': 0.3935, 'learning_rate': 3.663124658179948e-05, 'epoch': 2.24}
Step 626: {'loss': 0.4292, 'learning_rate': 3.630904977823082e-05, 'epoch': 2.24}
Step 627: {'loss': 0.3939, 'learning_rate': 3.598796160533789e-05, 'epoch': 2.25}
Step 628: {'loss': 0.3879, 'learning_rate': 3.566798765211245e-05, 'epoch': 2.25}
Step 629: {'loss': 0.4204, 'learning_rate': 3.534913348815176e-05, 'epoch': 2.25}
Step 630: {'loss': 0.4111, 'learning_rate': 3.503140466356151e-05, 'epoch': 2.26}
Step 631: {'loss': 0.3671, 'learning_rate': 3.471480670885935e-05, 'epoch': 2.26}
Step 632: {'loss': 0.39, 'learning_rate': 3.439934513487845e-05, 'epoch': 2.27}
Step 633: {'loss': 0.391, 'learning_rate': 3.4085025432671746e-05, 'epoch': 2.27}
Step 634: {'loss': 0.4118, 'learning_rate': 3.37718530734163e-05, 'epoch': 2.27}
Step 635: {'loss': 0.4204, 'learning_rate': 3.345983350831798e-05, 'epoch': 2.28}
Step 636: {'loss': 0.4039, 'learning_rate': 3.314897216851673e-05, 'epoch': 2.28}
Step 637: {'loss': 0.3603, 'learning_rate': 3.283927446499185e-05, 'epoch': 2.28}
Step 638: {'loss': 0.4219, 'learning_rate': 3.253074578846805e-05, 'epoch': 2.29}
Step 639: {'loss': 0.3945, 'learning_rate': 3.2223391509321334e-05, 'epoch': 2.29}
Step 640: {'loss': 0.435, 'learning_rate': 3.191721697748576e-05, 'epoch': 2.29}
Step 641: {'loss': 0.4125, 'learning_rate': 3.161222752236024e-05, 'epoch': 2.3}
Step 642: {'loss': 0.3875, 'learning_rate': 3.130842845271564e-05, 'epoch': 2.3}
Step 643: {'loss': 0.4227, 'learning_rate': 3.100582505660263e-05, 'epoch': 2.3}
Step 644: {'loss': 0.3566, 'learning_rate': 3.070442260125939e-05, 'epoch': 2.31}
Step 645: {'loss': 0.4393, 'learning_rate': 3.0404226333020114e-05, 'epoch': 2.31}
Step 646: {'loss': 0.4213, 'learning_rate': 3.0105241477223533e-05, 'epoch': 2.32}
Step 647: {'loss': 0.3813, 'learning_rate': 2.9807473238122098e-05, 'epoch': 2.32}
Step 648: {'loss': 0.4245, 'learning_rate': 2.951092679879136e-05, 'epoch': 2.32}
Step 649: {'loss': 0.4042, 'learning_rate': 2.9215607321039606e-05, 'epoch': 2.33}
Step 650: {'loss': 0.4169, 'learning_rate': 2.8921519945318276e-05, 'epoch': 2.33}
Step 651: {'loss': 0.4157, 'learning_rate': 2.862866979063219e-05, 'epoch': 2.33}
Step 652: {'loss': 0.3914, 'learning_rate': 2.833706195445075e-05, 'epoch': 2.34}
Step 653: {'loss': 0.446, 'learning_rate': 2.804670151261891e-05, 'epoch': 2.34}
Step 654: {'loss': 0.3891, 'learning_rate': 2.7757593519269087e-05, 'epoch': 2.34}
Step 655: {'loss': 0.4063, 'learning_rate': 2.7469743006732963e-05, 'epoch': 2.35}
Step 656: {'loss': 0.3856, 'learning_rate': 2.7183154985454074e-05, 'epoch': 2.35}
Step 657: {'loss': 0.3719, 'learning_rate': 2.6897834443900526e-05, 'epoch': 2.35}
Step 658: {'loss': 0.3817, 'learning_rate': 2.6613786348478053e-05, 'epoch': 2.36}
Step 659: {'loss': 0.3713, 'learning_rate': 2.633101564344381e-05, 'epoch': 2.36}
Step 660: {'loss': 0.4205, 'learning_rate': 2.6049527250820048e-05, 'epoch': 2.37}
Step 661: {'loss': 0.4038, 'learning_rate': 2.5769326070308676e-05, 'epoch': 2.37}
Step 662: {'loss': 0.4417, 'learning_rate': 2.5490416979205757e-05, 'epoch': 2.37}
Step 663: {'loss': 0.4441, 'learning_rate': 2.5212804832316784e-05, 'epoch': 2.38}
Step 664: {'loss': 0.4814, 'learning_rate': 2.493649446187213e-05, 'epoch': 2.38}
Step 665: {'loss': 0.4164, 'learning_rate': 2.4661490677442833e-05, 'epoch': 2.38}
Step 666: {'loss': 0.4204, 'learning_rate': 2.4387798265857074e-05, 'epoch': 2.39}
Step 667: {'loss': 0.4322, 'learning_rate': 2.4115421991116606e-05, 'epoch': 2.39}
Step 668: {'loss': 0.4092, 'learning_rate': 2.3844366594314093e-05, 'epoch': 2.39}
Step 669: {'loss': 0.4275, 'learning_rate': 2.3574636793550377e-05, 'epoch': 2.4}
Step 670: {'loss': 0.422, 'learning_rate': 2.3306237283852462e-05, 'epoch': 2.4}
Step 671: {'loss': 0.3889, 'learning_rate': 2.303917273709181e-05, 'epoch': 2.41}
Step 672: {'loss': 0.3971, 'learning_rate': 2.277344780190286e-05, 'epoch': 2.41}
Step 673: {'loss': 0.4504, 'learning_rate': 2.2509067103602356e-05, 'epoch': 2.41}
Step 674: {'loss': 0.3881, 'learning_rate': 2.2246035244108586e-05, 'epoch': 2.42}
Step 675: {'loss': 0.3994, 'learning_rate': 2.1984356801861506e-05, 'epoch': 2.42}
Step 676: {'loss': 0.4185, 'learning_rate': 2.1724036331742835e-05, 'epoch': 2.42}
Step 677: {'loss': 0.4441, 'learning_rate': 2.1465078364996972e-05, 'epoch': 2.43}
Step 678: {'loss': 0.4336, 'learning_rate': 2.120748740915198e-05, 'epoch': 2.43}
Step 679: {'loss': 0.3887, 'learning_rate': 2.0951267947941145e-05, 'epoch': 2.43}
Step 680: {'loss': 0.4406, 'learning_rate': 2.069642444122504e-05, 'epoch': 2.44}
Step 681: {'loss': 0.4067, 'learning_rate': 2.044296132491369e-05, 'epoch': 2.44}
Step 682: {'loss': 0.4106, 'learning_rate': 2.0190883010889615e-05, 'epoch': 2.44}
Step 683: {'loss': 0.4069, 'learning_rate': 1.994019388693078e-05, 'epoch': 2.45}
Step 684: {'loss': 0.4506, 'learning_rate': 1.969089831663443e-05, 'epoch': 2.45}
Step 685: {'loss': 0.3517, 'learning_rate': 1.9443000639341048e-05, 'epoch': 2.46}
Step 686: {'loss': 0.4342, 'learning_rate': 1.9196505170058722e-05, 'epoch': 2.46}
Step 687: {'loss': 0.4005, 'learning_rate': 1.895141619938825e-05, 'epoch': 2.46}
Step 688: {'loss': 0.4069, 'learning_rate': 1.870773799344825e-05, 'epoch': 2.47}
Step 689: {'loss': 0.3993, 'learning_rate': 1.8465474793801084e-05, 'epoch': 2.47}
Step 690: {'loss': 0.4162, 'learning_rate': 1.822463081737883e-05, 'epoch': 2.47}
Step 691: {'loss': 0.4289, 'learning_rate': 1.798521025641009e-05, 'epoch': 2.48}
Step 692: {'loss': 0.4392, 'learning_rate': 1.774721727834684e-05, 'epoch': 2.48}
Step 693: {'loss': 0.4423, 'learning_rate': 1.7510656025792005e-05, 'epoch': 2.48}
Step 694: {'loss': 0.3523, 'learning_rate': 1.727553061642734e-05, 'epoch': 2.49}
Step 695: {'loss': 0.4122, 'learning_rate': 1.7041845142941614e-05, 'epoch': 2.49}
Step 696: {'loss': 0.3929, 'learning_rate': 1.6809603672959617e-05, 'epoch': 2.49}
Step 697: {'loss': 0.417, 'learning_rate': 1.6578810248971144e-05, 'epoch': 2.5}
Step 698: {'loss': 0.3658, 'learning_rate': 1.6349468888260767e-05, 'epoch': 2.5}
Step 699: {'loss': 0.3573, 'learning_rate': 1.6121583582837772e-05, 'epoch': 2.51}
Step 700: {'loss': 0.4342, 'learning_rate': 1.5895158299366843e-05, 'epoch': 2.51}
Step 701: {'loss': 0.3751, 'learning_rate': 1.5670196979098838e-05, 'epoch': 2.51}
Step 702: {'loss': 0.3892, 'learning_rate': 1.5446703537802344e-05, 'epoch': 2.52}
Step 703: {'loss': 0.3536, 'learning_rate': 1.5224681865695422e-05, 'epoch': 2.52}
Step 704: {'loss': 0.404, 'learning_rate': 1.5004135827377907e-05, 'epoch': 2.52}
Step 705: {'loss': 0.3844, 'learning_rate': 1.4785069261764184e-05, 'epoch': 2.53}
Step 706: {'loss': 0.4118, 'learning_rate': 1.456748598201626e-05, 'epoch': 2.53}
Step 707: {'loss': 0.3481, 'learning_rate': 1.4351389775477575e-05, 'epoch': 2.53}
Step 708: {'loss': 0.4573, 'learning_rate': 1.413678440360684e-05, 'epoch': 2.54}
Step 709: {'loss': 0.4232, 'learning_rate': 1.392367360191278e-05, 'epoch': 2.54}
Step 710: {'loss': 0.3816, 'learning_rate': 1.3712061079889016e-05, 'epoch': 2.54}
Step 711: {'loss': 0.4166, 'learning_rate': 1.3501950520949436e-05, 'epoch': 2.55}
Step 712: {'loss': 0.4217, 'learning_rate': 1.3293345582364225e-05, 'epoch': 2.55}
Step 713: {'loss': 0.3996, 'learning_rate': 1.3086249895196046e-05, 'epoch': 2.56}
Step 714: {'loss': 0.4398, 'learning_rate': 1.2880667064237007e-05, 'epoch': 2.56}
Step 715: {'loss': 0.3796, 'learning_rate': 1.2676600667945715e-05, 'epoch': 2.56}
Step 716: {'loss': 0.4005, 'learning_rate': 1.2474054258385226e-05, 'epoch': 2.57}
Step 717: {'loss': 0.4297, 'learning_rate': 1.2273031361160958e-05, 'epoch': 2.57}
Step 718: {'loss': 0.4669, 'learning_rate': 1.2073535475359531e-05, 'epoch': 2.57}
Step 719: {'loss': 0.449, 'learning_rate': 1.1875570073487786e-05, 'epoch': 2.58}
Step 720: {'loss': 0.394, 'learning_rate': 1.1679138601412255e-05, 'epoch': 2.58}
Step 721: {'loss': 0.3735, 'learning_rate': 1.1484244478299366e-05, 'epoch': 2.58}
Step 722: {'loss': 0.3977, 'learning_rate': 1.1290891096555745e-05, 'epoch': 2.59}
Step 723: {'loss': 0.4015, 'learning_rate': 1.1099081821769297e-05, 'epoch': 2.59}
Step 724: {'loss': 0.3949, 'learning_rate': 1.090881999265051e-05, 'epoch': 2.59}
Step 725: {'loss': 0.4103, 'learning_rate': 1.072010892097447e-05, 'epoch': 2.6}
Step 726: {'loss': 0.4178, 'learning_rate': 1.0532951891523124e-05, 'epoch': 2.6}
Step 727: {'loss': 0.3737, 'learning_rate': 1.034735216202809e-05, 'epoch': 2.61}
Step 728: {'loss': 0.4229, 'learning_rate': 1.0163312963114036e-05, 'epoch': 2.61}
Step 729: {'loss': 0.3984, 'learning_rate': 9.980837498242356e-06, 'epoch': 2.61}
Step 730: {'loss': 0.4085, 'learning_rate': 9.79992894365549e-06, 'epoch': 2.62}
Step 731: {'loss': 0.351, 'learning_rate': 9.620590448321554e-06, 'epoch': 2.62}
Step 732: {'loss': 0.4323, 'learning_rate': 9.442825133879607e-06, 'epoch': 2.62}
Step 733: {'loss': 0.4335, 'learning_rate': 9.266636094585302e-06, 'epoch': 2.63}
Step 734: {'loss': 0.3973, 'learning_rate': 9.092026397256914e-06, 'epoch': 2.63}
Step 735: {'loss': 0.3902, 'learning_rate': 8.918999081222156e-06, 'epoch': 2.63}
Step 736: {'loss': 0.4168, 'learning_rate': 8.747557158265074e-06, 'epoch': 2.64}
Step 737: {'loss': 0.4336, 'learning_rate': 8.577703612573784e-06, 'epoch': 2.64}
Step 738: {'loss': 0.4121, 'learning_rate': 8.4094414006884e-06, 'epoch': 2.65}
Step 739: {'loss': 0.3905, 'learning_rate': 8.24277345144967e-06, 'epoch': 2.65}
Step 740: {'loss': 0.4134, 'learning_rate': 8.077702665947973e-06, 'epoch': 2.65}
Step 741: {'loss': 0.3865, 'learning_rate': 7.914231917472747e-06, 'epoch': 2.66}
Step 742: {'loss': 0.4066, 'learning_rate': 7.75236405146258e-06, 'epoch': 2.66}
Step 743: {'loss': 0.3926, 'learning_rate': 7.592101885455593e-06, 'epoch': 2.66}
Step 744: {'loss': 0.415, 'learning_rate': 7.433448209040495e-06, 'epoch': 2.67}
Step 745: {'loss': 0.4143, 'learning_rate': 7.276405783807894e-06, 'epoch': 2.67}
Step 746: {'loss': 0.4116, 'learning_rate': 7.12097734330236e-06, 'epoch': 2.67}
Step 747: {'loss': 0.3419, 'learning_rate': 6.967165592974789e-06, 'epoch': 2.68}
Step 748: {'loss': 0.3951, 'learning_rate': 6.814973210135256e-06, 'epoch': 2.68}
Step 749: {'loss': 0.3758, 'learning_rate': 6.6644028439065145e-06, 'epoch': 2.68}
Step 750: {'loss': 0.4115, 'learning_rate': 6.515457115177803e-06, 'epoch': 2.69}
Step 751: {'loss': 0.4065, 'learning_rate': 6.368138616559283e-06, 'epoch': 2.69}
Step 752: {'loss': 0.4027, 'learning_rate': 6.222449912336859e-06, 'epoch': 2.7}
Step 753: {'loss': 0.3761, 'learning_rate': 6.078393538427574e-06, 'epoch': 2.7}
Step 754: {'loss': 0.4166, 'learning_rate': 5.93597200233551e-06, 'epoch': 2.7}
Step 755: {'loss': 0.37, 'learning_rate': 5.795187783108003e-06, 'epoch': 2.71}
Step 756: {'loss': 0.3747, 'learning_rate': 5.6560433312926815e-06, 'epoch': 2.71}
Step 757: {'loss': 0.4307, 'learning_rate': 5.518541068894623e-06, 'epoch': 2.71}
Step 758: {'loss': 0.3857, 'learning_rate': 5.3826833893343755e-06, 'epoch': 2.72}
Step 759: {'loss': 0.4041, 'learning_rate': 5.248472657406123e-06, 'epoch': 2.72}
Step 760: {'loss': 0.4605, 'learning_rate': 5.115911209236668e-06, 'epoch': 2.72}
Step 761: {'loss': 0.4286, 'learning_rate': 4.985001352244667e-06, 'epoch': 2.73}
Step 762: {'loss': 0.4309, 'learning_rate': 4.8557453651005395e-06, 'epoch': 2.73}
Step 763: {'loss': 0.4374, 'learning_rate': 4.728145497686753e-06, 'epoch': 2.73}
Step 764: {'loss': 0.4245, 'learning_rate': 4.60220397105866e-06, 'epoch': 2.74}
Step 765: {'loss': 0.398, 'learning_rate': 4.477922977405913e-06, 'epoch': 2.74}
Step 766: {'loss': 0.4013, 'learning_rate': 4.355304680014171e-06, 'epoch': 2.75}
Step 767: {'loss': 0.4019, 'learning_rate': 4.234351213227605e-06, 'epoch': 2.75}
Step 768: {'loss': 0.4167, 'learning_rate': 4.1150646824116065e-06, 'epoch': 2.75}
Step 769: {'loss': 0.4149, 'learning_rate': 3.997447163916224e-06, 'epoch': 2.76}
Step 770: {'loss': 0.3866, 'learning_rate': 3.881500705039997e-06, 'epoch': 2.76}
Step 771: {'loss': 0.4323, 'learning_rate': 3.7672273239942932e-06, 'epoch': 2.76}
Step 772: {'loss': 0.4167, 'learning_rate': 3.654629009868249e-06, 'epoch': 2.77}
Step 773: {'loss': 0.4474, 'learning_rate': 3.5437077225940694e-06, 'epoch': 2.77}
Step 774: {'loss': 0.4333, 'learning_rate': 3.4344653929129555e-06, 'epoch': 2.77}
Step 775: {'loss': 0.3847, 'learning_rate': 3.326903922341473e-06, 'epoch': 2.78}
Step 776: {'loss': 0.3444, 'learning_rate': 3.221025183138493e-06, 'epoch': 2.78}
Step 777: {'loss': 0.4427, 'learning_rate': 3.116831018272581e-06, 'epoch': 2.78}
Step 778: {'loss': 0.4152, 'learning_rate': 3.0143232413898605e-06, 'epoch': 2.79}
Step 779: {'loss': 0.4177, 'learning_rate': 2.9135036367825773e-06, 'epoch': 2.79}
Step 780: {'loss': 0.4656, 'learning_rate': 2.8143739593578856e-06, 'epoch': 2.8}
Step 781: {'loss': 0.4916, 'learning_rate': 2.7169359346074343e-06, 'epoch': 2.8}
Step 782: {'loss': 0.3811, 'learning_rate': 2.621191258577238e-06, 'epoch': 2.8}
Step 783: {'loss': 0.4108, 'learning_rate': 2.527141597838212e-06, 'epoch': 2.81}
Step 784: {'loss': 0.3692, 'learning_rate': 2.4347885894571487e-06, 'epoch': 2.81}
Step 785: {'loss': 0.4094, 'learning_rate': 2.344133840968188e-06, 'epoch': 2.81}
Step 786: {'loss': 0.4121, 'learning_rate': 2.2551789303449034e-06, 'epoch': 2.82}
Step 787: {'loss': 0.4274, 'learning_rate': 2.1679254059727595e-06, 'epoch': 2.82}
Step 788: {'loss': 0.4457, 'learning_rate': 2.082374786622232e-06, 'epoch': 2.82}
Step 789: {'loss': 0.402, 'learning_rate': 1.998528561422297e-06, 'epoch': 2.83}
Step 790: {'loss': 0.3597, 'learning_rate': 1.9163881898345835e-06, 'epoch': 2.83}
Step 791: {'loss': 0.4327, 'learning_rate': 1.8359551016279398e-06, 'epoch': 2.84}
Step 792: {'loss': 0.4645, 'learning_rate': 1.7572306968535179e-06, 'epoch': 2.84}
Step 793: {'loss': 0.4077, 'learning_rate': 1.68021634582044e-06, 'epoch': 2.84}
Step 794: {'loss': 0.4106, 'learning_rate': 1.604913389071927e-06, 'epoch': 2.85}
Step 795: {'loss': 0.4171, 'learning_rate': 1.5313231373619952e-06, 'epoch': 2.85}
Step 796: {'loss': 0.4226, 'learning_rate': 1.459446871632586e-06, 'epoch': 2.85}
Step 797: {'loss': 0.4638, 'learning_rate': 1.389285842991339e-06, 'epoch': 2.86}
Step 798: {'loss': 0.3799, 'learning_rate': 1.3208412726897323e-06, 'epoch': 2.86}
Step 799: {'loss': 0.3627, 'learning_rate': 1.2541143521019095e-06, 'epoch': 2.86}
Step 800: {'loss': 0.3892, 'learning_rate': 1.1891062427038746e-06, 'epoch': 2.87}
Step 801: {'loss': 0.3786, 'learning_rate': 1.1258180760533089e-06, 'epoch': 2.87}
Step 802: {'loss': 0.3916, 'learning_rate': 1.0642509537698964e-06, 'epoch': 2.87}
Step 803: {'loss': 0.4067, 'learning_rate': 1.004405947516085e-06, 'epoch': 2.88}
Step 804: {'loss': 0.4013, 'learning_rate': 9.462840989784671e-07, 'epoch': 2.88}
Step 805: {'loss': 0.3925, 'learning_rate': 8.898864198496836e-07, 'epoch': 2.89}
Step 806: {'loss': 0.4008, 'learning_rate': 8.352138918107377e-07, 'epoch': 2.89}
Step 807: {'loss': 0.4246, 'learning_rate': 7.822674665139751e-07, 'epoch': 2.89}
Step 808: {'loss': 0.4076, 'learning_rate': 7.310480655664865e-07, 'epoch': 2.9}
Step 809: {'loss': 0.3898, 'learning_rate': 6.815565805140644e-07, 'epoch': 2.9}
Step 810: {'loss': 0.3839, 'learning_rate': 6.337938728257054e-07, 'epoch': 2.9}
Step 811: {'loss': 0.3988, 'learning_rate': 5.877607738785984e-07, 'epoch': 2.91}
Step 812: {'loss': 0.3799, 'learning_rate': 5.434580849436378e-07, 'epoch': 2.91}
Step 813: {'loss': 0.4311, 'learning_rate': 5.008865771715221e-07, 'epoch': 2.91}
Step 814: {'loss': 0.4227, 'learning_rate': 4.600469915792882e-07, 'epoch': 2.92}
Step 815: {'loss': 0.4234, 'learning_rate': 4.2094003903743186e-07, 'epoch': 2.92}
Step 816: {'loss': 0.4065, 'learning_rate': 3.83566400257529e-07, 'epoch': 2.92}
Step 817: {'loss': 0.4176, 'learning_rate': 3.4792672578038977e-07, 'epoch': 2.93}
Step 818: {'loss': 0.4143, 'learning_rate': 3.140216359647452e-07, 'epoch': 2.93}
Step 819: {'loss': 0.4473, 'learning_rate': 2.8185172097641156e-07, 'epoch': 2.94}
Step 820: {'loss': 0.389, 'learning_rate': 2.5141754077807613e-07, 'epoch': 2.94}
Step 821: {'loss': 0.3664, 'learning_rate': 2.2271962511948296e-07, 'epoch': 2.94}
Step 822: {'loss': 0.4722, 'learning_rate': 1.957584735282847e-07, 'epoch': 2.95}
Step 823: {'loss': 0.4009, 'learning_rate': 1.705345553012716e-07, 'epoch': 2.95}
Step 824: {'loss': 0.3858, 'learning_rate': 1.4704830949627824e-07, 'epoch': 2.95}
Step 825: {'loss': 0.4227, 'learning_rate': 1.2530014492446728e-07, 'epoch': 2.96}
Step 826: {'loss': 0.3809, 'learning_rate': 1.0529044014329081e-07, 'epoch': 2.96}
Step 827: {'loss': 0.3792, 'learning_rate': 8.701954344980667e-08, 'epoch': 2.96}
Step 828: {'loss': 0.3996, 'learning_rate': 7.048777287472774e-08, 'epoch': 2.97}
Step 829: {'loss': 0.436, 'learning_rate': 5.569541617679308e-08, 'epoch': 2.97}
Step 830: {'loss': 0.4156, 'learning_rate': 4.264273083778303e-08, 'epoch': 2.97}
Step 831: {'loss': 0.3736, 'learning_rate': 3.132994405808942e-08, 'epoch': 2.98}
Step 832: {'loss': 0.3697, 'learning_rate': 2.1757252752685476e-08, 'epoch': 2.98}
Step 833: {'loss': 0.3832, 'learning_rate': 1.3924823547750709e-08, 'epoch': 2.99}
Step 834: {'loss': 0.4101, 'learning_rate': 7.83279277773996e-09, 'epoch': 2.99}
Step 835: {'loss': 0.4274, 'learning_rate': 3.4812664830186082e-09, 'epoch': 2.99}
Step 836: {'loss': 0.3917, 'learning_rate': 8.703204080418026e-10, 'epoch': 3.0}
Step 837: {'loss': 0.3689, 'learning_rate': 0.0, 'epoch': 3.0}
Step 837: {'train_runtime': 1675.0521, 'train_samples_per_second': 15.981, 'train_steps_per_second': 0.5, 'total_flos': 0.0, 'train_loss': 0.54452361136212, 'epoch': 3.0}
