Step 1: {'loss': 9.7175, 'learning_rate': 1.183431952662722e-06, 'epoch': 0.0}
Step 2: {'loss': 8.49, 'learning_rate': 2.366863905325444e-06, 'epoch': 0.0}
Step 3: {'loss': 9.8821, 'learning_rate': 3.550295857988166e-06, 'epoch': 0.01}
Step 4: {'loss': 8.7414, 'learning_rate': 4.733727810650888e-06, 'epoch': 0.01}
Step 5: {'loss': 9.8122, 'learning_rate': 5.917159763313609e-06, 'epoch': 0.01}
Step 6: {'loss': 9.0085, 'learning_rate': 7.100591715976332e-06, 'epoch': 0.01}
Step 7: {'loss': 9.5524, 'learning_rate': 8.284023668639054e-06, 'epoch': 0.01}
Step 8: {'loss': 8.7429, 'learning_rate': 9.467455621301776e-06, 'epoch': 0.01}
Step 9: {'loss': 9.6134, 'learning_rate': 1.0650887573964498e-05, 'epoch': 0.02}
Step 10: {'loss': 8.4873, 'learning_rate': 1.1834319526627219e-05, 'epoch': 0.02}
Step 11: {'loss': 8.8762, 'learning_rate': 1.3017751479289941e-05, 'epoch': 0.02}
Step 12: {'loss': 9.1203, 'learning_rate': 1.4201183431952663e-05, 'epoch': 0.02}
Step 13: {'loss': 9.9935, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.02}
Step 14: {'loss': 8.6327, 'learning_rate': 1.6568047337278108e-05, 'epoch': 0.02}
Step 15: {'loss': 8.3733, 'learning_rate': 1.7751479289940828e-05, 'epoch': 0.03}
Step 16: {'loss': 9.272, 'learning_rate': 1.8934911242603552e-05, 'epoch': 0.03}
Step 17: {'loss': 8.8987, 'learning_rate': 2.0118343195266273e-05, 'epoch': 0.03}
Step 18: {'loss': 9.4566, 'learning_rate': 2.1301775147928997e-05, 'epoch': 0.03}
Step 19: {'loss': 9.0598, 'learning_rate': 2.2485207100591717e-05, 'epoch': 0.03}
Step 20: {'loss': 9.7302, 'learning_rate': 2.3668639053254438e-05, 'epoch': 0.04}
Step 21: {'loss': 8.4495, 'learning_rate': 2.485207100591716e-05, 'epoch': 0.04}
Step 22: {'loss': 8.8194, 'learning_rate': 2.6035502958579882e-05, 'epoch': 0.04}
Step 23: {'loss': 9.742, 'learning_rate': 2.7218934911242606e-05, 'epoch': 0.04}
Step 24: {'loss': 8.9013, 'learning_rate': 2.8402366863905327e-05, 'epoch': 0.04}
Step 25: {'loss': 8.9415, 'learning_rate': 2.958579881656805e-05, 'epoch': 0.04}
Step 26: {'loss': 8.9734, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.05}
Step 27: {'loss': 8.6768, 'learning_rate': 3.195266272189349e-05, 'epoch': 0.05}
Step 28: {'loss': 9.9354, 'learning_rate': 3.3136094674556215e-05, 'epoch': 0.05}
Step 29: {'loss': 8.0826, 'learning_rate': 3.431952662721893e-05, 'epoch': 0.05}
Step 30: {'loss': 8.5918, 'learning_rate': 3.5502958579881656e-05, 'epoch': 0.05}
Step 31: {'loss': 9.5877, 'learning_rate': 3.668639053254438e-05, 'epoch': 0.06}
Step 32: {'loss': 8.8823, 'learning_rate': 3.7869822485207104e-05, 'epoch': 0.06}
Step 33: {'loss': 8.692, 'learning_rate': 3.905325443786982e-05, 'epoch': 0.06}
Step 34: {'loss': 8.4491, 'learning_rate': 4.0236686390532545e-05, 'epoch': 0.06}
Step 35: {'loss': 10.0482, 'learning_rate': 4.142011834319527e-05, 'epoch': 0.06}
Step 36: {'loss': 8.877, 'learning_rate': 4.260355029585799e-05, 'epoch': 0.06}
Step 37: {'loss': 9.973, 'learning_rate': 4.378698224852072e-05, 'epoch': 0.07}
Step 38: {'loss': 9.2305, 'learning_rate': 4.4970414201183434e-05, 'epoch': 0.07}
Step 39: {'loss': 9.0286, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.07}
Step 40: {'loss': 9.1377, 'learning_rate': 4.7337278106508875e-05, 'epoch': 0.07}
Step 41: {'loss': 9.6309, 'learning_rate': 4.85207100591716e-05, 'epoch': 0.07}
Step 42: {'loss': 9.8569, 'learning_rate': 4.970414201183432e-05, 'epoch': 0.07}
Step 43: {'loss': 10.1784, 'learning_rate': 5.088757396449705e-05, 'epoch': 0.08}
Step 44: {'loss': 9.212, 'learning_rate': 5.2071005917159764e-05, 'epoch': 0.08}
Step 45: {'loss': 9.4598, 'learning_rate': 5.3254437869822495e-05, 'epoch': 0.08}
Step 46: {'loss': 9.5713, 'learning_rate': 5.443786982248521e-05, 'epoch': 0.08}
Step 47: {'loss': 8.8408, 'learning_rate': 5.562130177514793e-05, 'epoch': 0.08}
Step 48: {'loss': 9.7555, 'learning_rate': 5.680473372781065e-05, 'epoch': 0.09}
Step 49: {'loss': 8.2442, 'learning_rate': 5.798816568047337e-05, 'epoch': 0.09}
Step 50: {'loss': 9.9195, 'learning_rate': 5.91715976331361e-05, 'epoch': 0.09}
Step 51: {'loss': 8.2352, 'learning_rate': 6.035502958579882e-05, 'epoch': 0.09}
Step 52: {'loss': 9.4412, 'learning_rate': 6.153846153846155e-05, 'epoch': 0.09}
Step 53: {'loss': 8.5176, 'learning_rate': 6.272189349112427e-05, 'epoch': 0.09}
Step 54: {'loss': 9.7649, 'learning_rate': 6.390532544378698e-05, 'epoch': 0.1}
Step 55: {'loss': 9.6671, 'learning_rate': 6.50887573964497e-05, 'epoch': 0.1}
Step 56: {'loss': 8.4077, 'learning_rate': 6.627218934911243e-05, 'epoch': 0.1}
Step 57: {'loss': 8.9721, 'learning_rate': 6.745562130177515e-05, 'epoch': 0.1}
Step 58: {'loss': 8.9888, 'learning_rate': 6.863905325443787e-05, 'epoch': 0.1}
Step 59: {'loss': 9.7236, 'learning_rate': 6.98224852071006e-05, 'epoch': 0.1}
Step 60: {'loss': 9.1368, 'learning_rate': 7.100591715976331e-05, 'epoch': 0.11}
Step 61: {'loss': 9.2404, 'learning_rate': 7.218934911242604e-05, 'epoch': 0.11}
Step 62: {'loss': 8.4849, 'learning_rate': 7.337278106508876e-05, 'epoch': 0.11}
Step 63: {'loss': 9.3764, 'learning_rate': 7.455621301775149e-05, 'epoch': 0.11}
Step 64: {'loss': 9.3041, 'learning_rate': 7.573964497041421e-05, 'epoch': 0.11}
Step 65: {'loss': 8.8195, 'learning_rate': 7.692307692307693e-05, 'epoch': 0.12}
Step 66: {'loss': 9.543, 'learning_rate': 7.810650887573964e-05, 'epoch': 0.12}
Step 67: {'loss': 9.9599, 'learning_rate': 7.928994082840237e-05, 'epoch': 0.12}
Step 68: {'loss': 8.1851, 'learning_rate': 8.047337278106509e-05, 'epoch': 0.12}
Step 69: {'loss': 8.8871, 'learning_rate': 8.165680473372781e-05, 'epoch': 0.12}
Step 70: {'loss': 8.4553, 'learning_rate': 8.284023668639054e-05, 'epoch': 0.12}
Step 71: {'loss': 8.6192, 'learning_rate': 8.402366863905326e-05, 'epoch': 0.13}
Step 72: {'loss': 8.4452, 'learning_rate': 8.520710059171599e-05, 'epoch': 0.13}
Step 73: {'loss': 7.9353, 'learning_rate': 8.63905325443787e-05, 'epoch': 0.13}
Step 74: {'loss': 9.0686, 'learning_rate': 8.757396449704143e-05, 'epoch': 0.13}
Step 75: {'loss': 10.0398, 'learning_rate': 8.875739644970414e-05, 'epoch': 0.13}
Step 76: {'loss': 10.272, 'learning_rate': 8.994082840236687e-05, 'epoch': 0.14}
Step 77: {'loss': 8.7329, 'learning_rate': 9.112426035502959e-05, 'epoch': 0.14}
Step 78: {'loss': 8.1742, 'learning_rate': 9.230769230769232e-05, 'epoch': 0.14}
Step 79: {'loss': 9.626, 'learning_rate': 9.349112426035503e-05, 'epoch': 0.14}
Step 80: {'loss': 9.6293, 'learning_rate': 9.467455621301775e-05, 'epoch': 0.14}
Step 81: {'loss': 8.6653, 'learning_rate': 9.585798816568048e-05, 'epoch': 0.14}
Step 82: {'loss': 9.0028, 'learning_rate': 9.70414201183432e-05, 'epoch': 0.15}
Step 83: {'loss': 9.7145, 'learning_rate': 9.822485207100593e-05, 'epoch': 0.15}
Step 84: {'loss': 8.2188, 'learning_rate': 9.940828402366865e-05, 'epoch': 0.15}
Step 85: {'loss': 9.5044, 'learning_rate': 0.00010059171597633136, 'epoch': 0.15}
Step 86: {'loss': 9.1374, 'learning_rate': 0.0001017751479289941, 'epoch': 0.15}
Step 87: {'loss': 8.4266, 'learning_rate': 0.0001029585798816568, 'epoch': 0.15}
Step 88: {'loss': 8.3173, 'learning_rate': 0.00010414201183431953, 'epoch': 0.16}
Step 89: {'loss': 9.6581, 'learning_rate': 0.00010532544378698226, 'epoch': 0.16}
Step 90: {'loss': 8.5045, 'learning_rate': 0.00010650887573964499, 'epoch': 0.16}
Step 91: {'loss': 8.7503, 'learning_rate': 0.0001076923076923077, 'epoch': 0.16}
Step 92: {'loss': 9.2135, 'learning_rate': 0.00010887573964497042, 'epoch': 0.16}
Step 93: {'loss': 9.1437, 'learning_rate': 0.00011005917159763315, 'epoch': 0.17}
Step 94: {'loss': 7.4783, 'learning_rate': 0.00011124260355029586, 'epoch': 0.17}
Step 95: {'loss': 8.1333, 'learning_rate': 0.00011242603550295858, 'epoch': 0.17}
Step 96: {'loss': 8.5343, 'learning_rate': 0.0001136094674556213, 'epoch': 0.17}
Step 97: {'loss': 7.8249, 'learning_rate': 0.00011479289940828404, 'epoch': 0.17}
Step 98: {'loss': 8.6755, 'learning_rate': 0.00011597633136094674, 'epoch': 0.17}
Step 99: {'loss': 8.7818, 'learning_rate': 0.00011715976331360947, 'epoch': 0.18}
Step 100: {'loss': 8.1929, 'learning_rate': 0.0001183431952662722, 'epoch': 0.18}
Step 101: {'loss': 7.9659, 'learning_rate': 0.00011952662721893493, 'epoch': 0.18}
Step 102: {'loss': 8.577, 'learning_rate': 0.00012071005917159764, 'epoch': 0.18}
Step 103: {'loss': 7.8046, 'learning_rate': 0.00012189349112426037, 'epoch': 0.18}
Step 104: {'loss': 8.6, 'learning_rate': 0.0001230769230769231, 'epoch': 0.18}
Step 105: {'loss': 8.7755, 'learning_rate': 0.0001242603550295858, 'epoch': 0.19}
Step 106: {'loss': 8.5305, 'learning_rate': 0.00012544378698224853, 'epoch': 0.19}
Step 107: {'loss': 8.7556, 'learning_rate': 0.00012662721893491125, 'epoch': 0.19}
Step 108: {'loss': 8.7508, 'learning_rate': 0.00012781065088757397, 'epoch': 0.19}
Step 109: {'loss': 7.4689, 'learning_rate': 0.00012899408284023668, 'epoch': 0.19}
Step 110: {'loss': 8.282, 'learning_rate': 0.0001301775147928994, 'epoch': 0.2}
Step 111: {'loss': 7.8209, 'learning_rate': 0.00013136094674556214, 'epoch': 0.2}
Step 112: {'loss': 8.6692, 'learning_rate': 0.00013254437869822486, 'epoch': 0.2}
Step 113: {'loss': 7.2113, 'learning_rate': 0.00013372781065088758, 'epoch': 0.2}
Step 114: {'loss': 7.668, 'learning_rate': 0.0001349112426035503, 'epoch': 0.2}
Step 115: {'loss': 7.896, 'learning_rate': 0.00013609467455621304, 'epoch': 0.2}
Step 116: {'loss': 8.4281, 'learning_rate': 0.00013727810650887573, 'epoch': 0.21}
Step 117: {'loss': 8.5329, 'learning_rate': 0.00013846153846153847, 'epoch': 0.21}
Step 118: {'loss': 7.3359, 'learning_rate': 0.0001396449704142012, 'epoch': 0.21}
Step 119: {'loss': 7.9012, 'learning_rate': 0.0001408284023668639, 'epoch': 0.21}
Step 120: {'loss': 8.9807, 'learning_rate': 0.00014201183431952663, 'epoch': 0.21}
Step 121: {'loss': 8.1042, 'learning_rate': 0.00014319526627218934, 'epoch': 0.22}
Step 122: {'loss': 8.0041, 'learning_rate': 0.0001443786982248521, 'epoch': 0.22}
Step 123: {'loss': 8.0813, 'learning_rate': 0.0001455621301775148, 'epoch': 0.22}
Step 124: {'loss': 9.4349, 'learning_rate': 0.00014674556213017752, 'epoch': 0.22}
Step 125: {'loss': 8.0612, 'learning_rate': 0.00014792899408284024, 'epoch': 0.22}
Step 126: {'loss': 7.4005, 'learning_rate': 0.00014911242603550298, 'epoch': 0.22}
Step 127: {'loss': 7.7007, 'learning_rate': 0.00015029585798816567, 'epoch': 0.23}
Step 128: {'loss': 8.0006, 'learning_rate': 0.00015147928994082842, 'epoch': 0.23}
Step 129: {'loss': 7.6653, 'learning_rate': 0.00015266272189349113, 'epoch': 0.23}
Step 130: {'loss': 8.1489, 'learning_rate': 0.00015384615384615385, 'epoch': 0.23}
Step 131: {'loss': 7.8575, 'learning_rate': 0.00015502958579881657, 'epoch': 0.23}
Step 132: {'loss': 7.7952, 'learning_rate': 0.00015621301775147929, 'epoch': 0.23}
Step 133: {'loss': 8.3348, 'learning_rate': 0.00015739644970414203, 'epoch': 0.24}
Step 134: {'loss': 8.3343, 'learning_rate': 0.00015857988165680475, 'epoch': 0.24}
Step 135: {'loss': 7.9683, 'learning_rate': 0.00015976331360946746, 'epoch': 0.24}
Step 136: {'loss': 7.3259, 'learning_rate': 0.00016094674556213018, 'epoch': 0.24}
Step 137: {'loss': 9.0608, 'learning_rate': 0.00016213017751479293, 'epoch': 0.24}
Step 138: {'loss': 7.4414, 'learning_rate': 0.00016331360946745562, 'epoch': 0.25}
Step 139: {'loss': 7.6484, 'learning_rate': 0.00016449704142011836, 'epoch': 0.25}
Step 140: {'loss': 8.5199, 'learning_rate': 0.00016568047337278108, 'epoch': 0.25}
Step 141: {'loss': 8.082, 'learning_rate': 0.0001668639053254438, 'epoch': 0.25}
Step 142: {'loss': 8.2951, 'learning_rate': 0.0001680473372781065, 'epoch': 0.25}
Step 143: {'loss': 7.4481, 'learning_rate': 0.00016923076923076923, 'epoch': 0.25}
Step 144: {'loss': 7.7827, 'learning_rate': 0.00017041420118343197, 'epoch': 0.26}
Step 145: {'loss': 8.1713, 'learning_rate': 0.0001715976331360947, 'epoch': 0.26}
Step 146: {'loss': 8.0058, 'learning_rate': 0.0001727810650887574, 'epoch': 0.26}
Step 147: {'loss': 8.0186, 'learning_rate': 0.00017396449704142012, 'epoch': 0.26}
Step 148: {'loss': 8.1687, 'learning_rate': 0.00017514792899408287, 'epoch': 0.26}
Step 149: {'loss': 7.8581, 'learning_rate': 0.00017633136094674556, 'epoch': 0.26}
Step 150: {'loss': 7.9233, 'learning_rate': 0.00017751479289940828, 'epoch': 0.27}
Step 151: {'loss': 7.2657, 'learning_rate': 0.00017869822485207102, 'epoch': 0.27}
Step 152: {'loss': 7.8614, 'learning_rate': 0.00017988165680473374, 'epoch': 0.27}
Step 153: {'loss': 7.9918, 'learning_rate': 0.00018106508875739645, 'epoch': 0.27}
Step 154: {'loss': 7.2611, 'learning_rate': 0.00018224852071005917, 'epoch': 0.27}
Step 155: {'loss': 8.176, 'learning_rate': 0.00018343195266272192, 'epoch': 0.28}
Step 156: {'loss': 7.0095, 'learning_rate': 0.00018461538461538463, 'epoch': 0.28}
Step 157: {'loss': 7.848, 'learning_rate': 0.00018579881656804735, 'epoch': 0.28}
Step 158: {'loss': 7.4671, 'learning_rate': 0.00018698224852071007, 'epoch': 0.28}
Step 159: {'loss': 7.3962, 'learning_rate': 0.00018816568047337278, 'epoch': 0.28}
Step 160: {'loss': 7.6175, 'learning_rate': 0.0001893491124260355, 'epoch': 0.28}
Step 161: {'loss': 7.1645, 'learning_rate': 0.00019053254437869822, 'epoch': 0.29}
Step 162: {'loss': 8.4666, 'learning_rate': 0.00019171597633136096, 'epoch': 0.29}
Step 163: {'loss': 8.4522, 'learning_rate': 0.00019289940828402368, 'epoch': 0.29}
Step 164: {'loss': 7.919, 'learning_rate': 0.0001940828402366864, 'epoch': 0.29}
Step 165: {'loss': 7.1403, 'learning_rate': 0.00019526627218934911, 'epoch': 0.29}
Step 166: {'loss': 8.3229, 'learning_rate': 0.00019644970414201186, 'epoch': 0.3}
Step 167: {'loss': 6.7177, 'learning_rate': 0.00019763313609467458, 'epoch': 0.3}
Step 168: {'loss': 7.0951, 'learning_rate': 0.0001988165680473373, 'epoch': 0.3}
Step 169: {'loss': 7.104, 'learning_rate': 0.0002, 'epoch': 0.3}
Step 170: {'loss': 7.9473, 'learning_rate': 0.00019999978556363687, 'epoch': 0.3}
Step 171: {'loss': 7.1586, 'learning_rate': 0.0001999991422554671, 'epoch': 0.3}
Step 172: {'loss': 7.9916, 'learning_rate': 0.00019999807007824974, 'epoch': 0.31}
Step 173: {'loss': 6.96, 'learning_rate': 0.00019999656903658296, 'epoch': 0.31}
Step 174: {'loss': 6.5821, 'learning_rate': 0.0001999946391369044, 'epoch': 0.31}
Step 175: {'loss': 7.3074, 'learning_rate': 0.00019999228038749083, 'epoch': 0.31}
Step 176: {'loss': 7.9589, 'learning_rate': 0.00019998949279845832, 'epoch': 0.31}
Step 177: {'loss': 7.4941, 'learning_rate': 0.00019998627638176202, 'epoch': 0.31}
Step 178: {'loss': 7.3509, 'learning_rate': 0.00019998263115119633, 'epoch': 0.32}
Step 179: {'loss': 7.3434, 'learning_rate': 0.00019997855712239462, 'epoch': 0.32}
Step 180: {'loss': 7.648, 'learning_rate': 0.00019997405431282928, 'epoch': 0.32}
Step 181: {'loss': 7.6672, 'learning_rate': 0.00019996912274181162, 'epoch': 0.32}
Step 182: {'loss': 7.749, 'learning_rate': 0.0001999637624304919, 'epoch': 0.32}
Step 183: {'loss': 7.1065, 'learning_rate': 0.00019995797340185888, 'epoch': 0.33}
Step 184: {'loss': 7.4988, 'learning_rate': 0.00019995175568074026, 'epoch': 0.33}
Step 185: {'loss': 6.6818, 'learning_rate': 0.00019994510929380205, 'epoch': 0.33}
Step 186: {'loss': 7.1385, 'learning_rate': 0.00019993803426954885, 'epoch': 0.33}
Step 187: {'loss': 7.1184, 'learning_rate': 0.00019993053063832347, 'epoch': 0.33}
Step 188: {'loss': 7.0803, 'learning_rate': 0.000199922598432307, 'epoch': 0.33}
Step 189: {'loss': 7.3987, 'learning_rate': 0.00019991423768551844, 'epoch': 0.34}
Step 190: {'loss': 7.3759, 'learning_rate': 0.0001999054484338148, 'epoch': 0.34}
Step 191: {'loss': 7.2967, 'learning_rate': 0.00019989623071489074, 'epoch': 0.34}
Step 192: {'loss': 7.0312, 'learning_rate': 0.0001998865845682786, 'epoch': 0.34}
Step 193: {'loss': 7.1146, 'learning_rate': 0.00019987651003534803, 'epoch': 0.34}
Step 194: {'loss': 6.2583, 'learning_rate': 0.00019986600715930596, 'epoch': 0.34}
Step 195: {'loss': 7.3602, 'learning_rate': 0.00019985507598519636, 'epoch': 0.35}
Step 196: {'loss': 7.3508, 'learning_rate': 0.00019984371655990007, 'epoch': 0.35}
Step 197: {'loss': 7.1587, 'learning_rate': 0.00019983192893213453, 'epoch': 0.35}
Step 198: {'loss': 7.3977, 'learning_rate': 0.0001998197131524537, 'epoch': 0.35}
Step 199: {'loss': 6.6187, 'learning_rate': 0.00019980706927324776, 'epoch': 0.35}
Step 200: {'loss': 6.4671, 'learning_rate': 0.00019979399734874274, 'epoch': 0.36}
Step 201: {'loss': 7.1834, 'learning_rate': 0.00019978049743500068, 'epoch': 0.36}
Step 202: {'loss': 7.3386, 'learning_rate': 0.00019976656958991894, 'epoch': 0.36}
Step 203: {'loss': 6.5018, 'learning_rate': 0.00019975221387323033, 'epoch': 0.36}
Step 204: {'loss': 7.2225, 'learning_rate': 0.00019973743034650254, 'epoch': 0.36}
Step 205: {'loss': 6.996, 'learning_rate': 0.00019972221907313813, 'epoch': 0.36}
Step 206: {'loss': 7.2448, 'learning_rate': 0.00019970658011837404, 'epoch': 0.37}
Step 207: {'loss': 7.0872, 'learning_rate': 0.00019969051354928156, 'epoch': 0.37}
Step 208: {'loss': 7.0581, 'learning_rate': 0.00019967401943476575, 'epoch': 0.37}
Step 209: {'loss': 7.6021, 'learning_rate': 0.00019965709784556545, 'epoch': 0.37}
Step 210: {'loss': 7.467, 'learning_rate': 0.00019963974885425266, 'epoch': 0.37}
Step 211: {'loss': 7.1469, 'learning_rate': 0.00019962197253523253, 'epoch': 0.38}
Step 212: {'loss': 7.5184, 'learning_rate': 0.00019960376896474279, 'epoch': 0.38}
Step 213: {'loss': 6.3914, 'learning_rate': 0.00019958513822085363, 'epoch': 0.38}
Step 214: {'loss': 6.5471, 'learning_rate': 0.00019956608038346722, 'epoch': 0.38}
Step 215: {'loss': 7.2493, 'learning_rate': 0.00019954659553431743, 'epoch': 0.38}
Step 216: {'loss': 6.694, 'learning_rate': 0.00019952668375696945, 'epoch': 0.38}
Step 217: {'loss': 6.2502, 'learning_rate': 0.00019950634513681944, 'epoch': 0.39}
Step 218: {'loss': 6.7186, 'learning_rate': 0.0001994855797610943, 'epoch': 0.39}
Step 219: {'loss': 6.2637, 'learning_rate': 0.00019946438771885095, 'epoch': 0.39}
Step 220: {'loss': 6.9723, 'learning_rate': 0.0001994427691009763, 'epoch': 0.39}
Step 221: {'loss': 6.9529, 'learning_rate': 0.00019942072400018675, 'epoch': 0.39}
Step 222: {'loss': 6.7944, 'learning_rate': 0.00019939825251102765, 'epoch': 0.39}
Step 223: {'loss': 5.9566, 'learning_rate': 0.0001993753547298732, 'epoch': 0.4}
Step 224: {'loss': 6.6539, 'learning_rate': 0.00019935203075492565, 'epoch': 0.4}
Step 225: {'loss': 6.8087, 'learning_rate': 0.0001993282806862152, 'epoch': 0.4}
Step 226: {'loss': 7.0233, 'learning_rate': 0.00019930410462559942, 'epoch': 0.4}
Step 227: {'loss': 7.0599, 'learning_rate': 0.00019927950267676278, 'epoch': 0.4}
Step 228: {'loss': 7.4043, 'learning_rate': 0.00019925447494521643, 'epoch': 0.41}
Step 229: {'loss': 6.6303, 'learning_rate': 0.00019922902153829742, 'epoch': 0.41}
Step 230: {'loss': 6.9552, 'learning_rate': 0.00019920314256516845, 'epoch': 0.41}
Step 231: {'loss': 6.9818, 'learning_rate': 0.00019917683813681746, 'epoch': 0.41}
Step 232: {'loss': 6.625, 'learning_rate': 0.0001991501083660569, 'epoch': 0.41}
Step 233: {'loss': 7.0308, 'learning_rate': 0.0001991229533675235, 'epoch': 0.41}
Step 234: {'loss': 6.8095, 'learning_rate': 0.0001990953732576776, 'epoch': 0.42}
Step 235: {'loss': 6.54, 'learning_rate': 0.0001990673681548028, 'epoch': 0.42}
Step 236: {'loss': 6.1655, 'learning_rate': 0.00019903893817900536, 'epoch': 0.42}
Step 237: {'loss': 6.6921, 'learning_rate': 0.00019901008345221368, 'epoch': 0.42}
Step 238: {'loss': 6.457, 'learning_rate': 0.00019898080409817782, 'epoch': 0.42}
Step 239: {'loss': 6.7666, 'learning_rate': 0.00019895110024246892, 'epoch': 0.42}
Step 240: {'loss': 6.815, 'learning_rate': 0.00019892097201247873, 'epoch': 0.43}
Step 241: {'loss': 6.1876, 'learning_rate': 0.00019889041953741903, 'epoch': 0.43}
Step 242: {'loss': 6.1993, 'learning_rate': 0.00019885944294832102, 'epoch': 0.43}
Step 243: {'loss': 6.7005, 'learning_rate': 0.00019882804237803488, 'epoch': 0.43}
Step 244: {'loss': 6.7211, 'learning_rate': 0.00019879621796122906, 'epoch': 0.43}
Step 245: {'loss': 6.9857, 'learning_rate': 0.0001987639698343898, 'epoch': 0.44}
Step 246: {'loss': 5.9906, 'learning_rate': 0.00019873129813582053, 'epoch': 0.44}
Step 247: {'loss': 6.2533, 'learning_rate': 0.00019869820300564127, 'epoch': 0.44}
Step 248: {'loss': 6.8626, 'learning_rate': 0.00019866468458578797, 'epoch': 0.44}
Step 249: {'loss': 6.3664, 'learning_rate': 0.00019863074302001207, 'epoch': 0.44}
Step 250: {'loss': 6.5827, 'learning_rate': 0.0001985963784538796, 'epoch': 0.44}
Step 251: {'loss': 6.5195, 'learning_rate': 0.00019856159103477086, 'epoch': 0.45}
Step 252: {'loss': 5.7229, 'learning_rate': 0.0001985263809118796, 'epoch': 0.45}
Step 253: {'loss': 6.0328, 'learning_rate': 0.0001984907482362124, 'epoch': 0.45}
Step 254: {'loss': 6.4312, 'learning_rate': 0.0001984546931605881, 'epoch': 0.45}
Step 255: {'loss': 6.0994, 'learning_rate': 0.00019841821583963713, 'epoch': 0.45}
Step 256: {'loss': 5.909, 'learning_rate': 0.00019838131642980073, 'epoch': 0.46}
Step 257: {'loss': 6.1679, 'learning_rate': 0.0001983439950893304, 'epoch': 0.46}
Step 258: {'loss': 6.0597, 'learning_rate': 0.00019830625197828723, 'epoch': 0.46}
Step 259: {'loss': 5.8634, 'learning_rate': 0.00019826808725854106, 'epoch': 0.46}
Step 260: {'loss': 6.105, 'learning_rate': 0.00019822950109377004, 'epoch': 0.46}
Step 261: {'loss': 6.0042, 'learning_rate': 0.0001981904936494597, 'epoch': 0.46}
Step 262: {'loss': 5.6725, 'learning_rate': 0.00019815106509290224, 'epoch': 0.47}
Step 263: {'loss': 5.9471, 'learning_rate': 0.00019811121559319607, 'epoch': 0.47}
Step 264: {'loss': 5.7607, 'learning_rate': 0.00019807094532124482, 'epoch': 0.47}
Step 265: {'loss': 6.0328, 'learning_rate': 0.00019803025444975667, 'epoch': 0.47}
Step 266: {'loss': 6.2172, 'learning_rate': 0.00019798914315324369, 'epoch': 0.47}
Step 267: {'loss': 5.7672, 'learning_rate': 0.00019794761160802103, 'epoch': 0.47}
Step 268: {'loss': 6.3709, 'learning_rate': 0.00019790565999220613, 'epoch': 0.48}
Step 269: {'loss': 5.8703, 'learning_rate': 0.00019786328848571806, 'epoch': 0.48}
Step 270: {'loss': 6.2142, 'learning_rate': 0.00019782049727027663, 'epoch': 0.48}
Step 271: {'loss': 6.148, 'learning_rate': 0.00019777728652940171, 'epoch': 0.48}
Step 272: {'loss': 6.0174, 'learning_rate': 0.00019773365644841238, 'epoch': 0.48}
Step 273: {'loss': 6.3632, 'learning_rate': 0.00019768960721442614, 'epoch': 0.49}
Step 274: {'loss': 6.35, 'learning_rate': 0.00019764513901635814, 'epoch': 0.49}
Step 275: {'loss': 6.1904, 'learning_rate': 0.00019760025204492037, 'epoch': 0.49}
Step 276: {'loss': 5.9402, 'learning_rate': 0.00019755494649262084, 'epoch': 0.49}
Step 277: {'loss': 6.0486, 'learning_rate': 0.00019750922255376262, 'epoch': 0.49}
Step 278: {'loss': 5.5751, 'learning_rate': 0.00019746308042444327, 'epoch': 0.49}
Step 279: {'loss': 6.122, 'learning_rate': 0.00019741652030255384, 'epoch': 0.5}
Step 280: {'loss': 4.9517, 'learning_rate': 0.00019736954238777792, 'epoch': 0.5}
Step 281: {'loss': 5.8748, 'learning_rate': 0.00019732214688159098, 'epoch': 0.5}
Step 282: {'loss': 6.2254, 'learning_rate': 0.00019727433398725947, 'epoch': 0.5}
Step 283: {'loss': 6.0933, 'learning_rate': 0.00019722610390983982, 'epoch': 0.5}
Step 284: {'loss': 4.7198, 'learning_rate': 0.00019717745685617768, 'epoch': 0.5}
Step 285: {'loss': 5.982, 'learning_rate': 0.000197128393034907, 'epoch': 0.51}
Step 286: {'loss': 5.2066, 'learning_rate': 0.00019707891265644908, 'epoch': 0.51}
Step 287: {'loss': 5.8858, 'learning_rate': 0.0001970290159330119, 'epoch': 0.51}
Step 288: {'loss': 5.7841, 'learning_rate': 0.00019697870307858875, 'epoch': 0.51}
Step 289: {'loss': 6.2115, 'learning_rate': 0.0001969279743089578, 'epoch': 0.51}
Step 290: {'loss': 5.9276, 'learning_rate': 0.00019687682984168093, 'epoch': 0.52}
Step 291: {'loss': 6.0226, 'learning_rate': 0.00019682526989610278, 'epoch': 0.52}
Step 292: {'loss': 5.7672, 'learning_rate': 0.0001967732946933499, 'epoch': 0.52}
Step 293: {'loss': 5.6741, 'learning_rate': 0.00019672090445632976, 'epoch': 0.52}
Step 294: {'loss': 5.6458, 'learning_rate': 0.00019666809940972982, 'epoch': 0.52}
Step 295: {'loss': 6.2771, 'learning_rate': 0.00019661487978001648, 'epoch': 0.52}
Step 296: {'loss': 5.3858, 'learning_rate': 0.00019656124579543426, 'epoch': 0.53}
Step 297: {'loss': 5.1929, 'learning_rate': 0.00019650719768600467, 'epoch': 0.53}
Step 298: {'loss': 5.1838, 'learning_rate': 0.00019645273568352528, 'epoch': 0.53}
Step 299: {'loss': 5.9483, 'learning_rate': 0.00019639786002156884, 'epoch': 0.53}
Step 300: {'loss': 6.0114, 'learning_rate': 0.00019634257093548206, 'epoch': 0.53}
Step 301: {'loss': 5.7738, 'learning_rate': 0.0001962868686623847, 'epoch': 0.54}
Step 302: {'loss': 5.5711, 'learning_rate': 0.0001962307534411687, 'epoch': 0.54}
Step 303: {'loss': 5.4897, 'learning_rate': 0.00019617422551249688, 'epoch': 0.54}
Step 304: {'loss': 5.981, 'learning_rate': 0.00019611728511880218, 'epoch': 0.54}
Step 305: {'loss': 5.2317, 'learning_rate': 0.00019605993250428633, 'epoch': 0.54}
Step 306: {'loss': 4.7728, 'learning_rate': 0.0001960021679149191, 'epoch': 0.54}
Step 307: {'loss': 5.024, 'learning_rate': 0.00019594399159843703, 'epoch': 0.55}
Step 308: {'loss': 6.1201, 'learning_rate': 0.00019588540380434253, 'epoch': 0.55}
Step 309: {'loss': 5.5184, 'learning_rate': 0.00019582640478390262, 'epoch': 0.55}
Step 310: {'loss': 5.5054, 'learning_rate': 0.000195766994790148, 'epoch': 0.55}
Step 311: {'loss': 5.0718, 'learning_rate': 0.00019570717407787198, 'epoch': 0.55}
Step 312: {'loss': 5.3648, 'learning_rate': 0.00019564694290362926, 'epoch': 0.55}
Step 313: {'loss': 5.2185, 'learning_rate': 0.0001955863015257349, 'epoch': 0.56}
Step 314: {'loss': 5.1871, 'learning_rate': 0.00019552525020426323, 'epoch': 0.56}
Step 315: {'loss': 5.329, 'learning_rate': 0.00019546378920104674, 'epoch': 0.56}
Step 316: {'loss': 5.5138, 'learning_rate': 0.00019540191877967492, 'epoch': 0.56}
Step 317: {'loss': 6.2258, 'learning_rate': 0.00019533963920549306, 'epoch': 0.56}
Step 318: {'loss': 5.4253, 'learning_rate': 0.00019527695074560134, 'epoch': 0.57}
Step 319: {'loss': 5.1102, 'learning_rate': 0.00019521385366885348, 'epoch': 0.57}
Step 320: {'loss': 5.382, 'learning_rate': 0.00019515034824585557, 'epoch': 0.57}
Step 321: {'loss': 5.3048, 'learning_rate': 0.00019508643474896507, 'epoch': 0.57}
Step 322: {'loss': 5.104, 'learning_rate': 0.00019502211345228955, 'epoch': 0.57}
Step 323: {'loss': 4.9341, 'learning_rate': 0.00019495738463168552, 'epoch': 0.57}
Step 324: {'loss': 4.7144, 'learning_rate': 0.00019489224856475721, 'epoch': 0.58}
Step 325: {'loss': 5.2258, 'learning_rate': 0.00019482670553085547, 'epoch': 0.58}
Step 326: {'loss': 5.1767, 'learning_rate': 0.00019476075581107644, 'epoch': 0.58}
Step 327: {'loss': 4.8046, 'learning_rate': 0.00019469439968826057, 'epoch': 0.58}
Step 328: {'loss': 5.127, 'learning_rate': 0.00019462763744699114, 'epoch': 0.58}
Step 329: {'loss': 5.1799, 'learning_rate': 0.00019456046937359314, 'epoch': 0.58}
Step 330: {'loss': 5.0463, 'learning_rate': 0.00019449289575613219, 'epoch': 0.59}
Step 331: {'loss': 4.6979, 'learning_rate': 0.00019442491688441305, 'epoch': 0.59}
Step 332: {'loss': 5.2837, 'learning_rate': 0.00019435653304997858, 'epoch': 0.59}
Step 333: {'loss': 4.6827, 'learning_rate': 0.00019428774454610843, 'epoch': 0.59}
Step 334: {'loss': 4.9488, 'learning_rate': 0.00019421855166781767, 'epoch': 0.59}
Step 335: {'loss': 4.8667, 'learning_rate': 0.00019414895471185574, 'epoch': 0.6}
Step 336: {'loss': 4.2446, 'learning_rate': 0.00019407895397670499, 'epoch': 0.6}
Step 337: {'loss': 4.7713, 'learning_rate': 0.00019400854976257944, 'epoch': 0.6}
Step 338: {'loss': 4.4028, 'learning_rate': 0.00019393774237142362, 'epoch': 0.6}
Step 339: {'loss': 4.7393, 'learning_rate': 0.00019386653210691108, 'epoch': 0.6}
Step 340: {'loss': 4.8771, 'learning_rate': 0.00019379491927444322, 'epoch': 0.6}
Step 341: {'loss': 4.9372, 'learning_rate': 0.000193722904181148, 'epoch': 0.61}
Step 342: {'loss': 5.1963, 'learning_rate': 0.00019365048713587842, 'epoch': 0.61}
Step 343: {'loss': 4.578, 'learning_rate': 0.00019357766844921152, 'epoch': 0.61}
Step 344: {'loss': 4.2255, 'learning_rate': 0.00019350444843344678, 'epoch': 0.61}
Step 345: {'loss': 4.8798, 'learning_rate': 0.00019343082740260484, 'epoch': 0.61}
Step 346: {'loss': 4.7437, 'learning_rate': 0.0001933568056724262, 'epoch': 0.62}
Step 347: {'loss': 4.9714, 'learning_rate': 0.00019328238356036993, 'epoch': 0.62}
Step 348: {'loss': 4.3636, 'learning_rate': 0.00019320756138561219, 'epoch': 0.62}
Step 349: {'loss': 4.2543, 'learning_rate': 0.0001931323394690448, 'epoch': 0.62}
Step 350: {'loss': 4.2361, 'learning_rate': 0.00019305671813327408, 'epoch': 0.62}
Step 351: {'loss': 4.4762, 'learning_rate': 0.00019298069770261935, 'epoch': 0.62}
Step 352: {'loss': 4.9305, 'learning_rate': 0.00019290427850311148, 'epoch': 0.63}
Step 353: {'loss': 4.5237, 'learning_rate': 0.00019282746086249155, 'epoch': 0.63}
Step 354: {'loss': 4.7559, 'learning_rate': 0.0001927502451102095, 'epoch': 0.63}
Step 355: {'loss': 4.2694, 'learning_rate': 0.0001926726315774226, 'epoch': 0.63}
Step 356: {'loss': 4.3937, 'learning_rate': 0.00019259462059699413, 'epoch': 0.63}
Step 357: {'loss': 4.5063, 'learning_rate': 0.00019251621250349196, 'epoch': 0.63}
Step 358: {'loss': 4.9654, 'learning_rate': 0.00019243740763318697, 'epoch': 0.64}
Step 359: {'loss': 4.5009, 'learning_rate': 0.00019235820632405176, 'epoch': 0.64}
Step 360: {'loss': 3.8527, 'learning_rate': 0.00019227860891575914, 'epoch': 0.64}
Step 361: {'loss': 4.8515, 'learning_rate': 0.0001921986157496807, 'epoch': 0.64}
Step 362: {'loss': 4.8787, 'learning_rate': 0.0001921182271688853, 'epoch': 0.64}
Step 363: {'loss': 4.15, 'learning_rate': 0.00019203744351813765, 'epoch': 0.65}
Step 364: {'loss': 4.6886, 'learning_rate': 0.00019195626514389682, 'epoch': 0.65}
Step 365: {'loss': 4.5946, 'learning_rate': 0.00019187469239431465, 'epoch': 0.65}
Step 366: {'loss': 4.4281, 'learning_rate': 0.0001917927256192345, 'epoch': 0.65}
Step 367: {'loss': 4.6618, 'learning_rate': 0.00019171036517018944, 'epoch': 0.65}
Step 368: {'loss': 4.424, 'learning_rate': 0.00019162761140040097, 'epoch': 0.65}
Step 369: {'loss': 4.129, 'learning_rate': 0.0001915444646647775, 'epoch': 0.66}
Step 370: {'loss': 5.0478, 'learning_rate': 0.00019146092531991267, 'epoch': 0.66}
Step 371: {'loss': 4.7623, 'learning_rate': 0.00019137699372408391, 'epoch': 0.66}
Step 372: {'loss': 4.32, 'learning_rate': 0.000191292670237251, 'epoch': 0.66}
Step 373: {'loss': 4.4143, 'learning_rate': 0.00019120795522105434, 'epoch': 0.66}
Step 374: {'loss': 4.7343, 'learning_rate': 0.0001911228490388136, 'epoch': 0.66}
Step 375: {'loss': 4.1289, 'learning_rate': 0.00019103735205552587, 'epoch': 0.67}
Step 376: {'loss': 4.5535, 'learning_rate': 0.00019095146463786447, 'epoch': 0.67}
Step 377: {'loss': 4.4928, 'learning_rate': 0.00019086518715417708, 'epoch': 0.67}
Step 378: {'loss': 4.5334, 'learning_rate': 0.00019077851997448432, 'epoch': 0.67}
Step 379: {'loss': 4.6289, 'learning_rate': 0.00019069146347047808, 'epoch': 0.67}
Step 380: {'loss': 4.6891, 'learning_rate': 0.00019060401801551994, 'epoch': 0.68}
Step 381: {'loss': 4.5943, 'learning_rate': 0.00019051618398463965, 'epoch': 0.68}
Step 382: {'loss': 4.7123, 'learning_rate': 0.00019042796175453334, 'epoch': 0.68}
Step 383: {'loss': 5.1916, 'learning_rate': 0.0001903393517035622, 'epoch': 0.68}
Step 384: {'loss': 4.2417, 'learning_rate': 0.00019025035421175047, 'epoch': 0.68}
Step 385: {'loss': 4.1541, 'learning_rate': 0.00019016096966078416, 'epoch': 0.68}
Step 386: {'loss': 4.1985, 'learning_rate': 0.00019007119843400926, 'epoch': 0.69}
Step 387: {'loss': 4.0816, 'learning_rate': 0.00018998104091642998, 'epoch': 0.69}
Step 388: {'loss': 4.4085, 'learning_rate': 0.00018989049749470747, 'epoch': 0.69}
Step 389: {'loss': 4.5651, 'learning_rate': 0.00018979956855715764, 'epoch': 0.69}
Step 390: {'loss': 4.7128, 'learning_rate': 0.00018970825449375, 'epoch': 0.69}
Step 391: {'loss': 4.0284, 'learning_rate': 0.00018961655569610557, 'epoch': 0.7}
Step 392: {'loss': 4.4574, 'learning_rate': 0.00018952447255749557, 'epoch': 0.7}
Step 393: {'loss': 4.9247, 'learning_rate': 0.0001894320054728394, 'epoch': 0.7}
Step 394: {'loss': 4.5169, 'learning_rate': 0.0001893391548387032, 'epoch': 0.7}
Step 395: {'loss': 4.3231, 'learning_rate': 0.00018924592105329805, 'epoch': 0.7}
Step 396: {'loss': 4.1693, 'learning_rate': 0.00018915230451647816, 'epoch': 0.7}
Step 397: {'loss': 4.2697, 'learning_rate': 0.00018905830562973938, 'epoch': 0.71}
Step 398: {'loss': 4.6675, 'learning_rate': 0.00018896392479621725, 'epoch': 0.71}
Step 399: {'loss': 4.1574, 'learning_rate': 0.00018886916242068545, 'epoch': 0.71}
Step 400: {'loss': 4.2906, 'learning_rate': 0.00018877401890955394, 'epoch': 0.71}
Step 401: {'loss': 4.5377, 'learning_rate': 0.00018867849467086732, 'epoch': 0.71}
Step 402: {'loss': 4.627, 'learning_rate': 0.000188582590114303, 'epoch': 0.71}
Step 403: {'loss': 3.9516, 'learning_rate': 0.00018848630565116947, 'epoch': 0.72}
Step 404: {'loss': 4.105, 'learning_rate': 0.00018838964169440447, 'epoch': 0.72}
Step 405: {'loss': 3.9232, 'learning_rate': 0.00018829259865857343, 'epoch': 0.72}
Step 406: {'loss': 3.7691, 'learning_rate': 0.00018819517695986738, 'epoch': 0.72}
Step 407: {'loss': 4.335, 'learning_rate': 0.0001880973770161015, 'epoch': 0.72}
Step 408: {'loss': 3.8192, 'learning_rate': 0.00018799919924671304, 'epoch': 0.73}
Step 409: {'loss': 4.353, 'learning_rate': 0.00018790064407275963, 'epoch': 0.73}
Step 410: {'loss': 4.1172, 'learning_rate': 0.0001878017119169176, 'epoch': 0.73}
Step 411: {'loss': 4.3467, 'learning_rate': 0.00018770240320347995, 'epoch': 0.73}
Step 412: {'loss': 3.9428, 'learning_rate': 0.0001876027183583547, 'epoch': 0.73}
Step 413: {'loss': 4.3879, 'learning_rate': 0.0001875026578090629, 'epoch': 0.73}
Step 414: {'loss': 4.128, 'learning_rate': 0.00018740222198473697, 'epoch': 0.74}
Step 415: {'loss': 3.9112, 'learning_rate': 0.00018730141131611882, 'epoch': 0.74}
Step 416: {'loss': 4.6286, 'learning_rate': 0.00018720022623555787, 'epoch': 0.74}
Step 417: {'loss': 4.3785, 'learning_rate': 0.00018709866717700938, 'epoch': 0.74}
Step 418: {'loss': 3.9223, 'learning_rate': 0.0001869967345760324, 'epoch': 0.74}
Step 419: {'loss': 4.2536, 'learning_rate': 0.00018689442886978807, 'epoch': 0.74}
Step 420: {'loss': 4.1782, 'learning_rate': 0.00018679175049703768, 'epoch': 0.75}
Step 421: {'loss': 4.1113, 'learning_rate': 0.00018668869989814073, 'epoch': 0.75}
Step 422: {'loss': 3.856, 'learning_rate': 0.00018658527751505316, 'epoch': 0.75}
Step 423: {'loss': 4.1159, 'learning_rate': 0.00018648148379132537, 'epoch': 0.75}
Step 424: {'loss': 4.3192, 'learning_rate': 0.00018637731917210034, 'epoch': 0.75}
Step 425: {'loss': 4.378, 'learning_rate': 0.00018627278410411163, 'epoch': 0.76}
Step 426: {'loss': 3.9626, 'learning_rate': 0.00018616787903568175, 'epoch': 0.76}
Step 427: {'loss': 4.6403, 'learning_rate': 0.00018606260441671988, 'epoch': 0.76}
Step 428: {'loss': 4.4489, 'learning_rate': 0.00018595696069872013, 'epoch': 0.76}
Step 429: {'loss': 4.1485, 'learning_rate': 0.0001858509483347596, 'epoch': 0.76}
Step 430: {'loss': 3.8686, 'learning_rate': 0.00018574456777949644, 'epoch': 0.76}
Step 431: {'loss': 3.8686, 'learning_rate': 0.0001856378194891678, 'epoch': 0.77}
Step 432: {'loss': 4.1871, 'learning_rate': 0.00018553070392158798, 'epoch': 0.77}
Step 433: {'loss': 4.0226, 'learning_rate': 0.00018542322153614646, 'epoch': 0.77}
Step 434: {'loss': 4.4887, 'learning_rate': 0.00018531537279380586, 'epoch': 0.77}
Step 435: {'loss': 4.1842, 'learning_rate': 0.00018520715815710002, 'epoch': 0.77}
Step 436: {'loss': 3.8093, 'learning_rate': 0.00018509857809013207, 'epoch': 0.78}
Step 437: {'loss': 4.0884, 'learning_rate': 0.00018498963305857218, 'epoch': 0.78}
Step 438: {'loss': 4.5328, 'learning_rate': 0.00018488032352965598, 'epoch': 0.78}
Step 439: {'loss': 3.945, 'learning_rate': 0.00018477064997218218, 'epoch': 0.78}
Step 440: {'loss': 4.3162, 'learning_rate': 0.00018466061285651075, 'epoch': 0.78}
Step 441: {'loss': 3.7311, 'learning_rate': 0.00018455021265456088, 'epoch': 0.78}
Step 442: {'loss': 3.5726, 'learning_rate': 0.00018443944983980893, 'epoch': 0.79}
Step 443: {'loss': 4.1377, 'learning_rate': 0.00018432832488728639, 'epoch': 0.79}
Step 444: {'loss': 4.2682, 'learning_rate': 0.00018421683827357793, 'epoch': 0.79}
Step 445: {'loss': 4.2732, 'learning_rate': 0.00018410499047681914, 'epoch': 0.79}
Step 446: {'loss': 3.9668, 'learning_rate': 0.00018399278197669475, 'epoch': 0.79}
Step 447: {'loss': 4.0896, 'learning_rate': 0.00018388021325443647, 'epoch': 0.79}
Step 448: {'loss': 3.6093, 'learning_rate': 0.00018376728479282077, 'epoch': 0.8}
Step 449: {'loss': 4.2486, 'learning_rate': 0.00018365399707616706, 'epoch': 0.8}
Step 450: {'loss': 3.7417, 'learning_rate': 0.00018354035059033543, 'epoch': 0.8}
Step 451: {'loss': 3.696, 'learning_rate': 0.00018342634582272472, 'epoch': 0.8}
Step 452: {'loss': 4.615, 'learning_rate': 0.00018331198326227024, 'epoch': 0.8}
Step 453: {'loss': 3.8776, 'learning_rate': 0.00018319726339944184, 'epoch': 0.81}
Step 454: {'loss': 3.8653, 'learning_rate': 0.0001830821867262417, 'epoch': 0.81}
Step 455: {'loss': 4.3043, 'learning_rate': 0.00018296675373620226, 'epoch': 0.81}
Step 456: {'loss': 4.2265, 'learning_rate': 0.00018285096492438424, 'epoch': 0.81}
Step 457: {'loss': 3.8023, 'learning_rate': 0.00018273482078737417, 'epoch': 0.81}
Step 458: {'loss': 3.959, 'learning_rate': 0.0001826183218232826, 'epoch': 0.81}
Step 459: {'loss': 4.3838, 'learning_rate': 0.00018250146853174184, 'epoch': 0.82}
Step 460: {'loss': 3.575, 'learning_rate': 0.00018238426141390377, 'epoch': 0.82}
Step 461: {'loss': 4.2667, 'learning_rate': 0.00018226670097243775, 'epoch': 0.82}
Step 462: {'loss': 3.7765, 'learning_rate': 0.00018214878771152844, 'epoch': 0.82}
Step 463: {'loss': 3.9748, 'learning_rate': 0.0001820305221368737, 'epoch': 0.82}
Step 464: {'loss': 3.9197, 'learning_rate': 0.00018191190475568228, 'epoch': 0.82}
Step 465: {'loss': 4.2481, 'learning_rate': 0.00018179293607667178, 'epoch': 0.83}
Step 466: {'loss': 3.7957, 'learning_rate': 0.00018167361661006643, 'epoch': 0.83}
Step 467: {'loss': 3.9785, 'learning_rate': 0.0001815539468675949, 'epoch': 0.83}
Step 468: {'loss': 4.1307, 'learning_rate': 0.00018143392736248804, 'epoch': 0.83}
Step 469: {'loss': 4.0277, 'learning_rate': 0.0001813135586094768, 'epoch': 0.83}
Step 470: {'loss': 4.4199, 'learning_rate': 0.0001811928411247899, 'epoch': 0.84}
Step 471: {'loss': 4.2803, 'learning_rate': 0.00018107177542615172, 'epoch': 0.84}
Step 472: {'loss': 3.6878, 'learning_rate': 0.00018095036203278006, 'epoch': 0.84}
Step 473: {'loss': 4.4168, 'learning_rate': 0.0001808286014653838, 'epoch': 0.84}
Step 474: {'loss': 3.695, 'learning_rate': 0.00018070649424616083, 'epoch': 0.84}
Step 475: {'loss': 3.4284, 'learning_rate': 0.00018058404089879573, 'epoch': 0.84}
Step 476: {'loss': 4.0613, 'learning_rate': 0.00018046124194845745, 'epoch': 0.85}
Step 477: {'loss': 3.5467, 'learning_rate': 0.00018033809792179726, 'epoch': 0.85}
Step 478: {'loss': 4.068, 'learning_rate': 0.00018021460934694624, 'epoch': 0.85}
Step 479: {'loss': 3.5048, 'learning_rate': 0.00018009077675351328, 'epoch': 0.85}
Step 480: {'loss': 3.8484, 'learning_rate': 0.00017996660067258255, 'epoch': 0.85}
Step 481: {'loss': 3.857, 'learning_rate': 0.0001798420816367114, 'epoch': 0.86}
Step 482: {'loss': 3.9535, 'learning_rate': 0.00017971722017992806, 'epoch': 0.86}
Step 483: {'loss': 3.7007, 'learning_rate': 0.0001795920168377292, 'epoch': 0.86}
Step 484: {'loss': 3.9646, 'learning_rate': 0.0001794664721470778, 'epoch': 0.86}
Step 485: {'loss': 3.7536, 'learning_rate': 0.00017934058664640086, 'epoch': 0.86}
Step 486: {'loss': 4.0073, 'learning_rate': 0.00017921436087558692, 'epoch': 0.86}
Step 487: {'loss': 3.6733, 'learning_rate': 0.00017908779537598388, 'epoch': 0.87}
Step 488: {'loss': 4.2656, 'learning_rate': 0.0001789608906903967, 'epoch': 0.87}
Step 489: {'loss': 3.6408, 'learning_rate': 0.00017883364736308486, 'epoch': 0.87}
Step 490: {'loss': 3.4561, 'learning_rate': 0.0001787060659397604, 'epoch': 0.87}
Step 491: {'loss': 3.5892, 'learning_rate': 0.00017857814696758522, 'epoch': 0.87}
Step 492: {'loss': 3.9519, 'learning_rate': 0.00017844989099516885, 'epoch': 0.87}
Step 493: {'loss': 4.0873, 'learning_rate': 0.0001783212985725662, 'epoch': 0.88}
Step 494: {'loss': 3.5916, 'learning_rate': 0.00017819237025127512, 'epoch': 0.88}
Step 495: {'loss': 3.8151, 'learning_rate': 0.000178063106584234, 'epoch': 0.88}
Step 496: {'loss': 3.8647, 'learning_rate': 0.0001779335081258195, 'epoch': 0.88}
Step 497: {'loss': 3.8499, 'learning_rate': 0.00017780357543184397, 'epoch': 0.88}
Step 498: {'loss': 4.2824, 'learning_rate': 0.00017767330905955336, 'epoch': 0.89}
Step 499: {'loss': 3.434, 'learning_rate': 0.0001775427095676246, 'epoch': 0.89}
Step 500: {'loss': 4.0502, 'learning_rate': 0.00017741177751616328, 'epoch': 0.89}
Step 501: {'loss': 4.0976, 'learning_rate': 0.00017728051346670127, 'epoch': 0.89}
Step 502: {'loss': 3.9064, 'learning_rate': 0.0001771489179821943, 'epoch': 0.89}
Step 503: {'loss': 3.6892, 'learning_rate': 0.00017701699162701948, 'epoch': 0.89}
Step 504: {'loss': 3.6991, 'learning_rate': 0.00017688473496697298, 'epoch': 0.9}
Step 505: {'loss': 3.7122, 'learning_rate': 0.00017675214856926753, 'epoch': 0.9}
Step 506: {'loss': 3.9202, 'learning_rate': 0.00017661923300253001, 'epoch': 0.9}
Step 507: {'loss': 3.767, 'learning_rate': 0.0001764859888367991, 'epoch': 0.9}
Step 508: {'loss': 4.0609, 'learning_rate': 0.00017635241664352264, 'epoch': 0.9}
Step 509: {'loss': 3.664, 'learning_rate': 0.00017621851699555535, 'epoch': 0.9}
Step 510: {'loss': 3.9733, 'learning_rate': 0.00017608429046715629, 'epoch': 0.91}
Step 511: {'loss': 3.5692, 'learning_rate': 0.00017594973763398642, 'epoch': 0.91}
Step 512: {'loss': 3.895, 'learning_rate': 0.00017581485907310616, 'epoch': 0.91}
Step 513: {'loss': 4.1429, 'learning_rate': 0.00017567965536297288, 'epoch': 0.91}
Step 514: {'loss': 4.187, 'learning_rate': 0.00017554412708343842, 'epoch': 0.91}
Step 515: {'loss': 4.0816, 'learning_rate': 0.00017540827481574657, 'epoch': 0.92}
Step 516: {'loss': 3.8092, 'learning_rate': 0.00017527209914253074, 'epoch': 0.92}
Step 517: {'loss': 3.6807, 'learning_rate': 0.00017513560064781115, 'epoch': 0.92}
Step 518: {'loss': 3.7535, 'learning_rate': 0.00017499877991699266, 'epoch': 0.92}
Step 519: {'loss': 3.6127, 'learning_rate': 0.00017486163753686207, 'epoch': 0.92}
Step 520: {'loss': 3.6523, 'learning_rate': 0.00017472417409558565, 'epoch': 0.92}
Step 521: {'loss': 3.7133, 'learning_rate': 0.0001745863901827066, 'epoch': 0.93}
Step 522: {'loss': 3.7011, 'learning_rate': 0.00017444828638914252, 'epoch': 0.93}
Step 523: {'loss': 4.0366, 'learning_rate': 0.00017430986330718294, 'epoch': 0.93}
Step 524: {'loss': 3.9233, 'learning_rate': 0.00017417112153048675, 'epoch': 0.93}
Step 525: {'loss': 3.7491, 'learning_rate': 0.0001740320616540795, 'epoch': 0.93}
Step 526: {'loss': 3.6585, 'learning_rate': 0.00017389268427435114, 'epoch': 0.94}
Step 527: {'loss': 3.4039, 'learning_rate': 0.00017375298998905322, 'epoch': 0.94}
Step 528: {'loss': 3.5411, 'learning_rate': 0.00017361297939729638, 'epoch': 0.94}
Step 529: {'loss': 4.1856, 'learning_rate': 0.00017347265309954795, 'epoch': 0.94}
Step 530: {'loss': 3.5495, 'learning_rate': 0.00017333201169762908, 'epoch': 0.94}
Step 531: {'loss': 4.2359, 'learning_rate': 0.00017319105579471247, 'epoch': 0.94}
Step 532: {'loss': 3.8196, 'learning_rate': 0.00017304978599531944, 'epoch': 0.95}
Step 533: {'loss': 3.8431, 'learning_rate': 0.00017290820290531765, 'epoch': 0.95}
Step 534: {'loss': 3.9089, 'learning_rate': 0.00017276630713191843, 'epoch': 0.95}
Step 535: {'loss': 4.2675, 'learning_rate': 0.00017262409928367397, 'epoch': 0.95}
Step 536: {'loss': 4.0151, 'learning_rate': 0.00017248157997047498, 'epoch': 0.95}
Step 537: {'loss': 4.0548, 'learning_rate': 0.00017233874980354793, 'epoch': 0.95}
Step 538: {'loss': 3.6768, 'learning_rate': 0.00017219560939545246, 'epoch': 0.96}
Step 539: {'loss': 4.1145, 'learning_rate': 0.0001720521593600787, 'epoch': 0.96}
Step 540: {'loss': 3.6987, 'learning_rate': 0.00017190840031264476, 'epoch': 0.96}
Step 541: {'loss': 3.9022, 'learning_rate': 0.000171764332869694, 'epoch': 0.96}
Step 542: {'loss': 3.6097, 'learning_rate': 0.00017161995764909235, 'epoch': 0.96}
Step 543: {'loss': 3.9034, 'learning_rate': 0.0001714752752700258, 'epoch': 0.97}
Step 544: {'loss': 3.5528, 'learning_rate': 0.00017133028635299758, 'epoch': 0.97}
Step 545: {'loss': 4.3261, 'learning_rate': 0.0001711849915198256, 'epoch': 0.97}
Step 546: {'loss': 3.8296, 'learning_rate': 0.00017103939139363977, 'epoch': 0.97}
Step 547: {'loss': 3.5348, 'learning_rate': 0.0001708934865988794, 'epoch': 0.97}
Step 548: {'loss': 3.6037, 'learning_rate': 0.00017074727776129024, 'epoch': 0.97}
Step 549: {'loss': 4.0756, 'learning_rate': 0.00017060076550792221, 'epoch': 0.98}
Step 550: {'loss': 3.5069, 'learning_rate': 0.00017045395046712638, 'epoch': 0.98}
Step 551: {'loss': 3.2534, 'learning_rate': 0.00017030683326855242, 'epoch': 0.98}
Step 552: {'loss': 3.4889, 'learning_rate': 0.00017015941454314584, 'epoch': 0.98}
Step 553: {'loss': 4.0459, 'learning_rate': 0.0001700116949231454, 'epoch': 0.98}
Step 554: {'loss': 3.5855, 'learning_rate': 0.0001698636750420802, 'epoch': 0.98}
Step 555: {'loss': 3.7409, 'learning_rate': 0.0001697153555347672, 'epoch': 0.99}
Step 556: {'loss': 3.9199, 'learning_rate': 0.00016956673703730828, 'epoch': 0.99}
Step 557: {'loss': 3.7537, 'learning_rate': 0.00016941782018708762, 'epoch': 0.99}
Step 558: {'loss': 3.5114, 'learning_rate': 0.00016926860562276904, 'epoch': 0.99}
Step 559: {'loss': 3.529, 'learning_rate': 0.00016911909398429305, 'epoch': 0.99}
Step 560: {'loss': 4.0742, 'learning_rate': 0.00016896928591287434, 'epoch': 1.0}
Step 561: {'loss': 3.8786, 'learning_rate': 0.0001688191820509988, 'epoch': 1.0}
Step 562: {'loss': 3.7815, 'learning_rate': 0.00016866878304242104, 'epoch': 1.0}
Step 563: {'loss': 3.8563, 'learning_rate': 0.00016851808953216132, 'epoch': 1.0}
Step 564: {'loss': 3.6659, 'learning_rate': 0.00016836710216650304, 'epoch': 1.0}
Step 565: {'loss': 3.4591, 'learning_rate': 0.00016821582159298984, 'epoch': 1.0}
Step 566: {'loss': 3.5447, 'learning_rate': 0.0001680642484604228, 'epoch': 1.01}
Step 567: {'loss': 3.7604, 'learning_rate': 0.00016791238341885777, 'epoch': 1.01}
Step 568: {'loss': 3.7123, 'learning_rate': 0.0001677602271196025, 'epoch': 1.01}
Step 569: {'loss': 3.5784, 'learning_rate': 0.00016760778021521387, 'epoch': 1.01}
Step 570: {'loss': 3.7514, 'learning_rate': 0.00016745504335949503, 'epoch': 1.01}
Step 571: {'loss': 3.9763, 'learning_rate': 0.00016730201720749273, 'epoch': 1.02}
Step 572: {'loss': 3.8497, 'learning_rate': 0.00016714870241549444, 'epoch': 1.02}
Step 573: {'loss': 3.7598, 'learning_rate': 0.0001669950996410254, 'epoch': 1.02}
Step 574: {'loss': 3.7017, 'learning_rate': 0.00016684120954284606, 'epoch': 1.02}
Step 575: {'loss': 3.8136, 'learning_rate': 0.0001666870327809491, 'epoch': 1.02}
Step 576: {'loss': 4.1727, 'learning_rate': 0.00016653257001655652, 'epoch': 1.02}
Step 577: {'loss': 3.7114, 'learning_rate': 0.00016637782191211714, 'epoch': 1.03}
Step 578: {'loss': 4.1365, 'learning_rate': 0.0001662227891313032, 'epoch': 1.03}
Step 579: {'loss': 3.98, 'learning_rate': 0.00016606747233900815, 'epoch': 1.03}
Step 580: {'loss': 3.4053, 'learning_rate': 0.0001659118722013433, 'epoch': 1.03}
Step 581: {'loss': 3.7913, 'learning_rate': 0.00016575598938563517, 'epoch': 1.03}
Step 582: {'loss': 3.5938, 'learning_rate': 0.00016559982456042268, 'epoch': 1.03}
Step 583: {'loss': 3.5105, 'learning_rate': 0.0001654433783954542, 'epoch': 1.04}
Step 584: {'loss': 3.7252, 'learning_rate': 0.0001652866515616846, 'epoch': 1.04}
Step 585: {'loss': 3.5864, 'learning_rate': 0.00016512964473127254, 'epoch': 1.04}
Step 586: {'loss': 3.5942, 'learning_rate': 0.00016497235857757753, 'epoch': 1.04}
Step 587: {'loss': 3.6861, 'learning_rate': 0.00016481479377515698, 'epoch': 1.04}
Step 588: {'loss': 3.3445, 'learning_rate': 0.00016465695099976332, 'epoch': 1.05}
Step 589: {'loss': 3.6225, 'learning_rate': 0.00016449883092834117, 'epoch': 1.05}
Step 590: {'loss': 3.2836, 'learning_rate': 0.00016434043423902442, 'epoch': 1.05}
Step 591: {'loss': 3.5322, 'learning_rate': 0.00016418176161113324, 'epoch': 1.05}
Step 592: {'loss': 3.652, 'learning_rate': 0.00016402281372517128, 'epoch': 1.05}
Step 593: {'loss': 3.7475, 'learning_rate': 0.00016386359126282262, 'epoch': 1.05}
Step 594: {'loss': 3.9944, 'learning_rate': 0.00016370409490694908, 'epoch': 1.06}
Step 595: {'loss': 3.9548, 'learning_rate': 0.00016354432534158693, 'epoch': 1.06}
Step 596: {'loss': 3.4753, 'learning_rate': 0.00016338428325194429, 'epoch': 1.06}
Step 597: {'loss': 3.6366, 'learning_rate': 0.00016322396932439803, 'epoch': 1.06}
Step 598: {'loss': 3.9836, 'learning_rate': 0.0001630633842464909, 'epoch': 1.06}
Step 599: {'loss': 3.2891, 'learning_rate': 0.00016290252870692842, 'epoch': 1.06}
Step 600: {'loss': 3.5599, 'learning_rate': 0.00016274140339557624, 'epoch': 1.07}
Step 601: {'loss': 3.7261, 'learning_rate': 0.0001625800090034568, 'epoch': 1.07}
Step 602: {'loss': 3.8701, 'learning_rate': 0.0001624183462227466, 'epoch': 1.07}
Step 603: {'loss': 3.9406, 'learning_rate': 0.00016225641574677332, 'epoch': 1.07}
Step 604: {'loss': 3.5293, 'learning_rate': 0.00016209421827001252, 'epoch': 1.07}
Step 605: {'loss': 3.4982, 'learning_rate': 0.00016193175448808494, 'epoch': 1.08}
Step 606: {'loss': 4.1938, 'learning_rate': 0.0001617690250977535, 'epoch': 1.08}
Step 607: {'loss': 3.5302, 'learning_rate': 0.00016160603079692012, 'epoch': 1.08}
Step 608: {'loss': 3.6281, 'learning_rate': 0.00016144277228462287, 'epoch': 1.08}
Step 609: {'loss': 3.7579, 'learning_rate': 0.00016127925026103307, 'epoch': 1.08}
Step 610: {'loss': 3.6927, 'learning_rate': 0.00016111546542745204, 'epoch': 1.08}
Step 611: {'loss': 3.7068, 'learning_rate': 0.0001609514184863082, 'epoch': 1.09}
Step 612: {'loss': 4.0961, 'learning_rate': 0.00016078711014115427, 'epoch': 1.09}
Step 613: {'loss': 3.921, 'learning_rate': 0.0001606225410966638, 'epoch': 1.09}
Step 614: {'loss': 3.7102, 'learning_rate': 0.00016045771205862864, 'epoch': 1.09}
Step 615: {'loss': 3.5146, 'learning_rate': 0.0001602926237339555, 'epoch': 1.09}
Step 616: {'loss': 3.8113, 'learning_rate': 0.0001601272768306632, 'epoch': 1.1}
Step 617: {'loss': 3.6522, 'learning_rate': 0.0001599616720578795, 'epoch': 1.1}
Step 618: {'loss': 3.6971, 'learning_rate': 0.0001597958101258382, 'epoch': 1.1}
Step 619: {'loss': 3.8742, 'learning_rate': 0.00015962969174587578, 'epoch': 1.1}
Step 620: {'loss': 4.0871, 'learning_rate': 0.00015946331763042867, 'epoch': 1.1}
Step 621: {'loss': 3.3912, 'learning_rate': 0.00015929668849303013, 'epoch': 1.1}
Step 622: {'loss': 3.7629, 'learning_rate': 0.00015912980504830708, 'epoch': 1.11}
Step 623: {'loss': 3.7593, 'learning_rate': 0.00015896266801197705, 'epoch': 1.11}
Step 624: {'loss': 3.992, 'learning_rate': 0.00015879527810084524, 'epoch': 1.11}
Step 625: {'loss': 3.7275, 'learning_rate': 0.00015862763603280132, 'epoch': 1.11}
Step 626: {'loss': 3.5902, 'learning_rate': 0.00015845974252681638, 'epoch': 1.11}
Step 627: {'loss': 3.7174, 'learning_rate': 0.00015829159830293993, 'epoch': 1.11}
Step 628: {'loss': 3.5698, 'learning_rate': 0.00015812320408229658, 'epoch': 1.12}
Step 629: {'loss': 3.8454, 'learning_rate': 0.00015795456058708334, 'epoch': 1.12}
Step 630: {'loss': 3.4577, 'learning_rate': 0.00015778566854056614, 'epoch': 1.12}
Step 631: {'loss': 3.7743, 'learning_rate': 0.00015761652866707682, 'epoch': 1.12}
Step 632: {'loss': 3.9654, 'learning_rate': 0.00015744714169201022, 'epoch': 1.12}
Step 633: {'loss': 3.7514, 'learning_rate': 0.00015727750834182089, 'epoch': 1.13}
Step 634: {'loss': 3.8572, 'learning_rate': 0.00015710762934402, 'epoch': 1.13}
Step 635: {'loss': 3.5404, 'learning_rate': 0.00015693750542717223, 'epoch': 1.13}
Step 636: {'loss': 3.571, 'learning_rate': 0.00015676713732089268, 'epoch': 1.13}
Step 637: {'loss': 3.4937, 'learning_rate': 0.00015659652575584365, 'epoch': 1.13}
Step 638: {'loss': 3.5543, 'learning_rate': 0.00015642567146373164, 'epoch': 1.13}
Step 639: {'loss': 3.6247, 'learning_rate': 0.0001562545751773041, 'epoch': 1.14}
Step 640: {'loss': 3.6591, 'learning_rate': 0.0001560832376303463, 'epoch': 1.14}
Step 641: {'loss': 3.9096, 'learning_rate': 0.0001559116595576784, 'epoch': 1.14}
Step 642: {'loss': 3.644, 'learning_rate': 0.00015573984169515176, 'epoch': 1.14}
Step 643: {'loss': 4.0919, 'learning_rate': 0.00015556778477964644, 'epoch': 1.14}
Step 644: {'loss': 3.9398, 'learning_rate': 0.00015539548954906764, 'epoch': 1.14}
Step 645: {'loss': 3.5947, 'learning_rate': 0.00015522295674234252, 'epoch': 1.15}
Step 646: {'loss': 3.5715, 'learning_rate': 0.00015505018709941734, 'epoch': 1.15}
Step 647: {'loss': 3.7823, 'learning_rate': 0.0001548771813612539, 'epoch': 1.15}
Step 648: {'loss': 3.7055, 'learning_rate': 0.00015470394026982667, 'epoch': 1.15}
Step 649: {'loss': 4.11, 'learning_rate': 0.0001545304645681194, 'epoch': 1.15}
Step 650: {'loss': 3.642, 'learning_rate': 0.00015435675500012212, 'epoch': 1.16}
Step 651: {'loss': 4.1617, 'learning_rate': 0.00015418281231082776, 'epoch': 1.16}
Step 652: {'loss': 3.4782, 'learning_rate': 0.00015400863724622906, 'epoch': 1.16}
Step 653: {'loss': 3.6016, 'learning_rate': 0.00015383423055331536, 'epoch': 1.16}
Step 654: {'loss': 3.3887, 'learning_rate': 0.0001536595929800694, 'epoch': 1.16}
Step 655: {'loss': 3.282, 'learning_rate': 0.00015348472527546415, 'epoch': 1.16}
Step 656: {'loss': 4.0538, 'learning_rate': 0.00015330962818945948, 'epoch': 1.17}
Step 657: {'loss': 3.5285, 'learning_rate': 0.00015313430247299901, 'epoch': 1.17}
Step 658: {'loss': 3.8088, 'learning_rate': 0.00015295874887800694, 'epoch': 1.17}
Step 659: {'loss': 3.6806, 'learning_rate': 0.00015278296815738476, 'epoch': 1.17}
Step 660: {'loss': 4.171, 'learning_rate': 0.00015260696106500805, 'epoch': 1.17}
Step 661: {'loss': 3.5056, 'learning_rate': 0.00015243072835572318, 'epoch': 1.18}
Step 662: {'loss': 3.3681, 'learning_rate': 0.00015225427078534423, 'epoch': 1.18}
Step 663: {'loss': 3.545, 'learning_rate': 0.00015207758911064956, 'epoch': 1.18}
Step 664: {'loss': 3.8706, 'learning_rate': 0.00015190068408937868, 'epoch': 1.18}
Step 665: {'loss': 3.6153, 'learning_rate': 0.000151723556480229, 'epoch': 1.18}
Step 666: {'loss': 3.7821, 'learning_rate': 0.00015154620704285252, 'epoch': 1.18}
Step 667: {'loss': 3.7175, 'learning_rate': 0.00015136863653785257, 'epoch': 1.19}
Step 668: {'loss': 3.8423, 'learning_rate': 0.00015119084572678073, 'epoch': 1.19}
Step 669: {'loss': 3.6948, 'learning_rate': 0.00015101283537213316, 'epoch': 1.19}
Step 670: {'loss': 4.0725, 'learning_rate': 0.00015083460623734776, 'epoch': 1.19}
Step 671: {'loss': 3.5485, 'learning_rate': 0.00015065615908680074, 'epoch': 1.19}
Step 672: {'loss': 3.7123, 'learning_rate': 0.00015047749468580324, 'epoch': 1.19}
Step 673: {'loss': 3.5624, 'learning_rate': 0.00015029861380059804, 'epoch': 1.2}
Step 674: {'loss': 3.6117, 'learning_rate': 0.00015011951719835664, 'epoch': 1.2}
Step 675: {'loss': 3.6246, 'learning_rate': 0.0001499402056471754, 'epoch': 1.2}
Step 676: {'loss': 3.5917, 'learning_rate': 0.0001497606799160727, 'epoch': 1.2}
Step 677: {'loss': 3.5778, 'learning_rate': 0.00014958094077498544, 'epoch': 1.2}
Step 678: {'loss': 3.2627, 'learning_rate': 0.00014940098899476575, 'epoch': 1.21}
Step 679: {'loss': 3.9062, 'learning_rate': 0.00014922082534717777, 'epoch': 1.21}
Step 680: {'loss': 3.9267, 'learning_rate': 0.0001490404506048942, 'epoch': 1.21}
Step 681: {'loss': 3.419, 'learning_rate': 0.00014885986554149315, 'epoch': 1.21}
Step 682: {'loss': 3.6324, 'learning_rate': 0.00014867907093145472, 'epoch': 1.21}
Step 683: {'loss': 3.8507, 'learning_rate': 0.00014849806755015766, 'epoch': 1.21}
Step 684: {'loss': 3.5958, 'learning_rate': 0.00014831685617387608, 'epoch': 1.22}
Step 685: {'loss': 3.7645, 'learning_rate': 0.00014813543757977618, 'epoch': 1.22}
Step 686: {'loss': 4.0724, 'learning_rate': 0.00014795381254591286, 'epoch': 1.22}
Step 687: {'loss': 3.6304, 'learning_rate': 0.0001477719818512263, 'epoch': 1.22}
Step 688: {'loss': 3.6372, 'learning_rate': 0.0001475899462755388, 'epoch': 1.22}
Step 689: {'loss': 3.7082, 'learning_rate': 0.00014740770659955126, 'epoch': 1.22}
Step 690: {'loss': 3.8406, 'learning_rate': 0.00014722526360483996, 'epoch': 1.23}
Step 691: {'loss': 4.0697, 'learning_rate': 0.00014704261807385314, 'epoch': 1.23}
Step 692: {'loss': 3.5841, 'learning_rate': 0.00014685977078990767, 'epoch': 1.23}
Step 693: {'loss': 3.7048, 'learning_rate': 0.00014667672253718572, 'epoch': 1.23}
Step 694: {'loss': 3.7561, 'learning_rate': 0.00014649347410073126, 'epoch': 1.23}
Step 695: {'loss': 3.7274, 'learning_rate': 0.0001463100262664469, 'epoch': 1.24}
Step 696: {'loss': 3.975, 'learning_rate': 0.00014612637982109035, 'epoch': 1.24}
Step 697: {'loss': 4.0729, 'learning_rate': 0.0001459425355522711, 'epoch': 1.24}
Step 698: {'loss': 3.5612, 'learning_rate': 0.00014575849424844716, 'epoch': 1.24}
Step 699: {'loss': 3.7599, 'learning_rate': 0.0001455742566989214, 'epoch': 1.24}
Step 700: {'loss': 3.5086, 'learning_rate': 0.00014538982369383848, 'epoch': 1.24}
Step 701: {'loss': 3.7545, 'learning_rate': 0.0001452051960241812, 'epoch': 1.25}
Step 702: {'loss': 3.7691, 'learning_rate': 0.00014502037448176734, 'epoch': 1.25}
Step 703: {'loss': 3.5927, 'learning_rate': 0.00014483535985924606, 'epoch': 1.25}
Step 704: {'loss': 3.4672, 'learning_rate': 0.00014465015295009464, 'epoch': 1.25}
Step 705: {'loss': 3.6273, 'learning_rate': 0.0001444647545486149, 'epoch': 1.25}
Step 706: {'loss': 3.737, 'learning_rate': 0.00014427916544993016, 'epoch': 1.26}
Step 707: {'loss': 3.5087, 'learning_rate': 0.0001440933864499814, 'epoch': 1.26}
Step 708: {'loss': 3.7442, 'learning_rate': 0.000143907418345524, 'epoch': 1.26}
Step 709: {'loss': 3.472, 'learning_rate': 0.0001437212619341245, 'epoch': 1.26}
Step 710: {'loss': 3.5557, 'learning_rate': 0.00014353491801415705, 'epoch': 1.26}
Step 711: {'loss': 3.0951, 'learning_rate': 0.00014334838738479979, 'epoch': 1.26}
Step 712: {'loss': 3.4905, 'learning_rate': 0.00014316167084603177, 'epoch': 1.27}
Step 713: {'loss': 3.4073, 'learning_rate': 0.0001429747691986293, 'epoch': 1.27}
Step 714: {'loss': 3.6698, 'learning_rate': 0.00014278768324416251, 'epoch': 1.27}
Step 715: {'loss': 3.9831, 'learning_rate': 0.00014260041378499213, 'epoch': 1.27}
Step 716: {'loss': 3.628, 'learning_rate': 0.00014241296162426575, 'epoch': 1.27}
Step 717: {'loss': 3.7795, 'learning_rate': 0.00014222532756591453, 'epoch': 1.27}
Step 718: {'loss': 3.713, 'learning_rate': 0.0001420375124146498, 'epoch': 1.28}
Step 719: {'loss': 3.5924, 'learning_rate': 0.00014184951697595954, 'epoch': 1.28}
Step 720: {'loss': 3.4428, 'learning_rate': 0.00014166134205610483, 'epoch': 1.28}
Step 721: {'loss': 4.0728, 'learning_rate': 0.00014147298846211673, 'epoch': 1.28}
Step 722: {'loss': 3.2098, 'learning_rate': 0.0001412844570017923, 'epoch': 1.28}
Step 723: {'loss': 3.8873, 'learning_rate': 0.0001410957484836916, 'epoch': 1.29}
Step 724: {'loss': 3.6664, 'learning_rate': 0.00014090686371713402, 'epoch': 1.29}
Step 725: {'loss': 3.507, 'learning_rate': 0.00014071780351219474, 'epoch': 1.29}
Step 726: {'loss': 3.7823, 'learning_rate': 0.0001405285686797015, 'epoch': 1.29}
Step 727: {'loss': 3.6477, 'learning_rate': 0.0001403391600312308, 'epoch': 1.29}
Step 728: {'loss': 3.393, 'learning_rate': 0.00014014957837910473, 'epoch': 1.29}
Step 729: {'loss': 3.5372, 'learning_rate': 0.00013995982453638732, 'epoch': 1.3}
Step 730: {'loss': 3.8188, 'learning_rate': 0.00013976989931688096, 'epoch': 1.3}
Step 731: {'loss': 3.4882, 'learning_rate': 0.00013957980353512318, 'epoch': 1.3}
Step 732: {'loss': 3.5339, 'learning_rate': 0.00013938953800638292, 'epoch': 1.3}
Step 733: {'loss': 3.7657, 'learning_rate': 0.00013919910354665715, 'epoch': 1.3}
Step 734: {'loss': 3.4703, 'learning_rate': 0.00013900850097266733, 'epoch': 1.3}
Step 735: {'loss': 3.5874, 'learning_rate': 0.0001388177311018559, 'epoch': 1.31}
Step 736: {'loss': 3.1529, 'learning_rate': 0.00013862679475238284, 'epoch': 1.31}
Step 737: {'loss': 4.0041, 'learning_rate': 0.00013843569274312202, 'epoch': 1.31}
Step 738: {'loss': 3.4265, 'learning_rate': 0.00013824442589365786, 'epoch': 1.31}
Step 739: {'loss': 3.9227, 'learning_rate': 0.00013805299502428175, 'epoch': 1.31}
Step 740: {'loss': 3.1959, 'learning_rate': 0.00013786140095598846, 'epoch': 1.32}
Step 741: {'loss': 4.073, 'learning_rate': 0.00013766964451047267, 'epoch': 1.32}
Step 742: {'loss': 3.6013, 'learning_rate': 0.00013747772651012547, 'epoch': 1.32}
Step 743: {'loss': 3.9377, 'learning_rate': 0.00013728564777803088, 'epoch': 1.32}
Step 744: {'loss': 3.5398, 'learning_rate': 0.00013709340913796214, 'epoch': 1.32}
Step 745: {'loss': 3.3439, 'learning_rate': 0.00013690101141437835, 'epoch': 1.32}
Step 746: {'loss': 4.0995, 'learning_rate': 0.00013670845543242087, 'epoch': 1.33}
Step 747: {'loss': 3.3126, 'learning_rate': 0.00013651574201790985, 'epoch': 1.33}
Step 748: {'loss': 3.5815, 'learning_rate': 0.0001363228719973405, 'epoch': 1.33}
Step 749: {'loss': 3.9654, 'learning_rate': 0.00013612984619787972, 'epoch': 1.33}
Step 750: {'loss': 3.6681, 'learning_rate': 0.0001359366654473626, 'epoch': 1.33}
Step 751: {'loss': 3.7062, 'learning_rate': 0.00013574333057428864, 'epoch': 1.34}
Step 752: {'loss': 3.6497, 'learning_rate': 0.00013554984240781833, 'epoch': 1.34}
Step 753: {'loss': 3.6036, 'learning_rate': 0.00013535620177776973, 'epoch': 1.34}
Step 754: {'loss': 3.4346, 'learning_rate': 0.0001351624095146147, 'epoch': 1.34}
Step 755: {'loss': 3.2447, 'learning_rate': 0.0001349684664494753, 'epoch': 1.34}
Step 756: {'loss': 3.7579, 'learning_rate': 0.00013477437341412053, 'epoch': 1.34}
Step 757: {'loss': 3.7419, 'learning_rate': 0.00013458013124096246, 'epoch': 1.35}
Step 758: {'loss': 3.4617, 'learning_rate': 0.00013438574076305278, 'epoch': 1.35}
Step 759: {'loss': 3.8285, 'learning_rate': 0.00013419120281407925, 'epoch': 1.35}
Step 760: {'loss': 3.3444, 'learning_rate': 0.00013399651822836205, 'epoch': 1.35}
Step 761: {'loss': 3.3376, 'learning_rate': 0.00013380168784085027, 'epoch': 1.35}
Step 762: {'loss': 3.2069, 'learning_rate': 0.00013360671248711836, 'epoch': 1.35}
Step 763: {'loss': 3.9899, 'learning_rate': 0.0001334115930033624, 'epoch': 1.36}
Step 764: {'loss': 3.7133, 'learning_rate': 0.00013321633022639657, 'epoch': 1.36}
Step 765: {'loss': 3.5309, 'learning_rate': 0.0001330209249936498, 'epoch': 1.36}
Step 766: {'loss': 3.402, 'learning_rate': 0.00013282537814316174, 'epoch': 1.36}
Step 767: {'loss': 3.8667, 'learning_rate': 0.0001326296905135795, 'epoch': 1.36}
Step 768: {'loss': 3.9745, 'learning_rate': 0.00013243386294415404, 'epoch': 1.37}
Step 769: {'loss': 3.6023, 'learning_rate': 0.0001322378962747363, 'epoch': 1.37}
Step 770: {'loss': 3.5508, 'learning_rate': 0.0001320417913457739, 'epoch': 1.37}
Step 771: {'loss': 3.7571, 'learning_rate': 0.00013184554899830744, 'epoch': 1.37}
Step 772: {'loss': 3.7291, 'learning_rate': 0.00013164917007396672, 'epoch': 1.37}
Step 773: {'loss': 3.5417, 'learning_rate': 0.00013145265541496755, 'epoch': 1.37}
Step 774: {'loss': 3.7502, 'learning_rate': 0.0001312560058641076, 'epoch': 1.38}
Step 775: {'loss': 3.4567, 'learning_rate': 0.00013105922226476312, 'epoch': 1.38}
Step 776: {'loss': 3.9446, 'learning_rate': 0.00013086230546088544, 'epoch': 1.38}
Step 777: {'loss': 3.519, 'learning_rate': 0.0001306652562969969, 'epoch': 1.38}
Step 778: {'loss': 3.8555, 'learning_rate': 0.0001304680756181876, 'epoch': 1.38}
Step 779: {'loss': 3.7997, 'learning_rate': 0.00013027076427011184, 'epoch': 1.38}
Step 780: {'loss': 3.5754, 'learning_rate': 0.00013007332309898406, 'epoch': 1.39}
Step 781: {'loss': 3.4414, 'learning_rate': 0.00012987575295157563, 'epoch': 1.39}
Step 782: {'loss': 3.3819, 'learning_rate': 0.000129678054675211, 'epoch': 1.39}
Step 783: {'loss': 3.5351, 'learning_rate': 0.0001294802291177642, 'epoch': 1.39}
Step 784: {'loss': 4.014, 'learning_rate': 0.00012928227712765504, 'epoch': 1.39}
Step 785: {'loss': 3.6526, 'learning_rate': 0.00012908419955384568, 'epoch': 1.4}
Step 786: {'loss': 3.5726, 'learning_rate': 0.00012888599724583677, 'epoch': 1.4}
Step 787: {'loss': 3.6839, 'learning_rate': 0.00012868767105366394, 'epoch': 1.4}
Step 788: {'loss': 3.7741, 'learning_rate': 0.00012848922182789418, 'epoch': 1.4}
Step 789: {'loss': 3.8074, 'learning_rate': 0.00012829065041962206, 'epoch': 1.4}
Step 790: {'loss': 3.5335, 'learning_rate': 0.00012809195768046622, 'epoch': 1.4}
Step 791: {'loss': 3.7929, 'learning_rate': 0.00012789314446256562, 'epoch': 1.41}
Step 792: {'loss': 3.3978, 'learning_rate': 0.00012769421161857588, 'epoch': 1.41}
Step 793: {'loss': 3.3059, 'learning_rate': 0.0001274951600016658, 'epoch': 1.41}
Step 794: {'loss': 3.4726, 'learning_rate': 0.0001272959904655134, 'epoch': 1.41}
Step 795: {'loss': 3.5107, 'learning_rate': 0.00012709670386430253, 'epoch': 1.41}
Step 796: {'loss': 3.5356, 'learning_rate': 0.00012689730105271905, 'epoch': 1.42}
Step 797: {'loss': 3.4008, 'learning_rate': 0.00012669778288594726, 'epoch': 1.42}
Step 798: {'loss': 3.6598, 'learning_rate': 0.0001264981502196662, 'epoch': 1.42}
Step 799: {'loss': 3.8752, 'learning_rate': 0.00012629840391004582, 'epoch': 1.42}
Step 800: {'loss': 3.8735, 'learning_rate': 0.00012609854481374362, 'epoch': 1.42}
Step 801: {'loss': 3.5266, 'learning_rate': 0.0001258985737879008, 'epoch': 1.42}
Step 802: {'loss': 3.4716, 'learning_rate': 0.0001256984916901385, 'epoch': 1.43}
Step 803: {'loss': 3.9301, 'learning_rate': 0.00012549829937855427, 'epoch': 1.43}
Step 804: {'loss': 3.3523, 'learning_rate': 0.00012529799771171835, 'epoch': 1.43}
Step 805: {'loss': 3.4312, 'learning_rate': 0.00012509758754866994, 'epoch': 1.43}
Step 806: {'loss': 3.6703, 'learning_rate': 0.0001248970697489136, 'epoch': 1.43}
Step 807: {'loss': 3.6753, 'learning_rate': 0.00012469644517241544, 'epoch': 1.43}
Step 808: {'loss': 3.6079, 'learning_rate': 0.00012449571467959956, 'epoch': 1.44}
Step 809: {'loss': 3.3571, 'learning_rate': 0.00012429487913134435, 'epoch': 1.44}
Step 810: {'loss': 3.4901, 'learning_rate': 0.00012409393938897867, 'epoch': 1.44}
Step 811: {'loss': 3.8641, 'learning_rate': 0.00012389289631427824, 'epoch': 1.44}
Step 812: {'loss': 3.5548, 'learning_rate': 0.00012369175076946203, 'epoch': 1.44}
Step 813: {'loss': 3.4756, 'learning_rate': 0.00012349050361718837, 'epoch': 1.45}
Step 814: {'loss': 3.866, 'learning_rate': 0.0001232891557205514, 'epoch': 1.45}
Step 815: {'loss': 3.7271, 'learning_rate': 0.00012308770794307742, 'epoch': 1.45}
Step 816: {'loss': 3.414, 'learning_rate': 0.00012288616114872092, 'epoch': 1.45}
Step 817: {'loss': 3.4617, 'learning_rate': 0.0001226845162018612, 'epoch': 1.45}
Step 818: {'loss': 3.2156, 'learning_rate': 0.00012248277396729836, 'epoch': 1.45}
Step 819: {'loss': 3.4522, 'learning_rate': 0.00012228093531024985, 'epoch': 1.46}
Step 820: {'loss': 3.4105, 'learning_rate': 0.00012207900109634668, 'epoch': 1.46}
Step 821: {'loss': 3.6666, 'learning_rate': 0.00012187697219162956, 'epoch': 1.46}
Step 822: {'loss': 3.8356, 'learning_rate': 0.00012167484946254535, 'epoch': 1.46}
Step 823: {'loss': 3.758, 'learning_rate': 0.00012147263377594338, 'epoch': 1.46}
Step 824: {'loss': 3.8589, 'learning_rate': 0.00012127032599907151, 'epoch': 1.46}
Step 825: {'loss': 3.3116, 'learning_rate': 0.00012106792699957263, 'epoch': 1.47}
Step 826: {'loss': 3.5038, 'learning_rate': 0.00012086543764548088, 'epoch': 1.47}
Step 827: {'loss': 3.6455, 'learning_rate': 0.00012066285880521784, 'epoch': 1.47}
Step 828: {'loss': 3.7947, 'learning_rate': 0.00012046019134758892, 'epoch': 1.47}
Step 829: {'loss': 4.1594, 'learning_rate': 0.00012025743614177955, 'epoch': 1.47}
Step 830: {'loss': 3.6866, 'learning_rate': 0.00012005459405735153, 'epoch': 1.48}
Step 831: {'loss': 3.3328, 'learning_rate': 0.00011985166596423924, 'epoch': 1.48}
Step 832: {'loss': 3.489, 'learning_rate': 0.00011964865273274592, 'epoch': 1.48}
Step 833: {'loss': 3.5253, 'learning_rate': 0.00011944555523353995, 'epoch': 1.48}
Step 834: {'loss': 3.5134, 'learning_rate': 0.00011924237433765111, 'epoch': 1.48}
Step 835: {'loss': 3.5851, 'learning_rate': 0.00011903911091646684, 'epoch': 1.48}
Step 836: {'loss': 3.246, 'learning_rate': 0.00011883576584172853, 'epoch': 1.49}
Step 837: {'loss': 3.7927, 'learning_rate': 0.00011863233998552774, 'epoch': 1.49}
Step 838: {'loss': 3.8613, 'learning_rate': 0.00011842883422030248, 'epoch': 1.49}
Step 839: {'loss': 3.5123, 'learning_rate': 0.00011822524941883349, 'epoch': 1.49}
Step 840: {'loss': 3.7636, 'learning_rate': 0.00011802158645424044, 'epoch': 1.49}
Step 841: {'loss': 3.4108, 'learning_rate': 0.00011781784619997824, 'epoch': 1.5}
Step 842: {'loss': 3.5639, 'learning_rate': 0.00011761402952983329, 'epoch': 1.5}
Step 843: {'loss': 3.5946, 'learning_rate': 0.00011741013731791968, 'epoch': 1.5}
Step 844: {'loss': 3.3733, 'learning_rate': 0.00011720617043867552, 'epoch': 1.5}
Step 845: {'loss': 3.3871, 'learning_rate': 0.00011700212976685911, 'epoch': 1.5}
Step 846: {'loss': 3.8478, 'learning_rate': 0.00011679801617754523, 'epoch': 1.5}
Step 847: {'loss': 4.147, 'learning_rate': 0.0001165938305461214, 'epoch': 1.51}
Step 848: {'loss': 3.6128, 'learning_rate': 0.00011638957374828417, 'epoch': 1.51}
Step 849: {'loss': 3.2989, 'learning_rate': 0.00011618524666003512, 'epoch': 1.51}
Step 850: {'loss': 3.6592, 'learning_rate': 0.00011598085015767748, 'epoch': 1.51}
Step 851: {'loss': 3.4301, 'learning_rate': 0.00011577638511781211, 'epoch': 1.51}
Step 852: {'loss': 3.2862, 'learning_rate': 0.00011557185241733375, 'epoch': 1.51}
Step 853: {'loss': 3.6744, 'learning_rate': 0.00011536725293342743, 'epoch': 1.52}
Step 854: {'loss': 3.7295, 'learning_rate': 0.00011516258754356447, 'epoch': 1.52}
Step 855: {'loss': 3.5703, 'learning_rate': 0.00011495785712549892, 'epoch': 1.52}
Step 856: {'loss': 3.6908, 'learning_rate': 0.00011475306255726376, 'epoch': 1.52}
Step 857: {'loss': 3.7835, 'learning_rate': 0.00011454820471716701, 'epoch': 1.52}
Step 858: {'loss': 3.5413, 'learning_rate': 0.00011434328448378802, 'epoch': 1.53}
Step 859: {'loss': 3.6208, 'learning_rate': 0.00011413830273597387, 'epoch': 1.53}
Step 860: {'loss': 3.3869, 'learning_rate': 0.00011393326035283531, 'epoch': 1.53}
Step 861: {'loss': 3.7811, 'learning_rate': 0.0001137281582137432, 'epoch': 1.53}
Step 862: {'loss': 3.4211, 'learning_rate': 0.00011352299719832473, 'epoch': 1.53}
Step 863: {'loss': 4.0778, 'learning_rate': 0.00011331777818645946, 'epoch': 1.53}
Step 864: {'loss': 3.5987, 'learning_rate': 0.00011311250205827584, 'epoch': 1.54}
Step 865: {'loss': 3.6315, 'learning_rate': 0.00011290716969414714, 'epoch': 1.54}
Step 866: {'loss': 3.6067, 'learning_rate': 0.00011270178197468789, 'epoch': 1.54}
Step 867: {'loss': 3.6395, 'learning_rate': 0.00011249633978075, 'epoch': 1.54}
Step 868: {'loss': 3.5636, 'learning_rate': 0.000112290843993419, 'epoch': 1.54}
Step 869: {'loss': 3.7474, 'learning_rate': 0.00011208529549401028, 'epoch': 1.54}
Step 870: {'loss': 3.1328, 'learning_rate': 0.00011187969516406534, 'epoch': 1.55}
Step 871: {'loss': 3.7095, 'learning_rate': 0.00011167404388534783, 'epoch': 1.55}
Step 872: {'loss': 3.7937, 'learning_rate': 0.00011146834253984006, 'epoch': 1.55}
Step 873: {'loss': 3.206, 'learning_rate': 0.00011126259200973898, 'epoch': 1.55}
Step 874: {'loss': 3.6199, 'learning_rate': 0.0001110567931774525, 'epoch': 1.55}
Step 875: {'loss': 2.9409, 'learning_rate': 0.00011085094692559567, 'epoch': 1.56}
Step 876: {'loss': 3.511, 'learning_rate': 0.00011064505413698693, 'epoch': 1.56}
Step 877: {'loss': 3.8198, 'learning_rate': 0.00011043911569464431, 'epoch': 1.56}
Step 878: {'loss': 4.1653, 'learning_rate': 0.00011023313248178162, 'epoch': 1.56}
Step 879: {'loss': 3.716, 'learning_rate': 0.00011002710538180468, 'epoch': 1.56}
Step 880: {'loss': 3.6433, 'learning_rate': 0.00010982103527830749, 'epoch': 1.56}
Step 881: {'loss': 3.7488, 'learning_rate': 0.00010961492305506858, 'epoch': 1.57}
Step 882: {'loss': 3.4179, 'learning_rate': 0.00010940876959604703, 'epoch': 1.57}
Step 883: {'loss': 3.7495, 'learning_rate': 0.00010920257578537878, 'epoch': 1.57}
Step 884: {'loss': 3.8634, 'learning_rate': 0.0001089963425073729, 'epoch': 1.57}
Step 885: {'loss': 3.5583, 'learning_rate': 0.00010879007064650764, 'epoch': 1.57}
Step 886: {'loss': 3.6881, 'learning_rate': 0.00010858376108742674, 'epoch': 1.58}
Step 887: {'loss': 3.9613, 'learning_rate': 0.00010837741471493566, 'epoch': 1.58}
Step 888: {'loss': 3.4009, 'learning_rate': 0.0001081710324139977, 'epoch': 1.58}
Step 889: {'loss': 3.5292, 'learning_rate': 0.00010796461506973025, 'epoch': 1.58}
Step 890: {'loss': 3.8058, 'learning_rate': 0.00010775816356740105, 'epoch': 1.58}
Step 891: {'loss': 3.4561, 'learning_rate': 0.0001075516787924242, 'epoch': 1.58}
Step 892: {'loss': 3.577, 'learning_rate': 0.00010734516163035668, 'epoch': 1.59}
Step 893: {'loss': 3.693, 'learning_rate': 0.0001071386129668942, 'epoch': 1.59}
Step 894: {'loss': 4.0667, 'learning_rate': 0.00010693203368786767, 'epoch': 1.59}
Step 895: {'loss': 3.8349, 'learning_rate': 0.00010672542467923929, 'epoch': 1.59}
Step 896: {'loss': 3.5864, 'learning_rate': 0.00010651878682709873, 'epoch': 1.59}
Step 897: {'loss': 3.7034, 'learning_rate': 0.00010631212101765938, 'epoch': 1.59}
Step 898: {'loss': 3.1324, 'learning_rate': 0.00010610542813725455, 'epoch': 1.6}
Step 899: {'loss': 3.4818, 'learning_rate': 0.00010589870907233357, 'epoch': 1.6}
Step 900: {'loss': 3.7223, 'learning_rate': 0.00010569196470945823, 'epoch': 1.6}
Step 901: {'loss': 3.4887, 'learning_rate': 0.00010548519593529864, 'epoch': 1.6}
Step 902: {'loss': 3.729, 'learning_rate': 0.00010527840363662969, 'epoch': 1.6}
Step 903: {'loss': 3.6128, 'learning_rate': 0.0001050715887003272, 'epoch': 1.61}
Step 904: {'loss': 3.3154, 'learning_rate': 0.00010486475201336397, 'epoch': 1.61}
Step 905: {'loss': 3.6774, 'learning_rate': 0.0001046578944628061, 'epoch': 1.61}
Step 906: {'loss': 3.4307, 'learning_rate': 0.00010445101693580932, 'epoch': 1.61}
Step 907: {'loss': 3.6316, 'learning_rate': 0.00010424412031961484, 'epoch': 1.61}
Step 908: {'loss': 3.3574, 'learning_rate': 0.00010403720550154583, 'epoch': 1.61}
Step 909: {'loss': 3.587, 'learning_rate': 0.00010383027336900355, 'epoch': 1.62}
Step 910: {'loss': 3.4616, 'learning_rate': 0.00010362332480946342, 'epoch': 1.62}
Step 911: {'loss': 3.4221, 'learning_rate': 0.00010341636071047142, 'epoch': 1.62}
Step 912: {'loss': 3.8129, 'learning_rate': 0.0001032093819596401, 'epoch': 1.62}
Step 913: {'loss': 3.4234, 'learning_rate': 0.00010300238944464484, 'epoch': 1.62}
Step 914: {'loss': 3.7863, 'learning_rate': 0.00010279538405322016, 'epoch': 1.62}
Step 915: {'loss': 3.5242, 'learning_rate': 0.00010258836667315565, 'epoch': 1.63}
Step 916: {'loss': 3.1396, 'learning_rate': 0.0001023813381922924, 'epoch': 1.63}
Step 917: {'loss': 3.5302, 'learning_rate': 0.0001021742994985192, 'epoch': 1.63}
Step 918: {'loss': 3.7136, 'learning_rate': 0.0001019672514797684, 'epoch': 1.63}
Step 919: {'loss': 3.8284, 'learning_rate': 0.00010176019502401257, 'epoch': 1.63}
Step 920: {'loss': 3.5984, 'learning_rate': 0.00010155313101926036, 'epoch': 1.64}
Step 921: {'loss': 3.9063, 'learning_rate': 0.00010134606035355279, 'epoch': 1.64}
Step 922: {'loss': 3.6742, 'learning_rate': 0.00010113898391495948, 'epoch': 1.64}
Step 923: {'loss': 3.2088, 'learning_rate': 0.00010093190259157482, 'epoch': 1.64}
Step 924: {'loss': 3.7802, 'learning_rate': 0.00010072481727151409, 'epoch': 1.64}
Step 925: {'loss': 3.382, 'learning_rate': 0.00010051772884290977, 'epoch': 1.64}
Step 926: {'loss': 3.8582, 'learning_rate': 0.00010031063819390765, 'epoch': 1.65}
Step 927: {'loss': 3.4165, 'learning_rate': 0.00010010354621266304, 'epoch': 1.65}
Step 928: {'loss': 3.9438, 'learning_rate': 9.989645378733698e-05, 'epoch': 1.65}
Step 929: {'loss': 3.3117, 'learning_rate': 9.968936180609234e-05, 'epoch': 1.65}
Step 930: {'loss': 3.5368, 'learning_rate': 9.948227115709025e-05, 'epoch': 1.65}
Step 931: {'loss': 3.5473, 'learning_rate': 9.927518272848592e-05, 'epoch': 1.66}
Step 932: {'loss': 3.5827, 'learning_rate': 9.906809740842519e-05, 'epoch': 1.66}
Step 933: {'loss': 3.6053, 'learning_rate': 9.886101608504054e-05, 'epoch': 1.66}
Step 934: {'loss': 3.5981, 'learning_rate': 9.865393964644723e-05, 'epoch': 1.66}
Step 935: {'loss': 4.0321, 'learning_rate': 9.844686898073965e-05, 'epoch': 1.66}
Step 936: {'loss': 3.6676, 'learning_rate': 9.823980497598744e-05, 'epoch': 1.66}
Step 937: {'loss': 3.8306, 'learning_rate': 9.803274852023161e-05, 'epoch': 1.67}
Step 938: {'loss': 3.7903, 'learning_rate': 9.782570050148082e-05, 'epoch': 1.67}
Step 939: {'loss': 3.3161, 'learning_rate': 9.761866180770761e-05, 'epoch': 1.67}
Step 940: {'loss': 3.2156, 'learning_rate': 9.741163332684437e-05, 'epoch': 1.67}
Step 941: {'loss': 3.1348, 'learning_rate': 9.720461594677987e-05, 'epoch': 1.67}
Step 942: {'loss': 3.7214, 'learning_rate': 9.69976105553552e-05, 'epoch': 1.67}
Step 943: {'loss': 3.4807, 'learning_rate': 9.679061804035992e-05, 'epoch': 1.68}
Step 944: {'loss': 3.7628, 'learning_rate': 9.658363928952859e-05, 'epoch': 1.68}
Step 945: {'loss': 3.5958, 'learning_rate': 9.637667519053662e-05, 'epoch': 1.68}
Step 946: {'loss': 3.722, 'learning_rate': 9.616972663099647e-05, 'epoch': 1.68}
Step 947: {'loss': 3.2475, 'learning_rate': 9.596279449845417e-05, 'epoch': 1.68}
Step 948: {'loss': 3.3848, 'learning_rate': 9.57558796803852e-05, 'epoch': 1.69}
Step 949: {'loss': 3.6087, 'learning_rate': 9.55489830641907e-05, 'epoch': 1.69}
Step 950: {'loss': 3.4383, 'learning_rate': 9.534210553719389e-05, 'epoch': 1.69}
Step 951: {'loss': 3.7484, 'learning_rate': 9.513524798663608e-05, 'epoch': 1.69}
Step 952: {'loss': 3.817, 'learning_rate': 9.492841129967282e-05, 'epoch': 1.69}
Step 953: {'loss': 3.7937, 'learning_rate': 9.472159636337031e-05, 'epoch': 1.69}
Step 954: {'loss': 3.7129, 'learning_rate': 9.451480406470139e-05, 'epoch': 1.7}
Step 955: {'loss': 3.5296, 'learning_rate': 9.430803529054179e-05, 'epoch': 1.7}
Step 956: {'loss': 3.4202, 'learning_rate': 9.410129092766642e-05, 'epoch': 1.7}
Step 957: {'loss': 3.4619, 'learning_rate': 9.389457186274549e-05, 'epoch': 1.7}
Step 958: {'loss': 3.7699, 'learning_rate': 9.368787898234066e-05, 'epoch': 1.7}
Step 959: {'loss': 3.6945, 'learning_rate': 9.348121317290128e-05, 'epoch': 1.7}
Step 960: {'loss': 3.3802, 'learning_rate': 9.327457532076073e-05, 'epoch': 1.71}
Step 961: {'loss': 3.8018, 'learning_rate': 9.306796631213234e-05, 'epoch': 1.71}
Step 962: {'loss': 3.3795, 'learning_rate': 9.28613870331058e-05, 'epoch': 1.71}
Step 963: {'loss': 3.7745, 'learning_rate': 9.265483836964335e-05, 'epoch': 1.71}
Step 964: {'loss': 3.5145, 'learning_rate': 9.24483212075758e-05, 'epoch': 1.71}
Step 965: {'loss': 3.5277, 'learning_rate': 9.224183643259896e-05, 'epoch': 1.72}
Step 966: {'loss': 3.6755, 'learning_rate': 9.203538493026976e-05, 'epoch': 1.72}
Step 967: {'loss': 3.584, 'learning_rate': 9.182896758600232e-05, 'epoch': 1.72}
Step 968: {'loss': 3.3328, 'learning_rate': 9.162258528506434e-05, 'epoch': 1.72}
Step 969: {'loss': 3.942, 'learning_rate': 9.141623891257327e-05, 'epoch': 1.72}
Step 970: {'loss': 3.2192, 'learning_rate': 9.120992935349238e-05, 'epoch': 1.72}
Step 971: {'loss': 3.3656, 'learning_rate': 9.10036574926271e-05, 'epoch': 1.73}
Step 972: {'loss': 3.7305, 'learning_rate': 9.079742421462123e-05, 'epoch': 1.73}
Step 973: {'loss': 3.3636, 'learning_rate': 9.059123040395301e-05, 'epoch': 1.73}
Step 974: {'loss': 3.6492, 'learning_rate': 9.038507694493142e-05, 'epoch': 1.73}
Step 975: {'loss': 3.4187, 'learning_rate': 9.017896472169255e-05, 'epoch': 1.73}
Step 976: {'loss': 3.7143, 'learning_rate': 8.997289461819536e-05, 'epoch': 1.74}
Step 977: {'loss': 3.5196, 'learning_rate': 8.97668675182184e-05, 'epoch': 1.74}
Step 978: {'loss': 3.4023, 'learning_rate': 8.956088430535572e-05, 'epoch': 1.74}
Step 979: {'loss': 3.6405, 'learning_rate': 8.935494586301309e-05, 'epoch': 1.74}
Step 980: {'loss': 3.4796, 'learning_rate': 8.914905307440435e-05, 'epoch': 1.74}
Step 981: {'loss': 3.2711, 'learning_rate': 8.894320682254755e-05, 'epoch': 1.74}
Step 982: {'loss': 3.1996, 'learning_rate': 8.873740799026104e-05, 'epoch': 1.75}
Step 983: {'loss': 3.5617, 'learning_rate': 8.853165746015997e-05, 'epoch': 1.75}
Step 984: {'loss': 3.5535, 'learning_rate': 8.83259561146522e-05, 'epoch': 1.75}
Step 985: {'loss': 3.8987, 'learning_rate': 8.81203048359347e-05, 'epoch': 1.75}
Step 986: {'loss': 3.539, 'learning_rate': 8.791470450598972e-05, 'epoch': 1.75}
Step 987: {'loss': 3.4211, 'learning_rate': 8.770915600658104e-05, 'epoch': 1.75}
Step 988: {'loss': 3.2837, 'learning_rate': 8.750366021925002e-05, 'epoch': 1.76}
Step 989: {'loss': 3.398, 'learning_rate': 8.729821802531212e-05, 'epoch': 1.76}
Step 990: {'loss': 3.7938, 'learning_rate': 8.709283030585291e-05, 'epoch': 1.76}
Step 991: {'loss': 3.5422, 'learning_rate': 8.688749794172419e-05, 'epoch': 1.76}
Step 992: {'loss': 3.7549, 'learning_rate': 8.668222181354054e-05, 'epoch': 1.76}
Step 993: {'loss': 4.1357, 'learning_rate': 8.647700280167532e-05, 'epoch': 1.77}
Step 994: {'loss': 3.7888, 'learning_rate': 8.627184178625683e-05, 'epoch': 1.77}
Step 995: {'loss': 3.5778, 'learning_rate': 8.606673964716471e-05, 'epoch': 1.77}
Step 996: {'loss': 3.4069, 'learning_rate': 8.586169726402618e-05, 'epoch': 1.77}
Step 997: {'loss': 3.8823, 'learning_rate': 8.5656715516212e-05, 'epoch': 1.77}
Step 998: {'loss': 3.3409, 'learning_rate': 8.545179528283303e-05, 'epoch': 1.77}
Step 999: {'loss': 3.2811, 'learning_rate': 8.524693744273627e-05, 'epoch': 1.78}
Step 1000: {'loss': 3.6529, 'learning_rate': 8.504214287450109e-05, 'epoch': 1.78}
Step 1001: {'loss': 3.5574, 'learning_rate': 8.483741245643554e-05, 'epoch': 1.78}
Step 1002: {'loss': 3.6859, 'learning_rate': 8.463274706657262e-05, 'epoch': 1.78}
Step 1003: {'loss': 3.4604, 'learning_rate': 8.442814758266629e-05, 'epoch': 1.78}
Step 1004: {'loss': 3.959, 'learning_rate': 8.42236148821879e-05, 'epoch': 1.78}
Step 1005: {'loss': 3.2933, 'learning_rate': 8.401914984232255e-05, 'epoch': 1.79}
Step 1006: {'loss': 3.6992, 'learning_rate': 8.381475333996491e-05, 'epoch': 1.79}
Step 1007: {'loss': 3.5902, 'learning_rate': 8.361042625171586e-05, 'epoch': 1.79}
Step 1008: {'loss': 3.6357, 'learning_rate': 8.34061694538786e-05, 'epoch': 1.79}
Step 1009: {'loss': 3.9903, 'learning_rate': 8.320198382245478e-05, 'epoch': 1.79}
Step 1010: {'loss': 3.2962, 'learning_rate': 8.29978702331409e-05, 'epoch': 1.8}
Step 1011: {'loss': 3.2255, 'learning_rate': 8.279382956132452e-05, 'epoch': 1.8}
Step 1012: {'loss': 3.7591, 'learning_rate': 8.258986268208033e-05, 'epoch': 1.8}
Step 1013: {'loss': 3.5854, 'learning_rate': 8.238597047016673e-05, 'epoch': 1.8}
Step 1014: {'loss': 3.9253, 'learning_rate': 8.218215380002178e-05, 'epoch': 1.8}
Step 1015: {'loss': 3.6908, 'learning_rate': 8.197841354575957e-05, 'epoch': 1.8}
Step 1016: {'loss': 3.69, 'learning_rate': 8.177475058116652e-05, 'epoch': 1.81}
Step 1017: {'loss': 3.6393, 'learning_rate': 8.157116577969751e-05, 'epoch': 1.81}
Step 1018: {'loss': 3.7008, 'learning_rate': 8.136766001447228e-05, 'epoch': 1.81}
Step 1019: {'loss': 3.6604, 'learning_rate': 8.116423415827148e-05, 'epoch': 1.81}
Step 1020: {'loss': 3.7576, 'learning_rate': 8.096088908353315e-05, 'epoch': 1.81}
Step 1021: {'loss': 3.5372, 'learning_rate': 8.075762566234891e-05, 'epoch': 1.82}
Step 1022: {'loss': 3.7354, 'learning_rate': 8.055444476646007e-05, 'epoch': 1.82}
Step 1023: {'loss': 3.5049, 'learning_rate': 8.035134726725407e-05, 'epoch': 1.82}
Step 1024: {'loss': 3.1504, 'learning_rate': 8.014833403576077e-05, 'epoch': 1.82}
Step 1025: {'loss': 3.8528, 'learning_rate': 7.994540594264848e-05, 'epoch': 1.82}
Step 1026: {'loss': 3.5807, 'learning_rate': 7.974256385822045e-05, 'epoch': 1.82}
Step 1027: {'loss': 3.1927, 'learning_rate': 7.95398086524111e-05, 'epoch': 1.83}
Step 1028: {'loss': 3.3627, 'learning_rate': 7.933714119478219e-05, 'epoch': 1.83}
Step 1029: {'loss': 3.6073, 'learning_rate': 7.913456235451912e-05, 'epoch': 1.83}
Step 1030: {'loss': 3.4406, 'learning_rate': 7.89320730004274e-05, 'epoch': 1.83}
Step 1031: {'loss': 3.7415, 'learning_rate': 7.87296740009285e-05, 'epoch': 1.83}
Step 1032: {'loss': 3.2665, 'learning_rate': 7.852736622405663e-05, 'epoch': 1.83}
Step 1033: {'loss': 3.6446, 'learning_rate': 7.832515053745466e-05, 'epoch': 1.84}
Step 1034: {'loss': 3.3364, 'learning_rate': 7.812302780837046e-05, 'epoch': 1.84}
Step 1035: {'loss': 3.4077, 'learning_rate': 7.792099890365333e-05, 'epoch': 1.84}
Step 1036: {'loss': 3.3034, 'learning_rate': 7.771906468975017e-05, 'epoch': 1.84}
Step 1037: {'loss': 3.6441, 'learning_rate': 7.751722603270167e-05, 'epoch': 1.84}
Step 1038: {'loss': 3.4332, 'learning_rate': 7.731548379813884e-05, 'epoch': 1.85}
Step 1039: {'loss': 4.0033, 'learning_rate': 7.711383885127911e-05, 'epoch': 1.85}
Step 1040: {'loss': 4.052, 'learning_rate': 7.69122920569226e-05, 'epoch': 1.85}
Step 1041: {'loss': 3.5799, 'learning_rate': 7.67108442794486e-05, 'epoch': 1.85}
Step 1042: {'loss': 3.5451, 'learning_rate': 7.650949638281168e-05, 'epoch': 1.85}
Step 1043: {'loss': 3.9097, 'learning_rate': 7.630824923053801e-05, 'epoch': 1.85}
Step 1044: {'loss': 3.5281, 'learning_rate': 7.610710368572177e-05, 'epoch': 1.86}
Step 1045: {'loss': 3.6384, 'learning_rate': 7.590606061102137e-05, 'epoch': 1.86}
Step 1046: {'loss': 3.564, 'learning_rate': 7.570512086865565e-05, 'epoch': 1.86}
Step 1047: {'loss': 3.6069, 'learning_rate': 7.550428532040043e-05, 'epoch': 1.86}
Step 1048: {'loss': 3.7632, 'learning_rate': 7.53035548275846e-05, 'epoch': 1.86}
Step 1049: {'loss': 3.5539, 'learning_rate': 7.510293025108643e-05, 'epoch': 1.86}
Step 1050: {'loss': 3.4338, 'learning_rate': 7.490241245133007e-05, 'epoch': 1.87}
Step 1051: {'loss': 3.474, 'learning_rate': 7.470200228828168e-05, 'epoch': 1.87}
Step 1052: {'loss': 3.7124, 'learning_rate': 7.450170062144576e-05, 'epoch': 1.87}
Step 1053: {'loss': 4.0433, 'learning_rate': 7.43015083098615e-05, 'epoch': 1.87}
Step 1054: {'loss': 3.6075, 'learning_rate': 7.410142621209922e-05, 'epoch': 1.87}
Step 1055: {'loss': 3.5094, 'learning_rate': 7.390145518625639e-05, 'epoch': 1.88}
Step 1056: {'loss': 3.6848, 'learning_rate': 7.370159608995419e-05, 'epoch': 1.88}
Step 1057: {'loss': 3.2946, 'learning_rate': 7.350184978033386e-05, 'epoch': 1.88}
Step 1058: {'loss': 3.5826, 'learning_rate': 7.330221711405274e-05, 'epoch': 1.88}
Step 1059: {'loss': 3.6746, 'learning_rate': 7.310269894728095e-05, 'epoch': 1.88}
Step 1060: {'loss': 4.0169, 'learning_rate': 7.290329613569751e-05, 'epoch': 1.88}
Step 1061: {'loss': 3.5542, 'learning_rate': 7.270400953448663e-05, 'epoch': 1.89}
Step 1062: {'loss': 3.5473, 'learning_rate': 7.250483999833422e-05, 'epoch': 1.89}
Step 1063: {'loss': 3.4374, 'learning_rate': 7.230578838142413e-05, 'epoch': 1.89}
Step 1064: {'loss': 3.2984, 'learning_rate': 7.210685553743441e-05, 'epoch': 1.89}
Step 1065: {'loss': 3.2722, 'learning_rate': 7.190804231953377e-05, 'epoch': 1.89}
Step 1066: {'loss': 3.2246, 'learning_rate': 7.170934958037794e-05, 'epoch': 1.9}
Step 1067: {'loss': 3.592, 'learning_rate': 7.151077817210583e-05, 'epoch': 1.9}
Step 1068: {'loss': 3.6375, 'learning_rate': 7.131232894633604e-05, 'epoch': 1.9}
Step 1069: {'loss': 3.6803, 'learning_rate': 7.111400275416328e-05, 'epoch': 1.9}
Step 1070: {'loss': 3.5481, 'learning_rate': 7.091580044615434e-05, 'epoch': 1.9}
Step 1071: {'loss': 3.8049, 'learning_rate': 7.071772287234497e-05, 'epoch': 1.9}
Step 1072: {'loss': 3.7002, 'learning_rate': 7.051977088223585e-05, 'epoch': 1.91}
Step 1073: {'loss': 3.9251, 'learning_rate': 7.032194532478902e-05, 'epoch': 1.91}
Step 1074: {'loss': 3.7129, 'learning_rate': 7.012424704842441e-05, 'epoch': 1.91}
Step 1075: {'loss': 3.5757, 'learning_rate': 6.992667690101599e-05, 'epoch': 1.91}
Step 1076: {'loss': 3.5531, 'learning_rate': 6.972923572988819e-05, 'epoch': 1.91}
Step 1077: {'loss': 3.6765, 'learning_rate': 6.953192438181238e-05, 'epoch': 1.91}
Step 1078: {'loss': 3.4591, 'learning_rate': 6.933474370300316e-05, 'epoch': 1.92}
Step 1079: {'loss': 3.5115, 'learning_rate': 6.913769453911459e-05, 'epoch': 1.92}
Step 1080: {'loss': 3.7547, 'learning_rate': 6.894077773523686e-05, 'epoch': 1.92}
Step 1081: {'loss': 3.6249, 'learning_rate': 6.874399413589245e-05, 'epoch': 1.92}
Step 1082: {'loss': 3.8371, 'learning_rate': 6.854734458503246e-05, 'epoch': 1.92}
Step 1083: {'loss': 3.3306, 'learning_rate': 6.835082992603326e-05, 'epoch': 1.93}
Step 1084: {'loss': 3.7312, 'learning_rate': 6.815445100169261e-05, 'epoch': 1.93}
Step 1085: {'loss': 3.6728, 'learning_rate': 6.79582086542261e-05, 'epoch': 1.93}
Step 1086: {'loss': 3.5672, 'learning_rate': 6.776210372526372e-05, 'epoch': 1.93}
Step 1087: {'loss': 3.6975, 'learning_rate': 6.756613705584601e-05, 'epoch': 1.93}
Step 1088: {'loss': 3.3357, 'learning_rate': 6.737030948642051e-05, 'epoch': 1.93}
Step 1089: {'loss': 3.7394, 'learning_rate': 6.71746218568383e-05, 'epoch': 1.94}
Step 1090: {'loss': 3.9379, 'learning_rate': 6.697907500635025e-05, 'epoch': 1.94}
Step 1091: {'loss': 3.1476, 'learning_rate': 6.678366977360344e-05, 'epoch': 1.94}
Step 1092: {'loss': 3.7737, 'learning_rate': 6.658840699663764e-05, 'epoch': 1.94}
Step 1093: {'loss': 3.7577, 'learning_rate': 6.639328751288168e-05, 'epoch': 1.94}
Step 1094: {'loss': 3.6418, 'learning_rate': 6.619831215914974e-05, 'epoch': 1.94}
Step 1095: {'loss': 3.6319, 'learning_rate': 6.600348177163796e-05, 'epoch': 1.95}
Step 1096: {'loss': 3.6276, 'learning_rate': 6.58087971859208e-05, 'epoch': 1.95}
Step 1097: {'loss': 3.7021, 'learning_rate': 6.561425923694726e-05, 'epoch': 1.95}
Step 1098: {'loss': 3.7534, 'learning_rate': 6.541986875903755e-05, 'epoch': 1.95}
Step 1099: {'loss': 3.6575, 'learning_rate': 6.52256265858795e-05, 'epoch': 1.95}
Step 1100: {'loss': 3.2898, 'learning_rate': 6.503153355052472e-05, 'epoch': 1.96}
Step 1101: {'loss': 3.6248, 'learning_rate': 6.483759048538532e-05, 'epoch': 1.96}
Step 1102: {'loss': 2.9975, 'learning_rate': 6.464379822223028e-05, 'epoch': 1.96}
Step 1103: {'loss': 3.3525, 'learning_rate': 6.445015759218169e-05, 'epoch': 1.96}
Step 1104: {'loss': 3.0746, 'learning_rate': 6.42566694257114e-05, 'epoch': 1.96}
Step 1105: {'loss': 3.6083, 'learning_rate': 6.406333455263746e-05, 'epoch': 1.96}
Step 1106: {'loss': 3.7558, 'learning_rate': 6.387015380212029e-05, 'epoch': 1.97}
Step 1107: {'loss': 3.7702, 'learning_rate': 6.367712800265955e-05, 'epoch': 1.97}
Step 1108: {'loss': 3.5859, 'learning_rate': 6.348425798209016e-05, 'epoch': 1.97}
Step 1109: {'loss': 3.2635, 'learning_rate': 6.329154456757914e-05, 'epoch': 1.97}
Step 1110: {'loss': 3.6914, 'learning_rate': 6.309898858562169e-05, 'epoch': 1.97}
Step 1111: {'loss': 3.6986, 'learning_rate': 6.290659086203787e-05, 'epoch': 1.98}
Step 1112: {'loss': 3.1998, 'learning_rate': 6.271435222196916e-05, 'epoch': 1.98}
Step 1113: {'loss': 3.6641, 'learning_rate': 6.252227348987454e-05, 'epoch': 1.98}
Step 1114: {'loss': 3.8184, 'learning_rate': 6.233035548952734e-05, 'epoch': 1.98}
Step 1115: {'loss': 3.6369, 'learning_rate': 6.213859904401156e-05, 'epoch': 1.98}
Step 1116: {'loss': 3.3475, 'learning_rate': 6.194700497571826e-05, 'epoch': 1.98}
Step 1117: {'loss': 3.523, 'learning_rate': 6.175557410634212e-05, 'epoch': 1.99}
Step 1118: {'loss': 3.1039, 'learning_rate': 6.1564307256878e-05, 'epoch': 1.99}
Step 1119: {'loss': 3.5619, 'learning_rate': 6.137320524761721e-05, 'epoch': 1.99}
Step 1120: {'loss': 3.7792, 'learning_rate': 6.118226889814409e-05, 'epoch': 1.99}
Step 1121: {'loss': 3.2079, 'learning_rate': 6.099149902733269e-05, 'epoch': 1.99}
Step 1122: {'loss': 3.308, 'learning_rate': 6.080089645334286e-05, 'epoch': 1.99}
Step 1123: {'loss': 3.7664, 'learning_rate': 6.0610461993617066e-05, 'epoch': 2.0}
Step 1124: {'loss': 3.6636, 'learning_rate': 6.042019646487685e-05, 'epoch': 2.0}
Step 1125: {'loss': 3.3847, 'learning_rate': 6.023010068311905e-05, 'epoch': 2.0}
Step 1126: {'loss': 3.7423, 'learning_rate': 6.0040175463612716e-05, 'epoch': 2.0}
Step 1127: {'loss': 3.4938, 'learning_rate': 5.985042162089529e-05, 'epoch': 2.0}
Step 1128: {'loss': 3.7172, 'learning_rate': 5.966083996876921e-05, 'epoch': 2.01}
Step 1129: {'loss': 3.7094, 'learning_rate': 5.947143132029853e-05, 'epoch': 2.01}
Step 1130: {'loss': 3.3915, 'learning_rate': 5.928219648780529e-05, 'epoch': 2.01}
Step 1131: {'loss': 3.5941, 'learning_rate': 5.909313628286601e-05, 'epoch': 2.01}
Step 1132: {'loss': 3.4235, 'learning_rate': 5.890425151630841e-05, 'epoch': 2.01}
Step 1133: {'loss': 3.8991, 'learning_rate': 5.871554299820774e-05, 'epoch': 2.01}
Step 1134: {'loss': 3.44, 'learning_rate': 5.852701153788329e-05, 'epoch': 2.02}
Step 1135: {'loss': 3.6511, 'learning_rate': 5.833865794389515e-05, 'epoch': 2.02}
Step 1136: {'loss': 3.7317, 'learning_rate': 5.8150483024040494e-05, 'epoch': 2.02}
Step 1137: {'loss': 3.7823, 'learning_rate': 5.796248758535021e-05, 'epoch': 2.02}
Step 1138: {'loss': 3.7306, 'learning_rate': 5.77746724340855e-05, 'epoch': 2.02}
Step 1139: {'loss': 3.6744, 'learning_rate': 5.758703837573428e-05, 'epoch': 2.02}
Step 1140: {'loss': 3.7375, 'learning_rate': 5.7399586215007875e-05, 'epoch': 2.03}
Step 1141: {'loss': 3.4887, 'learning_rate': 5.721231675583748e-05, 'epoch': 2.03}
Step 1142: {'loss': 3.6383, 'learning_rate': 5.702523080137072e-05, 'epoch': 2.03}
Step 1143: {'loss': 3.4021, 'learning_rate': 5.683832915396823e-05, 'epoch': 2.03}
Step 1144: {'loss': 3.8664, 'learning_rate': 5.665161261520021e-05, 'epoch': 2.03}
Step 1145: {'loss': 3.5991, 'learning_rate': 5.6465081985842996e-05, 'epoch': 2.04}
Step 1146: {'loss': 3.4784, 'learning_rate': 5.627873806587548e-05, 'epoch': 2.04}
Step 1147: {'loss': 3.422, 'learning_rate': 5.609258165447602e-05, 'epoch': 2.04}
Step 1148: {'loss': 3.6185, 'learning_rate': 5.5906613550018696e-05, 'epoch': 2.04}
Step 1149: {'loss': 3.819, 'learning_rate': 5.5720834550069854e-05, 'epoch': 2.04}
Step 1150: {'loss': 4.0932, 'learning_rate': 5.55352454513851e-05, 'epoch': 2.04}
Step 1151: {'loss': 3.244, 'learning_rate': 5.5349847049905445e-05, 'epoch': 2.05}
Step 1152: {'loss': 3.4132, 'learning_rate': 5.516464014075395e-05, 'epoch': 2.05}
Step 1153: {'loss': 3.7219, 'learning_rate': 5.497962551823266e-05, 'epoch': 2.05}
Step 1154: {'loss': 3.5722, 'learning_rate': 5.479480397581884e-05, 'epoch': 2.05}
Step 1155: {'loss': 4.0573, 'learning_rate': 5.4610176306161545e-05, 'epoch': 2.05}
Step 1156: {'loss': 3.5176, 'learning_rate': 5.44257433010786e-05, 'epoch': 2.06}
Step 1157: {'loss': 3.4003, 'learning_rate': 5.424150575155289e-05, 'epoch': 2.06}
Step 1158: {'loss': 3.3747, 'learning_rate': 5.405746444772888e-05, 'epoch': 2.06}
Step 1159: {'loss': 3.8129, 'learning_rate': 5.387362017890967e-05, 'epoch': 2.06}
Step 1160: {'loss': 3.3007, 'learning_rate': 5.3689973733553154e-05, 'epoch': 2.06}
Step 1161: {'loss': 3.5132, 'learning_rate': 5.3506525899268746e-05, 'epoch': 2.06}
Step 1162: {'loss': 3.1264, 'learning_rate': 5.332327746281429e-05, 'epoch': 2.07}
Step 1163: {'loss': 3.4984, 'learning_rate': 5.314022921009236e-05, 'epoch': 2.07}
Step 1164: {'loss': 3.5604, 'learning_rate': 5.295738192614691e-05, 'epoch': 2.07}
Step 1165: {'loss': 3.5354, 'learning_rate': 5.277473639516006e-05, 'epoch': 2.07}
Step 1166: {'loss': 3.6797, 'learning_rate': 5.25922934004488e-05, 'epoch': 2.07}
Step 1167: {'loss': 3.4069, 'learning_rate': 5.241005372446126e-05, 'epoch': 2.07}
Step 1168: {'loss': 3.3889, 'learning_rate': 5.222801814877369e-05, 'epoch': 2.08}
Step 1169: {'loss': 3.667, 'learning_rate': 5.204618745408718e-05, 'epoch': 2.08}
Step 1170: {'loss': 3.4697, 'learning_rate': 5.186456242022384e-05, 'epoch': 2.08}
Step 1171: {'loss': 3.4927, 'learning_rate': 5.1683143826123916e-05, 'epoch': 2.08}
Step 1172: {'loss': 3.6232, 'learning_rate': 5.150193244984238e-05, 'epoch': 2.08}
Step 1173: {'loss': 3.4348, 'learning_rate': 5.132092906854532e-05, 'epoch': 2.09}
Step 1174: {'loss': 3.4116, 'learning_rate': 5.114013445850684e-05, 'epoch': 2.09}
Step 1175: {'loss': 3.3652, 'learning_rate': 5.095954939510583e-05, 'epoch': 2.09}
Step 1176: {'loss': 3.6765, 'learning_rate': 5.0779174652822284e-05, 'epoch': 2.09}
Step 1177: {'loss': 3.524, 'learning_rate': 5.0599011005234255e-05, 'epoch': 2.09}
Step 1178: {'loss': 3.3147, 'learning_rate': 5.0419059225014595e-05, 'epoch': 2.09}
Step 1179: {'loss': 3.6961, 'learning_rate': 5.023932008392733e-05, 'epoch': 2.1}
Step 1180: {'loss': 3.6563, 'learning_rate': 5.0059794352824596e-05, 'epoch': 2.1}
Step 1181: {'loss': 3.3738, 'learning_rate': 4.98804828016434e-05, 'epoch': 2.1}
Step 1182: {'loss': 3.406, 'learning_rate': 4.9701386199401964e-05, 'epoch': 2.1}
Step 1183: {'loss': 3.4214, 'learning_rate': 4.952250531419682e-05, 'epoch': 2.1}
Step 1184: {'loss': 3.5527, 'learning_rate': 4.934384091319929e-05, 'epoch': 2.1}
Step 1185: {'loss': 3.5054, 'learning_rate': 4.916539376265226e-05, 'epoch': 2.11}
Step 1186: {'loss': 3.5071, 'learning_rate': 4.898716462786689e-05, 'epoch': 2.11}
Step 1187: {'loss': 3.4557, 'learning_rate': 4.880915427321933e-05, 'epoch': 2.11}
Step 1188: {'loss': 3.29, 'learning_rate': 4.863136346214744e-05, 'epoch': 2.11}
Step 1189: {'loss': 3.4918, 'learning_rate': 4.845379295714751e-05, 'epoch': 2.11}
Step 1190: {'loss': 3.4, 'learning_rate': 4.827644351977103e-05, 'epoch': 2.12}
Step 1191: {'loss': 3.8099, 'learning_rate': 4.8099315910621354e-05, 'epoch': 2.12}
Step 1192: {'loss': 3.9445, 'learning_rate': 4.792241088935049e-05, 'epoch': 2.12}
Step 1193: {'loss': 3.4224, 'learning_rate': 4.774572921465581e-05, 'epoch': 2.12}
Step 1194: {'loss': 3.7616, 'learning_rate': 4.756927164427685e-05, 'epoch': 2.12}
Step 1195: {'loss': 3.5944, 'learning_rate': 4.7393038934991995e-05, 'epoch': 2.12}
Step 1196: {'loss': 3.5904, 'learning_rate': 4.721703184261522e-05, 'epoch': 2.13}
Step 1197: {'loss': 3.5035, 'learning_rate': 4.704125112199308e-05, 'epoch': 2.13}
Step 1198: {'loss': 3.9071, 'learning_rate': 4.686569752700101e-05, 'epoch': 2.13}
Step 1199: {'loss': 3.7904, 'learning_rate': 4.6690371810540515e-05, 'epoch': 2.13}
Step 1200: {'loss': 3.7736, 'learning_rate': 4.651527472453586e-05, 'epoch': 2.13}
Step 1201: {'loss': 3.7726, 'learning_rate': 4.634040701993061e-05, 'epoch': 2.14}
Step 1202: {'loss': 3.755, 'learning_rate': 4.616576944668467e-05, 'epoch': 2.14}
Step 1203: {'loss': 3.4444, 'learning_rate': 4.5991362753770985e-05, 'epoch': 2.14}
Step 1204: {'loss': 3.3903, 'learning_rate': 4.581718768917228e-05, 'epoch': 2.14}
Step 1205: {'loss': 3.4824, 'learning_rate': 4.56432449998779e-05, 'epoch': 2.14}
Step 1206: {'loss': 3.471, 'learning_rate': 4.5469535431880603e-05, 'epoch': 2.14}
Step 1207: {'loss': 3.6626, 'learning_rate': 4.5296059730173344e-05, 'epoch': 2.15}
Step 1208: {'loss': 3.5617, 'learning_rate': 4.512281863874611e-05, 'epoch': 2.15}
Step 1209: {'loss': 4.0946, 'learning_rate': 4.4949812900582676e-05, 'epoch': 2.15}
Step 1210: {'loss': 3.4641, 'learning_rate': 4.477704325765748e-05, 'epoch': 2.15}
Step 1211: {'loss': 3.6094, 'learning_rate': 4.460451045093239e-05, 'epoch': 2.15}
Step 1212: {'loss': 3.6429, 'learning_rate': 4.443221522035357e-05, 'epoch': 2.15}
Step 1213: {'loss': 3.6881, 'learning_rate': 4.4260158304848254e-05, 'epoch': 2.16}
Step 1214: {'loss': 3.4681, 'learning_rate': 4.408834044232164e-05, 'epoch': 2.16}
Step 1215: {'loss': 3.1972, 'learning_rate': 4.3916762369653685e-05, 'epoch': 2.16}
Step 1216: {'loss': 3.604, 'learning_rate': 4.3745424822695924e-05, 'epoch': 2.16}
Step 1217: {'loss': 3.8379, 'learning_rate': 4.3574328536268394e-05, 'epoch': 2.16}
Step 1218: {'loss': 3.2051, 'learning_rate': 4.340347424415638e-05, 'epoch': 2.17}
Step 1219: {'loss': 3.6926, 'learning_rate': 4.323286267910736e-05, 'epoch': 2.17}
Step 1220: {'loss': 3.2123, 'learning_rate': 4.306249457282778e-05, 'epoch': 2.17}
Step 1221: {'loss': 3.7655, 'learning_rate': 4.2892370655980005e-05, 'epoch': 2.17}
Step 1222: {'loss': 3.6817, 'learning_rate': 4.2722491658179123e-05, 'epoch': 2.17}
Step 1223: {'loss': 3.3747, 'learning_rate': 4.255285830798979e-05, 'epoch': 2.17}
Step 1224: {'loss': 3.6115, 'learning_rate': 4.238347133292321e-05, 'epoch': 2.18}
Step 1225: {'loss': 3.9362, 'learning_rate': 4.22143314594339e-05, 'epoch': 2.18}
Step 1226: {'loss': 3.777, 'learning_rate': 4.204543941291665e-05, 'epoch': 2.18}
Step 1227: {'loss': 3.4498, 'learning_rate': 4.1876795917703405e-05, 'epoch': 2.18}
Step 1228: {'loss': 3.5063, 'learning_rate': 4.1708401697060104e-05, 'epoch': 2.18}
Step 1229: {'loss': 3.5668, 'learning_rate': 4.154025747318363e-05, 'epoch': 2.18}
Step 1230: {'loss': 3.4518, 'learning_rate': 4.13723639671987e-05, 'epoch': 2.19}
Step 1231: {'loss': 3.4904, 'learning_rate': 4.120472189915479e-05, 'epoch': 2.19}
Step 1232: {'loss': 3.3449, 'learning_rate': 4.1037331988022976e-05, 'epoch': 2.19}
Step 1233: {'loss': 3.2248, 'learning_rate': 4.087019495169295e-05, 'epoch': 2.19}
Step 1234: {'loss': 3.4794, 'learning_rate': 4.070331150696988e-05, 'epoch': 2.19}
Step 1235: {'loss': 3.4306, 'learning_rate': 4.053668236957134e-05, 'epoch': 2.2}
Step 1236: {'loss': 3.2275, 'learning_rate': 4.037030825412429e-05, 'epoch': 2.2}
Step 1237: {'loss': 3.4533, 'learning_rate': 4.020418987416183e-05, 'epoch': 2.2}
Step 1238: {'loss': 3.6849, 'learning_rate': 4.003832794212048e-05, 'epoch': 2.2}
Step 1239: {'loss': 3.4379, 'learning_rate': 3.987272316933685e-05, 'epoch': 2.2}
Step 1240: {'loss': 3.8832, 'learning_rate': 3.9707376266044524e-05, 'epoch': 2.2}
Step 1241: {'loss': 3.3892, 'learning_rate': 3.954228794137138e-05, 'epoch': 2.21}
Step 1242: {'loss': 3.3965, 'learning_rate': 3.937745890333623e-05, 'epoch': 2.21}
Step 1243: {'loss': 3.3424, 'learning_rate': 3.9212889858845745e-05, 'epoch': 2.21}
Step 1244: {'loss': 3.5565, 'learning_rate': 3.9048581513691776e-05, 'epoch': 2.21}
Step 1245: {'loss': 3.9615, 'learning_rate': 3.8884534572548014e-05, 'epoch': 2.21}
Step 1246: {'loss': 3.5679, 'learning_rate': 3.872074973896692e-05, 'epoch': 2.22}
Step 1247: {'loss': 3.3904, 'learning_rate': 3.8557227715377117e-05, 'epoch': 2.22}
Step 1248: {'loss': 3.7999, 'learning_rate': 3.8393969203079924e-05, 'epoch': 2.22}
Step 1249: {'loss': 3.6156, 'learning_rate': 3.823097490224651e-05, 'epoch': 2.22}
Step 1250: {'loss': 3.724, 'learning_rate': 3.806824551191505e-05, 'epoch': 2.22}
Step 1251: {'loss': 3.4863, 'learning_rate': 3.7905781729987536e-05, 'epoch': 2.22}
Step 1252: {'loss': 3.6379, 'learning_rate': 3.774358425322669e-05, 'epoch': 2.23}
Step 1253: {'loss': 3.8001, 'learning_rate': 3.758165377725338e-05, 'epoch': 2.23}
Step 1254: {'loss': 3.5288, 'learning_rate': 3.7419990996543245e-05, 'epoch': 2.23}
Step 1255: {'loss': 3.606, 'learning_rate': 3.7258596604423756e-05, 'epoch': 2.23}
Step 1256: {'loss': 3.7402, 'learning_rate': 3.709747129307155e-05, 'epoch': 2.23}
Step 1257: {'loss': 4.0381, 'learning_rate': 3.693661575350914e-05, 'epoch': 2.23}
Step 1258: {'loss': 3.868, 'learning_rate': 3.6776030675601993e-05, 'epoch': 2.24}
Step 1259: {'loss': 3.9131, 'learning_rate': 3.6615716748055704e-05, 'epoch': 2.24}
Step 1260: {'loss': 3.6038, 'learning_rate': 3.645567465841311e-05, 'epoch': 2.24}
Step 1261: {'loss': 3.6082, 'learning_rate': 3.629590509305097e-05, 'epoch': 2.24}
Step 1262: {'loss': 3.5265, 'learning_rate': 3.613640873717735e-05, 'epoch': 2.24}
Step 1263: {'loss': 3.4241, 'learning_rate': 3.597718627482876e-05, 'epoch': 2.25}
Step 1264: {'loss': 3.3304, 'learning_rate': 3.581823838886679e-05, 'epoch': 2.25}
Step 1265: {'loss': 3.5536, 'learning_rate': 3.5659565760975576e-05, 'epoch': 2.25}
Step 1266: {'loss': 3.5963, 'learning_rate': 3.550116907165886e-05, 'epoch': 2.25}
Step 1267: {'loss': 3.6449, 'learning_rate': 3.534304900023672e-05, 'epoch': 2.25}
Step 1268: {'loss': 3.5353, 'learning_rate': 3.5185206224843025e-05, 'epoch': 2.25}
Step 1269: {'loss': 3.5178, 'learning_rate': 3.502764142242249e-05, 'epoch': 2.26}
Step 1270: {'loss': 3.6739, 'learning_rate': 3.487035526872747e-05, 'epoch': 2.26}
Step 1271: {'loss': 3.8461, 'learning_rate': 3.4713348438315396e-05, 'epoch': 2.26}
Step 1272: {'loss': 3.723, 'learning_rate': 3.455662160454584e-05, 'epoch': 2.26}
Step 1273: {'loss': 3.6306, 'learning_rate': 3.440017543957733e-05, 'epoch': 2.26}
Step 1274: {'loss': 3.6843, 'learning_rate': 3.424401061436482e-05, 'epoch': 2.26}
Step 1275: {'loss': 3.3533, 'learning_rate': 3.4088127798656744e-05, 'epoch': 2.27}
Step 1276: {'loss': 3.4715, 'learning_rate': 3.393252766099187e-05, 'epoch': 2.27}
Step 1277: {'loss': 3.6752, 'learning_rate': 3.3777210868696804e-05, 'epoch': 2.27}
Step 1278: {'loss': 3.5638, 'learning_rate': 3.3622178087882905e-05, 'epoch': 2.27}
Step 1279: {'loss': 3.6407, 'learning_rate': 3.346742998344348e-05, 'epoch': 2.27}
Step 1280: {'loss': 3.1258, 'learning_rate': 3.331296721905095e-05, 'epoch': 2.28}
Step 1281: {'loss': 3.2495, 'learning_rate': 3.3158790457153966e-05, 'epoch': 2.28}
Step 1282: {'loss': 3.2992, 'learning_rate': 3.3004900358974636e-05, 'epoch': 2.28}
Step 1283: {'loss': 3.4979, 'learning_rate': 3.28512975845056e-05, 'epoch': 2.28}
Step 1284: {'loss': 3.821, 'learning_rate': 3.2697982792507277e-05, 'epoch': 2.28}
Step 1285: {'loss': 3.8004, 'learning_rate': 3.254495664050498e-05, 'epoch': 2.28}
Step 1286: {'loss': 3.3243, 'learning_rate': 3.2392219784786146e-05, 'epoch': 2.29}
Step 1287: {'loss': 3.8189, 'learning_rate': 3.223977288039748e-05, 'epoch': 2.29}
Step 1288: {'loss': 3.3127, 'learning_rate': 3.208761658114224e-05, 'epoch': 2.29}
Step 1289: {'loss': 3.37, 'learning_rate': 3.193575153957722e-05, 'epoch': 2.29}
Step 1290: {'loss': 3.4994, 'learning_rate': 3.178417840701016e-05, 'epoch': 2.29}
Step 1291: {'loss': 3.5651, 'learning_rate': 3.163289783349698e-05, 'epoch': 2.3}
Step 1292: {'loss': 3.25, 'learning_rate': 3.1481910467838694e-05, 'epoch': 2.3}
Step 1293: {'loss': 3.7885, 'learning_rate': 3.133121695757896e-05, 'epoch': 2.3}
Step 1294: {'loss': 3.146, 'learning_rate': 3.118081794900122e-05, 'epoch': 2.3}
Step 1295: {'loss': 3.7485, 'learning_rate': 3.10307140871257e-05, 'epoch': 2.3}
Step 1296: {'loss': 3.8663, 'learning_rate': 3.0880906015706966e-05, 'epoch': 2.3}
Step 1297: {'loss': 3.387, 'learning_rate': 3.0731394377230994e-05, 'epoch': 2.31}
Step 1298: {'loss': 3.5802, 'learning_rate': 3.0582179812912396e-05, 'epoch': 2.31}
Step 1299: {'loss': 3.8902, 'learning_rate': 3.0433262962691754e-05, 'epoch': 2.31}
Step 1300: {'loss': 3.43, 'learning_rate': 3.0284644465232824e-05, 'epoch': 2.31}
Step 1301: {'loss': 3.5322, 'learning_rate': 3.0136324957919816e-05, 'epoch': 2.31}
Step 1302: {'loss': 3.8702, 'learning_rate': 2.998830507685463e-05, 'epoch': 2.31}
Step 1303: {'loss': 3.4981, 'learning_rate': 2.9840585456854175e-05, 'epoch': 2.32}
Step 1304: {'loss': 3.354, 'learning_rate': 2.969316673144761e-05, 'epoch': 2.32}
Step 1305: {'loss': 3.4424, 'learning_rate': 2.9546049532873644e-05, 'epoch': 2.32}
Step 1306: {'loss': 3.8182, 'learning_rate': 2.9399234492077798e-05, 'epoch': 2.32}
Step 1307: {'loss': 3.3754, 'learning_rate': 2.9252722238709774e-05, 'epoch': 2.32}
Step 1308: {'loss': 3.4673, 'learning_rate': 2.910651340112064e-05, 'epoch': 2.33}
Step 1309: {'loss': 3.8635, 'learning_rate': 2.8960608606360238e-05, 'epoch': 2.33}
Step 1310: {'loss': 3.3955, 'learning_rate': 2.8815008480174433e-05, 'epoch': 2.33}
Step 1311: {'loss': 3.9705, 'learning_rate': 2.866971364700246e-05, 'epoch': 2.33}
Step 1312: {'loss': 3.6217, 'learning_rate': 2.8524724729974228e-05, 'epoch': 2.33}
Step 1313: {'loss': 3.9783, 'learning_rate': 2.8380042350907655e-05, 'epoch': 2.33}
Step 1314: {'loss': 3.1178, 'learning_rate': 2.8235667130306008e-05, 'epoch': 2.34}
Step 1315: {'loss': 3.2508, 'learning_rate': 2.809159968735524e-05, 'epoch': 2.34}
Step 1316: {'loss': 3.5508, 'learning_rate': 2.794784063992131e-05, 'epoch': 2.34}
Step 1317: {'loss': 3.7914, 'learning_rate': 2.7804390604547557e-05, 'epoch': 2.34}
Step 1318: {'loss': 3.528, 'learning_rate': 2.7661250196452083e-05, 'epoch': 2.34}
Step 1319: {'loss': 3.9197, 'learning_rate': 2.7518420029525026e-05, 'epoch': 2.34}
Step 1320: {'loss': 3.393, 'learning_rate': 2.7375900716326053e-05, 'epoch': 2.35}
Step 1321: {'loss': 3.9351, 'learning_rate': 2.7233692868081605e-05, 'epoch': 2.35}
Step 1322: {'loss': 3.7204, 'learning_rate': 2.7091797094682358e-05, 'epoch': 2.35}
Step 1323: {'loss': 3.2202, 'learning_rate': 2.6950214004680596e-05, 'epoch': 2.35}
Step 1324: {'loss': 3.5958, 'learning_rate': 2.6808944205287566e-05, 'epoch': 2.35}
Step 1325: {'loss': 3.2762, 'learning_rate': 2.6667988302370904e-05, 'epoch': 2.36}
Step 1326: {'loss': 3.7896, 'learning_rate': 2.6527346900452054e-05, 'epoch': 2.36}
Step 1327: {'loss': 3.9026, 'learning_rate': 2.6387020602703615e-05, 'epoch': 2.36}
Step 1328: {'loss': 3.9133, 'learning_rate': 2.6247010010946805e-05, 'epoch': 2.36}
Step 1329: {'loss': 3.6269, 'learning_rate': 2.6107315725648875e-05, 'epoch': 2.36}
Step 1330: {'loss': 3.5675, 'learning_rate': 2.5967938345920527e-05, 'epoch': 2.36}
Step 1331: {'loss': 3.8759, 'learning_rate': 2.5828878469513262e-05, 'epoch': 2.37}
Step 1332: {'loss': 3.3373, 'learning_rate': 2.5690136692817045e-05, 'epoch': 2.37}
Step 1333: {'loss': 3.4775, 'learning_rate': 2.555171361085751e-05, 'epoch': 2.37}
Step 1334: {'loss': 3.2919, 'learning_rate': 2.5413609817293425e-05, 'epoch': 2.37}
Step 1335: {'loss': 3.6484, 'learning_rate': 2.5275825904414362e-05, 'epoch': 2.37}
Step 1336: {'loss': 3.6086, 'learning_rate': 2.5138362463137967e-05, 'epoch': 2.38}
Step 1337: {'loss': 3.3186, 'learning_rate': 2.5001220083007347e-05, 'epoch': 2.38}
Step 1338: {'loss': 3.4836, 'learning_rate': 2.4864399352188872e-05, 'epoch': 2.38}
Step 1339: {'loss': 3.7989, 'learning_rate': 2.472790085746931e-05, 'epoch': 2.38}
Step 1340: {'loss': 4.0462, 'learning_rate': 2.4591725184253412e-05, 'epoch': 2.38}
Step 1341: {'loss': 3.5316, 'learning_rate': 2.4455872916561583e-05, 'epoch': 2.38}
Step 1342: {'loss': 3.8773, 'learning_rate': 2.432034463702715e-05, 'epoch': 2.39}
Step 1343: {'loss': 3.4832, 'learning_rate': 2.4185140926893845e-05, 'epoch': 2.39}
Step 1344: {'loss': 3.6804, 'learning_rate': 2.4050262366013597e-05, 'epoch': 2.39}
Step 1345: {'loss': 3.3349, 'learning_rate': 2.3915709532843765e-05, 'epoch': 2.39}
Step 1346: {'loss': 3.3955, 'learning_rate': 2.3781483004444673e-05, 'epoch': 2.39}
Step 1347: {'loss': 3.7161, 'learning_rate': 2.3647583356477377e-05, 'epoch': 2.39}
Step 1348: {'loss': 3.5362, 'learning_rate': 2.3514011163200934e-05, 'epoch': 2.4}
Step 1349: {'loss': 3.4006, 'learning_rate': 2.3380766997470015e-05, 'epoch': 2.4}
Step 1350: {'loss': 3.4711, 'learning_rate': 2.3247851430732494e-05, 'epoch': 2.4}
Step 1351: {'loss': 4.0677, 'learning_rate': 2.3115265033027068e-05, 'epoch': 2.4}
Step 1352: {'loss': 3.0483, 'learning_rate': 2.2983008372980552e-05, 'epoch': 2.4}
Step 1353: {'loss': 3.4666, 'learning_rate': 2.2851082017805703e-05, 'epoch': 2.41}
Step 1354: {'loss': 3.6768, 'learning_rate': 2.271948653329875e-05, 'epoch': 2.41}
Step 1355: {'loss': 3.4695, 'learning_rate': 2.258822248383674e-05, 'epoch': 2.41}
Step 1356: {'loss': 3.7691, 'learning_rate': 2.245729043237541e-05, 'epoch': 2.41}
Step 1357: {'loss': 3.7517, 'learning_rate': 2.2326690940446682e-05, 'epoch': 2.41}
Step 1358: {'loss': 3.3604, 'learning_rate': 2.2196424568156073e-05, 'epoch': 2.41}
Step 1359: {'loss': 3.9034, 'learning_rate': 2.2066491874180528e-05, 'epoch': 2.42}
Step 1360: {'loss': 3.542, 'learning_rate': 2.1936893415766025e-05, 'epoch': 2.42}
Step 1361: {'loss': 3.7676, 'learning_rate': 2.180762974872491e-05, 'epoch': 2.42}
Step 1362: {'loss': 3.1047, 'learning_rate': 2.16787014274338e-05, 'epoch': 2.42}
Step 1363: {'loss': 3.5417, 'learning_rate': 2.1550109004831198e-05, 'epoch': 2.42}
Step 1364: {'loss': 3.4145, 'learning_rate': 2.142185303241483e-05, 'epoch': 2.42}
Step 1365: {'loss': 3.1657, 'learning_rate': 2.1293934060239597e-05, 'epoch': 2.43}
Step 1366: {'loss': 3.7282, 'learning_rate': 2.1166352636915156e-05, 'epoch': 2.43}
Step 1367: {'loss': 3.3154, 'learning_rate': 2.1039109309603354e-05, 'epoch': 2.43}
Step 1368: {'loss': 3.531, 'learning_rate': 2.091220462401612e-05, 'epoch': 2.43}
Step 1369: {'loss': 3.3835, 'learning_rate': 2.0785639124413114e-05, 'epoch': 2.43}
Step 1370: {'loss': 3.8439, 'learning_rate': 2.065941335359918e-05, 'epoch': 2.44}
Step 1371: {'loss': 3.706, 'learning_rate': 2.0533527852922218e-05, 'epoch': 2.44}
Step 1372: {'loss': 3.4447, 'learning_rate': 2.040798316227085e-05, 'epoch': 2.44}
Step 1373: {'loss': 3.9227, 'learning_rate': 2.0282779820071974e-05, 'epoch': 2.44}
Step 1374: {'loss': 3.4079, 'learning_rate': 2.0157918363288607e-05, 'epoch': 2.44}
Step 1375: {'loss': 3.6187, 'learning_rate': 2.0033399327417436e-05, 'epoch': 2.44}
Step 1376: {'loss': 3.4134, 'learning_rate': 1.990922324648673e-05, 'epoch': 2.45}
Step 1377: {'loss': 3.5154, 'learning_rate': 1.978539065305376e-05, 'epoch': 2.45}
Step 1378: {'loss': 3.4767, 'learning_rate': 1.966190207820274e-05, 'epoch': 2.45}
Step 1379: {'loss': 3.5679, 'learning_rate': 1.953875805154256e-05, 'epoch': 2.45}
Step 1380: {'loss': 3.395, 'learning_rate': 1.9415959101204296e-05, 'epoch': 2.45}
Step 1381: {'loss': 3.4432, 'learning_rate': 1.9293505753839158e-05, 'epoch': 2.46}
Step 1382: {'loss': 3.1475, 'learning_rate': 1.9171398534616214e-05, 'epoch': 2.46}
Step 1383: {'loss': 3.9052, 'learning_rate': 1.904963796721997e-05, 'epoch': 2.46}
Step 1384: {'loss': 3.5465, 'learning_rate': 1.8928224573848262e-05, 'epoch': 2.46}
Step 1385: {'loss': 3.6154, 'learning_rate': 1.880715887521013e-05, 'epoch': 2.46}
Step 1386: {'loss': 3.7475, 'learning_rate': 1.8686441390523246e-05, 'epoch': 2.46}
Step 1387: {'loss': 3.6739, 'learning_rate': 1.8566072637511967e-05, 'epoch': 2.47}
Step 1388: {'loss': 3.5305, 'learning_rate': 1.844605313240513e-05, 'epoch': 2.47}
Step 1389: {'loss': 3.471, 'learning_rate': 1.8326383389933587e-05, 'epoch': 2.47}
Step 1390: {'loss': 3.5019, 'learning_rate': 1.8207063923328237e-05, 'epoch': 2.47}
Step 1391: {'loss': 3.6313, 'learning_rate': 1.808809524431775e-05, 'epoch': 2.47}
Step 1392: {'loss': 3.2671, 'learning_rate': 1.7969477863126328e-05, 'epoch': 2.47}
Step 1393: {'loss': 3.539, 'learning_rate': 1.7851212288471574e-05, 'epoch': 2.48}
Step 1394: {'loss': 3.7493, 'learning_rate': 1.773329902756228e-05, 'epoch': 2.48}
Step 1395: {'loss': 3.6959, 'learning_rate': 1.7615738586096264e-05, 'epoch': 2.48}
Step 1396: {'loss': 3.8098, 'learning_rate': 1.7498531468258184e-05, 'epoch': 2.48}
Step 1397: {'loss': 3.458, 'learning_rate': 1.738167817671742e-05, 'epoch': 2.48}
Step 1398: {'loss': 3.6939, 'learning_rate': 1.726517921262586e-05, 'epoch': 2.49}
Step 1399: {'loss': 3.4896, 'learning_rate': 1.7149035075615794e-05, 'epoch': 2.49}
Step 1400: {'loss': 3.5723, 'learning_rate': 1.7033246263797743e-05, 'epoch': 2.49}
Step 1401: {'loss': 3.4805, 'learning_rate': 1.6917813273758333e-05, 'epoch': 2.49}
Step 1402: {'loss': 3.5673, 'learning_rate': 1.680273660055819e-05, 'epoch': 2.49}
Step 1403: {'loss': 3.838, 'learning_rate': 1.6688016737729773e-05, 'epoch': 2.49}
Step 1404: {'loss': 3.6853, 'learning_rate': 1.657365417727529e-05, 'epoch': 2.5}
Step 1405: {'loss': 3.3945, 'learning_rate': 1.645964940966457e-05, 'epoch': 2.5}
Step 1406: {'loss': 3.6449, 'learning_rate': 1.6346002923832958e-05, 'epoch': 2.5}
Step 1407: {'loss': 3.5545, 'learning_rate': 1.623271520717925e-05, 'epoch': 2.5}
Step 1408: {'loss': 3.4002, 'learning_rate': 1.6119786745563546e-05, 'epoch': 2.5}
Step 1409: {'loss': 3.2764, 'learning_rate': 1.600721802330525e-05, 'epoch': 2.5}
Step 1410: {'loss': 4.32, 'learning_rate': 1.589500952318088e-05, 'epoch': 2.51}
Step 1411: {'loss': 4.3769, 'learning_rate': 1.57831617264221e-05, 'epoch': 2.51}
Step 1412: {'loss': 3.5316, 'learning_rate': 1.5671675112713613e-05, 'epoch': 2.51}
Step 1413: {'loss': 3.3159, 'learning_rate': 1.556055016019109e-05, 'epoch': 2.51}
Step 1414: {'loss': 3.6583, 'learning_rate': 1.544978734543914e-05, 'epoch': 2.51}
Step 1415: {'loss': 3.9183, 'learning_rate': 1.533938714348928e-05, 'epoch': 2.52}
Step 1416: {'loss': 3.5937, 'learning_rate': 1.5229350027817846e-05, 'epoch': 2.52}
Step 1417: {'loss': 4.0462, 'learning_rate': 1.5119676470344036e-05, 'epoch': 2.52}
Step 1418: {'loss': 3.608, 'learning_rate': 1.5010366941427823e-05, 'epoch': 2.52}
Step 1419: {'loss': 3.4481, 'learning_rate': 1.4901421909867952e-05, 'epoch': 2.52}
Step 1420: {'loss': 3.5643, 'learning_rate': 1.4792841842899962e-05, 'epoch': 2.52}
Step 1421: {'loss': 3.3275, 'learning_rate': 1.4684627206194135e-05, 'epoch': 2.53}
Step 1422: {'loss': 3.56, 'learning_rate': 1.4576778463853547e-05, 'epoch': 2.53}
Step 1423: {'loss': 3.5635, 'learning_rate': 1.4469296078412032e-05, 'epoch': 2.53}
Step 1424: {'loss': 3.6766, 'learning_rate': 1.4362180510832246e-05, 'epoch': 2.53}
Step 1425: {'loss': 3.5315, 'learning_rate': 1.4255432220503572e-05, 'epoch': 2.53}
Step 1426: {'loss': 3.4356, 'learning_rate': 1.4149051665240397e-05, 'epoch': 2.54}
Step 1427: {'loss': 3.2418, 'learning_rate': 1.4043039301279903e-05, 'epoch': 2.54}
Step 1428: {'loss': 3.617, 'learning_rate': 1.3937395583280133e-05, 'epoch': 2.54}
Step 1429: {'loss': 3.3715, 'learning_rate': 1.3832120964318251e-05, 'epoch': 2.54}
Step 1430: {'loss': 3.4427, 'learning_rate': 1.372721589588839e-05, 'epoch': 2.54}
Step 1431: {'loss': 3.6365, 'learning_rate': 1.3622680827899692e-05, 'epoch': 2.54}
Step 1432: {'loss': 3.4637, 'learning_rate': 1.3518516208674637e-05, 'epoch': 2.55}
Step 1433: {'loss': 3.7377, 'learning_rate': 1.3414722484946863e-05, 'epoch': 2.55}
Step 1434: {'loss': 3.6275, 'learning_rate': 1.331130010185928e-05, 'epoch': 2.55}
Step 1435: {'loss': 3.3189, 'learning_rate': 1.3208249502962344e-05, 'epoch': 2.55}
Step 1436: {'loss': 3.6268, 'learning_rate': 1.3105571130211957e-05, 'epoch': 2.55}
Step 1437: {'loss': 3.9771, 'learning_rate': 1.3003265423967614e-05, 'epoch': 2.55}
Step 1438: {'loss': 3.2816, 'learning_rate': 1.290133282299063e-05, 'epoch': 2.56}
Step 1439: {'loss': 3.3884, 'learning_rate': 1.2799773764442136e-05, 'epoch': 2.56}
Step 1440: {'loss': 3.5172, 'learning_rate': 1.2698588683881186e-05, 'epoch': 2.56}
Step 1441: {'loss': 3.5456, 'learning_rate': 1.2597778015263029e-05, 'epoch': 2.56}
Step 1442: {'loss': 3.6624, 'learning_rate': 1.2497342190937155e-05, 'epoch': 2.56}
Step 1443: {'loss': 3.3768, 'learning_rate': 1.2397281641645364e-05, 'epoch': 2.57}
Step 1444: {'loss': 3.5433, 'learning_rate': 1.2297596796520061e-05, 'epoch': 2.57}
Step 1445: {'loss': 3.1245, 'learning_rate': 1.2198288083082431e-05, 'epoch': 2.57}
Step 1446: {'loss': 3.658, 'learning_rate': 1.2099355927240396e-05, 'epoch': 2.57}
Step 1447: {'loss': 3.5826, 'learning_rate': 1.200080075328699e-05, 'epoch': 2.57}
Step 1448: {'loss': 3.4288, 'learning_rate': 1.1902622983898525e-05, 'epoch': 2.57}
Step 1449: {'loss': 3.9465, 'learning_rate': 1.180482304013264e-05, 'epoch': 2.58}
Step 1450: {'loss': 3.5519, 'learning_rate': 1.1707401341426594e-05, 'epoch': 2.58}
Step 1451: {'loss': 3.8187, 'learning_rate': 1.1610358305595549e-05, 'epoch': 2.58}
Step 1452: {'loss': 3.6853, 'learning_rate': 1.1513694348830573e-05, 'epoch': 2.58}
Step 1453: {'loss': 3.9365, 'learning_rate': 1.1417409885696994e-05, 'epoch': 2.58}
Step 1454: {'loss': 3.9569, 'learning_rate': 1.1321505329132687e-05, 'epoch': 2.58}
Step 1455: {'loss': 3.4013, 'learning_rate': 1.122598109044608e-05, 'epoch': 2.59}
Step 1456: {'loss': 3.6614, 'learning_rate': 1.1130837579314569e-05, 'epoch': 2.59}
Step 1457: {'loss': 3.5446, 'learning_rate': 1.103607520378278e-05, 'epoch': 2.59}
Step 1458: {'loss': 3.7431, 'learning_rate': 1.0941694370260659e-05, 'epoch': 2.59}
Step 1459: {'loss': 3.3777, 'learning_rate': 1.0847695483521835e-05, 'epoch': 2.59}
Step 1460: {'loss': 3.4477, 'learning_rate': 1.0754078946701973e-05, 'epoch': 2.6}
Step 1461: {'loss': 3.291, 'learning_rate': 1.0660845161296806e-05, 'epoch': 2.6}
Step 1462: {'loss': 4.0506, 'learning_rate': 1.0567994527160619e-05, 'epoch': 2.6}
Step 1463: {'loss': 3.5568, 'learning_rate': 1.047552744250444e-05, 'epoch': 2.6}
Step 1464: {'loss': 3.4313, 'learning_rate': 1.0383444303894452e-05, 'epoch': 2.6}
Step 1465: {'loss': 3.5536, 'learning_rate': 1.029174550625005e-05, 'epoch': 2.6}
Step 1466: {'loss': 3.5282, 'learning_rate': 1.0200431442842362e-05, 'epoch': 2.61}
Step 1467: {'loss': 3.8161, 'learning_rate': 1.0109502505292567e-05, 'epoch': 2.61}
Step 1468: {'loss': 3.5096, 'learning_rate': 1.0018959083570024e-05, 'epoch': 2.61}
Step 1469: {'loss': 3.6402, 'learning_rate': 9.928801565990775e-06, 'epoch': 2.61}
Step 1470: {'loss': 3.5614, 'learning_rate': 9.83903033921586e-06, 'epoch': 2.61}
Step 1471: {'loss': 4.097, 'learning_rate': 9.749645788249562e-06, 'epoch': 2.62}
Step 1472: {'loss': 3.5749, 'learning_rate': 9.660648296437813e-06, 'epoch': 2.62}
Step 1473: {'loss': 3.4998, 'learning_rate': 9.572038245466663e-06, 'epoch': 2.62}
Step 1474: {'loss': 3.3907, 'learning_rate': 9.483816015360381e-06, 'epoch': 2.62}
Step 1475: {'loss': 4.0214, 'learning_rate': 9.395981984480051e-06, 'epoch': 2.62}
Step 1476: {'loss': 3.568, 'learning_rate': 9.308536529521938e-06, 'epoch': 2.62}
Step 1477: {'loss': 3.9055, 'learning_rate': 9.221480025515694e-06, 'epoch': 2.63}
Step 1478: {'loss': 3.8297, 'learning_rate': 9.134812845822915e-06, 'epoch': 2.63}
Step 1479: {'loss': 3.7336, 'learning_rate': 9.048535362135546e-06, 'epoch': 2.63}
Step 1480: {'loss': 3.5358, 'learning_rate': 8.962647944474145e-06, 'epoch': 2.63}
Step 1481: {'loss': 3.7308, 'learning_rate': 8.87715096118642e-06, 'epoch': 2.63}
Step 1482: {'loss': 3.656, 'learning_rate': 8.792044778945652e-06, 'epoch': 2.63}
Step 1483: {'loss': 3.5565, 'learning_rate': 8.707329762749017e-06, 'epoch': 2.64}
Step 1484: {'loss': 3.4209, 'learning_rate': 8.623006275916102e-06, 'epoch': 2.64}
Step 1485: {'loss': 3.3841, 'learning_rate': 8.539074680087366e-06, 'epoch': 2.64}
Step 1486: {'loss': 3.6218, 'learning_rate': 8.45553533522252e-06, 'epoch': 2.64}
Step 1487: {'loss': 3.5857, 'learning_rate': 8.372388599599047e-06, 'epoch': 2.64}
Step 1488: {'loss': 3.2165, 'learning_rate': 8.2896348298106e-06, 'epoch': 2.65}
Step 1489: {'loss': 3.6712, 'learning_rate': 8.207274380765529e-06, 'epoch': 2.65}
Step 1490: {'loss': 3.4049, 'learning_rate': 8.12530760568535e-06, 'epoch': 2.65}
Step 1491: {'loss': 3.5111, 'learning_rate': 8.043734856103191e-06, 'epoch': 2.65}
Step 1492: {'loss': 3.6457, 'learning_rate': 7.962556481862338e-06, 'epoch': 2.65}
Step 1493: {'loss': 3.2968, 'learning_rate': 7.881772831114697e-06, 'epoch': 2.65}
Step 1494: {'loss': 3.8422, 'learning_rate': 7.801384250319311e-06, 'epoch': 2.66}
Step 1495: {'loss': 3.6658, 'learning_rate': 7.721391084240881e-06, 'epoch': 2.66}
Step 1496: {'loss': 3.0859, 'learning_rate': 7.641793675948271e-06, 'epoch': 2.66}
Step 1497: {'loss': 3.0533, 'learning_rate': 7.562592366813059e-06, 'epoch': 2.66}
Step 1498: {'loss': 3.8008, 'learning_rate': 7.483787496508065e-06, 'epoch': 2.66}
Step 1499: {'loss': 3.9996, 'learning_rate': 7.405379403005874e-06, 'epoch': 2.66}
Step 1500: {'loss': 3.6775, 'learning_rate': 7.3273684225774295e-06, 'epoch': 2.67}
Step 1501: {'loss': 3.629, 'learning_rate': 7.249754889790539e-06, 'epoch': 2.67}
Step 1502: {'loss': 3.8455, 'learning_rate': 7.172539137508472e-06, 'epoch': 2.67}
Step 1503: {'loss': 3.5725, 'learning_rate': 7.095721496888541e-06, 'epoch': 2.67}
Step 1504: {'loss': 3.5828, 'learning_rate': 7.019302297380659e-06, 'epoch': 2.67}
Step 1505: {'loss': 3.7156, 'learning_rate': 6.943281866725915e-06, 'epoch': 2.68}
Step 1506: {'loss': 3.7398, 'learning_rate': 6.867660530955211e-06, 'epoch': 2.68}
Step 1507: {'loss': 3.2295, 'learning_rate': 6.792438614387841e-06, 'epoch': 2.68}
Step 1508: {'loss': 3.6346, 'learning_rate': 6.71761643963007e-06, 'epoch': 2.68}
Step 1509: {'loss': 3.5115, 'learning_rate': 6.643194327573809e-06, 'epoch': 2.68}
Step 1510: {'loss': 3.9253, 'learning_rate': 6.569172597395201e-06, 'epoch': 2.68}
Step 1511: {'loss': 3.7466, 'learning_rate': 6.495551566553249e-06, 'epoch': 2.69}
Step 1512: {'loss': 3.3534, 'learning_rate': 6.422331550788485e-06, 'epoch': 2.69}
Step 1513: {'loss': 3.4567, 'learning_rate': 6.349512864121587e-06, 'epoch': 2.69}
Step 1514: {'loss': 3.5822, 'learning_rate': 6.27709581885203e-06, 'epoch': 2.69}
Step 1515: {'loss': 3.7968, 'learning_rate': 6.205080725556778e-06, 'epoch': 2.69}
Step 1516: {'loss': 3.322, 'learning_rate': 6.133467893088929e-06, 'epoch': 2.7}
Step 1517: {'loss': 3.5212, 'learning_rate': 6.062257628576395e-06, 'epoch': 2.7}
Step 1518: {'loss': 3.3354, 'learning_rate': 5.9914502374205704e-06, 'epoch': 2.7}
Step 1519: {'loss': 3.2176, 'learning_rate': 5.9210460232950185e-06, 'epoch': 2.7}
Step 1520: {'loss': 3.3269, 'learning_rate': 5.851045288144253e-06, 'epoch': 2.7}
Step 1521: {'loss': 3.94, 'learning_rate': 5.781448332182337e-06, 'epoch': 2.7}
Step 1522: {'loss': 3.5993, 'learning_rate': 5.71225545389158e-06, 'epoch': 2.71}
Step 1523: {'loss': 3.7873, 'learning_rate': 5.643466950021426e-06, 'epoch': 2.71}
Step 1524: {'loss': 3.4046, 'learning_rate': 5.575083115586976e-06, 'epoch': 2.71}
Step 1525: {'loss': 3.7126, 'learning_rate': 5.507104243867833e-06, 'epoch': 2.71}
Step 1526: {'loss': 3.5656, 'learning_rate': 5.439530626406875e-06, 'epoch': 2.71}
Step 1527: {'loss': 3.3942, 'learning_rate': 5.372362553008903e-06, 'epoch': 2.71}
Step 1528: {'loss': 3.6238, 'learning_rate': 5.305600311739434e-06, 'epoch': 2.72}
Step 1529: {'loss': 3.3903, 'learning_rate': 5.2392441889235534e-06, 'epoch': 2.72}
Step 1530: {'loss': 3.6282, 'learning_rate': 5.1732944691445735e-06, 'epoch': 2.72}
Step 1531: {'loss': 3.7241, 'learning_rate': 5.1077514352428026e-06, 'epoch': 2.72}
Step 1532: {'loss': 3.4377, 'learning_rate': 5.042615368314496e-06, 'epoch': 2.72}
Step 1533: {'loss': 3.8086, 'learning_rate': 4.977886547710464e-06, 'epoch': 2.73}
Step 1534: {'loss': 3.5231, 'learning_rate': 4.913565251034935e-06, 'epoch': 2.73}
Step 1535: {'loss': 3.6534, 'learning_rate': 4.849651754144447e-06, 'epoch': 2.73}
Step 1536: {'loss': 3.4206, 'learning_rate': 4.786146331146557e-06, 'epoch': 2.73}
Step 1537: {'loss': 3.8429, 'learning_rate': 4.72304925439867e-06, 'epoch': 2.73}
Step 1538: {'loss': 3.5601, 'learning_rate': 4.660360794506946e-06, 'epoch': 2.73}
Step 1539: {'loss': 3.9477, 'learning_rate': 4.5980812203251236e-06, 'epoch': 2.74}
Step 1540: {'loss': 3.7847, 'learning_rate': 4.5362107989532774e-06, 'epoch': 2.74}
Step 1541: {'loss': 3.705, 'learning_rate': 4.474749795736776e-06, 'epoch': 2.74}
Step 1542: {'loss': 3.9929, 'learning_rate': 4.413698474265126e-06, 'epoch': 2.74}
Step 1543: {'loss': 3.4152, 'learning_rate': 4.353057096370761e-06, 'epoch': 2.74}
Step 1544: {'loss': 3.8672, 'learning_rate': 4.2928259221280185e-06, 'epoch': 2.74}
Step 1545: {'loss': 3.3508, 'learning_rate': 4.233005209852003e-06, 'epoch': 2.75}
Step 1546: {'loss': 3.3572, 'learning_rate': 4.1735952160974034e-06, 'epoch': 2.75}
Step 1547: {'loss': 3.4265, 'learning_rate': 4.114596195657483e-06, 'epoch': 2.75}
Step 1548: {'loss': 3.9988, 'learning_rate': 4.056008401562972e-06, 'epoch': 2.75}
Step 1549: {'loss': 3.3842, 'learning_rate': 3.997832085080922e-06, 'epoch': 2.75}
Step 1550: {'loss': 3.5339, 'learning_rate': 3.940067495713673e-06, 'epoch': 2.76}
Step 1551: {'loss': 3.6097, 'learning_rate': 3.882714881197847e-06, 'epoch': 2.76}
Step 1552: {'loss': 3.1555, 'learning_rate': 3.825774487503109e-06, 'epoch': 2.76}
Step 1553: {'loss': 3.372, 'learning_rate': 3.7692465588312963e-06, 'epoch': 2.76}
Step 1554: {'loss': 3.4948, 'learning_rate': 3.713131337615283e-06, 'epoch': 2.76}
Step 1555: {'loss': 2.9791, 'learning_rate': 3.65742906451797e-06, 'epoch': 2.76}
Step 1556: {'loss': 3.6075, 'learning_rate': 3.602139978431174e-06, 'epoch': 2.77}
Step 1557: {'loss': 3.6105, 'learning_rate': 3.547264316474708e-06, 'epoch': 2.77}
Step 1558: {'loss': 3.5325, 'learning_rate': 3.4928023139953582e-06, 'epoch': 2.77}
Step 1559: {'loss': 3.6977, 'learning_rate': 3.438754204565764e-06, 'epoch': 2.77}
Step 1560: {'loss': 3.7577, 'learning_rate': 3.3851202199835177e-06, 'epoch': 2.77}
Step 1561: {'loss': 3.4495, 'learning_rate': 3.3319005902702095e-06, 'epoch': 2.78}
Step 1562: {'loss': 3.7808, 'learning_rate': 3.2790955436702518e-06, 'epoch': 2.78}
Step 1563: {'loss': 3.5637, 'learning_rate': 3.226705306650113e-06, 'epoch': 2.78}
Step 1564: {'loss': 3.3726, 'learning_rate': 3.17473010389725e-06, 'epoch': 2.78}
Step 1565: {'loss': 3.5712, 'learning_rate': 3.1231701583190997e-06, 'epoch': 2.78}
Step 1566: {'loss': 3.3197, 'learning_rate': 3.072025691042213e-06, 'epoch': 2.78}
Step 1567: {'loss': 3.358, 'learning_rate': 3.0212969214112764e-06, 'epoch': 2.79}
Step 1568: {'loss': 3.6664, 'learning_rate': 2.970984066988136e-06, 'epoch': 2.79}
Step 1569: {'loss': 3.6694, 'learning_rate': 2.921087343550899e-06, 'epoch': 2.79}
Step 1570: {'loss': 3.7485, 'learning_rate': 2.871606965093032e-06, 'epoch': 2.79}
Step 1571: {'loss': 3.7659, 'learning_rate': 2.8225431438223428e-06, 'epoch': 2.79}
Step 1572: {'loss': 3.4719, 'learning_rate': 2.7738960901601886e-06, 'epoch': 2.79}
Step 1573: {'loss': 3.1761, 'learning_rate': 2.7256660127405355e-06, 'epoch': 2.8}
Step 1574: {'loss': 3.63, 'learning_rate': 2.677853118409024e-06, 'epoch': 2.8}
Step 1575: {'loss': 3.6984, 'learning_rate': 2.6304576122221035e-06, 'epoch': 2.8}
Step 1576: {'loss': 3.5896, 'learning_rate': 2.5834796974461783e-06, 'epoch': 2.8}
Step 1577: {'loss': 3.5451, 'learning_rate': 2.5369195755567177e-06, 'epoch': 2.8}
Step 1578: {'loss': 3.592, 'learning_rate': 2.4907774462373912e-06, 'epoch': 2.81}
Step 1579: {'loss': 3.5512, 'learning_rate': 2.4450535073792024e-06, 'epoch': 2.81}
Step 1580: {'loss': 3.3792, 'learning_rate': 2.3997479550796453e-06, 'epoch': 2.81}
Step 1581: {'loss': 3.6883, 'learning_rate': 2.354860983641882e-06, 'epoch': 2.81}
Step 1582: {'loss': 3.3275, 'learning_rate': 2.3103927855738893e-06, 'epoch': 2.81}
Step 1583: {'loss': 3.9249, 'learning_rate': 2.2663435515876574e-06, 'epoch': 2.81}
Step 1584: {'loss': 3.6659, 'learning_rate': 2.2227134705983143e-06, 'epoch': 2.82}
Step 1585: {'loss': 3.3479, 'learning_rate': 2.1795027297233815e-06, 'epoch': 2.82}
Step 1586: {'loss': 4.1399, 'learning_rate': 2.1367115142819526e-06, 'epoch': 2.82}
Step 1587: {'loss': 3.4602, 'learning_rate': 2.0943400077938824e-06, 'epoch': 2.82}
Step 1588: {'loss': 3.6064, 'learning_rate': 2.0523883919789875e-06, 'epoch': 2.82}
Step 1589: {'loss': 3.5049, 'learning_rate': 2.010856846756315e-06, 'epoch': 2.82}
Step 1590: {'loss': 3.6703, 'learning_rate': 1.9697455502433515e-06, 'epoch': 2.83}
Step 1591: {'loss': 3.3679, 'learning_rate': 1.9290546787552044e-06, 'epoch': 2.83}
Step 1592: {'loss': 3.4564, 'learning_rate': 1.888784406803945e-06, 'epoch': 2.83}
Step 1593: {'loss': 3.7887, 'learning_rate': 1.848934907097777e-06, 'epoch': 2.83}
Step 1594: {'loss': 3.9414, 'learning_rate': 1.8095063505403464e-06, 'epoch': 2.83}
Step 1595: {'loss': 3.6153, 'learning_rate': 1.7704989062299782e-06, 'epoch': 2.84}
Step 1596: {'loss': 3.4498, 'learning_rate': 1.731912741458941e-06, 'epoch': 2.84}
Step 1597: {'loss': 3.757, 'learning_rate': 1.6937480217127933e-06, 'epoch': 2.84}
Step 1598: {'loss': 3.9117, 'learning_rate': 1.6560049106696064e-06, 'epoch': 2.84}
Step 1599: {'loss': 3.2687, 'learning_rate': 1.6186835701992865e-06, 'epoch': 2.84}
Step 1600: {'loss': 3.4303, 'learning_rate': 1.5817841603628869e-06, 'epoch': 2.84}
Step 1601: {'loss': 3.9049, 'learning_rate': 1.5453068394118975e-06, 'epoch': 2.85}
Step 1602: {'loss': 3.6116, 'learning_rate': 1.5092517637876224e-06, 'epoch': 2.85}
Step 1603: {'loss': 3.8941, 'learning_rate': 1.473619088120426e-06, 'epoch': 2.85}
Step 1604: {'loss': 3.6295, 'learning_rate': 1.4384089652291543e-06, 'epoch': 2.85}
Step 1605: {'loss': 3.4871, 'learning_rate': 1.403621546120415e-06, 'epoch': 2.85}
Step 1606: {'loss': 3.2786, 'learning_rate': 1.3692569799879429e-06, 'epoch': 2.86}
Step 1607: {'loss': 3.4696, 'learning_rate': 1.335315414212024e-06, 'epoch': 2.86}
Step 1608: {'loss': 3.3762, 'learning_rate': 1.3017969943587505e-06, 'epoch': 2.86}
Step 1609: {'loss': 3.8634, 'learning_rate': 1.268701864179489e-06, 'epoch': 2.86}
Step 1610: {'loss': 3.5399, 'learning_rate': 1.2360301656102247e-06, 'epoch': 2.86}
Step 1611: {'loss': 3.4481, 'learning_rate': 1.203782038770973e-06, 'epoch': 2.86}
Step 1612: {'loss': 3.7471, 'learning_rate': 1.1719576219651585e-06, 'epoch': 2.87}
Step 1613: {'loss': 3.5098, 'learning_rate': 1.140557051678992e-06, 'epoch': 2.87}
Step 1614: {'loss': 3.2947, 'learning_rate': 1.1095804625809835e-06, 'epoch': 2.87}
Step 1615: {'loss': 3.5603, 'learning_rate': 1.079027987521286e-06, 'epoch': 2.87}
Step 1616: {'loss': 3.6974, 'learning_rate': 1.0488997575310965e-06, 'epoch': 2.87}
Step 1617: {'loss': 3.4383, 'learning_rate': 1.0191959018222009e-06, 'epoch': 2.87}
Step 1618: {'loss': 3.651, 'learning_rate': 9.899165477863293e-07, 'epoch': 2.88}
Step 1619: {'loss': 4.0257, 'learning_rate': 9.610618209946464e-07, 'epoch': 2.88}
Step 1620: {'loss': 3.9953, 'learning_rate': 9.326318451972071e-07, 'epoch': 2.88}
Step 1621: {'loss': 3.7508, 'learning_rate': 9.046267423224231e-07, 'epoch': 2.88}
Step 1622: {'loss': 3.6488, 'learning_rate': 8.770466324765302e-07, 'epoch': 2.88}
Step 1623: {'loss': 3.2367, 'learning_rate': 8.498916339431117e-07, 'epoch': 2.89}
Step 1624: {'loss': 3.2699, 'learning_rate': 8.231618631825532e-07, 'epoch': 2.89}
Step 1625: {'loss': 3.4228, 'learning_rate': 7.968574348315438e-07, 'epoch': 2.89}
Step 1626: {'loss': 3.4438, 'learning_rate': 7.709784617025984e-07, 'epoch': 2.89}
Step 1627: {'loss': 3.5688, 'learning_rate': 7.455250547835913e-07, 'epoch': 2.89}
Step 1628: {'loss': 3.7332, 'learning_rate': 7.204973232372125e-07, 'epoch': 2.89}
Step 1629: {'loss': 3.5477, 'learning_rate': 6.958953744006125e-07, 'epoch': 2.9}
Step 1630: {'loss': 3.5862, 'learning_rate': 6.717193137848132e-07, 'epoch': 2.9}
Step 1631: {'loss': 3.4905, 'learning_rate': 6.479692450743646e-07, 'epoch': 2.9}
Step 1632: {'loss': 3.7861, 'learning_rate': 6.246452701268002e-07, 'epoch': 2.9}
Step 1633: {'loss': 3.8299, 'learning_rate': 6.017474889723374e-07, 'epoch': 2.9}
Step 1634: {'loss': 3.8617, 'learning_rate': 5.792759998132779e-07, 'epoch': 2.9}
Step 1635: {'loss': 3.6769, 'learning_rate': 5.572308990237086e-07, 'epoch': 2.91}
Step 1636: {'loss': 3.8613, 'learning_rate': 5.356122811490782e-07, 'epoch': 2.91}
Step 1637: {'loss': 3.5638, 'learning_rate': 5.144202389057329e-07, 'epoch': 2.91}
Step 1638: {'loss': 3.9876, 'learning_rate': 4.936548631805482e-07, 'epoch': 2.91}
Step 1639: {'loss': 3.4355, 'learning_rate': 4.7331624303057485e-07, 'epoch': 2.91}
Step 1640: {'loss': 3.8426, 'learning_rate': 4.5340446568259423e-07, 'epoch': 2.92}
Step 1641: {'loss': 3.6209, 'learning_rate': 4.339196165327963e-07, 'epoch': 2.92}
Step 1642: {'loss': 3.8854, 'learning_rate': 4.1486177914638047e-07, 'epoch': 2.92}
Step 1643: {'loss': 3.6788, 'learning_rate': 3.9623103525723294e-07, 'epoch': 2.92}
Step 1644: {'loss': 3.7184, 'learning_rate': 3.780274647674942e-07, 'epoch': 2.92}
Step 1645: {'loss': 3.4868, 'learning_rate': 3.6025114574734785e-07, 'epoch': 2.92}
Step 1646: {'loss': 3.7356, 'learning_rate': 3.4290215443456566e-07, 'epoch': 2.93}
Step 1647: {'loss': 3.8895, 'learning_rate': 3.259805652342407e-07, 'epoch': 2.93}
Step 1648: {'loss': 3.5056, 'learning_rate': 3.0948645071844365e-07, 'epoch': 2.93}
Step 1649: {'loss': 3.3406, 'learning_rate': 2.934198816259559e-07, 'epoch': 2.93}
Step 1650: {'loss': 3.4236, 'learning_rate': 2.777809268618925e-07, 'epoch': 2.93}
Step 1651: {'loss': 3.2697, 'learning_rate': 2.6256965349745754e-07, 'epoch': 2.94}
Step 1652: {'loss': 3.5165, 'learning_rate': 2.4778612676967793e-07, 'epoch': 2.94}
Step 1653: {'loss': 3.6006, 'learning_rate': 2.3343041008105915e-07, 'epoch': 2.94}
Step 1654: {'loss': 3.7493, 'learning_rate': 2.1950256499934097e-07, 'epoch': 2.94}
Step 1655: {'loss': 3.4092, 'learning_rate': 2.0600265125726437e-07, 'epoch': 2.94}
Step 1656: {'loss': 3.6458, 'learning_rate': 1.9293072675228284e-07, 'epoch': 2.94}
Step 1657: {'loss': 3.6477, 'learning_rate': 1.80286847546296e-07, 'epoch': 2.95}
Step 1658: {'loss': 3.302, 'learning_rate': 1.6807106786547177e-07, 'epoch': 2.95}
Step 1659: {'loss': 3.6737, 'learning_rate': 1.5628344009994688e-07, 'epoch': 2.95}
Step 1660: {'loss': 4.0242, 'learning_rate': 1.4492401480364904e-07, 'epoch': 2.95}
Step 1661: {'loss': 3.9499, 'learning_rate': 1.339928406940527e-07, 'epoch': 2.95}
Step 1662: {'loss': 3.7688, 'learning_rate': 1.2348996465199049e-07, 'epoch': 2.95}
Step 1663: {'loss': 3.5892, 'learning_rate': 1.1341543172140867e-07, 'epoch': 2.96}
Step 1664: {'loss': 3.8096, 'learning_rate': 1.0376928510925643e-07, 'epoch': 2.96}
Step 1665: {'loss': 3.2039, 'learning_rate': 9.455156618521921e-08, 'epoch': 2.96}
Step 1666: {'loss': 3.6248, 'learning_rate': 8.576231448156335e-08, 'epoch': 2.96}
Step 1667: {'loss': 3.5626, 'learning_rate': 7.740156769302508e-08, 'epoch': 2.96}
Step 1668: {'loss': 3.446, 'learning_rate': 6.946936167653295e-08, 'epoch': 2.97}
Step 1669: {'loss': 3.7496, 'learning_rate': 6.196573045117448e-08, 'epoch': 2.97}
Step 1670: {'loss': 3.5799, 'learning_rate': 5.489070619797421e-08, 'epoch': 2.97}
Step 1671: {'loss': 3.7112, 'learning_rate': 4.824431925977146e-08, 'epoch': 2.97}
Step 1672: {'loss': 3.5987, 'learning_rate': 4.2026598141120534e-08, 'epoch': 2.97}
Step 1673: {'loss': 3.1934, 'learning_rate': 3.623756950813517e-08, 'epoch': 2.97}
Step 1674: {'loss': 3.5115, 'learning_rate': 3.087725818836651e-08, 'epoch': 2.98}
Step 1675: {'loss': 3.4074, 'learning_rate': 2.594568717072532e-08, 'epoch': 2.98}
Step 1676: {'loss': 3.5927, 'learning_rate': 2.1442877605393207e-08, 'epoch': 2.98}
Step 1677: {'loss': 3.4244, 'learning_rate': 1.7368848803678283e-08, 'epoch': 2.98}
Step 1678: {'loss': 3.3139, 'learning_rate': 1.372361823798185e-08, 'epoch': 2.98}
Step 1679: {'loss': 3.6114, 'learning_rate': 1.0507201541698486e-08, 'epoch': 2.98}
Step 1680: {'loss': 3.4001, 'learning_rate': 7.719612509182738e-09, 'epoch': 2.99}
Step 1681: {'loss': 3.3406, 'learning_rate': 5.3608630956158975e-09, 'epoch': 2.99}
Step 1682: {'loss': 3.5364, 'learning_rate': 3.4309634170504036e-09, 'epoch': 2.99}
Step 1683: {'loss': 3.5041, 'learning_rate': 1.929921750287722e-09, 'epoch': 2.99}
Step 1684: {'loss': 3.6775, 'learning_rate': 8.577445328894485e-10, 'epoch': 2.99}
Step 1685: {'loss': 3.3679, 'learning_rate': 2.1443636313289718e-10, 'epoch': 3.0}
Step 1686: {'loss': 3.6244, 'learning_rate': 0.0, 'epoch': 3.0}
Step 1686: {'train_runtime': 1772.0073, 'train_samples_per_second': 15.237, 'train_steps_per_second': 0.951, 'total_flos': 0.0, 'train_loss': 4.436398256857341, 'epoch': 3.0}
