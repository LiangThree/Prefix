Step 1: {'loss': 10.3044, 'learning_rate': 1.183431952662722e-06, 'epoch': 0.0}
Step 2: {'loss': 9.3833, 'learning_rate': 2.366863905325444e-06, 'epoch': 0.0}
Step 3: {'loss': 8.6742, 'learning_rate': 3.550295857988166e-06, 'epoch': 0.01}
Step 4: {'loss': 9.1808, 'learning_rate': 4.733727810650888e-06, 'epoch': 0.01}
Step 5: {'loss': 8.3446, 'learning_rate': 5.917159763313609e-06, 'epoch': 0.01}
Step 6: {'loss': 8.608, 'learning_rate': 7.100591715976332e-06, 'epoch': 0.01}
Step 7: {'loss': 9.5874, 'learning_rate': 8.284023668639054e-06, 'epoch': 0.01}
Step 8: {'loss': 9.0237, 'learning_rate': 9.467455621301776e-06, 'epoch': 0.01}
Step 9: {'loss': 10.5133, 'learning_rate': 1.0650887573964498e-05, 'epoch': 0.02}
Step 10: {'loss': 9.619, 'learning_rate': 1.1834319526627219e-05, 'epoch': 0.02}
Step 11: {'loss': 8.8418, 'learning_rate': 1.3017751479289941e-05, 'epoch': 0.02}
Step 12: {'loss': 10.8993, 'learning_rate': 1.4201183431952663e-05, 'epoch': 0.02}
Step 13: {'loss': 8.9153, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.02}
Step 14: {'loss': 9.5402, 'learning_rate': 1.6568047337278108e-05, 'epoch': 0.02}
Step 15: {'loss': 9.037, 'learning_rate': 1.7751479289940828e-05, 'epoch': 0.03}
Step 16: {'loss': 8.8768, 'learning_rate': 1.8934911242603552e-05, 'epoch': 0.03}
Step 17: {'loss': 9.3038, 'learning_rate': 2.0118343195266273e-05, 'epoch': 0.03}
Step 18: {'loss': 9.5551, 'learning_rate': 2.1301775147928997e-05, 'epoch': 0.03}
Step 19: {'loss': 9.1847, 'learning_rate': 2.2485207100591717e-05, 'epoch': 0.03}
Step 20: {'loss': 9.5199, 'learning_rate': 2.3668639053254438e-05, 'epoch': 0.04}
Step 21: {'loss': 9.8312, 'learning_rate': 2.485207100591716e-05, 'epoch': 0.04}
Step 22: {'loss': 8.9364, 'learning_rate': 2.6035502958579882e-05, 'epoch': 0.04}
Step 23: {'loss': 9.37, 'learning_rate': 2.7218934911242606e-05, 'epoch': 0.04}
Step 24: {'loss': 8.7096, 'learning_rate': 2.8402366863905327e-05, 'epoch': 0.04}
Step 25: {'loss': 10.0006, 'learning_rate': 2.958579881656805e-05, 'epoch': 0.04}
Step 26: {'loss': 8.598, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.05}
Step 27: {'loss': 9.1276, 'learning_rate': 3.195266272189349e-05, 'epoch': 0.05}
Step 28: {'loss': 9.2706, 'learning_rate': 3.3136094674556215e-05, 'epoch': 0.05}
Step 29: {'loss': 8.6951, 'learning_rate': 3.431952662721893e-05, 'epoch': 0.05}
Step 30: {'loss': 9.6251, 'learning_rate': 3.5502958579881656e-05, 'epoch': 0.05}
Step 31: {'loss': 9.4115, 'learning_rate': 3.668639053254438e-05, 'epoch': 0.06}
Step 32: {'loss': 9.584, 'learning_rate': 3.7869822485207104e-05, 'epoch': 0.06}
Step 33: {'loss': 8.7502, 'learning_rate': 3.905325443786982e-05, 'epoch': 0.06}
Step 34: {'loss': 8.6145, 'learning_rate': 4.0236686390532545e-05, 'epoch': 0.06}
Step 35: {'loss': 9.1543, 'learning_rate': 4.142011834319527e-05, 'epoch': 0.06}
Step 36: {'loss': 9.9214, 'learning_rate': 4.260355029585799e-05, 'epoch': 0.06}
Step 37: {'loss': 9.3989, 'learning_rate': 4.378698224852072e-05, 'epoch': 0.07}
Step 38: {'loss': 8.4353, 'learning_rate': 4.4970414201183434e-05, 'epoch': 0.07}
Step 39: {'loss': 8.9346, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.07}
Step 40: {'loss': 10.5082, 'learning_rate': 4.7337278106508875e-05, 'epoch': 0.07}
Step 41: {'loss': 8.944, 'learning_rate': 4.85207100591716e-05, 'epoch': 0.07}
Step 42: {'loss': 9.9865, 'learning_rate': 4.970414201183432e-05, 'epoch': 0.07}
Step 43: {'loss': 8.732, 'learning_rate': 5.088757396449705e-05, 'epoch': 0.08}
Step 44: {'loss': 8.8566, 'learning_rate': 5.2071005917159764e-05, 'epoch': 0.08}
Step 45: {'loss': 9.1744, 'learning_rate': 5.3254437869822495e-05, 'epoch': 0.08}
Step 46: {'loss': 9.1521, 'learning_rate': 5.443786982248521e-05, 'epoch': 0.08}
Step 47: {'loss': 10.1986, 'learning_rate': 5.562130177514793e-05, 'epoch': 0.08}
Step 48: {'loss': 8.5871, 'learning_rate': 5.680473372781065e-05, 'epoch': 0.09}
Step 49: {'loss': 9.0059, 'learning_rate': 5.798816568047337e-05, 'epoch': 0.09}
Step 50: {'loss': 10.0001, 'learning_rate': 5.91715976331361e-05, 'epoch': 0.09}
Step 51: {'loss': 9.3429, 'learning_rate': 6.035502958579882e-05, 'epoch': 0.09}
Step 52: {'loss': 8.8366, 'learning_rate': 6.153846153846155e-05, 'epoch': 0.09}
Step 53: {'loss': 9.1669, 'learning_rate': 6.272189349112427e-05, 'epoch': 0.09}
Step 54: {'loss': 9.3985, 'learning_rate': 6.390532544378698e-05, 'epoch': 0.1}
Step 55: {'loss': 8.3779, 'learning_rate': 6.50887573964497e-05, 'epoch': 0.1}
Step 56: {'loss': 9.3788, 'learning_rate': 6.627218934911243e-05, 'epoch': 0.1}
Step 57: {'loss': 9.9066, 'learning_rate': 6.745562130177515e-05, 'epoch': 0.1}
Step 58: {'loss': 8.7615, 'learning_rate': 6.863905325443787e-05, 'epoch': 0.1}
Step 59: {'loss': 8.8793, 'learning_rate': 6.98224852071006e-05, 'epoch': 0.1}
Step 60: {'loss': 8.7555, 'learning_rate': 7.100591715976331e-05, 'epoch': 0.11}
Step 61: {'loss': 9.6185, 'learning_rate': 7.218934911242604e-05, 'epoch': 0.11}
Step 62: {'loss': 9.5037, 'learning_rate': 7.337278106508876e-05, 'epoch': 0.11}
Step 63: {'loss': 8.7977, 'learning_rate': 7.455621301775149e-05, 'epoch': 0.11}
Step 64: {'loss': 8.2634, 'learning_rate': 7.573964497041421e-05, 'epoch': 0.11}
Step 65: {'loss': 10.0659, 'learning_rate': 7.692307692307693e-05, 'epoch': 0.12}
Step 66: {'loss': 8.5575, 'learning_rate': 7.810650887573964e-05, 'epoch': 0.12}
Step 67: {'loss': 8.5601, 'learning_rate': 7.928994082840237e-05, 'epoch': 0.12}
Step 68: {'loss': 9.0293, 'learning_rate': 8.047337278106509e-05, 'epoch': 0.12}
Step 69: {'loss': 9.1044, 'learning_rate': 8.165680473372781e-05, 'epoch': 0.12}
Step 70: {'loss': 9.1306, 'learning_rate': 8.284023668639054e-05, 'epoch': 0.12}
Step 71: {'loss': 8.6829, 'learning_rate': 8.402366863905326e-05, 'epoch': 0.13}
Step 72: {'loss': 8.9821, 'learning_rate': 8.520710059171599e-05, 'epoch': 0.13}
Step 73: {'loss': 7.98, 'learning_rate': 8.63905325443787e-05, 'epoch': 0.13}
Step 74: {'loss': 9.3073, 'learning_rate': 8.757396449704143e-05, 'epoch': 0.13}
Step 75: {'loss': 10.0822, 'learning_rate': 8.875739644970414e-05, 'epoch': 0.13}
Step 76: {'loss': 9.1847, 'learning_rate': 8.994082840236687e-05, 'epoch': 0.14}
Step 77: {'loss': 9.2143, 'learning_rate': 9.112426035502959e-05, 'epoch': 0.14}
Step 78: {'loss': 8.4871, 'learning_rate': 9.230769230769232e-05, 'epoch': 0.14}
Step 79: {'loss': 9.246, 'learning_rate': 9.349112426035503e-05, 'epoch': 0.14}
Step 80: {'loss': 8.6084, 'learning_rate': 9.467455621301775e-05, 'epoch': 0.14}
Step 81: {'loss': 8.4185, 'learning_rate': 9.585798816568048e-05, 'epoch': 0.14}
Step 82: {'loss': 8.821, 'learning_rate': 9.70414201183432e-05, 'epoch': 0.15}
Step 83: {'loss': 7.8744, 'learning_rate': 9.822485207100593e-05, 'epoch': 0.15}
Step 84: {'loss': 8.5588, 'learning_rate': 9.940828402366865e-05, 'epoch': 0.15}
Step 85: {'loss': 8.2513, 'learning_rate': 0.00010059171597633136, 'epoch': 0.15}
Step 86: {'loss': 7.0557, 'learning_rate': 0.0001017751479289941, 'epoch': 0.15}
Step 87: {'loss': 9.4132, 'learning_rate': 0.0001029585798816568, 'epoch': 0.15}
Step 88: {'loss': 8.3421, 'learning_rate': 0.00010414201183431953, 'epoch': 0.16}
Step 89: {'loss': 8.3277, 'learning_rate': 0.00010532544378698226, 'epoch': 0.16}
Step 90: {'loss': 8.2719, 'learning_rate': 0.00010650887573964499, 'epoch': 0.16}
Step 91: {'loss': 8.4431, 'learning_rate': 0.0001076923076923077, 'epoch': 0.16}
Step 92: {'loss': 7.7377, 'learning_rate': 0.00010887573964497042, 'epoch': 0.16}
Step 93: {'loss': 8.2941, 'learning_rate': 0.00011005917159763315, 'epoch': 0.17}
Step 94: {'loss': 8.484, 'learning_rate': 0.00011124260355029586, 'epoch': 0.17}
Step 95: {'loss': 7.527, 'learning_rate': 0.00011242603550295858, 'epoch': 0.17}
Step 96: {'loss': 8.4748, 'learning_rate': 0.0001136094674556213, 'epoch': 0.17}
Step 97: {'loss': 9.1666, 'learning_rate': 0.00011479289940828404, 'epoch': 0.17}
Step 98: {'loss': 8.9736, 'learning_rate': 0.00011597633136094674, 'epoch': 0.17}
Step 99: {'loss': 7.9255, 'learning_rate': 0.00011715976331360947, 'epoch': 0.18}
Step 100: {'loss': 9.7185, 'learning_rate': 0.0001183431952662722, 'epoch': 0.18}
Step 101: {'loss': 8.5687, 'learning_rate': 0.00011952662721893493, 'epoch': 0.18}
Step 102: {'loss': 9.3998, 'learning_rate': 0.00012071005917159764, 'epoch': 0.18}
Step 103: {'loss': 8.7318, 'learning_rate': 0.00012189349112426037, 'epoch': 0.18}
Step 104: {'loss': 8.0571, 'learning_rate': 0.0001230769230769231, 'epoch': 0.18}
Step 105: {'loss': 7.8614, 'learning_rate': 0.0001242603550295858, 'epoch': 0.19}
Step 106: {'loss': 8.5538, 'learning_rate': 0.00012544378698224853, 'epoch': 0.19}
Step 107: {'loss': 8.2126, 'learning_rate': 0.00012662721893491125, 'epoch': 0.19}
Step 108: {'loss': 9.1467, 'learning_rate': 0.00012781065088757397, 'epoch': 0.19}
Step 109: {'loss': 7.1385, 'learning_rate': 0.00012899408284023668, 'epoch': 0.19}
Step 110: {'loss': 8.2389, 'learning_rate': 0.0001301775147928994, 'epoch': 0.2}
Step 111: {'loss': 7.926, 'learning_rate': 0.00013136094674556214, 'epoch': 0.2}
Step 112: {'loss': 8.217, 'learning_rate': 0.00013254437869822486, 'epoch': 0.2}
Step 113: {'loss': 8.6718, 'learning_rate': 0.00013372781065088758, 'epoch': 0.2}
Step 114: {'loss': 8.2606, 'learning_rate': 0.0001349112426035503, 'epoch': 0.2}
Step 115: {'loss': 7.6511, 'learning_rate': 0.00013609467455621304, 'epoch': 0.2}
Step 116: {'loss': 8.2626, 'learning_rate': 0.00013727810650887573, 'epoch': 0.21}
Step 117: {'loss': 8.3336, 'learning_rate': 0.00013846153846153847, 'epoch': 0.21}
Step 118: {'loss': 7.9296, 'learning_rate': 0.0001396449704142012, 'epoch': 0.21}
Step 119: {'loss': 7.9761, 'learning_rate': 0.0001408284023668639, 'epoch': 0.21}
Step 120: {'loss': 7.211, 'learning_rate': 0.00014201183431952663, 'epoch': 0.21}
Step 121: {'loss': 8.3596, 'learning_rate': 0.00014319526627218934, 'epoch': 0.22}
Step 122: {'loss': 8.447, 'learning_rate': 0.0001443786982248521, 'epoch': 0.22}
Step 123: {'loss': 9.5917, 'learning_rate': 0.0001455621301775148, 'epoch': 0.22}
Step 124: {'loss': 7.568, 'learning_rate': 0.00014674556213017752, 'epoch': 0.22}
Step 125: {'loss': 8.7211, 'learning_rate': 0.00014792899408284024, 'epoch': 0.22}
Step 126: {'loss': 8.1539, 'learning_rate': 0.00014911242603550298, 'epoch': 0.22}
Step 127: {'loss': 8.953, 'learning_rate': 0.00015029585798816567, 'epoch': 0.23}
Step 128: {'loss': 7.7419, 'learning_rate': 0.00015147928994082842, 'epoch': 0.23}
Step 129: {'loss': 7.4271, 'learning_rate': 0.00015266272189349113, 'epoch': 0.23}
Step 130: {'loss': 8.1009, 'learning_rate': 0.00015384615384615385, 'epoch': 0.23}
Step 131: {'loss': 7.7193, 'learning_rate': 0.00015502958579881657, 'epoch': 0.23}
Step 132: {'loss': 7.6923, 'learning_rate': 0.00015621301775147929, 'epoch': 0.23}
Step 133: {'loss': 7.7429, 'learning_rate': 0.00015739644970414203, 'epoch': 0.24}
Step 134: {'loss': 7.7375, 'learning_rate': 0.00015857988165680475, 'epoch': 0.24}
Step 135: {'loss': 7.9647, 'learning_rate': 0.00015976331360946746, 'epoch': 0.24}
Step 136: {'loss': 7.8107, 'learning_rate': 0.00016094674556213018, 'epoch': 0.24}
Step 137: {'loss': 8.7501, 'learning_rate': 0.00016213017751479293, 'epoch': 0.24}
Step 138: {'loss': 8.1103, 'learning_rate': 0.00016331360946745562, 'epoch': 0.25}
Step 139: {'loss': 7.544, 'learning_rate': 0.00016449704142011836, 'epoch': 0.25}
Step 140: {'loss': 8.103, 'learning_rate': 0.00016568047337278108, 'epoch': 0.25}
Step 141: {'loss': 7.5597, 'learning_rate': 0.0001668639053254438, 'epoch': 0.25}
Step 142: {'loss': 8.4272, 'learning_rate': 0.0001680473372781065, 'epoch': 0.25}
Step 143: {'loss': 7.4439, 'learning_rate': 0.00016923076923076923, 'epoch': 0.25}
Step 144: {'loss': 8.2574, 'learning_rate': 0.00017041420118343197, 'epoch': 0.26}
Step 145: {'loss': 7.8931, 'learning_rate': 0.0001715976331360947, 'epoch': 0.26}
Step 146: {'loss': 7.6615, 'learning_rate': 0.0001727810650887574, 'epoch': 0.26}
Step 147: {'loss': 7.5278, 'learning_rate': 0.00017396449704142012, 'epoch': 0.26}
Step 148: {'loss': 8.1971, 'learning_rate': 0.00017514792899408287, 'epoch': 0.26}
Step 149: {'loss': 8.2517, 'learning_rate': 0.00017633136094674556, 'epoch': 0.26}
Step 150: {'loss': 8.6253, 'learning_rate': 0.00017751479289940828, 'epoch': 0.27}
Step 151: {'loss': 8.5632, 'learning_rate': 0.00017869822485207102, 'epoch': 0.27}
Step 152: {'loss': 7.3956, 'learning_rate': 0.00017988165680473374, 'epoch': 0.27}
Step 153: {'loss': 8.3261, 'learning_rate': 0.00018106508875739645, 'epoch': 0.27}
Step 154: {'loss': 7.3056, 'learning_rate': 0.00018224852071005917, 'epoch': 0.27}
Step 155: {'loss': 7.0735, 'learning_rate': 0.00018343195266272192, 'epoch': 0.28}
Step 156: {'loss': 7.348, 'learning_rate': 0.00018461538461538463, 'epoch': 0.28}
Step 157: {'loss': 8.2926, 'learning_rate': 0.00018579881656804735, 'epoch': 0.28}
Step 158: {'loss': 7.9198, 'learning_rate': 0.00018698224852071007, 'epoch': 0.28}
Step 159: {'loss': 7.111, 'learning_rate': 0.00018816568047337278, 'epoch': 0.28}
Step 160: {'loss': 7.7558, 'learning_rate': 0.0001893491124260355, 'epoch': 0.28}
Step 161: {'loss': 7.585, 'learning_rate': 0.00019053254437869822, 'epoch': 0.29}
Step 162: {'loss': 8.3306, 'learning_rate': 0.00019171597633136096, 'epoch': 0.29}
Step 163: {'loss': 7.3514, 'learning_rate': 0.00019289940828402368, 'epoch': 0.29}
Step 164: {'loss': 7.8641, 'learning_rate': 0.0001940828402366864, 'epoch': 0.29}
Step 165: {'loss': 7.2408, 'learning_rate': 0.00019526627218934911, 'epoch': 0.29}
Step 166: {'loss': 7.5609, 'learning_rate': 0.00019644970414201186, 'epoch': 0.3}
Step 167: {'loss': 8.2854, 'learning_rate': 0.00019763313609467458, 'epoch': 0.3}
Step 168: {'loss': 7.7694, 'learning_rate': 0.0001988165680473373, 'epoch': 0.3}
Step 169: {'loss': 7.036, 'learning_rate': 0.0002, 'epoch': 0.3}
Step 170: {'loss': 7.8698, 'learning_rate': 0.00019999978556363687, 'epoch': 0.3}
Step 171: {'loss': 7.2939, 'learning_rate': 0.0001999991422554671, 'epoch': 0.3}
Step 172: {'loss': 6.8174, 'learning_rate': 0.00019999807007824974, 'epoch': 0.31}
Step 173: {'loss': 7.4486, 'learning_rate': 0.00019999656903658296, 'epoch': 0.31}
Step 174: {'loss': 7.6415, 'learning_rate': 0.0001999946391369044, 'epoch': 0.31}
Step 175: {'loss': 7.7893, 'learning_rate': 0.00019999228038749083, 'epoch': 0.31}
Step 176: {'loss': 7.1953, 'learning_rate': 0.00019998949279845832, 'epoch': 0.31}
Step 177: {'loss': 7.0171, 'learning_rate': 0.00019998627638176202, 'epoch': 0.31}
Step 178: {'loss': 7.3541, 'learning_rate': 0.00019998263115119633, 'epoch': 0.32}
Step 179: {'loss': 6.9537, 'learning_rate': 0.00019997855712239462, 'epoch': 0.32}
Step 180: {'loss': 7.8531, 'learning_rate': 0.00019997405431282928, 'epoch': 0.32}
Step 181: {'loss': 7.0205, 'learning_rate': 0.00019996912274181162, 'epoch': 0.32}
Step 182: {'loss': 7.8979, 'learning_rate': 0.0001999637624304919, 'epoch': 0.32}
Step 183: {'loss': 7.7246, 'learning_rate': 0.00019995797340185888, 'epoch': 0.33}
Step 184: {'loss': 7.4498, 'learning_rate': 0.00019995175568074026, 'epoch': 0.33}
Step 185: {'loss': 7.2172, 'learning_rate': 0.00019994510929380205, 'epoch': 0.33}
Step 186: {'loss': 6.5552, 'learning_rate': 0.00019993803426954885, 'epoch': 0.33}
Step 187: {'loss': 7.3222, 'learning_rate': 0.00019993053063832347, 'epoch': 0.33}
Step 188: {'loss': 7.1322, 'learning_rate': 0.000199922598432307, 'epoch': 0.33}
Step 189: {'loss': 7.719, 'learning_rate': 0.00019991423768551844, 'epoch': 0.34}
Step 190: {'loss': 7.6139, 'learning_rate': 0.0001999054484338148, 'epoch': 0.34}
Step 191: {'loss': 6.3957, 'learning_rate': 0.00019989623071489074, 'epoch': 0.34}
Step 192: {'loss': 6.8611, 'learning_rate': 0.0001998865845682786, 'epoch': 0.34}
Step 193: {'loss': 7.3963, 'learning_rate': 0.00019987651003534803, 'epoch': 0.34}
Step 194: {'loss': 6.9997, 'learning_rate': 0.00019986600715930596, 'epoch': 0.34}
Step 195: {'loss': 7.1815, 'learning_rate': 0.00019985507598519636, 'epoch': 0.35}
Step 196: {'loss': 7.9307, 'learning_rate': 0.00019984371655990007, 'epoch': 0.35}
Step 197: {'loss': 7.6261, 'learning_rate': 0.00019983192893213453, 'epoch': 0.35}
Step 198: {'loss': 7.0992, 'learning_rate': 0.0001998197131524537, 'epoch': 0.35}
Step 199: {'loss': 7.3424, 'learning_rate': 0.00019980706927324776, 'epoch': 0.35}
Step 200: {'loss': 6.8171, 'learning_rate': 0.00019979399734874274, 'epoch': 0.36}
Step 201: {'loss': 6.61, 'learning_rate': 0.00019978049743500068, 'epoch': 0.36}
Step 202: {'loss': 7.5795, 'learning_rate': 0.00019976656958991894, 'epoch': 0.36}
Step 203: {'loss': 6.7527, 'learning_rate': 0.00019975221387323033, 'epoch': 0.36}
Step 204: {'loss': 7.2139, 'learning_rate': 0.00019973743034650254, 'epoch': 0.36}
Step 205: {'loss': 6.7091, 'learning_rate': 0.00019972221907313813, 'epoch': 0.36}
Step 206: {'loss': 7.5821, 'learning_rate': 0.00019970658011837404, 'epoch': 0.37}
Step 207: {'loss': 7.2943, 'learning_rate': 0.00019969051354928156, 'epoch': 0.37}
Step 208: {'loss': 6.4873, 'learning_rate': 0.00019967401943476575, 'epoch': 0.37}
Step 209: {'loss': 6.9196, 'learning_rate': 0.00019965709784556545, 'epoch': 0.37}
Step 210: {'loss': 7.3611, 'learning_rate': 0.00019963974885425266, 'epoch': 0.37}
Step 211: {'loss': 7.2698, 'learning_rate': 0.00019962197253523253, 'epoch': 0.38}
Step 212: {'loss': 6.8229, 'learning_rate': 0.00019960376896474279, 'epoch': 0.38}
Step 213: {'loss': 7.2052, 'learning_rate': 0.00019958513822085363, 'epoch': 0.38}
Step 214: {'loss': 6.7817, 'learning_rate': 0.00019956608038346722, 'epoch': 0.38}
Step 215: {'loss': 6.5575, 'learning_rate': 0.00019954659553431743, 'epoch': 0.38}
Step 216: {'loss': 6.1756, 'learning_rate': 0.00019952668375696945, 'epoch': 0.38}
Step 217: {'loss': 7.0215, 'learning_rate': 0.00019950634513681944, 'epoch': 0.39}
Step 218: {'loss': 7.2178, 'learning_rate': 0.0001994855797610943, 'epoch': 0.39}
Step 219: {'loss': 5.9187, 'learning_rate': 0.00019946438771885095, 'epoch': 0.39}
Step 220: {'loss': 6.5899, 'learning_rate': 0.0001994427691009763, 'epoch': 0.39}
Step 221: {'loss': 6.8246, 'learning_rate': 0.00019942072400018675, 'epoch': 0.39}
Step 222: {'loss': 6.7759, 'learning_rate': 0.00019939825251102765, 'epoch': 0.39}
Step 223: {'loss': 7.0496, 'learning_rate': 0.0001993753547298732, 'epoch': 0.4}
Step 224: {'loss': 6.3737, 'learning_rate': 0.00019935203075492565, 'epoch': 0.4}
Step 225: {'loss': 6.2425, 'learning_rate': 0.0001993282806862152, 'epoch': 0.4}
Step 226: {'loss': 6.8949, 'learning_rate': 0.00019930410462559942, 'epoch': 0.4}
Step 227: {'loss': 6.6555, 'learning_rate': 0.00019927950267676278, 'epoch': 0.4}
Step 228: {'loss': 7.3547, 'learning_rate': 0.00019925447494521643, 'epoch': 0.41}
Step 229: {'loss': 6.4949, 'learning_rate': 0.00019922902153829742, 'epoch': 0.41}
Step 230: {'loss': 6.0095, 'learning_rate': 0.00019920314256516845, 'epoch': 0.41}
Step 231: {'loss': 6.1983, 'learning_rate': 0.00019917683813681746, 'epoch': 0.41}
Step 232: {'loss': 6.4792, 'learning_rate': 0.0001991501083660569, 'epoch': 0.41}
Step 233: {'loss': 6.0857, 'learning_rate': 0.0001991229533675235, 'epoch': 0.41}
Step 234: {'loss': 5.9806, 'learning_rate': 0.0001990953732576776, 'epoch': 0.42}
Step 235: {'loss': 6.199, 'learning_rate': 0.0001990673681548028, 'epoch': 0.42}
Step 236: {'loss': 6.3524, 'learning_rate': 0.00019903893817900536, 'epoch': 0.42}
Step 237: {'loss': 6.2199, 'learning_rate': 0.00019901008345221368, 'epoch': 0.42}
Step 238: {'loss': 6.7644, 'learning_rate': 0.00019898080409817782, 'epoch': 0.42}
Step 239: {'loss': 6.9553, 'learning_rate': 0.00019895110024246892, 'epoch': 0.42}
Step 240: {'loss': 6.3816, 'learning_rate': 0.00019892097201247873, 'epoch': 0.43}
Step 241: {'loss': 5.8287, 'learning_rate': 0.00019889041953741903, 'epoch': 0.43}
Step 242: {'loss': 5.911, 'learning_rate': 0.00019885944294832102, 'epoch': 0.43}
Step 243: {'loss': 7.0144, 'learning_rate': 0.00019882804237803488, 'epoch': 0.43}
Step 244: {'loss': 6.5267, 'learning_rate': 0.00019879621796122906, 'epoch': 0.43}
Step 245: {'loss': 6.5553, 'learning_rate': 0.0001987639698343898, 'epoch': 0.44}
Step 246: {'loss': 6.0236, 'learning_rate': 0.00019873129813582053, 'epoch': 0.44}
Step 247: {'loss': 6.189, 'learning_rate': 0.00019869820300564127, 'epoch': 0.44}
Step 248: {'loss': 6.5136, 'learning_rate': 0.00019866468458578797, 'epoch': 0.44}
Step 249: {'loss': 6.4325, 'learning_rate': 0.00019863074302001207, 'epoch': 0.44}
Step 250: {'loss': 6.2855, 'learning_rate': 0.0001985963784538796, 'epoch': 0.44}
Step 251: {'loss': 5.8573, 'learning_rate': 0.00019856159103477086, 'epoch': 0.45}
Step 252: {'loss': 7.0138, 'learning_rate': 0.0001985263809118796, 'epoch': 0.45}
Step 253: {'loss': 5.9065, 'learning_rate': 0.0001984907482362124, 'epoch': 0.45}
Step 254: {'loss': 5.8818, 'learning_rate': 0.0001984546931605881, 'epoch': 0.45}
Step 255: {'loss': 6.1298, 'learning_rate': 0.00019841821583963713, 'epoch': 0.45}
Step 256: {'loss': 6.2272, 'learning_rate': 0.00019838131642980073, 'epoch': 0.46}
Step 257: {'loss': 5.7804, 'learning_rate': 0.0001983439950893304, 'epoch': 0.46}
Step 258: {'loss': 6.2226, 'learning_rate': 0.00019830625197828723, 'epoch': 0.46}
Step 259: {'loss': 5.801, 'learning_rate': 0.00019826808725854106, 'epoch': 0.46}
Step 260: {'loss': 5.9586, 'learning_rate': 0.00019822950109377004, 'epoch': 0.46}
Step 261: {'loss': 6.1659, 'learning_rate': 0.0001981904936494597, 'epoch': 0.46}
Step 262: {'loss': 6.7495, 'learning_rate': 0.00019815106509290224, 'epoch': 0.47}
Step 263: {'loss': 5.9614, 'learning_rate': 0.00019811121559319607, 'epoch': 0.47}
Step 264: {'loss': 6.0915, 'learning_rate': 0.00019807094532124482, 'epoch': 0.47}
Step 265: {'loss': 6.2082, 'learning_rate': 0.00019803025444975667, 'epoch': 0.47}
Step 266: {'loss': 6.4302, 'learning_rate': 0.00019798914315324369, 'epoch': 0.47}
Step 267: {'loss': 6.3448, 'learning_rate': 0.00019794761160802103, 'epoch': 0.47}
Step 268: {'loss': 5.791, 'learning_rate': 0.00019790565999220613, 'epoch': 0.48}
Step 269: {'loss': 5.677, 'learning_rate': 0.00019786328848571806, 'epoch': 0.48}
Step 270: {'loss': 6.0089, 'learning_rate': 0.00019782049727027663, 'epoch': 0.48}
Step 271: {'loss': 6.1804, 'learning_rate': 0.00019777728652940171, 'epoch': 0.48}
Step 272: {'loss': 6.1865, 'learning_rate': 0.00019773365644841238, 'epoch': 0.48}
Step 273: {'loss': 5.8275, 'learning_rate': 0.00019768960721442614, 'epoch': 0.49}
Step 274: {'loss': 5.4942, 'learning_rate': 0.00019764513901635814, 'epoch': 0.49}
Step 275: {'loss': 6.2477, 'learning_rate': 0.00019760025204492037, 'epoch': 0.49}
Step 276: {'loss': 6.1895, 'learning_rate': 0.00019755494649262084, 'epoch': 0.49}
Step 277: {'loss': 5.649, 'learning_rate': 0.00019750922255376262, 'epoch': 0.49}
Step 278: {'loss': 6.3161, 'learning_rate': 0.00019746308042444327, 'epoch': 0.49}
Step 279: {'loss': 5.8545, 'learning_rate': 0.00019741652030255384, 'epoch': 0.5}
Step 280: {'loss': 5.845, 'learning_rate': 0.00019736954238777792, 'epoch': 0.5}
Step 281: {'loss': 5.8219, 'learning_rate': 0.00019732214688159098, 'epoch': 0.5}
Step 282: {'loss': 6.0313, 'learning_rate': 0.00019727433398725947, 'epoch': 0.5}
Step 283: {'loss': 5.9196, 'learning_rate': 0.00019722610390983982, 'epoch': 0.5}
Step 284: {'loss': 5.3972, 'learning_rate': 0.00019717745685617768, 'epoch': 0.5}
Step 285: {'loss': 5.6595, 'learning_rate': 0.000197128393034907, 'epoch': 0.51}
Step 286: {'loss': 6.1013, 'learning_rate': 0.00019707891265644908, 'epoch': 0.51}
Step 287: {'loss': 5.7811, 'learning_rate': 0.0001970290159330119, 'epoch': 0.51}
Step 288: {'loss': 5.5285, 'learning_rate': 0.00019697870307858875, 'epoch': 0.51}
Step 289: {'loss': 6.1667, 'learning_rate': 0.0001969279743089578, 'epoch': 0.51}
Step 290: {'loss': 6.0872, 'learning_rate': 0.00019687682984168093, 'epoch': 0.52}
Step 291: {'loss': 5.8135, 'learning_rate': 0.00019682526989610278, 'epoch': 0.52}
Step 292: {'loss': 5.947, 'learning_rate': 0.0001967732946933499, 'epoch': 0.52}
Step 293: {'loss': 4.9507, 'learning_rate': 0.00019672090445632976, 'epoch': 0.52}
Step 294: {'loss': 5.363, 'learning_rate': 0.00019666809940972982, 'epoch': 0.52}
Step 295: {'loss': 5.8646, 'learning_rate': 0.00019661487978001648, 'epoch': 0.52}
Step 296: {'loss': 5.7623, 'learning_rate': 0.00019656124579543426, 'epoch': 0.53}
Step 297: {'loss': 5.3849, 'learning_rate': 0.00019650719768600467, 'epoch': 0.53}
Step 298: {'loss': 6.2078, 'learning_rate': 0.00019645273568352528, 'epoch': 0.53}
Step 299: {'loss': 5.7571, 'learning_rate': 0.00019639786002156884, 'epoch': 0.53}
Step 300: {'loss': 6.0429, 'learning_rate': 0.00019634257093548206, 'epoch': 0.53}
Step 301: {'loss': 5.677, 'learning_rate': 0.0001962868686623847, 'epoch': 0.54}
Step 302: {'loss': 5.6171, 'learning_rate': 0.0001962307534411687, 'epoch': 0.54}
Step 303: {'loss': 5.2944, 'learning_rate': 0.00019617422551249688, 'epoch': 0.54}
Step 304: {'loss': 5.485, 'learning_rate': 0.00019611728511880218, 'epoch': 0.54}
Step 305: {'loss': 5.1123, 'learning_rate': 0.00019605993250428633, 'epoch': 0.54}
Step 306: {'loss': 5.2513, 'learning_rate': 0.0001960021679149191, 'epoch': 0.54}
Step 307: {'loss': 5.1524, 'learning_rate': 0.00019594399159843703, 'epoch': 0.55}
Step 308: {'loss': 5.5873, 'learning_rate': 0.00019588540380434253, 'epoch': 0.55}
Step 309: {'loss': 5.4495, 'learning_rate': 0.00019582640478390262, 'epoch': 0.55}
Step 310: {'loss': 5.0752, 'learning_rate': 0.000195766994790148, 'epoch': 0.55}
Step 311: {'loss': 5.2321, 'learning_rate': 0.00019570717407787198, 'epoch': 0.55}
Step 312: {'loss': 4.9815, 'learning_rate': 0.00019564694290362926, 'epoch': 0.55}
Step 313: {'loss': 5.2922, 'learning_rate': 0.0001955863015257349, 'epoch': 0.56}
Step 314: {'loss': 5.4717, 'learning_rate': 0.00019552525020426323, 'epoch': 0.56}
Step 315: {'loss': 5.4124, 'learning_rate': 0.00019546378920104674, 'epoch': 0.56}
Step 316: {'loss': 5.6992, 'learning_rate': 0.00019540191877967492, 'epoch': 0.56}
Step 317: {'loss': 6.294, 'learning_rate': 0.00019533963920549306, 'epoch': 0.56}
Step 318: {'loss': 5.5809, 'learning_rate': 0.00019527695074560134, 'epoch': 0.57}
Step 319: {'loss': 4.682, 'learning_rate': 0.00019521385366885348, 'epoch': 0.57}
Step 320: {'loss': 5.7429, 'learning_rate': 0.00019515034824585557, 'epoch': 0.57}
Step 321: {'loss': 4.8835, 'learning_rate': 0.00019508643474896507, 'epoch': 0.57}
Step 322: {'loss': 4.7424, 'learning_rate': 0.00019502211345228955, 'epoch': 0.57}
Step 323: {'loss': 5.4035, 'learning_rate': 0.00019495738463168552, 'epoch': 0.57}
Step 324: {'loss': 5.5243, 'learning_rate': 0.00019489224856475721, 'epoch': 0.58}
Step 325: {'loss': 4.8418, 'learning_rate': 0.00019482670553085547, 'epoch': 0.58}
Step 326: {'loss': 5.5079, 'learning_rate': 0.00019476075581107644, 'epoch': 0.58}
Step 327: {'loss': 5.0662, 'learning_rate': 0.00019469439968826057, 'epoch': 0.58}
Step 328: {'loss': 4.6958, 'learning_rate': 0.00019462763744699114, 'epoch': 0.58}
Step 329: {'loss': 4.8214, 'learning_rate': 0.00019456046937359314, 'epoch': 0.58}
Step 330: {'loss': 5.1846, 'learning_rate': 0.00019449289575613219, 'epoch': 0.59}
Step 331: {'loss': 5.0343, 'learning_rate': 0.00019442491688441305, 'epoch': 0.59}
Step 332: {'loss': 5.3971, 'learning_rate': 0.00019435653304997858, 'epoch': 0.59}
Step 333: {'loss': 4.893, 'learning_rate': 0.00019428774454610843, 'epoch': 0.59}
Step 334: {'loss': 5.2692, 'learning_rate': 0.00019421855166781767, 'epoch': 0.59}
Step 335: {'loss': 4.3355, 'learning_rate': 0.00019414895471185574, 'epoch': 0.6}
Step 336: {'loss': 4.5548, 'learning_rate': 0.00019407895397670499, 'epoch': 0.6}
Step 337: {'loss': 4.825, 'learning_rate': 0.00019400854976257944, 'epoch': 0.6}
Step 338: {'loss': 5.2211, 'learning_rate': 0.00019393774237142362, 'epoch': 0.6}
Step 339: {'loss': 4.9997, 'learning_rate': 0.00019386653210691108, 'epoch': 0.6}
Step 340: {'loss': 4.3179, 'learning_rate': 0.00019379491927444322, 'epoch': 0.6}
Step 341: {'loss': 4.2095, 'learning_rate': 0.000193722904181148, 'epoch': 0.61}
Step 342: {'loss': 5.0262, 'learning_rate': 0.00019365048713587842, 'epoch': 0.61}
Step 343: {'loss': 4.211, 'learning_rate': 0.00019357766844921152, 'epoch': 0.61}
Step 344: {'loss': 4.7545, 'learning_rate': 0.00019350444843344678, 'epoch': 0.61}
Step 345: {'loss': 4.3864, 'learning_rate': 0.00019343082740260484, 'epoch': 0.61}
Step 346: {'loss': 4.5294, 'learning_rate': 0.0001933568056724262, 'epoch': 0.62}
Step 347: {'loss': 5.0066, 'learning_rate': 0.00019328238356036993, 'epoch': 0.62}
Step 348: {'loss': 4.436, 'learning_rate': 0.00019320756138561219, 'epoch': 0.62}
Step 349: {'loss': 4.4864, 'learning_rate': 0.0001931323394690448, 'epoch': 0.62}
Step 350: {'loss': 4.3272, 'learning_rate': 0.00019305671813327408, 'epoch': 0.62}
Step 351: {'loss': 4.2809, 'learning_rate': 0.00019298069770261935, 'epoch': 0.62}
Step 352: {'loss': 5.0178, 'learning_rate': 0.00019290427850311148, 'epoch': 0.63}
Step 353: {'loss': 4.563, 'learning_rate': 0.00019282746086249155, 'epoch': 0.63}
Step 354: {'loss': 4.2151, 'learning_rate': 0.0001927502451102095, 'epoch': 0.63}
Step 355: {'loss': 5.0121, 'learning_rate': 0.0001926726315774226, 'epoch': 0.63}
Step 356: {'loss': 4.5194, 'learning_rate': 0.00019259462059699413, 'epoch': 0.63}
Step 357: {'loss': 4.8498, 'learning_rate': 0.00019251621250349196, 'epoch': 0.63}
Step 358: {'loss': 4.1208, 'learning_rate': 0.00019243740763318697, 'epoch': 0.64}
Step 359: {'loss': 4.8764, 'learning_rate': 0.00019235820632405176, 'epoch': 0.64}
Step 360: {'loss': 4.4394, 'learning_rate': 0.00019227860891575914, 'epoch': 0.64}
Step 361: {'loss': 4.5601, 'learning_rate': 0.0001921986157496807, 'epoch': 0.64}
Step 362: {'loss': 3.9538, 'learning_rate': 0.0001921182271688853, 'epoch': 0.64}
Step 363: {'loss': 4.5555, 'learning_rate': 0.00019203744351813765, 'epoch': 0.65}
Step 364: {'loss': 4.9775, 'learning_rate': 0.00019195626514389682, 'epoch': 0.65}
Step 365: {'loss': 4.9361, 'learning_rate': 0.00019187469239431465, 'epoch': 0.65}
Step 366: {'loss': 4.9139, 'learning_rate': 0.0001917927256192345, 'epoch': 0.65}
Step 367: {'loss': 5.1696, 'learning_rate': 0.00019171036517018944, 'epoch': 0.65}
Step 368: {'loss': 4.8085, 'learning_rate': 0.00019162761140040097, 'epoch': 0.65}
Step 369: {'loss': 4.3858, 'learning_rate': 0.0001915444646647775, 'epoch': 0.66}
Step 370: {'loss': 4.7046, 'learning_rate': 0.00019146092531991267, 'epoch': 0.66}
Step 371: {'loss': 4.9638, 'learning_rate': 0.00019137699372408391, 'epoch': 0.66}
Step 372: {'loss': 4.5062, 'learning_rate': 0.000191292670237251, 'epoch': 0.66}
Step 373: {'loss': 4.5606, 'learning_rate': 0.00019120795522105434, 'epoch': 0.66}
Step 374: {'loss': 4.6646, 'learning_rate': 0.0001911228490388136, 'epoch': 0.66}
Step 375: {'loss': 4.4358, 'learning_rate': 0.00019103735205552587, 'epoch': 0.67}
Step 376: {'loss': 4.2543, 'learning_rate': 0.00019095146463786447, 'epoch': 0.67}
Step 377: {'loss': 4.57, 'learning_rate': 0.00019086518715417708, 'epoch': 0.67}
Step 378: {'loss': 4.3728, 'learning_rate': 0.00019077851997448432, 'epoch': 0.67}
Step 379: {'loss': 4.291, 'learning_rate': 0.00019069146347047808, 'epoch': 0.67}
Step 380: {'loss': 4.1095, 'learning_rate': 0.00019060401801551994, 'epoch': 0.68}
Step 381: {'loss': 4.2739, 'learning_rate': 0.00019051618398463965, 'epoch': 0.68}
Step 382: {'loss': 4.5856, 'learning_rate': 0.00019042796175453334, 'epoch': 0.68}
Step 383: {'loss': 4.3282, 'learning_rate': 0.0001903393517035622, 'epoch': 0.68}
Step 384: {'loss': 4.3028, 'learning_rate': 0.00019025035421175047, 'epoch': 0.68}
Step 385: {'loss': 4.1879, 'learning_rate': 0.00019016096966078416, 'epoch': 0.68}
Step 386: {'loss': 4.2923, 'learning_rate': 0.00019007119843400926, 'epoch': 0.69}
Step 387: {'loss': 4.2798, 'learning_rate': 0.00018998104091642998, 'epoch': 0.69}
Step 388: {'loss': 4.4941, 'learning_rate': 0.00018989049749470747, 'epoch': 0.69}
Step 389: {'loss': 4.4451, 'learning_rate': 0.00018979956855715764, 'epoch': 0.69}
Step 390: {'loss': 4.0385, 'learning_rate': 0.00018970825449375, 'epoch': 0.69}
Step 391: {'loss': 3.9491, 'learning_rate': 0.00018961655569610557, 'epoch': 0.7}
Step 392: {'loss': 4.1939, 'learning_rate': 0.00018952447255749557, 'epoch': 0.7}
Step 393: {'loss': 4.3493, 'learning_rate': 0.0001894320054728394, 'epoch': 0.7}
Step 394: {'loss': 4.4317, 'learning_rate': 0.0001893391548387032, 'epoch': 0.7}
Step 395: {'loss': 4.2422, 'learning_rate': 0.00018924592105329805, 'epoch': 0.7}
Step 396: {'loss': 4.0912, 'learning_rate': 0.00018915230451647816, 'epoch': 0.7}
Step 397: {'loss': 4.2172, 'learning_rate': 0.00018905830562973938, 'epoch': 0.71}
Step 398: {'loss': 4.5675, 'learning_rate': 0.00018896392479621725, 'epoch': 0.71}
Step 399: {'loss': 4.2708, 'learning_rate': 0.00018886916242068545, 'epoch': 0.71}
Step 400: {'loss': 4.5282, 'learning_rate': 0.00018877401890955394, 'epoch': 0.71}
Step 401: {'loss': 3.9454, 'learning_rate': 0.00018867849467086732, 'epoch': 0.71}
Step 402: {'loss': 4.2954, 'learning_rate': 0.000188582590114303, 'epoch': 0.71}
Step 403: {'loss': 4.3649, 'learning_rate': 0.00018848630565116947, 'epoch': 0.72}
Step 404: {'loss': 4.0023, 'learning_rate': 0.00018838964169440447, 'epoch': 0.72}
Step 405: {'loss': 4.0122, 'learning_rate': 0.00018829259865857343, 'epoch': 0.72}
Step 406: {'loss': 4.3616, 'learning_rate': 0.00018819517695986738, 'epoch': 0.72}
Step 407: {'loss': 4.1033, 'learning_rate': 0.0001880973770161015, 'epoch': 0.72}
Step 408: {'loss': 4.0891, 'learning_rate': 0.00018799919924671304, 'epoch': 0.73}
Step 409: {'loss': 4.5011, 'learning_rate': 0.00018790064407275963, 'epoch': 0.73}
Step 410: {'loss': 4.1997, 'learning_rate': 0.0001878017119169176, 'epoch': 0.73}
Step 411: {'loss': 4.4122, 'learning_rate': 0.00018770240320347995, 'epoch': 0.73}
Step 412: {'loss': 4.8441, 'learning_rate': 0.0001876027183583547, 'epoch': 0.73}
Step 413: {'loss': 4.4105, 'learning_rate': 0.0001875026578090629, 'epoch': 0.73}
Step 414: {'loss': 4.1914, 'learning_rate': 0.00018740222198473697, 'epoch': 0.74}
Step 415: {'loss': 4.2163, 'learning_rate': 0.00018730141131611882, 'epoch': 0.74}
Step 416: {'loss': 4.4988, 'learning_rate': 0.00018720022623555787, 'epoch': 0.74}
Step 417: {'loss': 4.1617, 'learning_rate': 0.00018709866717700938, 'epoch': 0.74}
Step 418: {'loss': 4.2025, 'learning_rate': 0.0001869967345760324, 'epoch': 0.74}
Step 419: {'loss': 4.2055, 'learning_rate': 0.00018689442886978807, 'epoch': 0.74}
Step 420: {'loss': 4.2899, 'learning_rate': 0.00018679175049703768, 'epoch': 0.75}
Step 421: {'loss': 3.9455, 'learning_rate': 0.00018668869989814073, 'epoch': 0.75}
Step 422: {'loss': 4.0437, 'learning_rate': 0.00018658527751505316, 'epoch': 0.75}
Step 423: {'loss': 4.1052, 'learning_rate': 0.00018648148379132537, 'epoch': 0.75}
Step 424: {'loss': 4.2356, 'learning_rate': 0.00018637731917210034, 'epoch': 0.75}
Step 425: {'loss': 4.464, 'learning_rate': 0.00018627278410411163, 'epoch': 0.76}
Step 426: {'loss': 4.3396, 'learning_rate': 0.00018616787903568175, 'epoch': 0.76}
Step 427: {'loss': 4.2933, 'learning_rate': 0.00018606260441671988, 'epoch': 0.76}
Step 428: {'loss': 3.7836, 'learning_rate': 0.00018595696069872013, 'epoch': 0.76}
Step 429: {'loss': 3.7482, 'learning_rate': 0.0001858509483347596, 'epoch': 0.76}
Step 430: {'loss': 3.9834, 'learning_rate': 0.00018574456777949644, 'epoch': 0.76}
Step 431: {'loss': 3.7851, 'learning_rate': 0.0001856378194891678, 'epoch': 0.77}
Step 432: {'loss': 3.7549, 'learning_rate': 0.00018553070392158798, 'epoch': 0.77}
Step 433: {'loss': 4.1458, 'learning_rate': 0.00018542322153614646, 'epoch': 0.77}
Step 434: {'loss': 4.4613, 'learning_rate': 0.00018531537279380586, 'epoch': 0.77}
Step 435: {'loss': 4.0311, 'learning_rate': 0.00018520715815710002, 'epoch': 0.77}
Step 436: {'loss': 4.2251, 'learning_rate': 0.00018509857809013207, 'epoch': 0.78}
Step 437: {'loss': 4.1143, 'learning_rate': 0.00018498963305857218, 'epoch': 0.78}
Step 438: {'loss': 4.1097, 'learning_rate': 0.00018488032352965598, 'epoch': 0.78}
Step 439: {'loss': 4.0475, 'learning_rate': 0.00018477064997218218, 'epoch': 0.78}
Step 440: {'loss': 3.8918, 'learning_rate': 0.00018466061285651075, 'epoch': 0.78}
Step 441: {'loss': 4.003, 'learning_rate': 0.00018455021265456088, 'epoch': 0.78}
Step 442: {'loss': 3.9349, 'learning_rate': 0.00018443944983980893, 'epoch': 0.79}
Step 443: {'loss': 4.0637, 'learning_rate': 0.00018432832488728639, 'epoch': 0.79}
Step 444: {'loss': 4.6011, 'learning_rate': 0.00018421683827357793, 'epoch': 0.79}
Step 445: {'loss': 4.3725, 'learning_rate': 0.00018410499047681914, 'epoch': 0.79}
Step 446: {'loss': 4.1372, 'learning_rate': 0.00018399278197669475, 'epoch': 0.79}
Step 447: {'loss': 3.915, 'learning_rate': 0.00018388021325443647, 'epoch': 0.79}
Step 448: {'loss': 4.3517, 'learning_rate': 0.00018376728479282077, 'epoch': 0.8}
Step 449: {'loss': 4.0447, 'learning_rate': 0.00018365399707616706, 'epoch': 0.8}
Step 450: {'loss': 4.3545, 'learning_rate': 0.00018354035059033543, 'epoch': 0.8}
Step 451: {'loss': 4.3599, 'learning_rate': 0.00018342634582272472, 'epoch': 0.8}
Step 452: {'loss': 3.8335, 'learning_rate': 0.00018331198326227024, 'epoch': 0.8}
Step 453: {'loss': 4.2148, 'learning_rate': 0.00018319726339944184, 'epoch': 0.81}
Step 454: {'loss': 4.6218, 'learning_rate': 0.0001830821867262417, 'epoch': 0.81}
Step 455: {'loss': 4.2577, 'learning_rate': 0.00018296675373620226, 'epoch': 0.81}
Step 456: {'loss': 3.7368, 'learning_rate': 0.00018285096492438424, 'epoch': 0.81}
Step 457: {'loss': 4.3267, 'learning_rate': 0.00018273482078737417, 'epoch': 0.81}
Step 458: {'loss': 4.0658, 'learning_rate': 0.0001826183218232826, 'epoch': 0.81}
Step 459: {'loss': 4.124, 'learning_rate': 0.00018250146853174184, 'epoch': 0.82}
Step 460: {'loss': 3.8441, 'learning_rate': 0.00018238426141390377, 'epoch': 0.82}
Step 461: {'loss': 4.2472, 'learning_rate': 0.00018226670097243775, 'epoch': 0.82}
Step 462: {'loss': 4.0292, 'learning_rate': 0.00018214878771152844, 'epoch': 0.82}
Step 463: {'loss': 4.452, 'learning_rate': 0.0001820305221368737, 'epoch': 0.82}
Step 464: {'loss': 3.9252, 'learning_rate': 0.00018191190475568228, 'epoch': 0.82}
Step 465: {'loss': 4.1542, 'learning_rate': 0.00018179293607667178, 'epoch': 0.83}
Step 466: {'loss': 4.1558, 'learning_rate': 0.00018167361661006643, 'epoch': 0.83}
Step 467: {'loss': 3.7015, 'learning_rate': 0.0001815539468675949, 'epoch': 0.83}
Step 468: {'loss': 3.9259, 'learning_rate': 0.00018143392736248804, 'epoch': 0.83}
Step 469: {'loss': 4.1998, 'learning_rate': 0.0001813135586094768, 'epoch': 0.83}
Step 470: {'loss': 3.9776, 'learning_rate': 0.0001811928411247899, 'epoch': 0.84}
Step 471: {'loss': 4.1695, 'learning_rate': 0.00018107177542615172, 'epoch': 0.84}
Step 472: {'loss': 3.8314, 'learning_rate': 0.00018095036203278006, 'epoch': 0.84}
Step 473: {'loss': 3.9096, 'learning_rate': 0.0001808286014653838, 'epoch': 0.84}
Step 474: {'loss': 3.8775, 'learning_rate': 0.00018070649424616083, 'epoch': 0.84}
Step 475: {'loss': 3.6642, 'learning_rate': 0.00018058404089879573, 'epoch': 0.84}
Step 476: {'loss': 3.6943, 'learning_rate': 0.00018046124194845745, 'epoch': 0.85}
Step 477: {'loss': 4.5417, 'learning_rate': 0.00018033809792179726, 'epoch': 0.85}
Step 478: {'loss': 3.9116, 'learning_rate': 0.00018021460934694624, 'epoch': 0.85}
Step 479: {'loss': 3.9482, 'learning_rate': 0.00018009077675351328, 'epoch': 0.85}
Step 480: {'loss': 3.9576, 'learning_rate': 0.00017996660067258255, 'epoch': 0.85}
Step 481: {'loss': 3.95, 'learning_rate': 0.0001798420816367114, 'epoch': 0.86}
Step 482: {'loss': 3.9817, 'learning_rate': 0.00017971722017992806, 'epoch': 0.86}
Step 483: {'loss': 4.1895, 'learning_rate': 0.0001795920168377292, 'epoch': 0.86}
Step 484: {'loss': 3.8039, 'learning_rate': 0.0001794664721470778, 'epoch': 0.86}
Step 485: {'loss': 4.0692, 'learning_rate': 0.00017934058664640086, 'epoch': 0.86}
Step 486: {'loss': 4.0309, 'learning_rate': 0.00017921436087558692, 'epoch': 0.86}
Step 487: {'loss': 3.9016, 'learning_rate': 0.00017908779537598388, 'epoch': 0.87}
Step 488: {'loss': 3.9917, 'learning_rate': 0.0001789608906903967, 'epoch': 0.87}
Step 489: {'loss': 3.8621, 'learning_rate': 0.00017883364736308486, 'epoch': 0.87}
Step 490: {'loss': 4.0696, 'learning_rate': 0.0001787060659397604, 'epoch': 0.87}
Step 491: {'loss': 3.5695, 'learning_rate': 0.00017857814696758522, 'epoch': 0.87}
Step 492: {'loss': 3.6064, 'learning_rate': 0.00017844989099516885, 'epoch': 0.87}
Step 493: {'loss': 3.8168, 'learning_rate': 0.0001783212985725662, 'epoch': 0.88}
Step 494: {'loss': 4.0413, 'learning_rate': 0.00017819237025127512, 'epoch': 0.88}
Step 495: {'loss': 4.1613, 'learning_rate': 0.000178063106584234, 'epoch': 0.88}
Step 496: {'loss': 4.104, 'learning_rate': 0.0001779335081258195, 'epoch': 0.88}
Step 497: {'loss': 4.1528, 'learning_rate': 0.00017780357543184397, 'epoch': 0.88}
Step 498: {'loss': 4.0329, 'learning_rate': 0.00017767330905955336, 'epoch': 0.89}
Step 499: {'loss': 3.9892, 'learning_rate': 0.0001775427095676246, 'epoch': 0.89}
Step 500: {'loss': 4.1771, 'learning_rate': 0.00017741177751616328, 'epoch': 0.89}
Step 501: {'loss': 4.169, 'learning_rate': 0.00017728051346670127, 'epoch': 0.89}
Step 502: {'loss': 3.7846, 'learning_rate': 0.0001771489179821943, 'epoch': 0.89}
Step 503: {'loss': 3.9362, 'learning_rate': 0.00017701699162701948, 'epoch': 0.89}
Step 504: {'loss': 3.8431, 'learning_rate': 0.00017688473496697298, 'epoch': 0.9}
Step 505: {'loss': 3.9992, 'learning_rate': 0.00017675214856926753, 'epoch': 0.9}
Step 506: {'loss': 4.1117, 'learning_rate': 0.00017661923300253001, 'epoch': 0.9}
Step 507: {'loss': 3.5833, 'learning_rate': 0.0001764859888367991, 'epoch': 0.9}
Step 508: {'loss': 3.9997, 'learning_rate': 0.00017635241664352264, 'epoch': 0.9}
Step 509: {'loss': 4.4191, 'learning_rate': 0.00017621851699555535, 'epoch': 0.9}
Step 510: {'loss': 3.797, 'learning_rate': 0.00017608429046715629, 'epoch': 0.91}
Step 511: {'loss': 4.172, 'learning_rate': 0.00017594973763398642, 'epoch': 0.91}
Step 512: {'loss': 3.7916, 'learning_rate': 0.00017581485907310616, 'epoch': 0.91}
Step 513: {'loss': 3.4415, 'learning_rate': 0.00017567965536297288, 'epoch': 0.91}
Step 514: {'loss': 3.9622, 'learning_rate': 0.00017554412708343842, 'epoch': 0.91}
Step 515: {'loss': 3.8798, 'learning_rate': 0.00017540827481574657, 'epoch': 0.92}
Step 516: {'loss': 3.9172, 'learning_rate': 0.00017527209914253074, 'epoch': 0.92}
Step 517: {'loss': 3.719, 'learning_rate': 0.00017513560064781115, 'epoch': 0.92}
Step 518: {'loss': 4.097, 'learning_rate': 0.00017499877991699266, 'epoch': 0.92}
Step 519: {'loss': 3.723, 'learning_rate': 0.00017486163753686207, 'epoch': 0.92}
Step 520: {'loss': 3.6674, 'learning_rate': 0.00017472417409558565, 'epoch': 0.92}
Step 521: {'loss': 3.7807, 'learning_rate': 0.0001745863901827066, 'epoch': 0.93}
Step 522: {'loss': 3.6243, 'learning_rate': 0.00017444828638914252, 'epoch': 0.93}
Step 523: {'loss': 3.7126, 'learning_rate': 0.00017430986330718294, 'epoch': 0.93}
Step 524: {'loss': 3.9076, 'learning_rate': 0.00017417112153048675, 'epoch': 0.93}
Step 525: {'loss': 3.809, 'learning_rate': 0.0001740320616540795, 'epoch': 0.93}
Step 526: {'loss': 3.8822, 'learning_rate': 0.00017389268427435114, 'epoch': 0.94}
Step 527: {'loss': 3.7725, 'learning_rate': 0.00017375298998905322, 'epoch': 0.94}
Step 528: {'loss': 3.8145, 'learning_rate': 0.00017361297939729638, 'epoch': 0.94}
Step 529: {'loss': 3.6923, 'learning_rate': 0.00017347265309954795, 'epoch': 0.94}
Step 530: {'loss': 3.2939, 'learning_rate': 0.00017333201169762908, 'epoch': 0.94}
Step 531: {'loss': 3.9644, 'learning_rate': 0.00017319105579471247, 'epoch': 0.94}
Step 532: {'loss': 3.6189, 'learning_rate': 0.00017304978599531944, 'epoch': 0.95}
Step 533: {'loss': 4.1159, 'learning_rate': 0.00017290820290531765, 'epoch': 0.95}
Step 534: {'loss': 3.6433, 'learning_rate': 0.00017276630713191843, 'epoch': 0.95}
Step 535: {'loss': 3.4897, 'learning_rate': 0.00017262409928367397, 'epoch': 0.95}
Step 536: {'loss': 3.7359, 'learning_rate': 0.00017248157997047498, 'epoch': 0.95}
Step 537: {'loss': 3.5739, 'learning_rate': 0.00017233874980354793, 'epoch': 0.95}
Step 538: {'loss': 3.5118, 'learning_rate': 0.00017219560939545246, 'epoch': 0.96}
Step 539: {'loss': 4.0858, 'learning_rate': 0.0001720521593600787, 'epoch': 0.96}
Step 540: {'loss': 4.0703, 'learning_rate': 0.00017190840031264476, 'epoch': 0.96}
Step 541: {'loss': 3.7557, 'learning_rate': 0.000171764332869694, 'epoch': 0.96}
Step 542: {'loss': 3.7499, 'learning_rate': 0.00017161995764909235, 'epoch': 0.96}
Step 543: {'loss': 3.6238, 'learning_rate': 0.0001714752752700258, 'epoch': 0.97}
Step 544: {'loss': 3.7083, 'learning_rate': 0.00017133028635299758, 'epoch': 0.97}
Step 545: {'loss': 3.6575, 'learning_rate': 0.0001711849915198256, 'epoch': 0.97}
Step 546: {'loss': 3.9445, 'learning_rate': 0.00017103939139363977, 'epoch': 0.97}
Step 547: {'loss': 4.0177, 'learning_rate': 0.0001708934865988794, 'epoch': 0.97}
Step 548: {'loss': 3.8152, 'learning_rate': 0.00017074727776129024, 'epoch': 0.97}
Step 549: {'loss': 3.8504, 'learning_rate': 0.00017060076550792221, 'epoch': 0.98}
Step 550: {'loss': 4.2574, 'learning_rate': 0.00017045395046712638, 'epoch': 0.98}
Step 551: {'loss': 3.9563, 'learning_rate': 0.00017030683326855242, 'epoch': 0.98}
Step 552: {'loss': 3.6121, 'learning_rate': 0.00017015941454314584, 'epoch': 0.98}
Step 553: {'loss': 3.7454, 'learning_rate': 0.0001700116949231454, 'epoch': 0.98}
Step 554: {'loss': 3.676, 'learning_rate': 0.0001698636750420802, 'epoch': 0.98}
Step 555: {'loss': 3.5277, 'learning_rate': 0.0001697153555347672, 'epoch': 0.99}
Step 556: {'loss': 3.9455, 'learning_rate': 0.00016956673703730828, 'epoch': 0.99}
Step 557: {'loss': 3.5018, 'learning_rate': 0.00016941782018708762, 'epoch': 0.99}
Step 558: {'loss': 3.5877, 'learning_rate': 0.00016926860562276904, 'epoch': 0.99}
Step 559: {'loss': 3.3124, 'learning_rate': 0.00016911909398429305, 'epoch': 0.99}
Step 560: {'loss': 4.1512, 'learning_rate': 0.00016896928591287434, 'epoch': 1.0}
Step 561: {'loss': 3.7442, 'learning_rate': 0.0001688191820509988, 'epoch': 1.0}
Step 562: {'loss': 3.7588, 'learning_rate': 0.00016866878304242104, 'epoch': 1.0}
Step 563: {'loss': 3.4859, 'learning_rate': 0.00016851808953216132, 'epoch': 1.0}
Step 564: {'loss': 3.7596, 'learning_rate': 0.00016836710216650304, 'epoch': 1.0}
Step 565: {'loss': 3.9372, 'learning_rate': 0.00016821582159298984, 'epoch': 1.0}
Step 566: {'loss': 4.0721, 'learning_rate': 0.0001680642484604228, 'epoch': 1.01}
Step 567: {'loss': 3.799, 'learning_rate': 0.00016791238341885777, 'epoch': 1.01}
Step 568: {'loss': 3.8133, 'learning_rate': 0.0001677602271196025, 'epoch': 1.01}
Step 569: {'loss': 4.2732, 'learning_rate': 0.00016760778021521387, 'epoch': 1.01}
Step 570: {'loss': 3.9621, 'learning_rate': 0.00016745504335949503, 'epoch': 1.01}
Step 571: {'loss': 3.7657, 'learning_rate': 0.00016730201720749273, 'epoch': 1.02}
Step 572: {'loss': 3.7008, 'learning_rate': 0.00016714870241549444, 'epoch': 1.02}
Step 573: {'loss': 3.6551, 'learning_rate': 0.0001669950996410254, 'epoch': 1.02}
Step 574: {'loss': 3.4951, 'learning_rate': 0.00016684120954284606, 'epoch': 1.02}
Step 575: {'loss': 4.0599, 'learning_rate': 0.0001666870327809491, 'epoch': 1.02}
Step 576: {'loss': 3.8227, 'learning_rate': 0.00016653257001655652, 'epoch': 1.02}
Step 577: {'loss': 4.183, 'learning_rate': 0.00016637782191211714, 'epoch': 1.03}
Step 578: {'loss': 3.3591, 'learning_rate': 0.0001662227891313032, 'epoch': 1.03}
Step 579: {'loss': 3.5236, 'learning_rate': 0.00016606747233900815, 'epoch': 1.03}
Step 580: {'loss': 3.8453, 'learning_rate': 0.0001659118722013433, 'epoch': 1.03}
Step 581: {'loss': 3.8332, 'learning_rate': 0.00016575598938563517, 'epoch': 1.03}
Step 582: {'loss': 3.7021, 'learning_rate': 0.00016559982456042268, 'epoch': 1.03}
Step 583: {'loss': 3.8116, 'learning_rate': 0.0001654433783954542, 'epoch': 1.04}
Step 584: {'loss': 3.6585, 'learning_rate': 0.0001652866515616846, 'epoch': 1.04}
Step 585: {'loss': 3.4356, 'learning_rate': 0.00016512964473127254, 'epoch': 1.04}
Step 586: {'loss': 3.8402, 'learning_rate': 0.00016497235857757753, 'epoch': 1.04}
Step 587: {'loss': 3.4166, 'learning_rate': 0.00016481479377515698, 'epoch': 1.04}
Step 588: {'loss': 3.7307, 'learning_rate': 0.00016465695099976332, 'epoch': 1.05}
Step 589: {'loss': 3.4305, 'learning_rate': 0.00016449883092834117, 'epoch': 1.05}
Step 590: {'loss': 3.3661, 'learning_rate': 0.00016434043423902442, 'epoch': 1.05}
Step 591: {'loss': 4.054, 'learning_rate': 0.00016418176161113324, 'epoch': 1.05}
Step 592: {'loss': 3.8273, 'learning_rate': 0.00016402281372517128, 'epoch': 1.05}
Step 593: {'loss': 3.6091, 'learning_rate': 0.00016386359126282262, 'epoch': 1.05}
Step 594: {'loss': 4.05, 'learning_rate': 0.00016370409490694908, 'epoch': 1.06}
Step 595: {'loss': 3.577, 'learning_rate': 0.00016354432534158693, 'epoch': 1.06}
Step 596: {'loss': 3.7803, 'learning_rate': 0.00016338428325194429, 'epoch': 1.06}
Step 597: {'loss': 3.8329, 'learning_rate': 0.00016322396932439803, 'epoch': 1.06}
Step 598: {'loss': 3.9895, 'learning_rate': 0.0001630633842464909, 'epoch': 1.06}
Step 599: {'loss': 3.7096, 'learning_rate': 0.00016290252870692842, 'epoch': 1.06}
Step 600: {'loss': 3.5953, 'learning_rate': 0.00016274140339557624, 'epoch': 1.07}
Step 601: {'loss': 3.7157, 'learning_rate': 0.0001625800090034568, 'epoch': 1.07}
Step 602: {'loss': 3.6265, 'learning_rate': 0.0001624183462227466, 'epoch': 1.07}
Step 603: {'loss': 3.5503, 'learning_rate': 0.00016225641574677332, 'epoch': 1.07}
Step 604: {'loss': 3.7748, 'learning_rate': 0.00016209421827001252, 'epoch': 1.07}
Step 605: {'loss': 4.0112, 'learning_rate': 0.00016193175448808494, 'epoch': 1.08}
Step 606: {'loss': 3.7335, 'learning_rate': 0.0001617690250977535, 'epoch': 1.08}
Step 607: {'loss': 3.9064, 'learning_rate': 0.00016160603079692012, 'epoch': 1.08}
Step 608: {'loss': 3.8006, 'learning_rate': 0.00016144277228462287, 'epoch': 1.08}
Step 609: {'loss': 3.6793, 'learning_rate': 0.00016127925026103307, 'epoch': 1.08}
Step 610: {'loss': 3.7613, 'learning_rate': 0.00016111546542745204, 'epoch': 1.08}
Step 611: {'loss': 3.7416, 'learning_rate': 0.0001609514184863082, 'epoch': 1.09}
Step 612: {'loss': 3.6537, 'learning_rate': 0.00016078711014115427, 'epoch': 1.09}
Step 613: {'loss': 3.4754, 'learning_rate': 0.0001606225410966638, 'epoch': 1.09}
Step 614: {'loss': 4.0616, 'learning_rate': 0.00016045771205862864, 'epoch': 1.09}
Step 615: {'loss': 3.6031, 'learning_rate': 0.0001602926237339555, 'epoch': 1.09}
Step 616: {'loss': 3.7677, 'learning_rate': 0.0001601272768306632, 'epoch': 1.1}
Step 617: {'loss': 3.6942, 'learning_rate': 0.0001599616720578795, 'epoch': 1.1}
Step 618: {'loss': 3.3715, 'learning_rate': 0.0001597958101258382, 'epoch': 1.1}
Step 619: {'loss': 3.5631, 'learning_rate': 0.00015962969174587578, 'epoch': 1.1}
Step 620: {'loss': 3.5027, 'learning_rate': 0.00015946331763042867, 'epoch': 1.1}
Step 621: {'loss': 3.9515, 'learning_rate': 0.00015929668849303013, 'epoch': 1.1}
Step 622: {'loss': 3.8368, 'learning_rate': 0.00015912980504830708, 'epoch': 1.11}
Step 623: {'loss': 3.6455, 'learning_rate': 0.00015896266801197705, 'epoch': 1.11}
Step 624: {'loss': 3.8942, 'learning_rate': 0.00015879527810084524, 'epoch': 1.11}
Step 625: {'loss': 3.6995, 'learning_rate': 0.00015862763603280132, 'epoch': 1.11}
Step 626: {'loss': 3.7354, 'learning_rate': 0.00015845974252681638, 'epoch': 1.11}
Step 627: {'loss': 3.728, 'learning_rate': 0.00015829159830293993, 'epoch': 1.11}
Step 628: {'loss': 3.7417, 'learning_rate': 0.00015812320408229658, 'epoch': 1.12}
Step 629: {'loss': 3.6001, 'learning_rate': 0.00015795456058708334, 'epoch': 1.12}
Step 630: {'loss': 3.9279, 'learning_rate': 0.00015778566854056614, 'epoch': 1.12}
Step 631: {'loss': 3.7136, 'learning_rate': 0.00015761652866707682, 'epoch': 1.12}
Step 632: {'loss': 3.7955, 'learning_rate': 0.00015744714169201022, 'epoch': 1.12}
Step 633: {'loss': 3.4258, 'learning_rate': 0.00015727750834182089, 'epoch': 1.13}
Step 634: {'loss': 3.4196, 'learning_rate': 0.00015710762934402, 'epoch': 1.13}
Step 635: {'loss': 3.4911, 'learning_rate': 0.00015693750542717223, 'epoch': 1.13}
Step 636: {'loss': 4.0052, 'learning_rate': 0.00015676713732089268, 'epoch': 1.13}
Step 637: {'loss': 3.4916, 'learning_rate': 0.00015659652575584365, 'epoch': 1.13}
Step 638: {'loss': 3.5939, 'learning_rate': 0.00015642567146373164, 'epoch': 1.13}
Step 639: {'loss': 3.8646, 'learning_rate': 0.0001562545751773041, 'epoch': 1.14}
Step 640: {'loss': 3.6726, 'learning_rate': 0.0001560832376303463, 'epoch': 1.14}
Step 641: {'loss': 3.6661, 'learning_rate': 0.0001559116595576784, 'epoch': 1.14}
Step 642: {'loss': 3.9944, 'learning_rate': 0.00015573984169515176, 'epoch': 1.14}
Step 643: {'loss': 3.6617, 'learning_rate': 0.00015556778477964644, 'epoch': 1.14}
Step 644: {'loss': 3.9777, 'learning_rate': 0.00015539548954906764, 'epoch': 1.14}
Step 645: {'loss': 3.4692, 'learning_rate': 0.00015522295674234252, 'epoch': 1.15}
Step 646: {'loss': 3.4134, 'learning_rate': 0.00015505018709941734, 'epoch': 1.15}
Step 647: {'loss': 3.1534, 'learning_rate': 0.0001548771813612539, 'epoch': 1.15}
Step 648: {'loss': 3.8572, 'learning_rate': 0.00015470394026982667, 'epoch': 1.15}
Step 649: {'loss': 3.4637, 'learning_rate': 0.0001545304645681194, 'epoch': 1.15}
Step 650: {'loss': 3.3759, 'learning_rate': 0.00015435675500012212, 'epoch': 1.16}
Step 651: {'loss': 3.3554, 'learning_rate': 0.00015418281231082776, 'epoch': 1.16}
Step 652: {'loss': 3.5744, 'learning_rate': 0.00015400863724622906, 'epoch': 1.16}
Step 653: {'loss': 3.7992, 'learning_rate': 0.00015383423055331536, 'epoch': 1.16}
Step 654: {'loss': 3.3825, 'learning_rate': 0.0001536595929800694, 'epoch': 1.16}
Step 655: {'loss': 4.1586, 'learning_rate': 0.00015348472527546415, 'epoch': 1.16}
Step 656: {'loss': 3.4265, 'learning_rate': 0.00015330962818945948, 'epoch': 1.17}
Step 657: {'loss': 3.7489, 'learning_rate': 0.00015313430247299901, 'epoch': 1.17}
Step 658: {'loss': 3.7742, 'learning_rate': 0.00015295874887800694, 'epoch': 1.17}
Step 659: {'loss': 3.4898, 'learning_rate': 0.00015278296815738476, 'epoch': 1.17}
Step 660: {'loss': 3.5756, 'learning_rate': 0.00015260696106500805, 'epoch': 1.17}
Step 661: {'loss': 3.9913, 'learning_rate': 0.00015243072835572318, 'epoch': 1.18}
Step 662: {'loss': 3.5546, 'learning_rate': 0.00015225427078534423, 'epoch': 1.18}
Step 663: {'loss': 3.658, 'learning_rate': 0.00015207758911064956, 'epoch': 1.18}
Step 664: {'loss': 3.8749, 'learning_rate': 0.00015190068408937868, 'epoch': 1.18}
Step 665: {'loss': 3.5011, 'learning_rate': 0.000151723556480229, 'epoch': 1.18}
Step 666: {'loss': 3.6818, 'learning_rate': 0.00015154620704285252, 'epoch': 1.18}
Step 667: {'loss': 3.636, 'learning_rate': 0.00015136863653785257, 'epoch': 1.19}
Step 668: {'loss': 3.8436, 'learning_rate': 0.00015119084572678073, 'epoch': 1.19}
Step 669: {'loss': 3.7832, 'learning_rate': 0.00015101283537213316, 'epoch': 1.19}
Step 670: {'loss': 4.1025, 'learning_rate': 0.00015083460623734776, 'epoch': 1.19}
Step 671: {'loss': 3.699, 'learning_rate': 0.00015065615908680074, 'epoch': 1.19}
Step 672: {'loss': 3.5668, 'learning_rate': 0.00015047749468580324, 'epoch': 1.19}
Step 673: {'loss': 3.7248, 'learning_rate': 0.00015029861380059804, 'epoch': 1.2}
Step 674: {'loss': 3.6836, 'learning_rate': 0.00015011951719835664, 'epoch': 1.2}
Step 675: {'loss': 3.4481, 'learning_rate': 0.0001499402056471754, 'epoch': 1.2}
Step 676: {'loss': 3.8727, 'learning_rate': 0.0001497606799160727, 'epoch': 1.2}
Step 677: {'loss': 3.3266, 'learning_rate': 0.00014958094077498544, 'epoch': 1.2}
Step 678: {'loss': 4.0028, 'learning_rate': 0.00014940098899476575, 'epoch': 1.21}
Step 679: {'loss': 3.4738, 'learning_rate': 0.00014922082534717777, 'epoch': 1.21}
Step 680: {'loss': 4.0827, 'learning_rate': 0.0001490404506048942, 'epoch': 1.21}
Step 681: {'loss': 3.7235, 'learning_rate': 0.00014885986554149315, 'epoch': 1.21}
Step 682: {'loss': 3.7129, 'learning_rate': 0.00014867907093145472, 'epoch': 1.21}
Step 683: {'loss': 3.5558, 'learning_rate': 0.00014849806755015766, 'epoch': 1.21}
Step 684: {'loss': 3.9781, 'learning_rate': 0.00014831685617387608, 'epoch': 1.22}
Step 685: {'loss': 3.427, 'learning_rate': 0.00014813543757977618, 'epoch': 1.22}
Step 686: {'loss': 3.9357, 'learning_rate': 0.00014795381254591286, 'epoch': 1.22}
Step 687: {'loss': 3.665, 'learning_rate': 0.0001477719818512263, 'epoch': 1.22}
Step 688: {'loss': 3.7433, 'learning_rate': 0.0001475899462755388, 'epoch': 1.22}
Step 689: {'loss': 3.4305, 'learning_rate': 0.00014740770659955126, 'epoch': 1.22}
Step 690: {'loss': 3.7092, 'learning_rate': 0.00014722526360483996, 'epoch': 1.23}
Step 691: {'loss': 3.7275, 'learning_rate': 0.00014704261807385314, 'epoch': 1.23}
Step 692: {'loss': 3.6729, 'learning_rate': 0.00014685977078990767, 'epoch': 1.23}
Step 693: {'loss': 3.8625, 'learning_rate': 0.00014667672253718572, 'epoch': 1.23}
Step 694: {'loss': 3.9057, 'learning_rate': 0.00014649347410073126, 'epoch': 1.23}
Step 695: {'loss': 3.4766, 'learning_rate': 0.0001463100262664469, 'epoch': 1.24}
Step 696: {'loss': 3.5571, 'learning_rate': 0.00014612637982109035, 'epoch': 1.24}
Step 697: {'loss': 3.5521, 'learning_rate': 0.0001459425355522711, 'epoch': 1.24}
Step 698: {'loss': 4.2783, 'learning_rate': 0.00014575849424844716, 'epoch': 1.24}
Step 699: {'loss': 3.5315, 'learning_rate': 0.0001455742566989214, 'epoch': 1.24}
Step 700: {'loss': 3.3521, 'learning_rate': 0.00014538982369383848, 'epoch': 1.24}
Step 701: {'loss': 3.6009, 'learning_rate': 0.0001452051960241812, 'epoch': 1.25}
Step 702: {'loss': 3.4609, 'learning_rate': 0.00014502037448176734, 'epoch': 1.25}
Step 703: {'loss': 3.9165, 'learning_rate': 0.00014483535985924606, 'epoch': 1.25}
Step 704: {'loss': 3.7365, 'learning_rate': 0.00014465015295009464, 'epoch': 1.25}
Step 705: {'loss': 3.9255, 'learning_rate': 0.0001444647545486149, 'epoch': 1.25}
Step 706: {'loss': 3.834, 'learning_rate': 0.00014427916544993016, 'epoch': 1.26}
Step 707: {'loss': 3.5871, 'learning_rate': 0.0001440933864499814, 'epoch': 1.26}
Step 708: {'loss': 3.6017, 'learning_rate': 0.000143907418345524, 'epoch': 1.26}
Step 709: {'loss': 4.0164, 'learning_rate': 0.0001437212619341245, 'epoch': 1.26}
Step 710: {'loss': 3.5843, 'learning_rate': 0.00014353491801415705, 'epoch': 1.26}
Step 711: {'loss': 3.7823, 'learning_rate': 0.00014334838738479979, 'epoch': 1.26}
Step 712: {'loss': 3.5465, 'learning_rate': 0.00014316167084603177, 'epoch': 1.27}
Step 713: {'loss': 3.7767, 'learning_rate': 0.0001429747691986293, 'epoch': 1.27}
Step 714: {'loss': 3.5173, 'learning_rate': 0.00014278768324416251, 'epoch': 1.27}
Step 715: {'loss': 3.4187, 'learning_rate': 0.00014260041378499213, 'epoch': 1.27}
Step 716: {'loss': 3.9545, 'learning_rate': 0.00014241296162426575, 'epoch': 1.27}
Step 717: {'loss': 3.4517, 'learning_rate': 0.00014222532756591453, 'epoch': 1.27}
Step 718: {'loss': 3.3954, 'learning_rate': 0.0001420375124146498, 'epoch': 1.28}
Step 719: {'loss': 3.4989, 'learning_rate': 0.00014184951697595954, 'epoch': 1.28}
Step 720: {'loss': 3.8581, 'learning_rate': 0.00014166134205610483, 'epoch': 1.28}
Step 721: {'loss': 3.6052, 'learning_rate': 0.00014147298846211673, 'epoch': 1.28}
Step 722: {'loss': 3.388, 'learning_rate': 0.0001412844570017923, 'epoch': 1.28}
Step 723: {'loss': 3.7198, 'learning_rate': 0.0001410957484836916, 'epoch': 1.29}
Step 724: {'loss': 3.435, 'learning_rate': 0.00014090686371713402, 'epoch': 1.29}
Step 725: {'loss': 3.2833, 'learning_rate': 0.00014071780351219474, 'epoch': 1.29}
Step 726: {'loss': 3.7053, 'learning_rate': 0.0001405285686797015, 'epoch': 1.29}
Step 727: {'loss': 3.7613, 'learning_rate': 0.0001403391600312308, 'epoch': 1.29}
Step 728: {'loss': 3.6339, 'learning_rate': 0.00014014957837910473, 'epoch': 1.29}
Step 729: {'loss': 3.6802, 'learning_rate': 0.00013995982453638732, 'epoch': 1.3}
Step 730: {'loss': 3.5636, 'learning_rate': 0.00013976989931688096, 'epoch': 1.3}
Step 731: {'loss': 3.7512, 'learning_rate': 0.00013957980353512318, 'epoch': 1.3}
Step 732: {'loss': 3.0995, 'learning_rate': 0.00013938953800638292, 'epoch': 1.3}
Step 733: {'loss': 3.4139, 'learning_rate': 0.00013919910354665715, 'epoch': 1.3}
Step 734: {'loss': 3.9256, 'learning_rate': 0.00013900850097266733, 'epoch': 1.3}
Step 735: {'loss': 3.6558, 'learning_rate': 0.0001388177311018559, 'epoch': 1.31}
Step 736: {'loss': 3.5823, 'learning_rate': 0.00013862679475238284, 'epoch': 1.31}
Step 737: {'loss': 3.7422, 'learning_rate': 0.00013843569274312202, 'epoch': 1.31}
Step 738: {'loss': 3.8402, 'learning_rate': 0.00013824442589365786, 'epoch': 1.31}
Step 739: {'loss': 3.689, 'learning_rate': 0.00013805299502428175, 'epoch': 1.31}
Step 740: {'loss': 3.2399, 'learning_rate': 0.00013786140095598846, 'epoch': 1.32}
Step 741: {'loss': 3.6135, 'learning_rate': 0.00013766964451047267, 'epoch': 1.32}
Step 742: {'loss': 3.2544, 'learning_rate': 0.00013747772651012547, 'epoch': 1.32}
Step 743: {'loss': 3.7734, 'learning_rate': 0.00013728564777803088, 'epoch': 1.32}
Step 744: {'loss': 3.7302, 'learning_rate': 0.00013709340913796214, 'epoch': 1.32}
Step 745: {'loss': 3.6322, 'learning_rate': 0.00013690101141437835, 'epoch': 1.32}
Step 746: {'loss': 3.497, 'learning_rate': 0.00013670845543242087, 'epoch': 1.33}
Step 747: {'loss': 3.4042, 'learning_rate': 0.00013651574201790985, 'epoch': 1.33}
Step 748: {'loss': 3.6884, 'learning_rate': 0.0001363228719973405, 'epoch': 1.33}
Step 749: {'loss': 3.405, 'learning_rate': 0.00013612984619787972, 'epoch': 1.33}
Step 750: {'loss': 4.0584, 'learning_rate': 0.0001359366654473626, 'epoch': 1.33}
Step 751: {'loss': 3.3691, 'learning_rate': 0.00013574333057428864, 'epoch': 1.34}
Step 752: {'loss': 3.7284, 'learning_rate': 0.00013554984240781833, 'epoch': 1.34}
Step 753: {'loss': 3.9677, 'learning_rate': 0.00013535620177776973, 'epoch': 1.34}
Step 754: {'loss': 3.525, 'learning_rate': 0.0001351624095146147, 'epoch': 1.34}
Step 755: {'loss': 3.4528, 'learning_rate': 0.0001349684664494753, 'epoch': 1.34}
Step 756: {'loss': 3.627, 'learning_rate': 0.00013477437341412053, 'epoch': 1.34}
Step 757: {'loss': 3.2202, 'learning_rate': 0.00013458013124096246, 'epoch': 1.35}
Step 758: {'loss': 3.4873, 'learning_rate': 0.00013438574076305278, 'epoch': 1.35}
Step 759: {'loss': 3.6045, 'learning_rate': 0.00013419120281407925, 'epoch': 1.35}
Step 760: {'loss': 3.3574, 'learning_rate': 0.00013399651822836205, 'epoch': 1.35}
Step 761: {'loss': 3.9216, 'learning_rate': 0.00013380168784085027, 'epoch': 1.35}
Step 762: {'loss': 3.7703, 'learning_rate': 0.00013360671248711836, 'epoch': 1.35}
Step 763: {'loss': 3.6232, 'learning_rate': 0.0001334115930033624, 'epoch': 1.36}
Step 764: {'loss': 3.2115, 'learning_rate': 0.00013321633022639657, 'epoch': 1.36}
Step 765: {'loss': 3.4856, 'learning_rate': 0.0001330209249936498, 'epoch': 1.36}
Step 766: {'loss': 3.1567, 'learning_rate': 0.00013282537814316174, 'epoch': 1.36}
Step 767: {'loss': 3.6238, 'learning_rate': 0.0001326296905135795, 'epoch': 1.36}
Step 768: {'loss': 3.625, 'learning_rate': 0.00013243386294415404, 'epoch': 1.37}
Step 769: {'loss': 3.5147, 'learning_rate': 0.0001322378962747363, 'epoch': 1.37}
Step 770: {'loss': 3.5185, 'learning_rate': 0.0001320417913457739, 'epoch': 1.37}
Step 771: {'loss': 3.7838, 'learning_rate': 0.00013184554899830744, 'epoch': 1.37}
Step 772: {'loss': 3.9992, 'learning_rate': 0.00013164917007396672, 'epoch': 1.37}
Step 773: {'loss': 3.5123, 'learning_rate': 0.00013145265541496755, 'epoch': 1.37}
Step 774: {'loss': 3.7434, 'learning_rate': 0.0001312560058641076, 'epoch': 1.38}
Step 775: {'loss': 3.7224, 'learning_rate': 0.00013105922226476312, 'epoch': 1.38}
Step 776: {'loss': 3.7507, 'learning_rate': 0.00013086230546088544, 'epoch': 1.38}
Step 777: {'loss': 3.6295, 'learning_rate': 0.0001306652562969969, 'epoch': 1.38}
Step 778: {'loss': 3.5192, 'learning_rate': 0.0001304680756181876, 'epoch': 1.38}
Step 779: {'loss': 3.6132, 'learning_rate': 0.00013027076427011184, 'epoch': 1.38}
Step 780: {'loss': 3.6855, 'learning_rate': 0.00013007332309898406, 'epoch': 1.39}
Step 781: {'loss': 3.6039, 'learning_rate': 0.00012987575295157563, 'epoch': 1.39}
Step 782: {'loss': 3.6409, 'learning_rate': 0.000129678054675211, 'epoch': 1.39}
Step 783: {'loss': 3.4283, 'learning_rate': 0.0001294802291177642, 'epoch': 1.39}
Step 784: {'loss': 3.6761, 'learning_rate': 0.00012928227712765504, 'epoch': 1.39}
Step 785: {'loss': 3.8687, 'learning_rate': 0.00012908419955384568, 'epoch': 1.4}
Step 786: {'loss': 3.4332, 'learning_rate': 0.00012888599724583677, 'epoch': 1.4}
Step 787: {'loss': 3.7723, 'learning_rate': 0.00012868767105366394, 'epoch': 1.4}
Step 788: {'loss': 3.6575, 'learning_rate': 0.00012848922182789418, 'epoch': 1.4}
Step 789: {'loss': 3.6683, 'learning_rate': 0.00012829065041962206, 'epoch': 1.4}
Step 790: {'loss': 3.9844, 'learning_rate': 0.00012809195768046622, 'epoch': 1.4}
Step 791: {'loss': 3.5525, 'learning_rate': 0.00012789314446256562, 'epoch': 1.41}
Step 792: {'loss': 3.1679, 'learning_rate': 0.00012769421161857588, 'epoch': 1.41}
Step 793: {'loss': 3.8388, 'learning_rate': 0.0001274951600016658, 'epoch': 1.41}
Step 794: {'loss': 3.8366, 'learning_rate': 0.0001272959904655134, 'epoch': 1.41}
Step 795: {'loss': 3.7127, 'learning_rate': 0.00012709670386430253, 'epoch': 1.41}
Step 796: {'loss': 3.6479, 'learning_rate': 0.00012689730105271905, 'epoch': 1.42}
Step 797: {'loss': 3.8542, 'learning_rate': 0.00012669778288594726, 'epoch': 1.42}
Step 798: {'loss': 3.5527, 'learning_rate': 0.0001264981502196662, 'epoch': 1.42}
Step 799: {'loss': 3.6166, 'learning_rate': 0.00012629840391004582, 'epoch': 1.42}
Step 800: {'loss': 3.7404, 'learning_rate': 0.00012609854481374362, 'epoch': 1.42}
Step 801: {'loss': 3.8649, 'learning_rate': 0.0001258985737879008, 'epoch': 1.42}
Step 802: {'loss': 3.4365, 'learning_rate': 0.0001256984916901385, 'epoch': 1.43}
Step 803: {'loss': 3.392, 'learning_rate': 0.00012549829937855427, 'epoch': 1.43}
Step 804: {'loss': 3.4545, 'learning_rate': 0.00012529799771171835, 'epoch': 1.43}
Step 805: {'loss': 3.5118, 'learning_rate': 0.00012509758754866994, 'epoch': 1.43}
Step 806: {'loss': 3.432, 'learning_rate': 0.0001248970697489136, 'epoch': 1.43}
Step 807: {'loss': 3.7738, 'learning_rate': 0.00012469644517241544, 'epoch': 1.43}
Step 808: {'loss': 3.466, 'learning_rate': 0.00012449571467959956, 'epoch': 1.44}
Step 809: {'loss': 3.3756, 'learning_rate': 0.00012429487913134435, 'epoch': 1.44}
Step 810: {'loss': 3.541, 'learning_rate': 0.00012409393938897867, 'epoch': 1.44}
Step 811: {'loss': 3.892, 'learning_rate': 0.00012389289631427824, 'epoch': 1.44}
Step 812: {'loss': 3.3688, 'learning_rate': 0.00012369175076946203, 'epoch': 1.44}
Step 813: {'loss': 3.8262, 'learning_rate': 0.00012349050361718837, 'epoch': 1.45}
Step 814: {'loss': 3.7243, 'learning_rate': 0.0001232891557205514, 'epoch': 1.45}
Step 815: {'loss': 3.8537, 'learning_rate': 0.00012308770794307742, 'epoch': 1.45}
Step 816: {'loss': 3.4694, 'learning_rate': 0.00012288616114872092, 'epoch': 1.45}
Step 817: {'loss': 3.4906, 'learning_rate': 0.0001226845162018612, 'epoch': 1.45}
Step 818: {'loss': 3.8125, 'learning_rate': 0.00012248277396729836, 'epoch': 1.45}
Step 819: {'loss': 3.4505, 'learning_rate': 0.00012228093531024985, 'epoch': 1.46}
Step 820: {'loss': 3.9946, 'learning_rate': 0.00012207900109634668, 'epoch': 1.46}
Step 821: {'loss': 3.7764, 'learning_rate': 0.00012187697219162956, 'epoch': 1.46}
Step 822: {'loss': 3.762, 'learning_rate': 0.00012167484946254535, 'epoch': 1.46}
Step 823: {'loss': 3.7602, 'learning_rate': 0.00012147263377594338, 'epoch': 1.46}
Step 824: {'loss': 3.3005, 'learning_rate': 0.00012127032599907151, 'epoch': 1.46}
Step 825: {'loss': 3.7605, 'learning_rate': 0.00012106792699957263, 'epoch': 1.47}
Step 826: {'loss': 3.6471, 'learning_rate': 0.00012086543764548088, 'epoch': 1.47}
Step 827: {'loss': 3.6441, 'learning_rate': 0.00012066285880521784, 'epoch': 1.47}
Step 828: {'loss': 4.1338, 'learning_rate': 0.00012046019134758892, 'epoch': 1.47}
Step 829: {'loss': 3.6795, 'learning_rate': 0.00012025743614177955, 'epoch': 1.47}
Step 830: {'loss': 3.6779, 'learning_rate': 0.00012005459405735153, 'epoch': 1.48}
Step 831: {'loss': 3.7869, 'learning_rate': 0.00011985166596423924, 'epoch': 1.48}
Step 832: {'loss': 3.7501, 'learning_rate': 0.00011964865273274592, 'epoch': 1.48}
Step 833: {'loss': 3.8664, 'learning_rate': 0.00011944555523353995, 'epoch': 1.48}
Step 834: {'loss': 3.3696, 'learning_rate': 0.00011924237433765111, 'epoch': 1.48}
Step 835: {'loss': 3.9217, 'learning_rate': 0.00011903911091646684, 'epoch': 1.48}
Step 836: {'loss': 3.7713, 'learning_rate': 0.00011883576584172853, 'epoch': 1.49}
Step 837: {'loss': 3.416, 'learning_rate': 0.00011863233998552774, 'epoch': 1.49}
Step 838: {'loss': 3.4545, 'learning_rate': 0.00011842883422030248, 'epoch': 1.49}
Step 839: {'loss': 4.2686, 'learning_rate': 0.00011822524941883349, 'epoch': 1.49}
Step 840: {'loss': 3.5834, 'learning_rate': 0.00011802158645424044, 'epoch': 1.49}
Step 841: {'loss': 3.3962, 'learning_rate': 0.00011781784619997824, 'epoch': 1.5}
Step 842: {'loss': 3.8215, 'learning_rate': 0.00011761402952983329, 'epoch': 1.5}
Step 843: {'loss': 3.6575, 'learning_rate': 0.00011741013731791968, 'epoch': 1.5}
Step 844: {'loss': 3.3425, 'learning_rate': 0.00011720617043867552, 'epoch': 1.5}
Step 845: {'loss': 3.6977, 'learning_rate': 0.00011700212976685911, 'epoch': 1.5}
Step 846: {'loss': 3.7138, 'learning_rate': 0.00011679801617754523, 'epoch': 1.5}
Step 847: {'loss': 3.2843, 'learning_rate': 0.0001165938305461214, 'epoch': 1.51}
Step 848: {'loss': 3.5556, 'learning_rate': 0.00011638957374828417, 'epoch': 1.51}
Step 849: {'loss': 3.4023, 'learning_rate': 0.00011618524666003512, 'epoch': 1.51}
Step 850: {'loss': 4.0094, 'learning_rate': 0.00011598085015767748, 'epoch': 1.51}
Step 851: {'loss': 3.531, 'learning_rate': 0.00011577638511781211, 'epoch': 1.51}
Step 852: {'loss': 3.7211, 'learning_rate': 0.00011557185241733375, 'epoch': 1.51}
Step 853: {'loss': 3.5875, 'learning_rate': 0.00011536725293342743, 'epoch': 1.52}
Step 854: {'loss': 3.5146, 'learning_rate': 0.00011516258754356447, 'epoch': 1.52}
Step 855: {'loss': 3.6516, 'learning_rate': 0.00011495785712549892, 'epoch': 1.52}
Step 856: {'loss': 3.9336, 'learning_rate': 0.00011475306255726376, 'epoch': 1.52}
Step 857: {'loss': 3.5477, 'learning_rate': 0.00011454820471716701, 'epoch': 1.52}
Step 858: {'loss': 3.8361, 'learning_rate': 0.00011434328448378802, 'epoch': 1.53}
Step 859: {'loss': 3.5054, 'learning_rate': 0.00011413830273597387, 'epoch': 1.53}
Step 860: {'loss': 3.9296, 'learning_rate': 0.00011393326035283531, 'epoch': 1.53}
Step 861: {'loss': 3.1087, 'learning_rate': 0.0001137281582137432, 'epoch': 1.53}
Step 862: {'loss': 3.9769, 'learning_rate': 0.00011352299719832473, 'epoch': 1.53}
Step 863: {'loss': 3.9787, 'learning_rate': 0.00011331777818645946, 'epoch': 1.53}
Step 864: {'loss': 3.473, 'learning_rate': 0.00011311250205827584, 'epoch': 1.54}
Step 865: {'loss': 3.472, 'learning_rate': 0.00011290716969414714, 'epoch': 1.54}
Step 866: {'loss': 3.6223, 'learning_rate': 0.00011270178197468789, 'epoch': 1.54}
Step 867: {'loss': 3.7846, 'learning_rate': 0.00011249633978075, 'epoch': 1.54}
Step 868: {'loss': 3.677, 'learning_rate': 0.000112290843993419, 'epoch': 1.54}
Step 869: {'loss': 3.1151, 'learning_rate': 0.00011208529549401028, 'epoch': 1.54}
Step 870: {'loss': 3.8324, 'learning_rate': 0.00011187969516406534, 'epoch': 1.55}
Step 871: {'loss': 3.629, 'learning_rate': 0.00011167404388534783, 'epoch': 1.55}
Step 872: {'loss': 3.507, 'learning_rate': 0.00011146834253984006, 'epoch': 1.55}
Step 873: {'loss': 3.4821, 'learning_rate': 0.00011126259200973898, 'epoch': 1.55}
Step 874: {'loss': 3.5333, 'learning_rate': 0.0001110567931774525, 'epoch': 1.55}
Step 875: {'loss': 3.6196, 'learning_rate': 0.00011085094692559567, 'epoch': 1.56}
Step 876: {'loss': 3.4189, 'learning_rate': 0.00011064505413698693, 'epoch': 1.56}
Step 877: {'loss': 3.8066, 'learning_rate': 0.00011043911569464431, 'epoch': 1.56}
Step 878: {'loss': 4.1336, 'learning_rate': 0.00011023313248178162, 'epoch': 1.56}
Step 879: {'loss': 4.0867, 'learning_rate': 0.00011002710538180468, 'epoch': 1.56}
Step 880: {'loss': 3.7304, 'learning_rate': 0.00010982103527830749, 'epoch': 1.56}
Step 881: {'loss': 3.6175, 'learning_rate': 0.00010961492305506858, 'epoch': 1.57}
Step 882: {'loss': 3.7905, 'learning_rate': 0.00010940876959604703, 'epoch': 1.57}
Step 883: {'loss': 3.624, 'learning_rate': 0.00010920257578537878, 'epoch': 1.57}
Step 884: {'loss': 3.5175, 'learning_rate': 0.0001089963425073729, 'epoch': 1.57}
Step 885: {'loss': 3.4475, 'learning_rate': 0.00010879007064650764, 'epoch': 1.57}
Step 886: {'loss': 4.0242, 'learning_rate': 0.00010858376108742674, 'epoch': 1.58}
Step 887: {'loss': 3.5287, 'learning_rate': 0.00010837741471493566, 'epoch': 1.58}
Step 888: {'loss': 3.2726, 'learning_rate': 0.0001081710324139977, 'epoch': 1.58}
Step 889: {'loss': 3.6534, 'learning_rate': 0.00010796461506973025, 'epoch': 1.58}
Step 890: {'loss': 3.9354, 'learning_rate': 0.00010775816356740105, 'epoch': 1.58}
Step 891: {'loss': 3.8587, 'learning_rate': 0.0001075516787924242, 'epoch': 1.58}
Step 892: {'loss': 3.4916, 'learning_rate': 0.00010734516163035668, 'epoch': 1.59}
Step 893: {'loss': 3.4697, 'learning_rate': 0.0001071386129668942, 'epoch': 1.59}
Step 894: {'loss': 3.2411, 'learning_rate': 0.00010693203368786767, 'epoch': 1.59}
Step 895: {'loss': 3.5861, 'learning_rate': 0.00010672542467923929, 'epoch': 1.59}
Step 896: {'loss': 3.4318, 'learning_rate': 0.00010651878682709873, 'epoch': 1.59}
Step 897: {'loss': 3.5368, 'learning_rate': 0.00010631212101765938, 'epoch': 1.59}
Step 898: {'loss': 3.4355, 'learning_rate': 0.00010610542813725455, 'epoch': 1.6}
Step 899: {'loss': 3.8715, 'learning_rate': 0.00010589870907233357, 'epoch': 1.6}
Step 900: {'loss': 3.8255, 'learning_rate': 0.00010569196470945823, 'epoch': 1.6}
Step 901: {'loss': 3.39, 'learning_rate': 0.00010548519593529864, 'epoch': 1.6}
Step 902: {'loss': 3.6394, 'learning_rate': 0.00010527840363662969, 'epoch': 1.6}
Step 903: {'loss': 3.2162, 'learning_rate': 0.0001050715887003272, 'epoch': 1.61}
Step 904: {'loss': 3.7867, 'learning_rate': 0.00010486475201336397, 'epoch': 1.61}
Step 905: {'loss': 3.4933, 'learning_rate': 0.0001046578944628061, 'epoch': 1.61}
Step 906: {'loss': 3.2338, 'learning_rate': 0.00010445101693580932, 'epoch': 1.61}
Step 907: {'loss': 3.3076, 'learning_rate': 0.00010424412031961484, 'epoch': 1.61}
Step 908: {'loss': 3.5773, 'learning_rate': 0.00010403720550154583, 'epoch': 1.61}
Step 909: {'loss': 3.4875, 'learning_rate': 0.00010383027336900355, 'epoch': 1.62}
Step 910: {'loss': 3.2981, 'learning_rate': 0.00010362332480946342, 'epoch': 1.62}
Step 911: {'loss': 3.6114, 'learning_rate': 0.00010341636071047142, 'epoch': 1.62}
Step 912: {'loss': 3.6357, 'learning_rate': 0.0001032093819596401, 'epoch': 1.62}
Step 913: {'loss': 3.137, 'learning_rate': 0.00010300238944464484, 'epoch': 1.62}
Step 914: {'loss': 3.5416, 'learning_rate': 0.00010279538405322016, 'epoch': 1.62}
Step 915: {'loss': 3.5355, 'learning_rate': 0.00010258836667315565, 'epoch': 1.63}
Step 916: {'loss': 3.5333, 'learning_rate': 0.0001023813381922924, 'epoch': 1.63}
Step 917: {'loss': 3.5073, 'learning_rate': 0.0001021742994985192, 'epoch': 1.63}
Step 918: {'loss': 3.6089, 'learning_rate': 0.0001019672514797684, 'epoch': 1.63}
Step 919: {'loss': 3.1466, 'learning_rate': 0.00010176019502401257, 'epoch': 1.63}
Step 920: {'loss': 3.971, 'learning_rate': 0.00010155313101926036, 'epoch': 1.64}
Step 921: {'loss': 3.5721, 'learning_rate': 0.00010134606035355279, 'epoch': 1.64}
Step 922: {'loss': 3.6759, 'learning_rate': 0.00010113898391495948, 'epoch': 1.64}
Step 923: {'loss': 3.6009, 'learning_rate': 0.00010093190259157482, 'epoch': 1.64}
Step 924: {'loss': 3.4197, 'learning_rate': 0.00010072481727151409, 'epoch': 1.64}
Step 925: {'loss': 3.7205, 'learning_rate': 0.00010051772884290977, 'epoch': 1.64}
Step 926: {'loss': 3.3979, 'learning_rate': 0.00010031063819390765, 'epoch': 1.65}
Step 927: {'loss': 3.7089, 'learning_rate': 0.00010010354621266304, 'epoch': 1.65}
Step 928: {'loss': 3.6119, 'learning_rate': 9.989645378733698e-05, 'epoch': 1.65}
Step 929: {'loss': 3.7865, 'learning_rate': 9.968936180609234e-05, 'epoch': 1.65}
Step 930: {'loss': 3.6683, 'learning_rate': 9.948227115709025e-05, 'epoch': 1.65}
Step 931: {'loss': 3.194, 'learning_rate': 9.927518272848592e-05, 'epoch': 1.66}
Step 932: {'loss': 3.6921, 'learning_rate': 9.906809740842519e-05, 'epoch': 1.66}
Step 933: {'loss': 3.6072, 'learning_rate': 9.886101608504054e-05, 'epoch': 1.66}
Step 934: {'loss': 3.7759, 'learning_rate': 9.865393964644723e-05, 'epoch': 1.66}
Step 935: {'loss': 3.6077, 'learning_rate': 9.844686898073965e-05, 'epoch': 1.66}
Step 936: {'loss': 3.5674, 'learning_rate': 9.823980497598744e-05, 'epoch': 1.66}
Step 937: {'loss': 3.492, 'learning_rate': 9.803274852023161e-05, 'epoch': 1.67}
Step 938: {'loss': 3.57, 'learning_rate': 9.782570050148082e-05, 'epoch': 1.67}
Step 939: {'loss': 3.9058, 'learning_rate': 9.761866180770761e-05, 'epoch': 1.67}
Step 940: {'loss': 3.6077, 'learning_rate': 9.741163332684437e-05, 'epoch': 1.67}
Step 941: {'loss': 3.074, 'learning_rate': 9.720461594677987e-05, 'epoch': 1.67}
Step 942: {'loss': 3.6241, 'learning_rate': 9.69976105553552e-05, 'epoch': 1.67}
Step 943: {'loss': 3.8317, 'learning_rate': 9.679061804035992e-05, 'epoch': 1.68}
Step 944: {'loss': 3.218, 'learning_rate': 9.658363928952859e-05, 'epoch': 1.68}
Step 945: {'loss': 3.4178, 'learning_rate': 9.637667519053662e-05, 'epoch': 1.68}
Step 946: {'loss': 3.5496, 'learning_rate': 9.616972663099647e-05, 'epoch': 1.68}
Step 947: {'loss': 3.6288, 'learning_rate': 9.596279449845417e-05, 'epoch': 1.68}
Step 948: {'loss': 2.9788, 'learning_rate': 9.57558796803852e-05, 'epoch': 1.69}
Step 949: {'loss': 3.7087, 'learning_rate': 9.55489830641907e-05, 'epoch': 1.69}
Step 950: {'loss': 3.4959, 'learning_rate': 9.534210553719389e-05, 'epoch': 1.69}
Step 951: {'loss': 3.853, 'learning_rate': 9.513524798663608e-05, 'epoch': 1.69}
Step 952: {'loss': 3.5263, 'learning_rate': 9.492841129967282e-05, 'epoch': 1.69}
Step 953: {'loss': 3.5828, 'learning_rate': 9.472159636337031e-05, 'epoch': 1.69}
Step 954: {'loss': 3.5646, 'learning_rate': 9.451480406470139e-05, 'epoch': 1.7}
Step 955: {'loss': 3.6858, 'learning_rate': 9.430803529054179e-05, 'epoch': 1.7}
Step 956: {'loss': 3.4746, 'learning_rate': 9.410129092766642e-05, 'epoch': 1.7}
Step 957: {'loss': 3.7245, 'learning_rate': 9.389457186274549e-05, 'epoch': 1.7}
Step 958: {'loss': 3.7214, 'learning_rate': 9.368787898234066e-05, 'epoch': 1.7}
Step 959: {'loss': 3.5863, 'learning_rate': 9.348121317290128e-05, 'epoch': 1.7}
Step 960: {'loss': 3.7144, 'learning_rate': 9.327457532076073e-05, 'epoch': 1.71}
Step 961: {'loss': 3.5707, 'learning_rate': 9.306796631213234e-05, 'epoch': 1.71}
Step 962: {'loss': 3.8554, 'learning_rate': 9.28613870331058e-05, 'epoch': 1.71}
Step 963: {'loss': 3.2916, 'learning_rate': 9.265483836964335e-05, 'epoch': 1.71}
Step 964: {'loss': 3.9174, 'learning_rate': 9.24483212075758e-05, 'epoch': 1.71}
Step 965: {'loss': 3.5229, 'learning_rate': 9.224183643259896e-05, 'epoch': 1.72}
Step 966: {'loss': 3.7573, 'learning_rate': 9.203538493026976e-05, 'epoch': 1.72}
Step 967: {'loss': 3.5642, 'learning_rate': 9.182896758600232e-05, 'epoch': 1.72}
Step 968: {'loss': 3.6572, 'learning_rate': 9.162258528506434e-05, 'epoch': 1.72}
Step 969: {'loss': 3.9928, 'learning_rate': 9.141623891257327e-05, 'epoch': 1.72}
Step 970: {'loss': 3.778, 'learning_rate': 9.120992935349238e-05, 'epoch': 1.72}
Step 971: {'loss': 3.8348, 'learning_rate': 9.10036574926271e-05, 'epoch': 1.73}
Step 972: {'loss': 3.5282, 'learning_rate': 9.079742421462123e-05, 'epoch': 1.73}
Step 973: {'loss': 3.6502, 'learning_rate': 9.059123040395301e-05, 'epoch': 1.73}
Step 974: {'loss': 3.5708, 'learning_rate': 9.038507694493142e-05, 'epoch': 1.73}
Step 975: {'loss': 3.5284, 'learning_rate': 9.017896472169255e-05, 'epoch': 1.73}
Step 976: {'loss': 3.5257, 'learning_rate': 8.997289461819536e-05, 'epoch': 1.74}
Step 977: {'loss': 3.7731, 'learning_rate': 8.97668675182184e-05, 'epoch': 1.74}
Step 978: {'loss': 3.4928, 'learning_rate': 8.956088430535572e-05, 'epoch': 1.74}
Step 979: {'loss': 3.7725, 'learning_rate': 8.935494586301309e-05, 'epoch': 1.74}
Step 980: {'loss': 3.6781, 'learning_rate': 8.914905307440435e-05, 'epoch': 1.74}
Step 981: {'loss': 3.6704, 'learning_rate': 8.894320682254755e-05, 'epoch': 1.74}
Step 982: {'loss': 3.6879, 'learning_rate': 8.873740799026104e-05, 'epoch': 1.75}
Step 983: {'loss': 3.7173, 'learning_rate': 8.853165746015997e-05, 'epoch': 1.75}
Step 984: {'loss': 3.3001, 'learning_rate': 8.83259561146522e-05, 'epoch': 1.75}
Step 985: {'loss': 4.036, 'learning_rate': 8.81203048359347e-05, 'epoch': 1.75}
Step 986: {'loss': 3.4852, 'learning_rate': 8.791470450598972e-05, 'epoch': 1.75}
Step 987: {'loss': 3.071, 'learning_rate': 8.770915600658104e-05, 'epoch': 1.75}
Step 988: {'loss': 3.4976, 'learning_rate': 8.750366021925002e-05, 'epoch': 1.76}
Step 989: {'loss': 3.668, 'learning_rate': 8.729821802531212e-05, 'epoch': 1.76}
Step 990: {'loss': 3.5139, 'learning_rate': 8.709283030585291e-05, 'epoch': 1.76}
Step 991: {'loss': 3.4904, 'learning_rate': 8.688749794172419e-05, 'epoch': 1.76}
Step 992: {'loss': 3.5804, 'learning_rate': 8.668222181354054e-05, 'epoch': 1.76}
Step 993: {'loss': 3.6746, 'learning_rate': 8.647700280167532e-05, 'epoch': 1.77}
Step 994: {'loss': 3.8658, 'learning_rate': 8.627184178625683e-05, 'epoch': 1.77}
Step 995: {'loss': 3.6386, 'learning_rate': 8.606673964716471e-05, 'epoch': 1.77}
Step 996: {'loss': 3.3987, 'learning_rate': 8.586169726402618e-05, 'epoch': 1.77}
Step 997: {'loss': 3.2997, 'learning_rate': 8.5656715516212e-05, 'epoch': 1.77}
Step 998: {'loss': 3.5414, 'learning_rate': 8.545179528283303e-05, 'epoch': 1.77}
Step 999: {'loss': 3.735, 'learning_rate': 8.524693744273627e-05, 'epoch': 1.78}
Step 1000: {'loss': 3.5727, 'learning_rate': 8.504214287450109e-05, 'epoch': 1.78}
Step 1001: {'loss': 3.5704, 'learning_rate': 8.483741245643554e-05, 'epoch': 1.78}
Step 1002: {'loss': 3.8166, 'learning_rate': 8.463274706657262e-05, 'epoch': 1.78}
Step 1003: {'loss': 3.3219, 'learning_rate': 8.442814758266629e-05, 'epoch': 1.78}
Step 1004: {'loss': 3.8112, 'learning_rate': 8.42236148821879e-05, 'epoch': 1.78}
Step 1005: {'loss': 3.6337, 'learning_rate': 8.401914984232255e-05, 'epoch': 1.79}
Step 1006: {'loss': 3.1097, 'learning_rate': 8.381475333996491e-05, 'epoch': 1.79}
Step 1007: {'loss': 3.5281, 'learning_rate': 8.361042625171586e-05, 'epoch': 1.79}
Step 1008: {'loss': 3.1938, 'learning_rate': 8.34061694538786e-05, 'epoch': 1.79}
Step 1009: {'loss': 3.5474, 'learning_rate': 8.320198382245478e-05, 'epoch': 1.79}
Step 1010: {'loss': 3.3232, 'learning_rate': 8.29978702331409e-05, 'epoch': 1.8}
Step 1011: {'loss': 3.4527, 'learning_rate': 8.279382956132452e-05, 'epoch': 1.8}
Step 1012: {'loss': 3.6447, 'learning_rate': 8.258986268208033e-05, 'epoch': 1.8}
Step 1013: {'loss': 3.5896, 'learning_rate': 8.238597047016673e-05, 'epoch': 1.8}
Step 1014: {'loss': 3.5281, 'learning_rate': 8.218215380002178e-05, 'epoch': 1.8}
Step 1015: {'loss': 3.6082, 'learning_rate': 8.197841354575957e-05, 'epoch': 1.8}
Step 1016: {'loss': 3.8548, 'learning_rate': 8.177475058116652e-05, 'epoch': 1.81}
Step 1017: {'loss': 3.4835, 'learning_rate': 8.157116577969751e-05, 'epoch': 1.81}
Step 1018: {'loss': 3.4221, 'learning_rate': 8.136766001447228e-05, 'epoch': 1.81}
Step 1019: {'loss': 3.4207, 'learning_rate': 8.116423415827148e-05, 'epoch': 1.81}
Step 1020: {'loss': 3.7213, 'learning_rate': 8.096088908353315e-05, 'epoch': 1.81}
Step 1021: {'loss': 3.668, 'learning_rate': 8.075762566234891e-05, 'epoch': 1.82}
Step 1022: {'loss': 3.3721, 'learning_rate': 8.055444476646007e-05, 'epoch': 1.82}
Step 1023: {'loss': 4.0786, 'learning_rate': 8.035134726725407e-05, 'epoch': 1.82}
Step 1024: {'loss': 3.6759, 'learning_rate': 8.014833403576077e-05, 'epoch': 1.82}
Step 1025: {'loss': 3.3856, 'learning_rate': 7.994540594264848e-05, 'epoch': 1.82}
Step 1026: {'loss': 3.6971, 'learning_rate': 7.974256385822045e-05, 'epoch': 1.82}
Step 1027: {'loss': 3.655, 'learning_rate': 7.95398086524111e-05, 'epoch': 1.83}
Step 1028: {'loss': 3.8316, 'learning_rate': 7.933714119478219e-05, 'epoch': 1.83}
Step 1029: {'loss': 3.7917, 'learning_rate': 7.913456235451912e-05, 'epoch': 1.83}
Step 1030: {'loss': 3.2904, 'learning_rate': 7.89320730004274e-05, 'epoch': 1.83}
Step 1031: {'loss': 3.5265, 'learning_rate': 7.87296740009285e-05, 'epoch': 1.83}
Step 1032: {'loss': 3.531, 'learning_rate': 7.852736622405663e-05, 'epoch': 1.83}
Step 1033: {'loss': 3.5155, 'learning_rate': 7.832515053745466e-05, 'epoch': 1.84}
Step 1034: {'loss': 3.7202, 'learning_rate': 7.812302780837046e-05, 'epoch': 1.84}
Step 1035: {'loss': 3.5045, 'learning_rate': 7.792099890365333e-05, 'epoch': 1.84}
Step 1036: {'loss': 3.415, 'learning_rate': 7.771906468975017e-05, 'epoch': 1.84}
Step 1037: {'loss': 3.5097, 'learning_rate': 7.751722603270167e-05, 'epoch': 1.84}
Step 1038: {'loss': 3.7256, 'learning_rate': 7.731548379813884e-05, 'epoch': 1.85}
Step 1039: {'loss': 3.9181, 'learning_rate': 7.711383885127911e-05, 'epoch': 1.85}
Step 1040: {'loss': 3.5521, 'learning_rate': 7.69122920569226e-05, 'epoch': 1.85}
Step 1041: {'loss': 3.6396, 'learning_rate': 7.67108442794486e-05, 'epoch': 1.85}
Step 1042: {'loss': 3.6712, 'learning_rate': 7.650949638281168e-05, 'epoch': 1.85}
Step 1043: {'loss': 3.6824, 'learning_rate': 7.630824923053801e-05, 'epoch': 1.85}
Step 1044: {'loss': 3.1534, 'learning_rate': 7.610710368572177e-05, 'epoch': 1.86}
Step 1045: {'loss': 3.4879, 'learning_rate': 7.590606061102137e-05, 'epoch': 1.86}
Step 1046: {'loss': 3.5077, 'learning_rate': 7.570512086865565e-05, 'epoch': 1.86}
Step 1047: {'loss': 3.3974, 'learning_rate': 7.550428532040043e-05, 'epoch': 1.86}
Step 1048: {'loss': 3.9051, 'learning_rate': 7.53035548275846e-05, 'epoch': 1.86}
Step 1049: {'loss': 3.6876, 'learning_rate': 7.510293025108643e-05, 'epoch': 1.86}
Step 1050: {'loss': 3.5228, 'learning_rate': 7.490241245133007e-05, 'epoch': 1.87}
Step 1051: {'loss': 3.9241, 'learning_rate': 7.470200228828168e-05, 'epoch': 1.87}
Step 1052: {'loss': 4.0711, 'learning_rate': 7.450170062144576e-05, 'epoch': 1.87}
Step 1053: {'loss': 3.6095, 'learning_rate': 7.43015083098615e-05, 'epoch': 1.87}
Step 1054: {'loss': 3.5427, 'learning_rate': 7.410142621209922e-05, 'epoch': 1.87}
Step 1055: {'loss': 3.8034, 'learning_rate': 7.390145518625639e-05, 'epoch': 1.88}
Step 1056: {'loss': 3.2283, 'learning_rate': 7.370159608995419e-05, 'epoch': 1.88}
Step 1057: {'loss': 3.5108, 'learning_rate': 7.350184978033386e-05, 'epoch': 1.88}
Step 1058: {'loss': 3.6143, 'learning_rate': 7.330221711405274e-05, 'epoch': 1.88}
Step 1059: {'loss': 3.5092, 'learning_rate': 7.310269894728095e-05, 'epoch': 1.88}
Step 1060: {'loss': 3.5242, 'learning_rate': 7.290329613569751e-05, 'epoch': 1.88}
Step 1061: {'loss': 3.4298, 'learning_rate': 7.270400953448663e-05, 'epoch': 1.89}
Step 1062: {'loss': 3.3639, 'learning_rate': 7.250483999833422e-05, 'epoch': 1.89}
Step 1063: {'loss': 3.4364, 'learning_rate': 7.230578838142413e-05, 'epoch': 1.89}
Step 1064: {'loss': 3.378, 'learning_rate': 7.210685553743441e-05, 'epoch': 1.89}
Step 1065: {'loss': 3.5432, 'learning_rate': 7.190804231953377e-05, 'epoch': 1.89}
Step 1066: {'loss': 3.5067, 'learning_rate': 7.170934958037794e-05, 'epoch': 1.9}
Step 1067: {'loss': 3.4683, 'learning_rate': 7.151077817210583e-05, 'epoch': 1.9}
Step 1068: {'loss': 3.8367, 'learning_rate': 7.131232894633604e-05, 'epoch': 1.9}
Step 1069: {'loss': 3.8838, 'learning_rate': 7.111400275416328e-05, 'epoch': 1.9}
Step 1070: {'loss': 3.6946, 'learning_rate': 7.091580044615434e-05, 'epoch': 1.9}
Step 1071: {'loss': 3.449, 'learning_rate': 7.071772287234497e-05, 'epoch': 1.9}
Step 1072: {'loss': 3.4361, 'learning_rate': 7.051977088223585e-05, 'epoch': 1.91}
Step 1073: {'loss': 3.4016, 'learning_rate': 7.032194532478902e-05, 'epoch': 1.91}
Step 1074: {'loss': 3.4084, 'learning_rate': 7.012424704842441e-05, 'epoch': 1.91}
Step 1075: {'loss': 3.4771, 'learning_rate': 6.992667690101599e-05, 'epoch': 1.91}
Step 1076: {'loss': 3.963, 'learning_rate': 6.972923572988819e-05, 'epoch': 1.91}
Step 1077: {'loss': 3.5376, 'learning_rate': 6.953192438181238e-05, 'epoch': 1.91}
Step 1078: {'loss': 3.7762, 'learning_rate': 6.933474370300316e-05, 'epoch': 1.92}
Step 1079: {'loss': 3.4934, 'learning_rate': 6.913769453911459e-05, 'epoch': 1.92}
Step 1080: {'loss': 3.9428, 'learning_rate': 6.894077773523686e-05, 'epoch': 1.92}
Step 1081: {'loss': 3.7552, 'learning_rate': 6.874399413589245e-05, 'epoch': 1.92}
Step 1082: {'loss': 3.3614, 'learning_rate': 6.854734458503246e-05, 'epoch': 1.92}
Step 1083: {'loss': 3.5356, 'learning_rate': 6.835082992603326e-05, 'epoch': 1.93}
Step 1084: {'loss': 3.8625, 'learning_rate': 6.815445100169261e-05, 'epoch': 1.93}
Step 1085: {'loss': 3.885, 'learning_rate': 6.79582086542261e-05, 'epoch': 1.93}
Step 1086: {'loss': 3.1697, 'learning_rate': 6.776210372526372e-05, 'epoch': 1.93}
Step 1087: {'loss': 3.7079, 'learning_rate': 6.756613705584601e-05, 'epoch': 1.93}
Step 1088: {'loss': 3.6033, 'learning_rate': 6.737030948642051e-05, 'epoch': 1.93}
Step 1089: {'loss': 3.4222, 'learning_rate': 6.71746218568383e-05, 'epoch': 1.94}
Step 1090: {'loss': 3.5064, 'learning_rate': 6.697907500635025e-05, 'epoch': 1.94}
Step 1091: {'loss': 3.5111, 'learning_rate': 6.678366977360344e-05, 'epoch': 1.94}
Step 1092: {'loss': 3.712, 'learning_rate': 6.658840699663764e-05, 'epoch': 1.94}
Step 1093: {'loss': 3.2814, 'learning_rate': 6.639328751288168e-05, 'epoch': 1.94}
Step 1094: {'loss': 3.8801, 'learning_rate': 6.619831215914974e-05, 'epoch': 1.94}
Step 1095: {'loss': 3.4916, 'learning_rate': 6.600348177163796e-05, 'epoch': 1.95}
Step 1096: {'loss': 3.2639, 'learning_rate': 6.58087971859208e-05, 'epoch': 1.95}
Step 1097: {'loss': 3.6638, 'learning_rate': 6.561425923694726e-05, 'epoch': 1.95}
Step 1098: {'loss': 3.5122, 'learning_rate': 6.541986875903755e-05, 'epoch': 1.95}
Step 1099: {'loss': 3.6977, 'learning_rate': 6.52256265858795e-05, 'epoch': 1.95}
Step 1100: {'loss': 3.7724, 'learning_rate': 6.503153355052472e-05, 'epoch': 1.96}
Step 1101: {'loss': 3.3195, 'learning_rate': 6.483759048538532e-05, 'epoch': 1.96}
Step 1102: {'loss': 3.6366, 'learning_rate': 6.464379822223028e-05, 'epoch': 1.96}
Step 1103: {'loss': 3.8199, 'learning_rate': 6.445015759218169e-05, 'epoch': 1.96}
Step 1104: {'loss': 3.4993, 'learning_rate': 6.42566694257114e-05, 'epoch': 1.96}
Step 1105: {'loss': 4.1058, 'learning_rate': 6.406333455263746e-05, 'epoch': 1.96}
Step 1106: {'loss': 3.6724, 'learning_rate': 6.387015380212029e-05, 'epoch': 1.97}
Step 1107: {'loss': 3.7146, 'learning_rate': 6.367712800265955e-05, 'epoch': 1.97}
Step 1108: {'loss': 3.2415, 'learning_rate': 6.348425798209016e-05, 'epoch': 1.97}
Step 1109: {'loss': 3.7974, 'learning_rate': 6.329154456757914e-05, 'epoch': 1.97}
Step 1110: {'loss': 3.5489, 'learning_rate': 6.309898858562169e-05, 'epoch': 1.97}
Step 1111: {'loss': 3.8275, 'learning_rate': 6.290659086203787e-05, 'epoch': 1.98}
Step 1112: {'loss': 3.1371, 'learning_rate': 6.271435222196916e-05, 'epoch': 1.98}
Step 1113: {'loss': 3.0583, 'learning_rate': 6.252227348987454e-05, 'epoch': 1.98}
Step 1114: {'loss': 3.2994, 'learning_rate': 6.233035548952734e-05, 'epoch': 1.98}
Step 1115: {'loss': 3.6361, 'learning_rate': 6.213859904401156e-05, 'epoch': 1.98}
Step 1116: {'loss': 3.3426, 'learning_rate': 6.194700497571826e-05, 'epoch': 1.98}
Step 1117: {'loss': 3.4575, 'learning_rate': 6.175557410634212e-05, 'epoch': 1.99}
Step 1118: {'loss': 3.2367, 'learning_rate': 6.1564307256878e-05, 'epoch': 1.99}
Step 1119: {'loss': 3.3301, 'learning_rate': 6.137320524761721e-05, 'epoch': 1.99}
Step 1120: {'loss': 3.7273, 'learning_rate': 6.118226889814409e-05, 'epoch': 1.99}
Step 1121: {'loss': 3.4658, 'learning_rate': 6.099149902733269e-05, 'epoch': 1.99}
Step 1122: {'loss': 3.7816, 'learning_rate': 6.080089645334286e-05, 'epoch': 1.99}
Step 1123: {'loss': 3.669, 'learning_rate': 6.0610461993617066e-05, 'epoch': 2.0}
Step 1124: {'loss': 3.3867, 'learning_rate': 6.042019646487685e-05, 'epoch': 2.0}
Step 1125: {'loss': 3.8506, 'learning_rate': 6.023010068311905e-05, 'epoch': 2.0}
Step 1126: {'loss': 3.6133, 'learning_rate': 6.0040175463612716e-05, 'epoch': 2.0}
Step 1127: {'loss': 3.8994, 'learning_rate': 5.985042162089529e-05, 'epoch': 2.0}
Step 1128: {'loss': 3.7288, 'learning_rate': 5.966083996876921e-05, 'epoch': 2.01}
Step 1129: {'loss': 3.6295, 'learning_rate': 5.947143132029853e-05, 'epoch': 2.01}
Step 1130: {'loss': 3.4853, 'learning_rate': 5.928219648780529e-05, 'epoch': 2.01}
Step 1131: {'loss': 3.4794, 'learning_rate': 5.909313628286601e-05, 'epoch': 2.01}
Step 1132: {'loss': 3.7557, 'learning_rate': 5.890425151630841e-05, 'epoch': 2.01}
Step 1133: {'loss': 3.4884, 'learning_rate': 5.871554299820774e-05, 'epoch': 2.01}
Step 1134: {'loss': 3.2017, 'learning_rate': 5.852701153788329e-05, 'epoch': 2.02}
Step 1135: {'loss': 3.4505, 'learning_rate': 5.833865794389515e-05, 'epoch': 2.02}
Step 1136: {'loss': 3.8575, 'learning_rate': 5.8150483024040494e-05, 'epoch': 2.02}
Step 1137: {'loss': 3.6046, 'learning_rate': 5.796248758535021e-05, 'epoch': 2.02}
Step 1138: {'loss': 3.5594, 'learning_rate': 5.77746724340855e-05, 'epoch': 2.02}
Step 1139: {'loss': 3.7049, 'learning_rate': 5.758703837573428e-05, 'epoch': 2.02}
Step 1140: {'loss': 3.1742, 'learning_rate': 5.7399586215007875e-05, 'epoch': 2.03}
Step 1141: {'loss': 3.5598, 'learning_rate': 5.721231675583748e-05, 'epoch': 2.03}
Step 1142: {'loss': 3.6678, 'learning_rate': 5.702523080137072e-05, 'epoch': 2.03}
Step 1143: {'loss': 3.7255, 'learning_rate': 5.683832915396823e-05, 'epoch': 2.03}
Step 1144: {'loss': 3.4344, 'learning_rate': 5.665161261520021e-05, 'epoch': 2.03}
Step 1145: {'loss': 3.5919, 'learning_rate': 5.6465081985842996e-05, 'epoch': 2.04}
Step 1146: {'loss': 3.2561, 'learning_rate': 5.627873806587548e-05, 'epoch': 2.04}
Step 1147: {'loss': 3.2619, 'learning_rate': 5.609258165447602e-05, 'epoch': 2.04}
Step 1148: {'loss': 3.507, 'learning_rate': 5.5906613550018696e-05, 'epoch': 2.04}
Step 1149: {'loss': 3.3612, 'learning_rate': 5.5720834550069854e-05, 'epoch': 2.04}
Step 1150: {'loss': 3.2424, 'learning_rate': 5.55352454513851e-05, 'epoch': 2.04}
Step 1151: {'loss': 3.4664, 'learning_rate': 5.5349847049905445e-05, 'epoch': 2.05}
Step 1152: {'loss': 3.709, 'learning_rate': 5.516464014075395e-05, 'epoch': 2.05}
Step 1153: {'loss': 3.4551, 'learning_rate': 5.497962551823266e-05, 'epoch': 2.05}
Step 1154: {'loss': 3.5975, 'learning_rate': 5.479480397581884e-05, 'epoch': 2.05}
Step 1155: {'loss': 3.427, 'learning_rate': 5.4610176306161545e-05, 'epoch': 2.05}
Step 1156: {'loss': 3.4478, 'learning_rate': 5.44257433010786e-05, 'epoch': 2.06}
Step 1157: {'loss': 3.7186, 'learning_rate': 5.424150575155289e-05, 'epoch': 2.06}
Step 1158: {'loss': 3.7073, 'learning_rate': 5.405746444772888e-05, 'epoch': 2.06}
Step 1159: {'loss': 3.9696, 'learning_rate': 5.387362017890967e-05, 'epoch': 2.06}
Step 1160: {'loss': 3.8205, 'learning_rate': 5.3689973733553154e-05, 'epoch': 2.06}
Step 1161: {'loss': 3.437, 'learning_rate': 5.3506525899268746e-05, 'epoch': 2.06}
Step 1162: {'loss': 3.6571, 'learning_rate': 5.332327746281429e-05, 'epoch': 2.07}
Step 1163: {'loss': 3.6029, 'learning_rate': 5.314022921009236e-05, 'epoch': 2.07}
Step 1164: {'loss': 3.5335, 'learning_rate': 5.295738192614691e-05, 'epoch': 2.07}
Step 1165: {'loss': 3.5449, 'learning_rate': 5.277473639516006e-05, 'epoch': 2.07}
Step 1166: {'loss': 3.3788, 'learning_rate': 5.25922934004488e-05, 'epoch': 2.07}
Step 1167: {'loss': 3.4031, 'learning_rate': 5.241005372446126e-05, 'epoch': 2.07}
Step 1168: {'loss': 3.3977, 'learning_rate': 5.222801814877369e-05, 'epoch': 2.08}
Step 1169: {'loss': 3.614, 'learning_rate': 5.204618745408718e-05, 'epoch': 2.08}
Step 1170: {'loss': 3.3816, 'learning_rate': 5.186456242022384e-05, 'epoch': 2.08}
Step 1171: {'loss': 3.3445, 'learning_rate': 5.1683143826123916e-05, 'epoch': 2.08}
Step 1172: {'loss': 3.5104, 'learning_rate': 5.150193244984238e-05, 'epoch': 2.08}
Step 1173: {'loss': 3.5006, 'learning_rate': 5.132092906854532e-05, 'epoch': 2.09}
Step 1174: {'loss': 3.6356, 'learning_rate': 5.114013445850684e-05, 'epoch': 2.09}
Step 1175: {'loss': 3.3536, 'learning_rate': 5.095954939510583e-05, 'epoch': 2.09}
Step 1176: {'loss': 3.6304, 'learning_rate': 5.0779174652822284e-05, 'epoch': 2.09}
Step 1177: {'loss': 3.1021, 'learning_rate': 5.0599011005234255e-05, 'epoch': 2.09}
Step 1178: {'loss': 3.4406, 'learning_rate': 5.0419059225014595e-05, 'epoch': 2.09}
Step 1179: {'loss': 3.6606, 'learning_rate': 5.023932008392733e-05, 'epoch': 2.1}
Step 1180: {'loss': 3.7878, 'learning_rate': 5.0059794352824596e-05, 'epoch': 2.1}
Step 1181: {'loss': 3.8422, 'learning_rate': 4.98804828016434e-05, 'epoch': 2.1}
Step 1182: {'loss': 3.8625, 'learning_rate': 4.9701386199401964e-05, 'epoch': 2.1}
Step 1183: {'loss': 3.6171, 'learning_rate': 4.952250531419682e-05, 'epoch': 2.1}
Step 1184: {'loss': 3.9285, 'learning_rate': 4.934384091319929e-05, 'epoch': 2.1}
Step 1185: {'loss': 3.2477, 'learning_rate': 4.916539376265226e-05, 'epoch': 2.11}
Step 1186: {'loss': 3.425, 'learning_rate': 4.898716462786689e-05, 'epoch': 2.11}
Step 1187: {'loss': 3.2302, 'learning_rate': 4.880915427321933e-05, 'epoch': 2.11}
Step 1188: {'loss': 3.2733, 'learning_rate': 4.863136346214744e-05, 'epoch': 2.11}
Step 1189: {'loss': 3.5796, 'learning_rate': 4.845379295714751e-05, 'epoch': 2.11}
Step 1190: {'loss': 3.9244, 'learning_rate': 4.827644351977103e-05, 'epoch': 2.12}
Step 1191: {'loss': 3.7669, 'learning_rate': 4.8099315910621354e-05, 'epoch': 2.12}
Step 1192: {'loss': 3.4594, 'learning_rate': 4.792241088935049e-05, 'epoch': 2.12}
Step 1193: {'loss': 3.5309, 'learning_rate': 4.774572921465581e-05, 'epoch': 2.12}
Step 1194: {'loss': 3.464, 'learning_rate': 4.756927164427685e-05, 'epoch': 2.12}
Step 1195: {'loss': 3.469, 'learning_rate': 4.7393038934991995e-05, 'epoch': 2.12}
Step 1196: {'loss': 3.7939, 'learning_rate': 4.721703184261522e-05, 'epoch': 2.13}
Step 1197: {'loss': 3.687, 'learning_rate': 4.704125112199308e-05, 'epoch': 2.13}
Step 1198: {'loss': 3.6719, 'learning_rate': 4.686569752700101e-05, 'epoch': 2.13}
Step 1199: {'loss': 3.7158, 'learning_rate': 4.6690371810540515e-05, 'epoch': 2.13}
Step 1200: {'loss': 3.7833, 'learning_rate': 4.651527472453586e-05, 'epoch': 2.13}
Step 1201: {'loss': 3.8971, 'learning_rate': 4.634040701993061e-05, 'epoch': 2.14}
Step 1202: {'loss': 3.4245, 'learning_rate': 4.616576944668467e-05, 'epoch': 2.14}
Step 1203: {'loss': 3.7537, 'learning_rate': 4.5991362753770985e-05, 'epoch': 2.14}
Step 1204: {'loss': 3.8586, 'learning_rate': 4.581718768917228e-05, 'epoch': 2.14}
Step 1205: {'loss': 3.4195, 'learning_rate': 4.56432449998779e-05, 'epoch': 2.14}
Step 1206: {'loss': 3.7385, 'learning_rate': 4.5469535431880603e-05, 'epoch': 2.14}
Step 1207: {'loss': 3.4141, 'learning_rate': 4.5296059730173344e-05, 'epoch': 2.15}
Step 1208: {'loss': 3.4938, 'learning_rate': 4.512281863874611e-05, 'epoch': 2.15}
Step 1209: {'loss': 3.3698, 'learning_rate': 4.4949812900582676e-05, 'epoch': 2.15}
Step 1210: {'loss': 3.2815, 'learning_rate': 4.477704325765748e-05, 'epoch': 2.15}
Step 1211: {'loss': 3.5907, 'learning_rate': 4.460451045093239e-05, 'epoch': 2.15}
Step 1212: {'loss': 3.8112, 'learning_rate': 4.443221522035357e-05, 'epoch': 2.15}
Step 1213: {'loss': 3.605, 'learning_rate': 4.4260158304848254e-05, 'epoch': 2.16}
Step 1214: {'loss': 3.4224, 'learning_rate': 4.408834044232164e-05, 'epoch': 2.16}
Step 1215: {'loss': 3.6603, 'learning_rate': 4.3916762369653685e-05, 'epoch': 2.16}
Step 1216: {'loss': 3.643, 'learning_rate': 4.3745424822695924e-05, 'epoch': 2.16}
Step 1217: {'loss': 3.3152, 'learning_rate': 4.3574328536268394e-05, 'epoch': 2.16}
Step 1218: {'loss': 3.8834, 'learning_rate': 4.340347424415638e-05, 'epoch': 2.17}
Step 1219: {'loss': 3.2665, 'learning_rate': 4.323286267910736e-05, 'epoch': 2.17}
Step 1220: {'loss': 4.0072, 'learning_rate': 4.306249457282778e-05, 'epoch': 2.17}
Step 1221: {'loss': 3.2134, 'learning_rate': 4.2892370655980005e-05, 'epoch': 2.17}
Step 1222: {'loss': 3.3912, 'learning_rate': 4.2722491658179123e-05, 'epoch': 2.17}
Step 1223: {'loss': 3.3688, 'learning_rate': 4.255285830798979e-05, 'epoch': 2.17}
Step 1224: {'loss': 3.308, 'learning_rate': 4.238347133292321e-05, 'epoch': 2.18}
Step 1225: {'loss': 3.5835, 'learning_rate': 4.22143314594339e-05, 'epoch': 2.18}
Step 1226: {'loss': 3.431, 'learning_rate': 4.204543941291665e-05, 'epoch': 2.18}
Step 1227: {'loss': 3.9486, 'learning_rate': 4.1876795917703405e-05, 'epoch': 2.18}
Step 1228: {'loss': 3.5327, 'learning_rate': 4.1708401697060104e-05, 'epoch': 2.18}
Step 1229: {'loss': 3.4258, 'learning_rate': 4.154025747318363e-05, 'epoch': 2.18}
Step 1230: {'loss': 3.6412, 'learning_rate': 4.13723639671987e-05, 'epoch': 2.19}
Step 1231: {'loss': 3.9006, 'learning_rate': 4.120472189915479e-05, 'epoch': 2.19}
Step 1232: {'loss': 3.5632, 'learning_rate': 4.1037331988022976e-05, 'epoch': 2.19}
Step 1233: {'loss': 3.7905, 'learning_rate': 4.087019495169295e-05, 'epoch': 2.19}
Step 1234: {'loss': 3.5935, 'learning_rate': 4.070331150696988e-05, 'epoch': 2.19}
Step 1235: {'loss': 3.4282, 'learning_rate': 4.053668236957134e-05, 'epoch': 2.2}
Step 1236: {'loss': 3.4157, 'learning_rate': 4.037030825412429e-05, 'epoch': 2.2}
Step 1237: {'loss': 3.721, 'learning_rate': 4.020418987416183e-05, 'epoch': 2.2}
Step 1238: {'loss': 3.8402, 'learning_rate': 4.003832794212048e-05, 'epoch': 2.2}
Step 1239: {'loss': 3.632, 'learning_rate': 3.987272316933685e-05, 'epoch': 2.2}
Step 1240: {'loss': 3.9413, 'learning_rate': 3.9707376266044524e-05, 'epoch': 2.2}
Step 1241: {'loss': 3.6019, 'learning_rate': 3.954228794137138e-05, 'epoch': 2.21}
Step 1242: {'loss': 3.2212, 'learning_rate': 3.937745890333623e-05, 'epoch': 2.21}
Step 1243: {'loss': 3.5547, 'learning_rate': 3.9212889858845745e-05, 'epoch': 2.21}
Step 1244: {'loss': 3.557, 'learning_rate': 3.9048581513691776e-05, 'epoch': 2.21}
Step 1245: {'loss': 3.6797, 'learning_rate': 3.8884534572548014e-05, 'epoch': 2.21}
Step 1246: {'loss': 3.7009, 'learning_rate': 3.872074973896692e-05, 'epoch': 2.22}
Step 1247: {'loss': 3.5299, 'learning_rate': 3.8557227715377117e-05, 'epoch': 2.22}
Step 1248: {'loss': 3.7684, 'learning_rate': 3.8393969203079924e-05, 'epoch': 2.22}
Step 1249: {'loss': 3.3761, 'learning_rate': 3.823097490224651e-05, 'epoch': 2.22}
Step 1250: {'loss': 3.5891, 'learning_rate': 3.806824551191505e-05, 'epoch': 2.22}
Step 1251: {'loss': 3.6074, 'learning_rate': 3.7905781729987536e-05, 'epoch': 2.22}
Step 1252: {'loss': 3.9471, 'learning_rate': 3.774358425322669e-05, 'epoch': 2.23}
Step 1253: {'loss': 3.6244, 'learning_rate': 3.758165377725338e-05, 'epoch': 2.23}
Step 1254: {'loss': 3.5518, 'learning_rate': 3.7419990996543245e-05, 'epoch': 2.23}
Step 1255: {'loss': 3.7399, 'learning_rate': 3.7258596604423756e-05, 'epoch': 2.23}
Step 1256: {'loss': 3.5213, 'learning_rate': 3.709747129307155e-05, 'epoch': 2.23}
Step 1257: {'loss': 3.8756, 'learning_rate': 3.693661575350914e-05, 'epoch': 2.23}
Step 1258: {'loss': 3.5855, 'learning_rate': 3.6776030675601993e-05, 'epoch': 2.24}
Step 1259: {'loss': 3.7, 'learning_rate': 3.6615716748055704e-05, 'epoch': 2.24}
Step 1260: {'loss': 3.8095, 'learning_rate': 3.645567465841311e-05, 'epoch': 2.24}
Step 1261: {'loss': 3.4349, 'learning_rate': 3.629590509305097e-05, 'epoch': 2.24}
Step 1262: {'loss': 3.6005, 'learning_rate': 3.613640873717735e-05, 'epoch': 2.24}
Step 1263: {'loss': 3.6097, 'learning_rate': 3.597718627482876e-05, 'epoch': 2.25}
Step 1264: {'loss': 4.0757, 'learning_rate': 3.581823838886679e-05, 'epoch': 2.25}
Step 1265: {'loss': 3.5429, 'learning_rate': 3.5659565760975576e-05, 'epoch': 2.25}
Step 1266: {'loss': 3.4748, 'learning_rate': 3.550116907165886e-05, 'epoch': 2.25}
Step 1267: {'loss': 3.5703, 'learning_rate': 3.534304900023672e-05, 'epoch': 2.25}
Step 1268: {'loss': 3.761, 'learning_rate': 3.5185206224843025e-05, 'epoch': 2.25}
Step 1269: {'loss': 3.4363, 'learning_rate': 3.502764142242249e-05, 'epoch': 2.26}
Step 1270: {'loss': 3.4995, 'learning_rate': 3.487035526872747e-05, 'epoch': 2.26}
Step 1271: {'loss': 3.6553, 'learning_rate': 3.4713348438315396e-05, 'epoch': 2.26}
Step 1272: {'loss': 3.2978, 'learning_rate': 3.455662160454584e-05, 'epoch': 2.26}
Step 1273: {'loss': 3.4803, 'learning_rate': 3.440017543957733e-05, 'epoch': 2.26}
Step 1274: {'loss': 3.4232, 'learning_rate': 3.424401061436482e-05, 'epoch': 2.26}
Step 1275: {'loss': 3.6298, 'learning_rate': 3.4088127798656744e-05, 'epoch': 2.27}
Step 1276: {'loss': 3.7546, 'learning_rate': 3.393252766099187e-05, 'epoch': 2.27}
Step 1277: {'loss': 4.2042, 'learning_rate': 3.3777210868696804e-05, 'epoch': 2.27}
Step 1278: {'loss': 3.5681, 'learning_rate': 3.3622178087882905e-05, 'epoch': 2.27}
Step 1279: {'loss': 3.5355, 'learning_rate': 3.346742998344348e-05, 'epoch': 2.27}
Step 1280: {'loss': 3.7352, 'learning_rate': 3.331296721905095e-05, 'epoch': 2.28}
Step 1281: {'loss': 3.4828, 'learning_rate': 3.3158790457153966e-05, 'epoch': 2.28}
Step 1282: {'loss': 3.416, 'learning_rate': 3.3004900358974636e-05, 'epoch': 2.28}
Step 1283: {'loss': 3.6567, 'learning_rate': 3.28512975845056e-05, 'epoch': 2.28}
Step 1284: {'loss': 3.4716, 'learning_rate': 3.2697982792507277e-05, 'epoch': 2.28}
Step 1285: {'loss': 3.5792, 'learning_rate': 3.254495664050498e-05, 'epoch': 2.28}
Step 1286: {'loss': 3.4602, 'learning_rate': 3.2392219784786146e-05, 'epoch': 2.29}
Step 1287: {'loss': 3.8391, 'learning_rate': 3.223977288039748e-05, 'epoch': 2.29}
Step 1288: {'loss': 3.5229, 'learning_rate': 3.208761658114224e-05, 'epoch': 2.29}
Step 1289: {'loss': 3.5363, 'learning_rate': 3.193575153957722e-05, 'epoch': 2.29}
Step 1290: {'loss': 3.5823, 'learning_rate': 3.178417840701016e-05, 'epoch': 2.29}
Step 1291: {'loss': 3.685, 'learning_rate': 3.163289783349698e-05, 'epoch': 2.3}
Step 1292: {'loss': 3.6594, 'learning_rate': 3.1481910467838694e-05, 'epoch': 2.3}
Step 1293: {'loss': 3.7549, 'learning_rate': 3.133121695757896e-05, 'epoch': 2.3}
Step 1294: {'loss': 3.5195, 'learning_rate': 3.118081794900122e-05, 'epoch': 2.3}
Step 1295: {'loss': 3.5853, 'learning_rate': 3.10307140871257e-05, 'epoch': 2.3}
Step 1296: {'loss': 3.5204, 'learning_rate': 3.0880906015706966e-05, 'epoch': 2.3}
Step 1297: {'loss': 3.7175, 'learning_rate': 3.0731394377230994e-05, 'epoch': 2.31}
Step 1298: {'loss': 3.2943, 'learning_rate': 3.0582179812912396e-05, 'epoch': 2.31}
Step 1299: {'loss': 3.6234, 'learning_rate': 3.0433262962691754e-05, 'epoch': 2.31}
Step 1300: {'loss': 3.622, 'learning_rate': 3.0284644465232824e-05, 'epoch': 2.31}
Step 1301: {'loss': 3.7854, 'learning_rate': 3.0136324957919816e-05, 'epoch': 2.31}
Step 1302: {'loss': 3.2745, 'learning_rate': 2.998830507685463e-05, 'epoch': 2.31}
Step 1303: {'loss': 3.5244, 'learning_rate': 2.9840585456854175e-05, 'epoch': 2.32}
Step 1304: {'loss': 3.4441, 'learning_rate': 2.969316673144761e-05, 'epoch': 2.32}
Step 1305: {'loss': 4.1102, 'learning_rate': 2.9546049532873644e-05, 'epoch': 2.32}
Step 1306: {'loss': 3.5418, 'learning_rate': 2.9399234492077798e-05, 'epoch': 2.32}
Step 1307: {'loss': 3.3274, 'learning_rate': 2.9252722238709774e-05, 'epoch': 2.32}
Step 1308: {'loss': 3.532, 'learning_rate': 2.910651340112064e-05, 'epoch': 2.33}
Step 1309: {'loss': 3.3327, 'learning_rate': 2.8960608606360238e-05, 'epoch': 2.33}
Step 1310: {'loss': 3.33, 'learning_rate': 2.8815008480174433e-05, 'epoch': 2.33}
Step 1311: {'loss': 3.6489, 'learning_rate': 2.866971364700246e-05, 'epoch': 2.33}
Step 1312: {'loss': 3.7808, 'learning_rate': 2.8524724729974228e-05, 'epoch': 2.33}
Step 1313: {'loss': 3.5359, 'learning_rate': 2.8380042350907655e-05, 'epoch': 2.33}
Step 1314: {'loss': 3.8378, 'learning_rate': 2.8235667130306008e-05, 'epoch': 2.34}
Step 1315: {'loss': 3.3071, 'learning_rate': 2.809159968735524e-05, 'epoch': 2.34}
Step 1316: {'loss': 3.5116, 'learning_rate': 2.794784063992131e-05, 'epoch': 2.34}
Step 1317: {'loss': 3.5677, 'learning_rate': 2.7804390604547557e-05, 'epoch': 2.34}
Step 1318: {'loss': 3.2573, 'learning_rate': 2.7661250196452083e-05, 'epoch': 2.34}
Step 1319: {'loss': 3.4054, 'learning_rate': 2.7518420029525026e-05, 'epoch': 2.34}
Step 1320: {'loss': 3.3475, 'learning_rate': 2.7375900716326053e-05, 'epoch': 2.35}
Step 1321: {'loss': 3.7814, 'learning_rate': 2.7233692868081605e-05, 'epoch': 2.35}
Step 1322: {'loss': 3.8623, 'learning_rate': 2.7091797094682358e-05, 'epoch': 2.35}
Step 1323: {'loss': 3.5758, 'learning_rate': 2.6950214004680596e-05, 'epoch': 2.35}
Step 1324: {'loss': 3.2477, 'learning_rate': 2.6808944205287566e-05, 'epoch': 2.35}
Step 1325: {'loss': 3.5551, 'learning_rate': 2.6667988302370904e-05, 'epoch': 2.36}
Step 1326: {'loss': 3.5275, 'learning_rate': 2.6527346900452054e-05, 'epoch': 2.36}
Step 1327: {'loss': 3.2552, 'learning_rate': 2.6387020602703615e-05, 'epoch': 2.36}
Step 1328: {'loss': 3.6959, 'learning_rate': 2.6247010010946805e-05, 'epoch': 2.36}
Step 1329: {'loss': 3.449, 'learning_rate': 2.6107315725648875e-05, 'epoch': 2.36}
Step 1330: {'loss': 3.5754, 'learning_rate': 2.5967938345920527e-05, 'epoch': 2.36}
Step 1331: {'loss': 3.2922, 'learning_rate': 2.5828878469513262e-05, 'epoch': 2.37}
Step 1332: {'loss': 3.3205, 'learning_rate': 2.5690136692817045e-05, 'epoch': 2.37}
Step 1333: {'loss': 3.6227, 'learning_rate': 2.555171361085751e-05, 'epoch': 2.37}
Step 1334: {'loss': 3.6652, 'learning_rate': 2.5413609817293425e-05, 'epoch': 2.37}
Step 1335: {'loss': 3.4289, 'learning_rate': 2.5275825904414362e-05, 'epoch': 2.37}
Step 1336: {'loss': 3.4352, 'learning_rate': 2.5138362463137967e-05, 'epoch': 2.38}
Step 1337: {'loss': 3.5476, 'learning_rate': 2.5001220083007347e-05, 'epoch': 2.38}
Step 1338: {'loss': 3.7851, 'learning_rate': 2.4864399352188872e-05, 'epoch': 2.38}
Step 1339: {'loss': 3.3721, 'learning_rate': 2.472790085746931e-05, 'epoch': 2.38}
Step 1340: {'loss': 3.6798, 'learning_rate': 2.4591725184253412e-05, 'epoch': 2.38}
Step 1341: {'loss': 3.3706, 'learning_rate': 2.4455872916561583e-05, 'epoch': 2.38}
Step 1342: {'loss': 3.6805, 'learning_rate': 2.432034463702715e-05, 'epoch': 2.39}
Step 1343: {'loss': 3.2973, 'learning_rate': 2.4185140926893845e-05, 'epoch': 2.39}
Step 1344: {'loss': 3.6494, 'learning_rate': 2.4050262366013597e-05, 'epoch': 2.39}
Step 1345: {'loss': 3.3916, 'learning_rate': 2.3915709532843765e-05, 'epoch': 2.39}
Step 1346: {'loss': 3.2687, 'learning_rate': 2.3781483004444673e-05, 'epoch': 2.39}
Step 1347: {'loss': 3.7546, 'learning_rate': 2.3647583356477377e-05, 'epoch': 2.39}
Step 1348: {'loss': 3.7242, 'learning_rate': 2.3514011163200934e-05, 'epoch': 2.4}
Step 1349: {'loss': 3.3818, 'learning_rate': 2.3380766997470015e-05, 'epoch': 2.4}
Step 1350: {'loss': 3.6357, 'learning_rate': 2.3247851430732494e-05, 'epoch': 2.4}
Step 1351: {'loss': 3.6404, 'learning_rate': 2.3115265033027068e-05, 'epoch': 2.4}
Step 1352: {'loss': 3.8308, 'learning_rate': 2.2983008372980552e-05, 'epoch': 2.4}
Step 1353: {'loss': 3.8276, 'learning_rate': 2.2851082017805703e-05, 'epoch': 2.41}
Step 1354: {'loss': 3.3367, 'learning_rate': 2.271948653329875e-05, 'epoch': 2.41}
Step 1355: {'loss': 3.7256, 'learning_rate': 2.258822248383674e-05, 'epoch': 2.41}
Step 1356: {'loss': 3.76, 'learning_rate': 2.245729043237541e-05, 'epoch': 2.41}
Step 1357: {'loss': 3.602, 'learning_rate': 2.2326690940446682e-05, 'epoch': 2.41}
Step 1358: {'loss': 3.483, 'learning_rate': 2.2196424568156073e-05, 'epoch': 2.41}
Step 1359: {'loss': 3.8141, 'learning_rate': 2.2066491874180528e-05, 'epoch': 2.42}
Step 1360: {'loss': 4.0258, 'learning_rate': 2.1936893415766025e-05, 'epoch': 2.42}
Step 1361: {'loss': 3.3332, 'learning_rate': 2.180762974872491e-05, 'epoch': 2.42}
Step 1362: {'loss': 3.4533, 'learning_rate': 2.16787014274338e-05, 'epoch': 2.42}
Step 1363: {'loss': 3.5796, 'learning_rate': 2.1550109004831198e-05, 'epoch': 2.42}
Step 1364: {'loss': 3.3235, 'learning_rate': 2.142185303241483e-05, 'epoch': 2.42}
Step 1365: {'loss': 3.7438, 'learning_rate': 2.1293934060239597e-05, 'epoch': 2.43}
Step 1366: {'loss': 3.9076, 'learning_rate': 2.1166352636915156e-05, 'epoch': 2.43}
Step 1367: {'loss': 3.4722, 'learning_rate': 2.1039109309603354e-05, 'epoch': 2.43}
Step 1368: {'loss': 3.8223, 'learning_rate': 2.091220462401612e-05, 'epoch': 2.43}
Step 1369: {'loss': 4.2688, 'learning_rate': 2.0785639124413114e-05, 'epoch': 2.43}
Step 1370: {'loss': 3.7523, 'learning_rate': 2.065941335359918e-05, 'epoch': 2.44}
Step 1371: {'loss': 3.5675, 'learning_rate': 2.0533527852922218e-05, 'epoch': 2.44}
Step 1372: {'loss': 3.7909, 'learning_rate': 2.040798316227085e-05, 'epoch': 2.44}
Step 1373: {'loss': 3.6635, 'learning_rate': 2.0282779820071974e-05, 'epoch': 2.44}
Step 1374: {'loss': 3.9172, 'learning_rate': 2.0157918363288607e-05, 'epoch': 2.44}
Step 1375: {'loss': 3.7897, 'learning_rate': 2.0033399327417436e-05, 'epoch': 2.44}
Step 1376: {'loss': 3.5254, 'learning_rate': 1.990922324648673e-05, 'epoch': 2.45}
Step 1377: {'loss': 3.7416, 'learning_rate': 1.978539065305376e-05, 'epoch': 2.45}
Step 1378: {'loss': 3.8142, 'learning_rate': 1.966190207820274e-05, 'epoch': 2.45}
Step 1379: {'loss': 4.007, 'learning_rate': 1.953875805154256e-05, 'epoch': 2.45}
Step 1380: {'loss': 3.753, 'learning_rate': 1.9415959101204296e-05, 'epoch': 2.45}
Step 1381: {'loss': 3.5542, 'learning_rate': 1.9293505753839158e-05, 'epoch': 2.46}
Step 1382: {'loss': 3.4426, 'learning_rate': 1.9171398534616214e-05, 'epoch': 2.46}
Step 1383: {'loss': 3.6759, 'learning_rate': 1.904963796721997e-05, 'epoch': 2.46}
Step 1384: {'loss': 3.7618, 'learning_rate': 1.8928224573848262e-05, 'epoch': 2.46}
Step 1385: {'loss': 3.6453, 'learning_rate': 1.880715887521013e-05, 'epoch': 2.46}
Step 1386: {'loss': 3.6587, 'learning_rate': 1.8686441390523246e-05, 'epoch': 2.46}
Step 1387: {'loss': 3.6694, 'learning_rate': 1.8566072637511967e-05, 'epoch': 2.47}
Step 1388: {'loss': 3.336, 'learning_rate': 1.844605313240513e-05, 'epoch': 2.47}
Step 1389: {'loss': 3.6384, 'learning_rate': 1.8326383389933587e-05, 'epoch': 2.47}
Step 1390: {'loss': 3.5485, 'learning_rate': 1.8207063923328237e-05, 'epoch': 2.47}
Step 1391: {'loss': 3.229, 'learning_rate': 1.808809524431775e-05, 'epoch': 2.47}
Step 1392: {'loss': 3.5708, 'learning_rate': 1.7969477863126328e-05, 'epoch': 2.47}
Step 1393: {'loss': 3.6926, 'learning_rate': 1.7851212288471574e-05, 'epoch': 2.48}
Step 1394: {'loss': 3.6442, 'learning_rate': 1.773329902756228e-05, 'epoch': 2.48}
Step 1395: {'loss': 3.6426, 'learning_rate': 1.7615738586096264e-05, 'epoch': 2.48}
Step 1396: {'loss': 3.5801, 'learning_rate': 1.7498531468258184e-05, 'epoch': 2.48}
Step 1397: {'loss': 3.4819, 'learning_rate': 1.738167817671742e-05, 'epoch': 2.48}
Step 1398: {'loss': 3.7274, 'learning_rate': 1.726517921262586e-05, 'epoch': 2.49}
Step 1399: {'loss': 4.0029, 'learning_rate': 1.7149035075615794e-05, 'epoch': 2.49}
Step 1400: {'loss': 3.6223, 'learning_rate': 1.7033246263797743e-05, 'epoch': 2.49}
Step 1401: {'loss': 3.2648, 'learning_rate': 1.6917813273758333e-05, 'epoch': 2.49}
Step 1402: {'loss': 3.6645, 'learning_rate': 1.680273660055819e-05, 'epoch': 2.49}
Step 1403: {'loss': 3.2892, 'learning_rate': 1.6688016737729773e-05, 'epoch': 2.49}
Step 1404: {'loss': 3.6405, 'learning_rate': 1.657365417727529e-05, 'epoch': 2.5}
Step 1405: {'loss': 3.9853, 'learning_rate': 1.645964940966457e-05, 'epoch': 2.5}
Step 1406: {'loss': 3.8684, 'learning_rate': 1.6346002923832958e-05, 'epoch': 2.5}
Step 1407: {'loss': 3.6325, 'learning_rate': 1.623271520717925e-05, 'epoch': 2.5}
Step 1408: {'loss': 3.6263, 'learning_rate': 1.6119786745563546e-05, 'epoch': 2.5}
Step 1409: {'loss': 3.6619, 'learning_rate': 1.600721802330525e-05, 'epoch': 2.5}
Step 1410: {'loss': 3.6431, 'learning_rate': 1.589500952318088e-05, 'epoch': 2.51}
Step 1411: {'loss': 3.9595, 'learning_rate': 1.57831617264221e-05, 'epoch': 2.51}
Step 1412: {'loss': 3.4614, 'learning_rate': 1.5671675112713613e-05, 'epoch': 2.51}
Step 1413: {'loss': 3.4442, 'learning_rate': 1.556055016019109e-05, 'epoch': 2.51}
Step 1414: {'loss': 3.8076, 'learning_rate': 1.544978734543914e-05, 'epoch': 2.51}
Step 1415: {'loss': 3.5904, 'learning_rate': 1.533938714348928e-05, 'epoch': 2.52}
Step 1416: {'loss': 3.5391, 'learning_rate': 1.5229350027817846e-05, 'epoch': 2.52}
Step 1417: {'loss': 3.8125, 'learning_rate': 1.5119676470344036e-05, 'epoch': 2.52}
Step 1418: {'loss': 3.5382, 'learning_rate': 1.5010366941427823e-05, 'epoch': 2.52}
Step 1419: {'loss': 3.8742, 'learning_rate': 1.4901421909867952e-05, 'epoch': 2.52}
Step 1420: {'loss': 3.2513, 'learning_rate': 1.4792841842899962e-05, 'epoch': 2.52}
Step 1421: {'loss': 3.6635, 'learning_rate': 1.4684627206194135e-05, 'epoch': 2.53}
Step 1422: {'loss': 3.4204, 'learning_rate': 1.4576778463853547e-05, 'epoch': 2.53}
Step 1423: {'loss': 3.4234, 'learning_rate': 1.4469296078412032e-05, 'epoch': 2.53}
Step 1424: {'loss': 3.7231, 'learning_rate': 1.4362180510832246e-05, 'epoch': 2.53}
Step 1425: {'loss': 3.5912, 'learning_rate': 1.4255432220503572e-05, 'epoch': 2.53}
Step 1426: {'loss': 3.6168, 'learning_rate': 1.4149051665240397e-05, 'epoch': 2.54}
Step 1427: {'loss': 3.6278, 'learning_rate': 1.4043039301279903e-05, 'epoch': 2.54}
Step 1428: {'loss': 3.7566, 'learning_rate': 1.3937395583280133e-05, 'epoch': 2.54}
Step 1429: {'loss': 3.5744, 'learning_rate': 1.3832120964318251e-05, 'epoch': 2.54}
Step 1430: {'loss': 3.1584, 'learning_rate': 1.372721589588839e-05, 'epoch': 2.54}
Step 1431: {'loss': 3.3716, 'learning_rate': 1.3622680827899692e-05, 'epoch': 2.54}
Step 1432: {'loss': 3.8106, 'learning_rate': 1.3518516208674637e-05, 'epoch': 2.55}
Step 1433: {'loss': 3.742, 'learning_rate': 1.3414722484946863e-05, 'epoch': 2.55}
Step 1434: {'loss': 3.5214, 'learning_rate': 1.331130010185928e-05, 'epoch': 2.55}
Step 1435: {'loss': 3.5117, 'learning_rate': 1.3208249502962344e-05, 'epoch': 2.55}
Step 1436: {'loss': 3.5769, 'learning_rate': 1.3105571130211957e-05, 'epoch': 2.55}
Step 1437: {'loss': 3.4957, 'learning_rate': 1.3003265423967614e-05, 'epoch': 2.55}
Step 1438: {'loss': 3.649, 'learning_rate': 1.290133282299063e-05, 'epoch': 2.56}
Step 1439: {'loss': 3.6274, 'learning_rate': 1.2799773764442136e-05, 'epoch': 2.56}
Step 1440: {'loss': 3.3973, 'learning_rate': 1.2698588683881186e-05, 'epoch': 2.56}
Step 1441: {'loss': 3.6944, 'learning_rate': 1.2597778015263029e-05, 'epoch': 2.56}
Step 1442: {'loss': 3.4194, 'learning_rate': 1.2497342190937155e-05, 'epoch': 2.56}
Step 1443: {'loss': 3.8655, 'learning_rate': 1.2397281641645364e-05, 'epoch': 2.57}
Step 1444: {'loss': 4.0654, 'learning_rate': 1.2297596796520061e-05, 'epoch': 2.57}
Step 1445: {'loss': 3.59, 'learning_rate': 1.2198288083082431e-05, 'epoch': 2.57}
Step 1446: {'loss': 3.903, 'learning_rate': 1.2099355927240396e-05, 'epoch': 2.57}
Step 1447: {'loss': 3.4859, 'learning_rate': 1.200080075328699e-05, 'epoch': 2.57}
Step 1448: {'loss': 3.2989, 'learning_rate': 1.1902622983898525e-05, 'epoch': 2.57}
Step 1449: {'loss': 3.727, 'learning_rate': 1.180482304013264e-05, 'epoch': 2.58}
Step 1450: {'loss': 3.6479, 'learning_rate': 1.1707401341426594e-05, 'epoch': 2.58}
Step 1451: {'loss': 3.7565, 'learning_rate': 1.1610358305595549e-05, 'epoch': 2.58}
Step 1452: {'loss': 3.8333, 'learning_rate': 1.1513694348830573e-05, 'epoch': 2.58}
Step 1453: {'loss': 3.4706, 'learning_rate': 1.1417409885696994e-05, 'epoch': 2.58}
Step 1454: {'loss': 3.657, 'learning_rate': 1.1321505329132687e-05, 'epoch': 2.58}
Step 1455: {'loss': 3.8359, 'learning_rate': 1.122598109044608e-05, 'epoch': 2.59}
Step 1456: {'loss': 3.9397, 'learning_rate': 1.1130837579314569e-05, 'epoch': 2.59}
Step 1457: {'loss': 3.3922, 'learning_rate': 1.103607520378278e-05, 'epoch': 2.59}
Step 1458: {'loss': 3.4199, 'learning_rate': 1.0941694370260659e-05, 'epoch': 2.59}
Step 1459: {'loss': 3.4482, 'learning_rate': 1.0847695483521835e-05, 'epoch': 2.59}
Step 1460: {'loss': 3.4323, 'learning_rate': 1.0754078946701973e-05, 'epoch': 2.6}
Step 1461: {'loss': 3.8176, 'learning_rate': 1.0660845161296806e-05, 'epoch': 2.6}
Step 1462: {'loss': 3.6097, 'learning_rate': 1.0567994527160619e-05, 'epoch': 2.6}
Step 1463: {'loss': 3.7161, 'learning_rate': 1.047552744250444e-05, 'epoch': 2.6}
Step 1464: {'loss': 3.751, 'learning_rate': 1.0383444303894452e-05, 'epoch': 2.6}
Step 1465: {'loss': 3.9357, 'learning_rate': 1.029174550625005e-05, 'epoch': 2.6}
Step 1466: {'loss': 3.5833, 'learning_rate': 1.0200431442842362e-05, 'epoch': 2.61}
Step 1467: {'loss': 3.7545, 'learning_rate': 1.0109502505292567e-05, 'epoch': 2.61}
Step 1468: {'loss': 3.4391, 'learning_rate': 1.0018959083570024e-05, 'epoch': 2.61}
Step 1469: {'loss': 3.6392, 'learning_rate': 9.928801565990775e-06, 'epoch': 2.61}
Step 1470: {'loss': 3.6997, 'learning_rate': 9.83903033921586e-06, 'epoch': 2.61}
Step 1471: {'loss': 3.7222, 'learning_rate': 9.749645788249562e-06, 'epoch': 2.62}
Step 1472: {'loss': 2.978, 'learning_rate': 9.660648296437813e-06, 'epoch': 2.62}
Step 1473: {'loss': 3.7947, 'learning_rate': 9.572038245466663e-06, 'epoch': 2.62}
Step 1474: {'loss': 3.3034, 'learning_rate': 9.483816015360381e-06, 'epoch': 2.62}
Step 1475: {'loss': 3.3376, 'learning_rate': 9.395981984480051e-06, 'epoch': 2.62}
Step 1476: {'loss': 3.8002, 'learning_rate': 9.308536529521938e-06, 'epoch': 2.62}
Step 1477: {'loss': 3.8902, 'learning_rate': 9.221480025515694e-06, 'epoch': 2.63}
Step 1478: {'loss': 3.5555, 'learning_rate': 9.134812845822915e-06, 'epoch': 2.63}
Step 1479: {'loss': 3.642, 'learning_rate': 9.048535362135546e-06, 'epoch': 2.63}
Step 1480: {'loss': 3.9257, 'learning_rate': 8.962647944474145e-06, 'epoch': 2.63}
Step 1481: {'loss': 3.338, 'learning_rate': 8.87715096118642e-06, 'epoch': 2.63}
Step 1482: {'loss': 3.3777, 'learning_rate': 8.792044778945652e-06, 'epoch': 2.63}
Step 1483: {'loss': 3.5968, 'learning_rate': 8.707329762749017e-06, 'epoch': 2.64}
Step 1484: {'loss': 3.2811, 'learning_rate': 8.623006275916102e-06, 'epoch': 2.64}
Step 1485: {'loss': 3.3762, 'learning_rate': 8.539074680087366e-06, 'epoch': 2.64}
Step 1486: {'loss': 3.3746, 'learning_rate': 8.45553533522252e-06, 'epoch': 2.64}
Step 1487: {'loss': 3.658, 'learning_rate': 8.372388599599047e-06, 'epoch': 2.64}
Step 1488: {'loss': 3.7037, 'learning_rate': 8.2896348298106e-06, 'epoch': 2.65}
Step 1489: {'loss': 3.3873, 'learning_rate': 8.207274380765529e-06, 'epoch': 2.65}
Step 1490: {'loss': 3.328, 'learning_rate': 8.12530760568535e-06, 'epoch': 2.65}
Step 1491: {'loss': 3.8426, 'learning_rate': 8.043734856103191e-06, 'epoch': 2.65}
Step 1492: {'loss': 3.7075, 'learning_rate': 7.962556481862338e-06, 'epoch': 2.65}
Step 1493: {'loss': 3.5931, 'learning_rate': 7.881772831114697e-06, 'epoch': 2.65}
Step 1494: {'loss': 3.1632, 'learning_rate': 7.801384250319311e-06, 'epoch': 2.66}
Step 1495: {'loss': 3.2921, 'learning_rate': 7.721391084240881e-06, 'epoch': 2.66}
Step 1496: {'loss': 3.8611, 'learning_rate': 7.641793675948271e-06, 'epoch': 2.66}
Step 1497: {'loss': 3.4372, 'learning_rate': 7.562592366813059e-06, 'epoch': 2.66}
Step 1498: {'loss': 3.7317, 'learning_rate': 7.483787496508065e-06, 'epoch': 2.66}
Step 1499: {'loss': 3.5529, 'learning_rate': 7.405379403005874e-06, 'epoch': 2.66}
Step 1500: {'loss': 3.4654, 'learning_rate': 7.3273684225774295e-06, 'epoch': 2.67}
Step 1501: {'loss': 3.6192, 'learning_rate': 7.249754889790539e-06, 'epoch': 2.67}
Step 1502: {'loss': 3.6313, 'learning_rate': 7.172539137508472e-06, 'epoch': 2.67}
Step 1503: {'loss': 3.6458, 'learning_rate': 7.095721496888541e-06, 'epoch': 2.67}
Step 1504: {'loss': 3.4296, 'learning_rate': 7.019302297380659e-06, 'epoch': 2.67}
Step 1505: {'loss': 3.6048, 'learning_rate': 6.943281866725915e-06, 'epoch': 2.68}
Step 1506: {'loss': 3.4658, 'learning_rate': 6.867660530955211e-06, 'epoch': 2.68}
Step 1507: {'loss': 3.4664, 'learning_rate': 6.792438614387841e-06, 'epoch': 2.68}
Step 1508: {'loss': 3.9695, 'learning_rate': 6.71761643963007e-06, 'epoch': 2.68}
Step 1509: {'loss': 3.6336, 'learning_rate': 6.643194327573809e-06, 'epoch': 2.68}
Step 1510: {'loss': 3.4391, 'learning_rate': 6.569172597395201e-06, 'epoch': 2.68}
Step 1511: {'loss': 3.7423, 'learning_rate': 6.495551566553249e-06, 'epoch': 2.69}
Step 1512: {'loss': 3.5507, 'learning_rate': 6.422331550788485e-06, 'epoch': 2.69}
Step 1513: {'loss': 3.5887, 'learning_rate': 6.349512864121587e-06, 'epoch': 2.69}
Step 1514: {'loss': 3.6661, 'learning_rate': 6.27709581885203e-06, 'epoch': 2.69}
Step 1515: {'loss': 3.5817, 'learning_rate': 6.205080725556778e-06, 'epoch': 2.69}
Step 1516: {'loss': 3.5075, 'learning_rate': 6.133467893088929e-06, 'epoch': 2.7}
Step 1517: {'loss': 3.2104, 'learning_rate': 6.062257628576395e-06, 'epoch': 2.7}
Step 1518: {'loss': 3.7089, 'learning_rate': 5.9914502374205704e-06, 'epoch': 2.7}
Step 1519: {'loss': 3.8156, 'learning_rate': 5.9210460232950185e-06, 'epoch': 2.7}
Step 1520: {'loss': 3.5037, 'learning_rate': 5.851045288144253e-06, 'epoch': 2.7}
Step 1521: {'loss': 3.2265, 'learning_rate': 5.781448332182337e-06, 'epoch': 2.7}
Step 1522: {'loss': 3.6711, 'learning_rate': 5.71225545389158e-06, 'epoch': 2.71}
Step 1523: {'loss': 3.3566, 'learning_rate': 5.643466950021426e-06, 'epoch': 2.71}
Step 1524: {'loss': 3.282, 'learning_rate': 5.575083115586976e-06, 'epoch': 2.71}
Step 1525: {'loss': 3.772, 'learning_rate': 5.507104243867833e-06, 'epoch': 2.71}
Step 1526: {'loss': 3.4843, 'learning_rate': 5.439530626406875e-06, 'epoch': 2.71}
Step 1527: {'loss': 3.7417, 'learning_rate': 5.372362553008903e-06, 'epoch': 2.71}
Step 1528: {'loss': 3.4859, 'learning_rate': 5.305600311739434e-06, 'epoch': 2.72}
Step 1529: {'loss': 3.512, 'learning_rate': 5.2392441889235534e-06, 'epoch': 2.72}
Step 1530: {'loss': 3.519, 'learning_rate': 5.1732944691445735e-06, 'epoch': 2.72}
Step 1531: {'loss': 3.8362, 'learning_rate': 5.1077514352428026e-06, 'epoch': 2.72}
Step 1532: {'loss': 3.4836, 'learning_rate': 5.042615368314496e-06, 'epoch': 2.72}
Step 1533: {'loss': 3.506, 'learning_rate': 4.977886547710464e-06, 'epoch': 2.73}
Step 1534: {'loss': 3.7135, 'learning_rate': 4.913565251034935e-06, 'epoch': 2.73}
Step 1535: {'loss': 3.8557, 'learning_rate': 4.849651754144447e-06, 'epoch': 2.73}
Step 1536: {'loss': 3.7911, 'learning_rate': 4.786146331146557e-06, 'epoch': 2.73}
Step 1537: {'loss': 3.6847, 'learning_rate': 4.72304925439867e-06, 'epoch': 2.73}
Step 1538: {'loss': 3.349, 'learning_rate': 4.660360794506946e-06, 'epoch': 2.73}
Step 1539: {'loss': 3.3897, 'learning_rate': 4.5980812203251236e-06, 'epoch': 2.74}
Step 1540: {'loss': 3.3693, 'learning_rate': 4.5362107989532774e-06, 'epoch': 2.74}
Step 1541: {'loss': 3.4713, 'learning_rate': 4.474749795736776e-06, 'epoch': 2.74}
Step 1542: {'loss': 3.7712, 'learning_rate': 4.413698474265126e-06, 'epoch': 2.74}
Step 1543: {'loss': 3.4538, 'learning_rate': 4.353057096370761e-06, 'epoch': 2.74}
Step 1544: {'loss': 3.5539, 'learning_rate': 4.2928259221280185e-06, 'epoch': 2.74}
Step 1545: {'loss': 4.0165, 'learning_rate': 4.233005209852003e-06, 'epoch': 2.75}
Step 1546: {'loss': 3.3752, 'learning_rate': 4.1735952160974034e-06, 'epoch': 2.75}
Step 1547: {'loss': 3.4539, 'learning_rate': 4.114596195657483e-06, 'epoch': 2.75}
Step 1548: {'loss': 3.8793, 'learning_rate': 4.056008401562972e-06, 'epoch': 2.75}
Step 1549: {'loss': 3.3779, 'learning_rate': 3.997832085080922e-06, 'epoch': 2.75}
Step 1550: {'loss': 3.7682, 'learning_rate': 3.940067495713673e-06, 'epoch': 2.76}
Step 1551: {'loss': 3.3236, 'learning_rate': 3.882714881197847e-06, 'epoch': 2.76}
Step 1552: {'loss': 3.9381, 'learning_rate': 3.825774487503109e-06, 'epoch': 2.76}
Step 1553: {'loss': 3.6559, 'learning_rate': 3.7692465588312963e-06, 'epoch': 2.76}
Step 1554: {'loss': 3.5875, 'learning_rate': 3.713131337615283e-06, 'epoch': 2.76}
Step 1555: {'loss': 3.1311, 'learning_rate': 3.65742906451797e-06, 'epoch': 2.76}
Step 1556: {'loss': 3.7328, 'learning_rate': 3.602139978431174e-06, 'epoch': 2.77}
Step 1557: {'loss': 3.7676, 'learning_rate': 3.547264316474708e-06, 'epoch': 2.77}
Step 1558: {'loss': 3.2894, 'learning_rate': 3.4928023139953582e-06, 'epoch': 2.77}
Step 1559: {'loss': 3.6986, 'learning_rate': 3.438754204565764e-06, 'epoch': 2.77}
Step 1560: {'loss': 3.8428, 'learning_rate': 3.3851202199835177e-06, 'epoch': 2.77}
Step 1561: {'loss': 3.6085, 'learning_rate': 3.3319005902702095e-06, 'epoch': 2.78}
Step 1562: {'loss': 3.371, 'learning_rate': 3.2790955436702518e-06, 'epoch': 2.78}
Step 1563: {'loss': 3.4111, 'learning_rate': 3.226705306650113e-06, 'epoch': 2.78}
Step 1564: {'loss': 3.568, 'learning_rate': 3.17473010389725e-06, 'epoch': 2.78}
Step 1565: {'loss': 3.3986, 'learning_rate': 3.1231701583190997e-06, 'epoch': 2.78}
Step 1566: {'loss': 3.6748, 'learning_rate': 3.072025691042213e-06, 'epoch': 2.78}
Step 1567: {'loss': 3.4731, 'learning_rate': 3.0212969214112764e-06, 'epoch': 2.79}
Step 1568: {'loss': 3.5937, 'learning_rate': 2.970984066988136e-06, 'epoch': 2.79}
Step 1569: {'loss': 3.3821, 'learning_rate': 2.921087343550899e-06, 'epoch': 2.79}
Step 1570: {'loss': 4.0243, 'learning_rate': 2.871606965093032e-06, 'epoch': 2.79}
Step 1571: {'loss': 3.5852, 'learning_rate': 2.8225431438223428e-06, 'epoch': 2.79}
Step 1572: {'loss': 3.552, 'learning_rate': 2.7738960901601886e-06, 'epoch': 2.79}
Step 1573: {'loss': 3.949, 'learning_rate': 2.7256660127405355e-06, 'epoch': 2.8}
Step 1574: {'loss': 3.9255, 'learning_rate': 2.677853118409024e-06, 'epoch': 2.8}
Step 1575: {'loss': 3.5562, 'learning_rate': 2.6304576122221035e-06, 'epoch': 2.8}
Step 1576: {'loss': 3.4632, 'learning_rate': 2.5834796974461783e-06, 'epoch': 2.8}
Step 1577: {'loss': 3.5117, 'learning_rate': 2.5369195755567177e-06, 'epoch': 2.8}
Step 1578: {'loss': 3.3666, 'learning_rate': 2.4907774462373912e-06, 'epoch': 2.81}
Step 1579: {'loss': 3.2416, 'learning_rate': 2.4450535073792024e-06, 'epoch': 2.81}
Step 1580: {'loss': 3.6266, 'learning_rate': 2.3997479550796453e-06, 'epoch': 2.81}
Step 1581: {'loss': 4.0533, 'learning_rate': 2.354860983641882e-06, 'epoch': 2.81}
Step 1582: {'loss': 3.3063, 'learning_rate': 2.3103927855738893e-06, 'epoch': 2.81}
Step 1583: {'loss': 3.653, 'learning_rate': 2.2663435515876574e-06, 'epoch': 2.81}
Step 1584: {'loss': 3.3415, 'learning_rate': 2.2227134705983143e-06, 'epoch': 2.82}
Step 1585: {'loss': 3.6855, 'learning_rate': 2.1795027297233815e-06, 'epoch': 2.82}
Step 1586: {'loss': 3.1643, 'learning_rate': 2.1367115142819526e-06, 'epoch': 2.82}
Step 1587: {'loss': 3.4286, 'learning_rate': 2.0943400077938824e-06, 'epoch': 2.82}
Step 1588: {'loss': 3.4192, 'learning_rate': 2.0523883919789875e-06, 'epoch': 2.82}
Step 1589: {'loss': 3.7493, 'learning_rate': 2.010856846756315e-06, 'epoch': 2.82}
Step 1590: {'loss': 3.6196, 'learning_rate': 1.9697455502433515e-06, 'epoch': 2.83}
Step 1591: {'loss': 3.5754, 'learning_rate': 1.9290546787552044e-06, 'epoch': 2.83}
Step 1592: {'loss': 3.583, 'learning_rate': 1.888784406803945e-06, 'epoch': 2.83}
Step 1593: {'loss': 3.2833, 'learning_rate': 1.848934907097777e-06, 'epoch': 2.83}
Step 1594: {'loss': 3.6977, 'learning_rate': 1.8095063505403464e-06, 'epoch': 2.83}
Step 1595: {'loss': 3.2902, 'learning_rate': 1.7704989062299782e-06, 'epoch': 2.84}
Step 1596: {'loss': 3.0091, 'learning_rate': 1.731912741458941e-06, 'epoch': 2.84}
Step 1597: {'loss': 3.5424, 'learning_rate': 1.6937480217127933e-06, 'epoch': 2.84}
Step 1598: {'loss': 3.4034, 'learning_rate': 1.6560049106696064e-06, 'epoch': 2.84}
Step 1599: {'loss': 3.5511, 'learning_rate': 1.6186835701992865e-06, 'epoch': 2.84}
Step 1600: {'loss': 3.4968, 'learning_rate': 1.5817841603628869e-06, 'epoch': 2.84}
Step 1601: {'loss': 3.6636, 'learning_rate': 1.5453068394118975e-06, 'epoch': 2.85}
Step 1602: {'loss': 3.3498, 'learning_rate': 1.5092517637876224e-06, 'epoch': 2.85}
Step 1603: {'loss': 3.561, 'learning_rate': 1.473619088120426e-06, 'epoch': 2.85}
Step 1604: {'loss': 3.4289, 'learning_rate': 1.4384089652291543e-06, 'epoch': 2.85}
Step 1605: {'loss': 3.8387, 'learning_rate': 1.403621546120415e-06, 'epoch': 2.85}
Step 1606: {'loss': 3.9596, 'learning_rate': 1.3692569799879429e-06, 'epoch': 2.86}
Step 1607: {'loss': 3.5751, 'learning_rate': 1.335315414212024e-06, 'epoch': 2.86}
Step 1608: {'loss': 3.7895, 'learning_rate': 1.3017969943587505e-06, 'epoch': 2.86}
Step 1609: {'loss': 3.3806, 'learning_rate': 1.268701864179489e-06, 'epoch': 2.86}
Step 1610: {'loss': 3.5412, 'learning_rate': 1.2360301656102247e-06, 'epoch': 2.86}
Step 1611: {'loss': 3.8945, 'learning_rate': 1.203782038770973e-06, 'epoch': 2.86}
Step 1612: {'loss': 3.828, 'learning_rate': 1.1719576219651585e-06, 'epoch': 2.87}
Step 1613: {'loss': 3.552, 'learning_rate': 1.140557051678992e-06, 'epoch': 2.87}
Step 1614: {'loss': 3.269, 'learning_rate': 1.1095804625809835e-06, 'epoch': 2.87}
Step 1615: {'loss': 3.4566, 'learning_rate': 1.079027987521286e-06, 'epoch': 2.87}
Step 1616: {'loss': 3.9415, 'learning_rate': 1.0488997575310965e-06, 'epoch': 2.87}
Step 1617: {'loss': 3.7804, 'learning_rate': 1.0191959018222009e-06, 'epoch': 2.87}
Step 1618: {'loss': 3.6673, 'learning_rate': 9.899165477863293e-07, 'epoch': 2.88}
Step 1619: {'loss': 3.6219, 'learning_rate': 9.610618209946464e-07, 'epoch': 2.88}
Step 1620: {'loss': 3.9314, 'learning_rate': 9.326318451972071e-07, 'epoch': 2.88}
Step 1621: {'loss': 3.4855, 'learning_rate': 9.046267423224231e-07, 'epoch': 2.88}
Step 1622: {'loss': 3.0359, 'learning_rate': 8.770466324765302e-07, 'epoch': 2.88}
Step 1623: {'loss': 3.6057, 'learning_rate': 8.498916339431117e-07, 'epoch': 2.89}
Step 1624: {'loss': 3.8605, 'learning_rate': 8.231618631825532e-07, 'epoch': 2.89}
Step 1625: {'loss': 3.2777, 'learning_rate': 7.968574348315438e-07, 'epoch': 2.89}
Step 1626: {'loss': 3.6238, 'learning_rate': 7.709784617025984e-07, 'epoch': 2.89}
Step 1627: {'loss': 3.8439, 'learning_rate': 7.455250547835913e-07, 'epoch': 2.89}
Step 1628: {'loss': 3.3476, 'learning_rate': 7.204973232372125e-07, 'epoch': 2.89}
Step 1629: {'loss': 3.4485, 'learning_rate': 6.958953744006125e-07, 'epoch': 2.9}
Step 1630: {'loss': 3.3513, 'learning_rate': 6.717193137848132e-07, 'epoch': 2.9}
Step 1631: {'loss': 3.7359, 'learning_rate': 6.479692450743646e-07, 'epoch': 2.9}
Step 1632: {'loss': 3.6074, 'learning_rate': 6.246452701268002e-07, 'epoch': 2.9}
Step 1633: {'loss': 3.5776, 'learning_rate': 6.017474889723374e-07, 'epoch': 2.9}
Step 1634: {'loss': 3.1853, 'learning_rate': 5.792759998132779e-07, 'epoch': 2.9}
Step 1635: {'loss': 3.8797, 'learning_rate': 5.572308990237086e-07, 'epoch': 2.91}
Step 1636: {'loss': 3.8287, 'learning_rate': 5.356122811490782e-07, 'epoch': 2.91}
Step 1637: {'loss': 3.6452, 'learning_rate': 5.144202389057329e-07, 'epoch': 2.91}
Step 1638: {'loss': 3.1733, 'learning_rate': 4.936548631805482e-07, 'epoch': 2.91}
Step 1639: {'loss': 3.5193, 'learning_rate': 4.7331624303057485e-07, 'epoch': 2.91}
Step 1640: {'loss': 3.4939, 'learning_rate': 4.5340446568259423e-07, 'epoch': 2.92}
Step 1641: {'loss': 3.4451, 'learning_rate': 4.339196165327963e-07, 'epoch': 2.92}
Step 1642: {'loss': 3.7751, 'learning_rate': 4.1486177914638047e-07, 'epoch': 2.92}
Step 1643: {'loss': 3.967, 'learning_rate': 3.9623103525723294e-07, 'epoch': 2.92}
Step 1644: {'loss': 3.8028, 'learning_rate': 3.780274647674942e-07, 'epoch': 2.92}
Step 1645: {'loss': 3.8075, 'learning_rate': 3.6025114574734785e-07, 'epoch': 2.92}
Step 1646: {'loss': 3.7069, 'learning_rate': 3.4290215443456566e-07, 'epoch': 2.93}
Step 1647: {'loss': 3.3195, 'learning_rate': 3.259805652342407e-07, 'epoch': 2.93}
Step 1648: {'loss': 3.2601, 'learning_rate': 3.0948645071844365e-07, 'epoch': 2.93}
Step 1649: {'loss': 3.3844, 'learning_rate': 2.934198816259559e-07, 'epoch': 2.93}
Step 1650: {'loss': 3.4689, 'learning_rate': 2.777809268618925e-07, 'epoch': 2.93}
Step 1651: {'loss': 3.6478, 'learning_rate': 2.6256965349745754e-07, 'epoch': 2.94}
Step 1652: {'loss': 3.3269, 'learning_rate': 2.4778612676967793e-07, 'epoch': 2.94}
Step 1653: {'loss': 3.4218, 'learning_rate': 2.3343041008105915e-07, 'epoch': 2.94}
Step 1654: {'loss': 3.509, 'learning_rate': 2.1950256499934097e-07, 'epoch': 2.94}
Step 1655: {'loss': 3.4636, 'learning_rate': 2.0600265125726437e-07, 'epoch': 2.94}
Step 1656: {'loss': 3.7537, 'learning_rate': 1.9293072675228284e-07, 'epoch': 2.94}
Step 1657: {'loss': 3.9932, 'learning_rate': 1.80286847546296e-07, 'epoch': 2.95}
Step 1658: {'loss': 3.3759, 'learning_rate': 1.6807106786547177e-07, 'epoch': 2.95}
Step 1659: {'loss': 3.8562, 'learning_rate': 1.5628344009994688e-07, 'epoch': 2.95}
Step 1660: {'loss': 3.6504, 'learning_rate': 1.4492401480364904e-07, 'epoch': 2.95}
Step 1661: {'loss': 3.5123, 'learning_rate': 1.339928406940527e-07, 'epoch': 2.95}
Step 1662: {'loss': 3.8157, 'learning_rate': 1.2348996465199049e-07, 'epoch': 2.95}
Step 1663: {'loss': 3.524, 'learning_rate': 1.1341543172140867e-07, 'epoch': 2.96}
Step 1664: {'loss': 3.1516, 'learning_rate': 1.0376928510925643e-07, 'epoch': 2.96}
Step 1665: {'loss': 3.5549, 'learning_rate': 9.455156618521921e-08, 'epoch': 2.96}
Step 1666: {'loss': 3.8408, 'learning_rate': 8.576231448156335e-08, 'epoch': 2.96}
Step 1667: {'loss': 4.0374, 'learning_rate': 7.740156769302508e-08, 'epoch': 2.96}
Step 1668: {'loss': 3.4089, 'learning_rate': 6.946936167653295e-08, 'epoch': 2.97}
Step 1669: {'loss': 3.4975, 'learning_rate': 6.196573045117448e-08, 'epoch': 2.97}
Step 1670: {'loss': 3.8486, 'learning_rate': 5.489070619797421e-08, 'epoch': 2.97}
Step 1671: {'loss': 3.8559, 'learning_rate': 4.824431925977146e-08, 'epoch': 2.97}
Step 1672: {'loss': 3.7644, 'learning_rate': 4.2026598141120534e-08, 'epoch': 2.97}
Step 1673: {'loss': 3.146, 'learning_rate': 3.623756950813517e-08, 'epoch': 2.97}
Step 1674: {'loss': 3.7376, 'learning_rate': 3.087725818836651e-08, 'epoch': 2.98}
Step 1675: {'loss': 3.3656, 'learning_rate': 2.594568717072532e-08, 'epoch': 2.98}
Step 1676: {'loss': 3.6612, 'learning_rate': 2.1442877605393207e-08, 'epoch': 2.98}
Step 1677: {'loss': 3.5324, 'learning_rate': 1.7368848803678283e-08, 'epoch': 2.98}
Step 1678: {'loss': 3.5734, 'learning_rate': 1.372361823798185e-08, 'epoch': 2.98}
Step 1679: {'loss': 3.4343, 'learning_rate': 1.0507201541698486e-08, 'epoch': 2.98}
Step 1680: {'loss': 3.5496, 'learning_rate': 7.719612509182738e-09, 'epoch': 2.99}
Step 1681: {'loss': 3.4808, 'learning_rate': 5.3608630956158975e-09, 'epoch': 2.99}
Step 1682: {'loss': 3.4993, 'learning_rate': 3.4309634170504036e-09, 'epoch': 2.99}
Step 1683: {'loss': 3.3985, 'learning_rate': 1.929921750287722e-09, 'epoch': 2.99}
Step 1684: {'loss': 3.6392, 'learning_rate': 8.577445328894485e-10, 'epoch': 2.99}
Step 1685: {'loss': 3.7049, 'learning_rate': 2.1443636313289718e-10, 'epoch': 3.0}
Step 1686: {'loss': 3.6067, 'learning_rate': 0.0, 'epoch': 3.0}
Step 1686: {'train_runtime': 1754.7393, 'train_samples_per_second': 15.387, 'train_steps_per_second': 0.961, 'total_flos': 0.0, 'train_loss': 4.44078600632904, 'epoch': 3.0}
