Step 30: {'loss': 11.5183, 'learning_rate': 0.00014285714285714287, 'epoch': 0.21}
Step 1: {'loss': 15.0912, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.01}
Step 31: {'loss': 10.3579, 'learning_rate': 0.00014761904761904763, 'epoch': 0.22}
Step 2: {'loss': 16.8795, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.01}
Step 32: {'loss': 11.8617, 'learning_rate': 0.00015238095238095237, 'epoch': 0.23}
Step 3: {'loss': 22.6733, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.02}
Step 33: {'loss': 12.8829, 'learning_rate': 0.00015714285714285716, 'epoch': 0.23}
Step 4: {'loss': 25.135, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.03}
Step 34: {'loss': 11.4354, 'learning_rate': 0.00016190476190476192, 'epoch': 0.24}
Step 5: {'loss': 22.6846, 'learning_rate': 2.380952380952381e-05, 'epoch': 0.04}
Step 35: {'loss': 11.3169, 'learning_rate': 0.0001666666666666667, 'epoch': 0.25}
Step 6: {'loss': 17.9983, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.04}
Step 36: {'loss': 9.8518, 'learning_rate': 0.00017142857142857143, 'epoch': 0.26}
Step 7: {'loss': 24.4175, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.05}
Step 37: {'loss': 9.4131, 'learning_rate': 0.0001761904761904762, 'epoch': 0.26}
Step 8: {'loss': 23.9603, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.06}
Step 38: {'loss': 8.4913, 'learning_rate': 0.00018095238095238095, 'epoch': 0.27}
Step 9: {'loss': 29.096, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.06}
Step 39: {'loss': 8.5063, 'learning_rate': 0.00018571428571428572, 'epoch': 0.28}
Step 10: {'loss': 25.4958, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.07}
Step 40: {'loss': 8.0171, 'learning_rate': 0.00019047619047619048, 'epoch': 0.28}
Step 11: {'loss': 30.362, 'learning_rate': 5.2380952380952384e-05, 'epoch': 0.08}
Step 41: {'loss': 7.9225, 'learning_rate': 0.00019523809523809525, 'epoch': 0.29}
Step 12: {'loss': 21.4446, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.09}
Step 42: {'loss': 6.6655, 'learning_rate': 0.0002, 'epoch': 0.3}
Step 13: {'loss': 21.9089, 'learning_rate': 6.19047619047619e-05, 'epoch': 0.09}
Step 43: {'loss': 6.4128, 'learning_rate': 0.0001999965463076377, 'epoch': 0.31}
Step 14: {'loss': 21.1435, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.1}
Step 44: {'loss': 6.7197, 'learning_rate': 0.00019998618546911056, 'epoch': 0.31}
Step 15: {'loss': 20.9298, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.11}
Step 45: {'loss': 6.3489, 'learning_rate': 0.00019996891820008164, 'epoch': 0.32}
Step 16: {'loss': 20.6311, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.11}
Step 46: {'loss': 6.4041, 'learning_rate': 0.00019994474569326757, 'epoch': 0.33}
Step 17: {'loss': 22.0293, 'learning_rate': 8.095238095238096e-05, 'epoch': 0.12}
Step 47: {'loss': 5.5169, 'learning_rate': 0.00019991366961835642, 'epoch': 0.33}
Step 18: {'loss': 21.4031, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.13}
Step 48: {'loss': 6.6027, 'learning_rate': 0.00019987569212189224, 'epoch': 0.34}
Step 19: {'loss': 19.0471, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.14}
Step 49: {'loss': 5.3987, 'learning_rate': 0.00019983081582712685, 'epoch': 0.35}
Step 20: {'loss': 23.9857, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.14}
Step 50: {'loss': 6.0407, 'learning_rate': 0.0001997790438338385, 'epoch': 0.36}
Step 21: {'loss': 17.3825, 'learning_rate': 0.0001, 'epoch': 0.15}
Step 51: {'loss': 5.7578, 'learning_rate': 0.00019972037971811802, 'epoch': 0.36}
Step 22: {'loss': 16.0119, 'learning_rate': 0.00010476190476190477, 'epoch': 0.16}
Step 52: {'loss': 4.8687, 'learning_rate': 0.00019965482753212156, 'epoch': 0.37}
Step 23: {'loss': 16.5818, 'learning_rate': 0.00010952380952380953, 'epoch': 0.16}
Step 53: {'loss': 4.828, 'learning_rate': 0.0001995823918037908, 'epoch': 0.38}
Step 24: {'loss': 12.5063, 'learning_rate': 0.00011428571428571428, 'epoch': 0.17}
Step 54: {'loss': 4.8016, 'learning_rate': 0.00019950307753654017, 'epoch': 0.38}
Step 25: {'loss': 15.0778, 'learning_rate': 0.00011904761904761905, 'epoch': 0.18}
Step 55: {'loss': 4.8705, 'learning_rate': 0.0001994168902089112, 'epoch': 0.39}
Step 26: {'loss': 16.113, 'learning_rate': 0.0001238095238095238, 'epoch': 0.18}
Step 56: {'loss': 4.7993, 'learning_rate': 0.00019932383577419432, 'epoch': 0.4}
Step 27: {'loss': 12.9838, 'learning_rate': 0.00012857142857142858, 'epoch': 0.19}
Step 57: {'loss': 4.8054, 'learning_rate': 0.00019922392066001722, 'epoch': 0.41}
Step 28: {'loss': 12.9891, 'learning_rate': 0.00013333333333333334, 'epoch': 0.2}
Step 58: {'loss': 5.0425, 'learning_rate': 0.0001991171517679013, 'epoch': 0.41}
Step 29: {'loss': 13.6574, 'learning_rate': 0.0001380952380952381, 'epoch': 0.21}
Step 59: {'loss': 4.6182, 'learning_rate': 0.00019900353647278466, 'epoch': 0.42}
Step 30: {'loss': 11.5458, 'learning_rate': 0.00014285714285714287, 'epoch': 0.21}
Step 60: {'loss': 4.4962, 'learning_rate': 0.00019888308262251285, 'epoch': 0.43}
Step 31: {'loss': 10.1953, 'learning_rate': 0.00014761904761904763, 'epoch': 0.22}
Step 61: {'loss': 4.2662, 'learning_rate': 0.00019875579853729676, 'epoch': 0.43}
Step 32: {'loss': 12.0827, 'learning_rate': 0.00015238095238095237, 'epoch': 0.23}
Step 62: {'loss': 4.8224, 'learning_rate': 0.00019862169300913785, 'epoch': 0.44}
Step 33: {'loss': 14.2538, 'learning_rate': 0.00015714285714285716, 'epoch': 0.23}
Step 63: {'loss': 4.5757, 'learning_rate': 0.00019848077530122083, 'epoch': 0.45}
Step 34: {'loss': 11.4422, 'learning_rate': 0.00016190476190476192, 'epoch': 0.24}
Step 64: {'loss': 4.4241, 'learning_rate': 0.00019833305514727395, 'epoch': 0.46}
Step 35: {'loss': 12.5208, 'learning_rate': 0.0001666666666666667, 'epoch': 0.25}
Step 65: {'loss': 4.3448, 'learning_rate': 0.0001981785427508966, 'epoch': 0.46}
Step 36: {'loss': 9.7445, 'learning_rate': 0.00017142857142857143, 'epoch': 0.26}
Step 66: {'loss': 4.5992, 'learning_rate': 0.00019801724878485438, 'epoch': 0.47}
Step 37: {'loss': 8.5203, 'learning_rate': 0.0001761904761904762, 'epoch': 0.26}
Step 67: {'loss': 4.4473, 'learning_rate': 0.00019784918439034216, 'epoch': 0.48}
Step 38: {'loss': 8.9681, 'learning_rate': 0.00018095238095238095, 'epoch': 0.27}
Step 68: {'loss': 4.3701, 'learning_rate': 0.00019767436117621413, 'epoch': 0.48}
Step 39: {'loss': 8.5966, 'learning_rate': 0.00018571428571428572, 'epoch': 0.28}
Step 69: {'loss': 4.4206, 'learning_rate': 0.00019749279121818235, 'epoch': 0.49}
Step 40: {'loss': 7.7357, 'learning_rate': 0.00019047619047619048, 'epoch': 0.28}
Step 70: {'loss': 4.1278, 'learning_rate': 0.00019730448705798239, 'epoch': 0.5}
Step 41: {'loss': 7.2143, 'learning_rate': 0.00019523809523809525, 'epoch': 0.29}
Step 71: {'loss': 4.8965, 'learning_rate': 0.000197109461702507, 'epoch': 0.5}
Step 42: {'loss': 6.9034, 'learning_rate': 0.0002, 'epoch': 0.3}
Step 72: {'loss': 4.748, 'learning_rate': 0.0001969077286229078, 'epoch': 0.51}
Step 43: {'loss': 6.4704, 'learning_rate': 0.0001999965463076377, 'epoch': 0.31}
Step 73: {'loss': 4.3705, 'learning_rate': 0.00019669930175366472, 'epoch': 0.52}
Step 44: {'loss': 7.2198, 'learning_rate': 0.00019998618546911056, 'epoch': 0.31}
Step 74: {'loss': 4.3403, 'learning_rate': 0.00019648419549162348, 'epoch': 0.53}
Step 45: {'loss': 6.5308, 'learning_rate': 0.00019996891820008164, 'epoch': 0.32}
Step 75: {'loss': 5.0143, 'learning_rate': 0.0001962624246950012, 'epoch': 0.53}
Step 46: {'loss': 6.5293, 'learning_rate': 0.00019994474569326757, 'epoch': 0.33}
Step 76: {'loss': 4.2385, 'learning_rate': 0.00019603400468235998, 'epoch': 0.54}
Step 47: {'loss': 6.1094, 'learning_rate': 0.00019991366961835642, 'epoch': 0.33}
Step 77: {'loss': 3.8431, 'learning_rate': 0.0001957989512315489, 'epoch': 0.55}
Step 48: {'loss': 5.4499, 'learning_rate': 0.00019987569212189224, 'epoch': 0.34}
Step 78: {'loss': 4.2014, 'learning_rate': 0.0001955572805786141, 'epoch': 0.55}
Step 49: {'loss': 5.3317, 'learning_rate': 0.00019983081582712685, 'epoch': 0.35}
Step 79: {'loss': 4.6419, 'learning_rate': 0.0001953090094166773, 'epoch': 0.56}
Step 50: {'loss': 5.61, 'learning_rate': 0.0001997790438338385, 'epoch': 0.36}
Step 80: {'loss': 3.9032, 'learning_rate': 0.0001950541548947829, 'epoch': 0.57}
Step 51: {'loss': 5.5533, 'learning_rate': 0.00019972037971811802, 'epoch': 0.36}
Step 81: {'loss': 4.3694, 'learning_rate': 0.0001947927346167132, 'epoch': 0.58}
Step 52: {'loss': 5.0597, 'learning_rate': 0.00019965482753212156, 'epoch': 0.37}
Step 82: {'loss': 4.2768, 'learning_rate': 0.00019452476663977248, 'epoch': 0.58}
Step 53: {'loss': 4.7757, 'learning_rate': 0.0001995823918037908, 'epoch': 0.38}
Step 83: {'loss': 4.5006, 'learning_rate': 0.00019425026947353992, 'epoch': 0.59}
Step 54: {'loss': 4.9926, 'learning_rate': 0.00019950307753654017, 'epoch': 0.38}
Step 84: {'loss': 4.0081, 'learning_rate': 0.00019396926207859084, 'epoch': 0.6}
Step 55: {'loss': 4.7689, 'learning_rate': 0.0001994168902089112, 'epoch': 0.39}
Step 85: {'loss': 4.2471, 'learning_rate': 0.0001936817638651871, 'epoch': 0.6}
Step 56: {'loss': 4.86, 'learning_rate': 0.00019932383577419432, 'epoch': 0.4}
Step 86: {'loss': 4.3123, 'learning_rate': 0.00019338779469193639, 'epoch': 0.61}
Step 57: {'loss': 4.4413, 'learning_rate': 0.00019922392066001722, 'epoch': 0.41}
Step 87: {'loss': 4.5229, 'learning_rate': 0.00019308737486442045, 'epoch': 0.62}
Step 58: {'loss': 4.3216, 'learning_rate': 0.0001991171517679013, 'epoch': 0.41}
Step 88: {'loss': 3.7579, 'learning_rate': 0.00019278052513379255, 'epoch': 0.63}
Step 59: {'loss': 4.6786, 'learning_rate': 0.00019900353647278466, 'epoch': 0.42}
Step 89: {'loss': 4.2071, 'learning_rate': 0.00019246726669534415, 'epoch': 0.63}
Step 60: {'loss': 4.3868, 'learning_rate': 0.00019888308262251285, 'epoch': 0.43}
Step 90: {'loss': 3.98, 'learning_rate': 0.00019214762118704076, 'epoch': 0.64}
Step 61: {'loss': 4.9831, 'learning_rate': 0.00019875579853729676, 'epoch': 0.43}
Step 91: {'loss': 4.5905, 'learning_rate': 0.00019182161068802741, 'epoch': 0.65}
Step 62: {'loss': 4.4582, 'learning_rate': 0.00019862169300913785, 'epoch': 0.44}
Step 92: {'loss': 3.7907, 'learning_rate': 0.00019148925771710347, 'epoch': 0.65}
Step 63: {'loss': 4.7884, 'learning_rate': 0.00019848077530122083, 'epoch': 0.45}
Step 93: {'loss': 3.958, 'learning_rate': 0.00019115058523116733, 'epoch': 0.66}
Step 64: {'loss': 4.2612, 'learning_rate': 0.00019833305514727395, 'epoch': 0.46}
Step 94: {'loss': 3.8347, 'learning_rate': 0.0001908056166236305, 'epoch': 0.67}
Step 65: {'loss': 4.6106, 'learning_rate': 0.0001981785427508966, 'epoch': 0.46}
Step 95: {'loss': 3.9283, 'learning_rate': 0.00019045437572280194, 'epoch': 0.68}
Step 66: {'loss': 4.3793, 'learning_rate': 0.00019801724878485438, 'epoch': 0.47}
Step 96: {'loss': 4.0326, 'learning_rate': 0.0001900968867902419, 'epoch': 0.68}
Step 67: {'loss': 4.6832, 'learning_rate': 0.00019784918439034216, 'epoch': 0.48}
Step 97: {'loss': 4.0875, 'learning_rate': 0.00018973317451908642, 'epoch': 0.69}
Step 68: {'loss': 4.6469, 'learning_rate': 0.00019767436117621413, 'epoch': 0.48}
Step 98: {'loss': 3.8866, 'learning_rate': 0.00018936326403234125, 'epoch': 0.7}
Step 69: {'loss': 4.3849, 'learning_rate': 0.00019749279121818235, 'epoch': 0.49}
Step 99: {'loss': 4.1286, 'learning_rate': 0.0001889871808811469, 'epoch': 0.7}
Step 70: {'loss': 4.5483, 'learning_rate': 0.00019730448705798239, 'epoch': 0.5}
Step 100: {'loss': 3.971, 'learning_rate': 0.00018860495104301345, 'epoch': 0.71}
Step 71: {'loss': 4.9728, 'learning_rate': 0.000197109461702507, 'epoch': 0.5}
Step 101: {'loss': 3.9479, 'learning_rate': 0.00018821660092002641, 'epoch': 0.72}
Step 72: {'loss': 4.1565, 'learning_rate': 0.0001969077286229078, 'epoch': 0.51}
Step 102: {'loss': 4.507, 'learning_rate': 0.00018782215733702286, 'epoch': 0.73}
Step 73: {'loss': 4.8694, 'learning_rate': 0.00019669930175366472, 'epoch': 0.52}
Step 103: {'loss': 4.4492, 'learning_rate': 0.00018742164753973855, 'epoch': 0.73}
Step 74: {'loss': 4.3035, 'learning_rate': 0.00019648419549162348, 'epoch': 0.53}
Step 104: {'loss': 4.091, 'learning_rate': 0.00018701509919292613, 'epoch': 0.74}
Step 75: {'loss': 4.2176, 'learning_rate': 0.0001962624246950012, 'epoch': 0.53}
Step 105: {'loss': 4.0153, 'learning_rate': 0.00018660254037844388, 'epoch': 0.75}
Step 76: {'loss': 4.4373, 'learning_rate': 0.00019603400468235998, 'epoch': 0.54}
Step 106: {'loss': 4.2252, 'learning_rate': 0.0001861839995933164, 'epoch': 0.75}
Step 77: {'loss': 3.9422, 'learning_rate': 0.0001957989512315489, 'epoch': 0.55}
Step 107: {'loss': 4.3047, 'learning_rate': 0.00018575950574776595, 'epoch': 0.76}
Step 78: {'loss': 4.1534, 'learning_rate': 0.0001955572805786141, 'epoch': 0.55}
Step 108: {'loss': 3.781, 'learning_rate': 0.00018532908816321558, 'epoch': 0.77}
Step 79: {'loss': 3.91, 'learning_rate': 0.0001953090094166773, 'epoch': 0.56}
Step 109: {'loss': 3.8905, 'learning_rate': 0.00018489277657026375, 'epoch': 0.78}
Step 80: {'loss': 4.2352, 'learning_rate': 0.0001950541548947829, 'epoch': 0.57}
Step 110: {'loss': 4.6088, 'learning_rate': 0.0001844506011066308, 'epoch': 0.78}
Step 81: {'loss': 4.4212, 'learning_rate': 0.0001947927346167132, 'epoch': 0.58}
Step 111: {'loss': 3.741, 'learning_rate': 0.00018400259231507717, 'epoch': 0.79}
Step 82: {'loss': 4.7431, 'learning_rate': 0.00019452476663977248, 'epoch': 0.58}
Step 112: {'loss': 4.4601, 'learning_rate': 0.00018354878114129367, 'epoch': 0.8}
Step 83: {'loss': 4.5987, 'learning_rate': 0.00019425026947353992, 'epoch': 0.59}
Step 113: {'loss': 3.9796, 'learning_rate': 0.00018308919893176396, 'epoch': 0.8}
Step 84: {'loss': 4.2537, 'learning_rate': 0.00019396926207859084, 'epoch': 0.6}
Step 114: {'loss': 3.9335, 'learning_rate': 0.0001826238774315995, 'epoch': 0.81}
Step 85: {'loss': 3.7342, 'learning_rate': 0.0001936817638651871, 'epoch': 0.6}
Step 115: {'loss': 4.1682, 'learning_rate': 0.00018215284878234642, 'epoch': 0.82}
Step 86: {'loss': 4.3131, 'learning_rate': 0.00019338779469193639, 'epoch': 0.61}
Step 116: {'loss': 3.5728, 'learning_rate': 0.00018167614551976567, 'epoch': 0.82}
Step 87: {'loss': 4.0254, 'learning_rate': 0.00019308737486442045, 'epoch': 0.62}
Step 117: {'loss': 4.3603, 'learning_rate': 0.00018119380057158568, 'epoch': 0.83}
Step 88: {'loss': 4.1335, 'learning_rate': 0.00019278052513379255, 'epoch': 0.63}
Step 118: {'loss': 3.452, 'learning_rate': 0.00018070584725522762, 'epoch': 0.84}
Step 89: {'loss': 4.5115, 'learning_rate': 0.00019246726669534415, 'epoch': 0.63}
Step 119: {'loss': 3.8253, 'learning_rate': 0.0001802123192755044, 'epoch': 0.85}
Step 90: {'loss': 4.1205, 'learning_rate': 0.00019214762118704076, 'epoch': 0.64}
Step 120: {'loss': 3.833, 'learning_rate': 0.00017971325072229226, 'epoch': 0.85}
Step 91: {'loss': 3.9313, 'learning_rate': 0.00019182161068802741, 'epoch': 0.65}
Step 121: {'loss': 4.0916, 'learning_rate': 0.00017920867606817625, 'epoch': 0.86}
Step 92: {'loss': 3.788, 'learning_rate': 0.00019148925771710347, 'epoch': 0.65}
Step 122: {'loss': 3.8146, 'learning_rate': 0.0001786986301660689, 'epoch': 0.87}
Step 93: {'loss': 4.0924, 'learning_rate': 0.00019115058523116733, 'epoch': 0.66}
Step 123: {'loss': 3.7017, 'learning_rate': 0.000178183148246803, 'epoch': 0.87}
Step 94: {'loss': 4.1238, 'learning_rate': 0.0001908056166236305, 'epoch': 0.67}
Step 124: {'loss': 3.9391, 'learning_rate': 0.00017766226591669785, 'epoch': 0.88}
Step 95: {'loss': 4.1894, 'learning_rate': 0.00019045437572280194, 'epoch': 0.68}
Step 125: {'loss': 4.2414, 'learning_rate': 0.0001771360191551, 'epoch': 0.89}
Step 96: {'loss': 3.9788, 'learning_rate': 0.0001900968867902419, 'epoch': 0.68}
Step 126: {'loss': 3.8227, 'learning_rate': 0.0001766044443118978, 'epoch': 0.9}
Step 97: {'loss': 4.1087, 'learning_rate': 0.00018973317451908642, 'epoch': 0.69}
Step 127: {'loss': 3.968, 'learning_rate': 0.00017606757810501088, 'epoch': 0.9}
Step 98: {'loss': 3.6906, 'learning_rate': 0.00018936326403234125, 'epoch': 0.7}
Step 128: {'loss': 3.7581, 'learning_rate': 0.0001755254576178535, 'epoch': 0.91}
Step 99: {'loss': 4.3866, 'learning_rate': 0.0001889871808811469, 'epoch': 0.7}
Step 129: {'loss': 4.1174, 'learning_rate': 0.00017497812029677344, 'epoch': 0.92}
Step 100: {'loss': 4.2274, 'learning_rate': 0.00018860495104301345, 'epoch': 0.71}
Step 130: {'loss': 3.7678, 'learning_rate': 0.00017442560394846516, 'epoch': 0.92}
Step 101: {'loss': 4.2655, 'learning_rate': 0.00018821660092002641, 'epoch': 0.72}
Step 131: {'loss': 4.0231, 'learning_rate': 0.0001738679467373586, 'epoch': 0.93}
Step 102: {'loss': 4.1982, 'learning_rate': 0.00018782215733702286, 'epoch': 0.73}
Step 132: {'loss': 3.8752, 'learning_rate': 0.00017330518718298264, 'epoch': 0.94}
Step 103: {'loss': 4.0704, 'learning_rate': 0.00018742164753973855, 'epoch': 0.73}
Step 133: {'loss': 3.8858, 'learning_rate': 0.00017273736415730488, 'epoch': 0.95}
Step 104: {'loss': 4.0697, 'learning_rate': 0.00018701509919292613, 'epoch': 0.74}
Step 134: {'loss': 4.1486, 'learning_rate': 0.0001721645168820462, 'epoch': 0.95}
Step 105: {'loss': 4.2263, 'learning_rate': 0.00018660254037844388, 'epoch': 0.75}
Step 135: {'loss': 3.9326, 'learning_rate': 0.00017158668492597186, 'epoch': 0.96}
Step 106: {'loss': 4.0979, 'learning_rate': 0.0001861839995933164, 'epoch': 0.75}
Step 136: {'loss': 3.8421, 'learning_rate': 0.00017100390820215804, 'epoch': 0.97}
Step 107: {'loss': 4.0933, 'learning_rate': 0.00018575950574776595, 'epoch': 0.76}
Step 137: {'loss': 4.2588, 'learning_rate': 0.00017041622696523518, 'epoch': 0.97}
Step 108: {'loss': 3.7069, 'learning_rate': 0.00018532908816321558, 'epoch': 0.77}
Step 138: {'loss': 3.9404, 'learning_rate': 0.00016982368180860728, 'epoch': 0.98}
Step 109: {'loss': 4.0098, 'learning_rate': 0.00018489277657026375, 'epoch': 0.78}
Step 139: {'loss': 3.7706, 'learning_rate': 0.00016922631366164797, 'epoch': 0.99}
Step 110: {'loss': 3.3326, 'learning_rate': 0.0001844506011066308, 'epoch': 0.78}
Step 140: {'loss': 3.4641, 'learning_rate': 0.0001686241637868734, 'epoch': 1.0}
Step 111: {'loss': 3.9404, 'learning_rate': 0.00018400259231507717, 'epoch': 0.79}
Step 141: {'loss': 4.0647, 'learning_rate': 0.00016801727377709194, 'epoch': 1.0}
Step 112: {'loss': 4.74, 'learning_rate': 0.00018354878114129367, 'epoch': 0.8}
Step 142: {'loss': 3.7832, 'learning_rate': 0.00016740568555253155, 'epoch': 1.01}
Step 113: {'loss': 3.9483, 'learning_rate': 0.00018308919893176396, 'epoch': 0.8}
Step 143: {'loss': 4.0318, 'learning_rate': 0.00016678944135794374, 'epoch': 1.02}
Step 114: {'loss': 3.6357, 'learning_rate': 0.0001826238774315995, 'epoch': 0.81}
Step 144: {'loss': 4.3747, 'learning_rate': 0.00016616858375968595, 'epoch': 1.02}
Step 115: {'loss': 4.4814, 'learning_rate': 0.00018215284878234642, 'epoch': 0.82}
Step 145: {'loss': 4.1334, 'learning_rate': 0.000165543155642781, 'epoch': 1.03}
Step 116: {'loss': 3.7068, 'learning_rate': 0.00018167614551976567, 'epoch': 0.82}
Step 146: {'loss': 4.2646, 'learning_rate': 0.0001649132002079552, 'epoch': 1.04}
Step 117: {'loss': 3.9675, 'learning_rate': 0.00018119380057158568, 'epoch': 0.83}
Step 147: {'loss': 3.7678, 'learning_rate': 0.00016427876096865394, 'epoch': 1.05}
Step 118: {'loss': 3.841, 'learning_rate': 0.00018070584725522762, 'epoch': 0.84}
Step 148: {'loss': 3.4134, 'learning_rate': 0.00016363988174803638, 'epoch': 1.05}
Step 119: {'loss': 3.6318, 'learning_rate': 0.0001802123192755044, 'epoch': 0.85}
Step 149: {'loss': 3.6496, 'learning_rate': 0.00016299660667594814, 'epoch': 1.06}
Step 120: {'loss': 3.5457, 'learning_rate': 0.00017971325072229226, 'epoch': 0.85}
Step 150: {'loss': 4.0409, 'learning_rate': 0.00016234898018587337, 'epoch': 1.07}
Step 121: {'loss': 3.7711, 'learning_rate': 0.00017920867606817625, 'epoch': 0.86}
Step 151: {'loss': 3.6401, 'learning_rate': 0.00016169704701186527, 'epoch': 1.07}
Step 122: {'loss': 4.1597, 'learning_rate': 0.0001786986301660689, 'epoch': 0.87}
Step 152: {'loss': 3.6084, 'learning_rate': 0.00016104085218545633, 'epoch': 1.08}
Step 123: {'loss': 3.8835, 'learning_rate': 0.000178183148246803, 'epoch': 0.87}
Step 153: {'loss': 4.0378, 'learning_rate': 0.00016038044103254775, 'epoch': 1.09}
Step 124: {'loss': 3.8755, 'learning_rate': 0.00017766226591669785, 'epoch': 0.88}
Step 154: {'loss': 3.8928, 'learning_rate': 0.00015971585917027862, 'epoch': 1.1}
Step 125: {'loss': 3.9996, 'learning_rate': 0.0001771360191551, 'epoch': 0.89}
Step 155: {'loss': 4.2014, 'learning_rate': 0.00015904715250387498, 'epoch': 1.1}
Step 126: {'loss': 3.9069, 'learning_rate': 0.0001766044443118978, 'epoch': 0.9}
Step 156: {'loss': 3.873, 'learning_rate': 0.000158374367223479, 'epoch': 1.11}
Step 127: {'loss': 4.5083, 'learning_rate': 0.00017606757810501088, 'epoch': 0.9}
Step 157: {'loss': 3.7208, 'learning_rate': 0.0001576975498009583, 'epoch': 1.12}
Step 128: {'loss': 3.904, 'learning_rate': 0.0001755254576178535, 'epoch': 0.91}
Step 158: {'loss': 4.289, 'learning_rate': 0.0001570167469866962, 'epoch': 1.12}
Step 129: {'loss': 3.9957, 'learning_rate': 0.00017497812029677344, 'epoch': 0.92}
Step 159: {'loss': 3.983, 'learning_rate': 0.0001563320058063622, 'epoch': 1.13}
Step 130: {'loss': 3.9585, 'learning_rate': 0.00017442560394846516, 'epoch': 0.92}
Step 160: {'loss': 3.9136, 'learning_rate': 0.00015564337355766412, 'epoch': 1.14}
Step 131: {'loss': 4.1926, 'learning_rate': 0.0001738679467373586, 'epoch': 0.93}
Step 161: {'loss': 3.8937, 'learning_rate': 0.0001549508978070806, 'epoch': 1.14}
Step 132: {'loss': 3.8506, 'learning_rate': 0.00017330518718298264, 'epoch': 0.94}
Step 162: {'loss': 3.2671, 'learning_rate': 0.00015425462638657595, 'epoch': 1.15}
Step 133: {'loss': 3.5985, 'learning_rate': 0.00017273736415730488, 'epoch': 0.95}
Step 163: {'loss': 3.6271, 'learning_rate': 0.00015355460739029586, 'epoch': 1.16}
Step 134: {'loss': 4.4419, 'learning_rate': 0.0001721645168820462, 'epoch': 0.95}
Step 164: {'loss': 3.6839, 'learning_rate': 0.00015285088917124556, 'epoch': 1.17}
Step 135: {'loss': 4.3562, 'learning_rate': 0.00017158668492597186, 'epoch': 0.96}
Step 165: {'loss': 3.4732, 'learning_rate': 0.0001521435203379498, 'epoch': 1.17}
Step 136: {'loss': 3.6371, 'learning_rate': 0.00017100390820215804, 'epoch': 0.97}
Step 166: {'loss': 4.0029, 'learning_rate': 0.00015143254975109538, 'epoch': 1.18}
Step 137: {'loss': 3.85, 'learning_rate': 0.00017041622696523518, 'epoch': 0.97}
Step 167: {'loss': 4.071, 'learning_rate': 0.0001507180265201559, 'epoch': 1.19}
Step 138: {'loss': 4.0642, 'learning_rate': 0.00016982368180860728, 'epoch': 0.98}
Step 168: {'loss': 3.4726, 'learning_rate': 0.00015000000000000001, 'epoch': 1.19}
Step 139: {'loss': 3.9416, 'learning_rate': 0.00016922631366164797, 'epoch': 0.99}
Step 169: {'loss': 3.7777, 'learning_rate': 0.00014927851978748178, 'epoch': 1.2}
Step 140: {'loss': 3.5231, 'learning_rate': 0.0001686241637868734, 'epoch': 1.0}
Step 170: {'loss': 3.8781, 'learning_rate': 0.00014855363571801523, 'epoch': 1.21}
Step 141: {'loss': 3.6798, 'learning_rate': 0.00016801727377709194, 'epoch': 1.0}
Step 171: {'loss': 3.662, 'learning_rate': 0.00014782539786213183, 'epoch': 1.22}
Step 142: {'loss': 3.4393, 'learning_rate': 0.00016740568555253155, 'epoch': 1.01}
Step 172: {'loss': 3.7732, 'learning_rate': 0.00014709385652202203, 'epoch': 1.22}
Step 143: {'loss': 3.9694, 'learning_rate': 0.00016678944135794374, 'epoch': 1.02}
Step 173: {'loss': 4.0163, 'learning_rate': 0.00014635906222806058, 'epoch': 1.23}
Step 144: {'loss': 3.606, 'learning_rate': 0.00016616858375968595, 'epoch': 1.02}
Step 174: {'loss': 3.5349, 'learning_rate': 0.0001456210657353163, 'epoch': 1.24}
Step 145: {'loss': 3.7537, 'learning_rate': 0.000165543155642781, 'epoch': 1.03}
Step 175: {'loss': 3.4537, 'learning_rate': 0.00014487991802004623, 'epoch': 1.24}
Step 146: {'loss': 3.4169, 'learning_rate': 0.0001649132002079552, 'epoch': 1.04}
Step 176: {'loss': 3.862, 'learning_rate': 0.0001441356702761744, 'epoch': 1.25}
Step 147: {'loss': 3.605, 'learning_rate': 0.00016427876096865394, 'epoch': 1.05}
Step 177: {'loss': 3.9456, 'learning_rate': 0.00014338837391175582, 'epoch': 1.26}
Step 148: {'loss': 4.0749, 'learning_rate': 0.00016363988174803638, 'epoch': 1.05}
Step 178: {'loss': 3.8302, 'learning_rate': 0.0001426380805454254, 'epoch': 1.27}
Step 149: {'loss': 3.4764, 'learning_rate': 0.00016299660667594814, 'epoch': 1.06}
Step 179: {'loss': 3.4457, 'learning_rate': 0.0001418848420028325, 'epoch': 1.27}
Step 150: {'loss': 3.9161, 'learning_rate': 0.00016234898018587337, 'epoch': 1.07}
Step 180: {'loss': 3.8213, 'learning_rate': 0.00014112871031306119, 'epoch': 1.28}
Step 151: {'loss': 3.4598, 'learning_rate': 0.00016169704701186527, 'epoch': 1.07}
Step 181: {'loss': 4.0145, 'learning_rate': 0.00014036973770503624, 'epoch': 1.29}
Step 152: {'loss': 3.4562, 'learning_rate': 0.00016104085218545633, 'epoch': 1.08}
Step 182: {'loss': 3.8294, 'learning_rate': 0.0001396079766039157, 'epoch': 1.29}
Step 153: {'loss': 3.6476, 'learning_rate': 0.00016038044103254775, 'epoch': 1.09}
Step 183: {'loss': 4.1286, 'learning_rate': 0.00013884347962746948, 'epoch': 1.3}
Step 154: {'loss': 3.9566, 'learning_rate': 0.00015971585917027862, 'epoch': 1.1}
Step 184: {'loss': 3.6027, 'learning_rate': 0.00013807629958244498, 'epoch': 1.31}
Step 155: {'loss': 3.6427, 'learning_rate': 0.00015904715250387498, 'epoch': 1.1}
Step 185: {'loss': 3.8256, 'learning_rate': 0.0001373064894609194, 'epoch': 1.32}
Step 156: {'loss': 3.7345, 'learning_rate': 0.000158374367223479, 'epoch': 1.11}
Step 186: {'loss': 4.0057, 'learning_rate': 0.00013653410243663952, 'epoch': 1.32}
Step 157: {'loss': 3.7574, 'learning_rate': 0.0001576975498009583, 'epoch': 1.12}
Step 187: {'loss': 3.7253, 'learning_rate': 0.0001357591918613486, 'epoch': 1.33}
Step 158: {'loss': 4.3526, 'learning_rate': 0.0001570167469866962, 'epoch': 1.12}
Step 188: {'loss': 3.5168, 'learning_rate': 0.0001349818112611015, 'epoch': 1.34}
Step 159: {'loss': 4.4297, 'learning_rate': 0.0001563320058063622, 'epoch': 1.13}
Step 189: {'loss': 3.8876, 'learning_rate': 0.00013420201433256689, 'epoch': 1.34}
Step 160: {'loss': 3.7373, 'learning_rate': 0.00015564337355766412, 'epoch': 1.14}
Step 190: {'loss': 3.8625, 'learning_rate': 0.00013341985493931877, 'epoch': 1.35}
Step 161: {'loss': 4.1718, 'learning_rate': 0.0001549508978070806, 'epoch': 1.14}
Step 191: {'loss': 3.4302, 'learning_rate': 0.0001326353871081156, 'epoch': 1.36}
Step 162: {'loss': 4.4625, 'learning_rate': 0.00015425462638657595, 'epoch': 1.15}
Step 192: {'loss': 3.4593, 'learning_rate': 0.00013184866502516845, 'epoch': 1.37}
Step 163: {'loss': 4.3136, 'learning_rate': 0.00015355460739029586, 'epoch': 1.16}
Step 193: {'loss': 3.6302, 'learning_rate': 0.00013105974303239838, 'epoch': 1.37}
Step 164: {'loss': 3.2762, 'learning_rate': 0.00015285088917124556, 'epoch': 1.17}
Step 194: {'loss': 3.739, 'learning_rate': 0.0001302686756236826, 'epoch': 1.38}
Step 165: {'loss': 3.6025, 'learning_rate': 0.0001521435203379498, 'epoch': 1.17}
Step 195: {'loss': 3.6387, 'learning_rate': 0.00012947551744109043, 'epoch': 1.39}
Step 166: {'loss': 3.6461, 'learning_rate': 0.00015143254975109538, 'epoch': 1.18}
Step 196: {'loss': 3.7228, 'learning_rate': 0.00012868032327110904, 'epoch': 1.39}
Step 167: {'loss': 3.7804, 'learning_rate': 0.0001507180265201559, 'epoch': 1.19}
Step 197: {'loss': 3.7814, 'learning_rate': 0.00012788314804085903, 'epoch': 1.4}
Step 168: {'loss': 3.7414, 'learning_rate': 0.00015000000000000001, 'epoch': 1.19}
Step 198: {'loss': 4.367, 'learning_rate': 0.00012708404681430053, 'epoch': 1.41}
Step 169: {'loss': 3.5716, 'learning_rate': 0.00014927851978748178, 'epoch': 1.2}
Step 199: {'loss': 3.8803, 'learning_rate': 0.00012628307478842953, 'epoch': 1.42}
Step 170: {'loss': 3.7451, 'learning_rate': 0.00014855363571801523, 'epoch': 1.21}
Step 200: {'loss': 3.6976, 'learning_rate': 0.0001254802872894655, 'epoch': 1.42}
Step 171: {'loss': 3.8235, 'learning_rate': 0.00014782539786213183, 'epoch': 1.22}
Step 201: {'loss': 3.9535, 'learning_rate': 0.00012467573976902935, 'epoch': 1.43}
Step 172: {'loss': 4.1192, 'learning_rate': 0.00014709385652202203, 'epoch': 1.22}
Step 202: {'loss': 3.8626, 'learning_rate': 0.0001238694878003138, 'epoch': 1.44}
Step 173: {'loss': 3.8367, 'learning_rate': 0.00014635906222806058, 'epoch': 1.23}
Step 203: {'loss': 3.6274, 'learning_rate': 0.00012306158707424403, 'epoch': 1.44}
Step 174: {'loss': 3.3727, 'learning_rate': 0.0001456210657353163, 'epoch': 1.24}
Step 204: {'loss': 3.5064, 'learning_rate': 0.00012225209339563145, 'epoch': 1.45}
Step 175: {'loss': 3.7407, 'learning_rate': 0.00014487991802004623, 'epoch': 1.24}
Step 205: {'loss': 3.7618, 'learning_rate': 0.00012144106267931876, 'epoch': 1.46}
Step 176: {'loss': 3.3318, 'learning_rate': 0.0001441356702761744, 'epoch': 1.25}
Step 206: {'loss': 3.29, 'learning_rate': 0.00012062855094631778, 'epoch': 1.46}
Step 177: {'loss': 3.9222, 'learning_rate': 0.00014338837391175582, 'epoch': 1.26}
Step 207: {'loss': 3.8122, 'learning_rate': 0.00011981461431993977, 'epoch': 1.47}
Step 178: {'loss': 3.3311, 'learning_rate': 0.0001426380805454254, 'epoch': 1.27}
Step 208: {'loss': 3.4633, 'learning_rate': 0.00011899930902191902, 'epoch': 1.48}
Step 179: {'loss': 4.0837, 'learning_rate': 0.0001418848420028325, 'epoch': 1.27}
Step 209: {'loss': 3.9519, 'learning_rate': 0.00011818269136852909, 'epoch': 1.49}
Step 180: {'loss': 3.6001, 'learning_rate': 0.00014112871031306119, 'epoch': 1.28}
Step 210: {'loss': 4.0047, 'learning_rate': 0.00011736481776669306, 'epoch': 1.49}
Step 181: {'loss': 3.5781, 'learning_rate': 0.00014036973770503624, 'epoch': 1.29}
Step 211: {'loss': 3.3512, 'learning_rate': 0.00011654574471008713, 'epoch': 1.5}
Step 182: {'loss': 3.7422, 'learning_rate': 0.0001396079766039157, 'epoch': 1.29}
Step 212: {'loss': 3.8666, 'learning_rate': 0.00011572552877523854, 'epoch': 1.51}
Step 183: {'loss': 3.8757, 'learning_rate': 0.00013884347962746948, 'epoch': 1.3}
Step 213: {'loss': 3.5573, 'learning_rate': 0.00011490422661761744, 'epoch': 1.51}
Step 184: {'loss': 3.7242, 'learning_rate': 0.00013807629958244498, 'epoch': 1.31}
Step 214: {'loss': 3.4049, 'learning_rate': 0.00011408189496772368, 'epoch': 1.52}
Step 185: {'loss': 4.2093, 'learning_rate': 0.0001373064894609194, 'epoch': 1.32}
Step 215: {'loss': 3.339, 'learning_rate': 0.00011325859062716795, 'epoch': 1.53}
Step 186: {'loss': 3.8718, 'learning_rate': 0.00013653410243663952, 'epoch': 1.32}
Step 216: {'loss': 3.5799, 'learning_rate': 0.00011243437046474853, 'epoch': 1.54}
Step 187: {'loss': 3.9282, 'learning_rate': 0.0001357591918613486, 'epoch': 1.33}
Step 217: {'loss': 3.6979, 'learning_rate': 0.00011160929141252303, 'epoch': 1.54}
Step 188: {'loss': 3.7536, 'learning_rate': 0.0001349818112611015, 'epoch': 1.34}
Step 218: {'loss': 3.2939, 'learning_rate': 0.00011078341046187589, 'epoch': 1.55}
Step 189: {'loss': 4.0825, 'learning_rate': 0.00013420201433256689, 'epoch': 1.34}
Step 219: {'loss': 3.7601, 'learning_rate': 0.00010995678465958168, 'epoch': 1.56}
Step 190: {'loss': 4.3041, 'learning_rate': 0.00013341985493931877, 'epoch': 1.35}
Step 220: {'loss': 3.7272, 'learning_rate': 0.00010912947110386484, 'epoch': 1.56}
Step 191: {'loss': 3.9465, 'learning_rate': 0.0001326353871081156, 'epoch': 1.36}
Step 221: {'loss': 3.5721, 'learning_rate': 0.00010830152694045552, 'epoch': 1.57}
Step 192: {'loss': 3.3997, 'learning_rate': 0.00013184866502516845, 'epoch': 1.37}
Step 222: {'loss': 3.8766, 'learning_rate': 0.00010747300935864243, 'epoch': 1.58}
Step 193: {'loss': 4.0319, 'learning_rate': 0.00013105974303239838, 'epoch': 1.37}
Step 223: {'loss': 3.9963, 'learning_rate': 0.00010664397558732244, 'epoch': 1.59}
Step 194: {'loss': 3.6479, 'learning_rate': 0.0001302686756236826, 'epoch': 1.38}
Step 224: {'loss': 3.6036, 'learning_rate': 0.00010581448289104758, 'epoch': 1.59}
Step 195: {'loss': 3.5728, 'learning_rate': 0.00012947551744109043, 'epoch': 1.39}
Step 225: {'loss': 3.049, 'learning_rate': 0.00010498458856606972, 'epoch': 1.6}
Step 196: {'loss': 3.491, 'learning_rate': 0.00012868032327110904, 'epoch': 1.39}
Step 226: {'loss': 3.8116, 'learning_rate': 0.00010415434993638269, 'epoch': 1.61}
Step 197: {'loss': 3.6795, 'learning_rate': 0.00012788314804085903, 'epoch': 1.4}
Step 227: {'loss': 3.6057, 'learning_rate': 0.00010332382434976266, 'epoch': 1.61}
Step 198: {'loss': 3.5549, 'learning_rate': 0.00012708404681430053, 'epoch': 1.41}
Step 228: {'loss': 3.6895, 'learning_rate': 0.0001024930691738073, 'epoch': 1.62}
Step 199: {'loss': 3.5631, 'learning_rate': 0.00012628307478842953, 'epoch': 1.42}
Step 229: {'loss': 3.937, 'learning_rate': 0.00010166214179197264, 'epoch': 1.63}
Step 200: {'loss': 3.5713, 'learning_rate': 0.0001254802872894655, 'epoch': 1.42}
Step 230: {'loss': 3.651, 'learning_rate': 0.00010083109959960973, 'epoch': 1.64}
Step 201: {'loss': 3.9005, 'learning_rate': 0.00012467573976902935, 'epoch': 1.43}
Step 231: {'loss': 3.8504, 'learning_rate': 0.0001, 'epoch': 1.64}
Step 202: {'loss': 3.7307, 'learning_rate': 0.0001238694878003138, 'epoch': 1.44}
Step 232: {'loss': 3.4938, 'learning_rate': 9.916890040039031e-05, 'epoch': 1.65}
Step 203: {'loss': 3.5588, 'learning_rate': 0.00012306158707424403, 'epoch': 1.44}
Step 233: {'loss': 3.4253, 'learning_rate': 9.833785820802739e-05, 'epoch': 1.66}
Step 204: {'loss': 4.2193, 'learning_rate': 0.00012225209339563145, 'epoch': 1.45}
Step 234: {'loss': 3.9469, 'learning_rate': 9.750693082619273e-05, 'epoch': 1.66}
Step 205: {'loss': 3.8844, 'learning_rate': 0.00012144106267931876, 'epoch': 1.46}
Step 235: {'loss': 3.5783, 'learning_rate': 9.667617565023735e-05, 'epoch': 1.67}
Step 206: {'loss': 3.4161, 'learning_rate': 0.00012062855094631778, 'epoch': 1.46}
Step 236: {'loss': 3.9483, 'learning_rate': 9.584565006361734e-05, 'epoch': 1.68}
Step 207: {'loss': 3.5536, 'learning_rate': 0.00011981461431993977, 'epoch': 1.47}
Step 237: {'loss': 3.8809, 'learning_rate': 9.501541143393028e-05, 'epoch': 1.69}
Step 208: {'loss': 3.6866, 'learning_rate': 0.00011899930902191902, 'epoch': 1.48}
Step 238: {'loss': 3.9002, 'learning_rate': 9.418551710895243e-05, 'epoch': 1.69}
Step 209: {'loss': 3.7671, 'learning_rate': 0.00011818269136852909, 'epoch': 1.49}
Step 239: {'loss': 3.8625, 'learning_rate': 9.335602441267759e-05, 'epoch': 1.7}
Step 210: {'loss': 3.6879, 'learning_rate': 0.00011736481776669306, 'epoch': 1.49}
Step 240: {'loss': 3.8093, 'learning_rate': 9.252699064135758e-05, 'epoch': 1.71}
Step 211: {'loss': 3.8487, 'learning_rate': 0.00011654574471008713, 'epoch': 1.5}
Step 212: {'loss': 4.0437, 'learning_rate': 0.00011572552877523854, 'epoch': 1.51}
Step 241: {'loss': 3.9115, 'learning_rate': 9.169847305954447e-05, 'epoch': 1.71}
Step 213: {'loss': 3.9753, 'learning_rate': 0.00011490422661761744, 'epoch': 1.51}
Step 242: {'loss': 3.6716, 'learning_rate': 9.087052889613518e-05, 'epoch': 1.72}
Step 214: {'loss': 3.9476, 'learning_rate': 0.00011408189496772368, 'epoch': 1.52}
Step 243: {'loss': 3.7599, 'learning_rate': 9.004321534041835e-05, 'epoch': 1.73}
Step 215: {'loss': 3.7772, 'learning_rate': 0.00011325859062716795, 'epoch': 1.53}
Step 244: {'loss': 3.8654, 'learning_rate': 8.921658953812415e-05, 'epoch': 1.74}
Step 216: {'loss': 3.5318, 'learning_rate': 0.00011243437046474853, 'epoch': 1.54}
Step 245: {'loss': 3.73, 'learning_rate': 8.839070858747697e-05, 'epoch': 1.74}
Step 217: {'loss': 4.6842, 'learning_rate': 0.00011160929141252303, 'epoch': 1.54}
Step 246: {'loss': 3.4951, 'learning_rate': 8.756562953525152e-05, 'epoch': 1.75}
Step 218: {'loss': 3.3132, 'learning_rate': 0.00011078341046187589, 'epoch': 1.55}
Step 247: {'loss': 3.5179, 'learning_rate': 8.674140937283208e-05, 'epoch': 1.76}
Step 219: {'loss': 3.8658, 'learning_rate': 0.00010995678465958168, 'epoch': 1.56}
Step 248: {'loss': 4.1122, 'learning_rate': 8.591810503227635e-05, 'epoch': 1.76}
Step 220: {'loss': 3.7187, 'learning_rate': 0.00010912947110386484, 'epoch': 1.56}
Step 249: {'loss': 3.4643, 'learning_rate': 8.509577338238255e-05, 'epoch': 1.77}
Step 221: {'loss': 3.8064, 'learning_rate': 0.00010830152694045552, 'epoch': 1.57}
Step 250: {'loss': 3.645, 'learning_rate': 8.427447122476148e-05, 'epoch': 1.78}
Step 222: {'loss': 3.7383, 'learning_rate': 0.00010747300935864243, 'epoch': 1.58}
Step 251: {'loss': 3.7133, 'learning_rate': 8.345425528991288e-05, 'epoch': 1.78}
Step 223: {'loss': 3.6019, 'learning_rate': 0.00010664397558732244, 'epoch': 1.59}
Step 252: {'loss': 3.6081, 'learning_rate': 8.263518223330697e-05, 'epoch': 1.79}
Step 224: {'loss': 3.6536, 'learning_rate': 0.00010581448289104758, 'epoch': 1.59}
Step 253: {'loss': 3.5385, 'learning_rate': 8.181730863147093e-05, 'epoch': 1.8}
Step 225: {'loss': 3.6814, 'learning_rate': 0.00010498458856606972, 'epoch': 1.6}
Step 254: {'loss': 3.9061, 'learning_rate': 8.100069097808103e-05, 'epoch': 1.81}
Step 226: {'loss': 3.6419, 'learning_rate': 0.00010415434993638269, 'epoch': 1.61}
Step 255: {'loss': 3.3831, 'learning_rate': 8.018538568006027e-05, 'epoch': 1.81}
Step 227: {'loss': 4.0921, 'learning_rate': 0.00010332382434976266, 'epoch': 1.61}
Step 256: {'loss': 3.8128, 'learning_rate': 7.937144905368226e-05, 'epoch': 1.82}
Step 228: {'loss': 3.834, 'learning_rate': 0.0001024930691738073, 'epoch': 1.62}
Step 257: {'loss': 3.8703, 'learning_rate': 7.855893732068125e-05, 'epoch': 1.83}
Step 229: {'loss': 3.6129, 'learning_rate': 0.00010166214179197264, 'epoch': 1.63}
Step 258: {'loss': 3.689, 'learning_rate': 7.774790660436858e-05, 'epoch': 1.83}
Step 230: {'loss': 4.0653, 'learning_rate': 0.00010083109959960973, 'epoch': 1.64}
Step 259: {'loss': 3.5432, 'learning_rate': 7.693841292575598e-05, 'epoch': 1.84}
Step 231: {'loss': 4.0279, 'learning_rate': 0.0001, 'epoch': 1.64}
Step 260: {'loss': 3.7697, 'learning_rate': 7.613051219968623e-05, 'epoch': 1.85}
Step 232: {'loss': 3.8442, 'learning_rate': 9.916890040039031e-05, 'epoch': 1.65}
Step 261: {'loss': 3.8218, 'learning_rate': 7.532426023097063e-05, 'epoch': 1.86}
Step 233: {'loss': 4.1401, 'learning_rate': 9.833785820802739e-05, 'epoch': 1.66}
Step 262: {'loss': 3.7284, 'learning_rate': 7.451971271053455e-05, 'epoch': 1.86}
Step 234: {'loss': 4.1384, 'learning_rate': 9.750693082619273e-05, 'epoch': 1.66}
Step 263: {'loss': 4.0513, 'learning_rate': 7.371692521157048e-05, 'epoch': 1.87}
Step 235: {'loss': 3.2558, 'learning_rate': 9.667617565023735e-05, 'epoch': 1.67}
Step 264: {'loss': 3.5152, 'learning_rate': 7.291595318569951e-05, 'epoch': 1.88}
Step 236: {'loss': 4.0652, 'learning_rate': 9.584565006361734e-05, 'epoch': 1.68}
Step 265: {'loss': 3.7422, 'learning_rate': 7.211685195914097e-05, 'epoch': 1.88}
Step 237: {'loss': 4.0674, 'learning_rate': 9.501541143393028e-05, 'epoch': 1.69}
Step 266: {'loss': 3.8736, 'learning_rate': 7.131967672889101e-05, 'epoch': 1.89}
Step 238: {'loss': 3.9584, 'learning_rate': 9.418551710895243e-05, 'epoch': 1.69}
Step 267: {'loss': 3.5135, 'learning_rate': 7.052448255890957e-05, 'epoch': 1.9}
Step 239: {'loss': 3.3865, 'learning_rate': 9.335602441267759e-05, 'epoch': 1.7}
Step 268: {'loss': 3.8955, 'learning_rate': 6.973132437631742e-05, 'epoch': 1.91}
Step 240: {'loss': 3.5293, 'learning_rate': 9.252699064135758e-05, 'epoch': 1.71}
Step 269: {'loss': 3.5285, 'learning_rate': 6.894025696760163e-05, 'epoch': 1.91}
Step 241: {'loss': 3.6308, 'learning_rate': 9.169847305954447e-05, 'epoch': 1.71}
Step 270: {'loss': 3.7155, 'learning_rate': 6.815133497483157e-05, 'epoch': 1.92}
Step 242: {'loss': 3.4551, 'learning_rate': 9.087052889613518e-05, 'epoch': 1.72}
Step 271: {'loss': 3.8379, 'learning_rate': 6.736461289188445e-05, 'epoch': 1.93}
Step 243: {'loss': 3.5957, 'learning_rate': 9.004321534041835e-05, 'epoch': 1.73}
Step 272: {'loss': 3.4365, 'learning_rate': 6.658014506068126e-05, 'epoch': 1.93}
Step 244: {'loss': 3.6223, 'learning_rate': 8.921658953812415e-05, 'epoch': 1.74}
Step 273: {'loss': 3.4721, 'learning_rate': 6.579798566743314e-05, 'epoch': 1.94}
Step 245: {'loss': 3.5498, 'learning_rate': 8.839070858747697e-05, 'epoch': 1.74}
Step 274: {'loss': 3.89, 'learning_rate': 6.501818873889855e-05, 'epoch': 1.95}
Step 246: {'loss': 3.7914, 'learning_rate': 8.756562953525152e-05, 'epoch': 1.75}
Step 275: {'loss': 3.4866, 'learning_rate': 6.424080813865138e-05, 'epoch': 1.96}
Step 247: {'loss': 3.385, 'learning_rate': 8.674140937283208e-05, 'epoch': 1.76}
Step 276: {'loss': 3.5718, 'learning_rate': 6.34658975633605e-05, 'epoch': 1.96}
Step 248: {'loss': 3.8512, 'learning_rate': 8.591810503227635e-05, 'epoch': 1.76}
Step 277: {'loss': 3.3471, 'learning_rate': 6.269351053908061e-05, 'epoch': 1.97}
Step 249: {'loss': 3.5282, 'learning_rate': 8.509577338238255e-05, 'epoch': 1.77}
Step 278: {'loss': 3.6162, 'learning_rate': 6.192370041755505e-05, 'epoch': 1.98}
Step 250: {'loss': 3.8359, 'learning_rate': 8.427447122476148e-05, 'epoch': 1.78}
Step 279: {'loss': 3.6072, 'learning_rate': 6.115652037253053e-05, 'epoch': 1.98}
Step 251: {'loss': 3.3908, 'learning_rate': 8.345425528991288e-05, 'epoch': 1.78}
Step 280: {'loss': 3.2897, 'learning_rate': 6.039202339608432e-05, 'epoch': 1.99}
Step 252: {'loss': 4.4115, 'learning_rate': 8.263518223330697e-05, 'epoch': 1.79}
Step 281: {'loss': 3.7651, 'learning_rate': 5.963026229496378e-05, 'epoch': 2.0}
Step 253: {'loss': 3.83, 'learning_rate': 8.181730863147093e-05, 'epoch': 1.8}
Step 282: {'loss': 3.7823, 'learning_rate': 5.887128968693887e-05, 'epoch': 2.01}
Step 254: {'loss': 3.6543, 'learning_rate': 8.100069097808103e-05, 'epoch': 1.81}
Step 283: {'loss': 3.7314, 'learning_rate': 5.8115157997167536e-05, 'epoch': 2.01}
Step 255: {'loss': 3.7719, 'learning_rate': 8.018538568006027e-05, 'epoch': 1.81}
Step 284: {'loss': 3.529, 'learning_rate': 5.736191945457463e-05, 'epoch': 2.02}
Step 256: {'loss': 3.6241, 'learning_rate': 7.937144905368226e-05, 'epoch': 1.82}
Step 285: {'loss': 3.7256, 'learning_rate': 5.6611626088244194e-05, 'epoch': 2.03}
Step 257: {'loss': 3.5946, 'learning_rate': 7.855893732068125e-05, 'epoch': 1.83}
Step 286: {'loss': 3.7408, 'learning_rate': 5.58643297238256e-05, 'epoch': 2.03}
Step 258: {'loss': 3.9572, 'learning_rate': 7.774790660436858e-05, 'epoch': 1.83}
Step 287: {'loss': 3.1482, 'learning_rate': 5.5120081979953785e-05, 'epoch': 2.04}
Step 259: {'loss': 3.6612, 'learning_rate': 7.693841292575598e-05, 'epoch': 1.84}
Step 288: {'loss': 3.3545, 'learning_rate': 5.43789342646837e-05, 'epoch': 2.05}
Step 260: {'loss': 3.4489, 'learning_rate': 7.613051219968623e-05, 'epoch': 1.85}
Step 289: {'loss': 3.8211, 'learning_rate': 5.3640937771939436e-05, 'epoch': 2.06}
Step 261: {'loss': 3.6541, 'learning_rate': 7.532426023097063e-05, 'epoch': 1.86}
Step 290: {'loss': 3.771, 'learning_rate': 5.290614347797802e-05, 'epoch': 2.06}
Step 262: {'loss': 3.5616, 'learning_rate': 7.451971271053455e-05, 'epoch': 1.86}
Step 291: {'loss': 3.4828, 'learning_rate': 5.217460213786821e-05, 'epoch': 2.07}
Step 263: {'loss': 3.8308, 'learning_rate': 7.371692521157048e-05, 'epoch': 1.87}
Step 292: {'loss': 3.5843, 'learning_rate': 5.1446364281984774e-05, 'epoch': 2.08}
Step 264: {'loss': 3.9115, 'learning_rate': 7.291595318569951e-05, 'epoch': 1.88}
Step 293: {'loss': 3.7308, 'learning_rate': 5.072148021251821e-05, 'epoch': 2.08}
Step 265: {'loss': 3.3314, 'learning_rate': 7.211685195914097e-05, 'epoch': 1.88}
Step 294: {'loss': 3.3476, 'learning_rate': 5.000000000000002e-05, 'epoch': 2.09}
Step 266: {'loss': 4.0138, 'learning_rate': 7.131967672889101e-05, 'epoch': 1.89}
Step 295: {'loss': 3.7935, 'learning_rate': 4.92819734798441e-05, 'epoch': 2.1}
Step 267: {'loss': 3.6956, 'learning_rate': 7.052448255890957e-05, 'epoch': 1.9}
Step 296: {'loss': 3.7259, 'learning_rate': 4.856745024890466e-05, 'epoch': 2.1}
Step 268: {'loss': 3.4823, 'learning_rate': 6.973132437631742e-05, 'epoch': 1.91}
Step 297: {'loss': 3.6952, 'learning_rate': 4.78564796620502e-05, 'epoch': 2.11}
Step 269: {'loss': 4.2339, 'learning_rate': 6.894025696760163e-05, 'epoch': 1.91}
Step 298: {'loss': 3.1291, 'learning_rate': 4.7149110828754464e-05, 'epoch': 2.12}
Step 270: {'loss': 4.052, 'learning_rate': 6.815133497483157e-05, 'epoch': 1.92}
Step 299: {'loss': 3.737, 'learning_rate': 4.644539260970416e-05, 'epoch': 2.13}
Step 271: {'loss': 3.298, 'learning_rate': 6.736461289188445e-05, 'epoch': 1.93}
Step 300: {'loss': 4.0274, 'learning_rate': 4.574537361342407e-05, 'epoch': 2.13}
Step 272: {'loss': 3.3853, 'learning_rate': 6.658014506068126e-05, 'epoch': 1.93}
Step 301: {'loss': 3.6998, 'learning_rate': 4.50491021929194e-05, 'epoch': 2.14}
Step 273: {'loss': 3.5934, 'learning_rate': 6.579798566743314e-05, 'epoch': 1.94}
Step 302: {'loss': 3.9539, 'learning_rate': 4.435662644233594e-05, 'epoch': 2.15}
Step 274: {'loss': 3.4769, 'learning_rate': 6.501818873889855e-05, 'epoch': 1.95}
Step 303: {'loss': 3.7421, 'learning_rate': 4.3667994193637796e-05, 'epoch': 2.15}
Step 275: {'loss': 3.7383, 'learning_rate': 6.424080813865138e-05, 'epoch': 1.96}
Step 304: {'loss': 3.7413, 'learning_rate': 4.298325301330383e-05, 'epoch': 2.16}
Step 276: {'loss': 3.4133, 'learning_rate': 6.34658975633605e-05, 'epoch': 1.96}
Step 305: {'loss': 3.2811, 'learning_rate': 4.23024501990417e-05, 'epoch': 2.17}
Step 277: {'loss': 3.8446, 'learning_rate': 6.269351053908061e-05, 'epoch': 1.97}
Step 306: {'loss': 3.5281, 'learning_rate': 4.1625632776521037e-05, 'epoch': 2.18}
Step 278: {'loss': 3.9535, 'learning_rate': 6.192370041755505e-05, 'epoch': 1.98}
Step 307: {'loss': 3.4244, 'learning_rate': 4.095284749612503e-05, 'epoch': 2.18}
Step 279: {'loss': 3.3622, 'learning_rate': 6.115652037253053e-05, 'epoch': 1.98}
Step 308: {'loss': 3.7067, 'learning_rate': 4.028414082972141e-05, 'epoch': 2.19}
Step 280: {'loss': 3.4941, 'learning_rate': 6.039202339608432e-05, 'epoch': 1.99}
Step 309: {'loss': 3.8376, 'learning_rate': 3.961955896745224e-05, 'epoch': 2.2}
Step 281: {'loss': 3.4073, 'learning_rate': 5.963026229496378e-05, 'epoch': 2.0}
Step 310: {'loss': 3.7409, 'learning_rate': 3.89591478145437e-05, 'epoch': 2.2}
Step 282: {'loss': 3.6004, 'learning_rate': 5.887128968693887e-05, 'epoch': 2.01}
Step 311: {'loss': 3.4028, 'learning_rate': 3.8302952988134756e-05, 'epoch': 2.21}
Step 283: {'loss': 4.1614, 'learning_rate': 5.8115157997167536e-05, 'epoch': 2.01}
Step 312: {'loss': 3.7154, 'learning_rate': 3.7651019814126654e-05, 'epoch': 2.22}
Step 284: {'loss': 4.106, 'learning_rate': 5.736191945457463e-05, 'epoch': 2.02}
Step 313: {'loss': 3.7059, 'learning_rate': 3.7003393324051874e-05, 'epoch': 2.23}
Step 285: {'loss': 3.9691, 'learning_rate': 5.6611626088244194e-05, 'epoch': 2.03}
Step 314: {'loss': 3.9475, 'learning_rate': 3.6360118251963645e-05, 'epoch': 2.23}
Step 286: {'loss': 3.5177, 'learning_rate': 5.58643297238256e-05, 'epoch': 2.03}
Step 315: {'loss': 3.3461, 'learning_rate': 3.5721239031346066e-05, 'epoch': 2.24}
Step 287: {'loss': 3.4607, 'learning_rate': 5.5120081979953785e-05, 'epoch': 2.04}
Step 316: {'loss': 3.8167, 'learning_rate': 3.508679979204481e-05, 'epoch': 2.25}
Step 288: {'loss': 3.5245, 'learning_rate': 5.43789342646837e-05, 'epoch': 2.05}
Step 317: {'loss': 3.5307, 'learning_rate': 3.445684435721897e-05, 'epoch': 2.25}
Step 289: {'loss': 3.5059, 'learning_rate': 5.3640937771939436e-05, 'epoch': 2.06}
Step 318: {'loss': 3.9303, 'learning_rate': 3.383141624031408e-05, 'epoch': 2.26}
Step 290: {'loss': 3.4365, 'learning_rate': 5.290614347797802e-05, 'epoch': 2.06}
Step 319: {'loss': 3.8177, 'learning_rate': 3.3210558642056275e-05, 'epoch': 2.27}
Step 291: {'loss': 3.9427, 'learning_rate': 5.217460213786821e-05, 'epoch': 2.07}
Step 320: {'loss': 3.3837, 'learning_rate': 3.259431444746846e-05, 'epoch': 2.28}
Step 292: {'loss': 3.6662, 'learning_rate': 5.1446364281984774e-05, 'epoch': 2.08}
Step 321: {'loss': 4.0115, 'learning_rate': 3.198272622290804e-05, 'epoch': 2.28}
Step 293: {'loss': 3.3148, 'learning_rate': 5.072148021251821e-05, 'epoch': 2.08}
Step 322: {'loss': 3.3329, 'learning_rate': 3.137583621312665e-05, 'epoch': 2.29}
Step 294: {'loss': 3.8223, 'learning_rate': 5.000000000000002e-05, 'epoch': 2.09}
Step 323: {'loss': 3.6297, 'learning_rate': 3.077368633835205e-05, 'epoch': 2.3}
Step 295: {'loss': 3.6998, 'learning_rate': 4.92819734798441e-05, 'epoch': 2.1}
Step 324: {'loss': 3.591, 'learning_rate': 3.0176318191392726e-05, 'epoch': 2.3}
Step 296: {'loss': 3.7029, 'learning_rate': 4.856745024890466e-05, 'epoch': 2.1}
Step 325: {'loss': 3.5092, 'learning_rate': 2.9583773034764826e-05, 'epoch': 2.31}
Step 297: {'loss': 3.2949, 'learning_rate': 4.78564796620502e-05, 'epoch': 2.11}
Step 326: {'loss': 3.4423, 'learning_rate': 2.8996091797841973e-05, 'epoch': 2.32}
Step 298: {'loss': 3.8863, 'learning_rate': 4.7149110828754464e-05, 'epoch': 2.12}
Step 327: {'loss': 3.544, 'learning_rate': 2.8413315074028158e-05, 'epoch': 2.33}
Step 299: {'loss': 3.8762, 'learning_rate': 4.644539260970416e-05, 'epoch': 2.13}
Step 328: {'loss': 3.3751, 'learning_rate': 2.7835483117953788e-05, 'epoch': 2.33}
Step 300: {'loss': 3.942, 'learning_rate': 4.574537361342407e-05, 'epoch': 2.13}
Step 329: {'loss': 3.4203, 'learning_rate': 2.7262635842695127e-05, 'epoch': 2.34}
Step 301: {'loss': 3.6098, 'learning_rate': 4.50491021929194e-05, 'epoch': 2.14}
Step 330: {'loss': 3.5095, 'learning_rate': 2.669481281701739e-05, 'epoch': 2.35}
Step 302: {'loss': 3.5267, 'learning_rate': 4.435662644233594e-05, 'epoch': 2.15}
Step 331: {'loss': 3.4967, 'learning_rate': 2.6132053262641466e-05, 'epoch': 2.35}
Step 303: {'loss': 3.8526, 'learning_rate': 4.3667994193637796e-05, 'epoch': 2.15}
Step 332: {'loss': 3.6456, 'learning_rate': 2.5574396051534832e-05, 'epoch': 2.36}
Step 304: {'loss': 3.5991, 'learning_rate': 4.298325301330383e-05, 'epoch': 2.16}
Step 333: {'loss': 3.6485, 'learning_rate': 2.502187970322657e-05, 'epoch': 2.37}
Step 305: {'loss': 3.6591, 'learning_rate': 4.23024501990417e-05, 'epoch': 2.17}
Step 334: {'loss': 3.945, 'learning_rate': 2.4474542382146537e-05, 'epoch': 2.38}
Step 306: {'loss': 3.967, 'learning_rate': 4.1625632776521037e-05, 'epoch': 2.18}
Step 335: {'loss': 3.5188, 'learning_rate': 2.3932421894989167e-05, 'epoch': 2.38}
Step 307: {'loss': 4.1604, 'learning_rate': 4.095284749612503e-05, 'epoch': 2.18}
Step 336: {'loss': 3.6401, 'learning_rate': 2.339555568810221e-05, 'epoch': 2.39}
Step 308: {'loss': 3.4576, 'learning_rate': 4.028414082972141e-05, 'epoch': 2.19}
Step 337: {'loss': 3.3573, 'learning_rate': 2.2863980844900036e-05, 'epoch': 2.4}
Step 309: {'loss': 3.5611, 'learning_rate': 3.961955896745224e-05, 'epoch': 2.2}
Step 338: {'loss': 3.4493, 'learning_rate': 2.2337734083302164e-05, 'epoch': 2.4}
Step 310: {'loss': 3.7217, 'learning_rate': 3.89591478145437e-05, 'epoch': 2.2}
Step 339: {'loss': 3.3353, 'learning_rate': 2.181685175319702e-05, 'epoch': 2.41}
Step 311: {'loss': 3.4153, 'learning_rate': 3.8302952988134756e-05, 'epoch': 2.21}
Step 340: {'loss': 3.4965, 'learning_rate': 2.1301369833931117e-05, 'epoch': 2.42}
Step 312: {'loss': 3.7045, 'learning_rate': 3.7651019814126654e-05, 'epoch': 2.22}
Step 341: {'loss': 3.4782, 'learning_rate': 2.079132393182378e-05, 'epoch': 2.42}
Step 313: {'loss': 3.653, 'learning_rate': 3.7003393324051874e-05, 'epoch': 2.23}
Step 342: {'loss': 3.8954, 'learning_rate': 2.0286749277707782e-05, 'epoch': 2.43}
Step 314: {'loss': 3.7042, 'learning_rate': 3.6360118251963645e-05, 'epoch': 2.23}
Step 343: {'loss': 3.9489, 'learning_rate': 1.9787680724495617e-05, 'epoch': 2.44}
Step 315: {'loss': 3.5683, 'learning_rate': 3.5721239031346066e-05, 'epoch': 2.24}
Step 344: {'loss': 3.5033, 'learning_rate': 1.929415274477239e-05, 'epoch': 2.45}
Step 316: {'loss': 3.461, 'learning_rate': 3.508679979204481e-05, 'epoch': 2.25}
Step 345: {'loss': 3.3503, 'learning_rate': 1.880619942841435e-05, 'epoch': 2.45}
Step 317: {'loss': 3.9959, 'learning_rate': 3.445684435721897e-05, 'epoch': 2.25}
Step 346: {'loss': 3.8386, 'learning_rate': 1.832385448023435e-05, 'epoch': 2.46}
Step 318: {'loss': 3.4189, 'learning_rate': 3.383141624031408e-05, 'epoch': 2.26}
Step 347: {'loss': 3.5173, 'learning_rate': 1.7847151217653624e-05, 'epoch': 2.47}
Step 319: {'loss': 3.457, 'learning_rate': 3.3210558642056275e-05, 'epoch': 2.27}
Step 348: {'loss': 3.5046, 'learning_rate': 1.7376122568400532e-05, 'epoch': 2.47}
Step 320: {'loss': 4.0442, 'learning_rate': 3.259431444746846e-05, 'epoch': 2.28}
Step 349: {'loss': 3.3804, 'learning_rate': 1.6910801068236016e-05, 'epoch': 2.48}
Step 321: {'loss': 3.5222, 'learning_rate': 3.198272622290804e-05, 'epoch': 2.28}
Step 350: {'loss': 3.8971, 'learning_rate': 1.6451218858706374e-05, 'epoch': 2.49}
Step 322: {'loss': 3.6462, 'learning_rate': 3.137583621312665e-05, 'epoch': 2.29}
Step 351: {'loss': 4.093, 'learning_rate': 1.5997407684922862e-05, 'epoch': 2.5}
Step 323: {'loss': 3.409, 'learning_rate': 3.077368633835205e-05, 'epoch': 2.3}
Step 352: {'loss': 3.4853, 'learning_rate': 1.5549398893369216e-05, 'epoch': 2.5}
Step 324: {'loss': 3.5722, 'learning_rate': 3.0176318191392726e-05, 'epoch': 2.3}
Step 353: {'loss': 3.9373, 'learning_rate': 1.5107223429736272e-05, 'epoch': 2.51}
Step 325: {'loss': 3.6235, 'learning_rate': 2.9583773034764826e-05, 'epoch': 2.31}
Step 354: {'loss': 3.9409, 'learning_rate': 1.467091183678444e-05, 'epoch': 2.52}
Step 326: {'loss': 3.2369, 'learning_rate': 2.8996091797841973e-05, 'epoch': 2.32}
Step 355: {'loss': 3.1965, 'learning_rate': 1.4240494252234049e-05, 'epoch': 2.52}
Step 327: {'loss': 4.0526, 'learning_rate': 2.8413315074028158e-05, 'epoch': 2.33}
Step 356: {'loss': 3.4595, 'learning_rate': 1.3816000406683604e-05, 'epoch': 2.53}
Step 328: {'loss': 3.4971, 'learning_rate': 2.7835483117953788e-05, 'epoch': 2.33}
Step 357: {'loss': 3.7822, 'learning_rate': 1.339745962155613e-05, 'epoch': 2.54}
Step 329: {'loss': 3.7633, 'learning_rate': 2.7262635842695127e-05, 'epoch': 2.34}
Step 358: {'loss': 3.2721, 'learning_rate': 1.2984900807073919e-05, 'epoch': 2.55}
Step 330: {'loss': 3.7631, 'learning_rate': 2.669481281701739e-05, 'epoch': 2.35}
Step 359: {'loss': 3.6039, 'learning_rate': 1.2578352460261456e-05, 'epoch': 2.55}
Step 331: {'loss': 3.5185, 'learning_rate': 2.6132053262641466e-05, 'epoch': 2.35}
Step 360: {'loss': 3.6225, 'learning_rate': 1.2177842662977135e-05, 'epoch': 2.56}
Step 332: {'loss': 3.6065, 'learning_rate': 2.5574396051534832e-05, 'epoch': 2.36}
Step 361: {'loss': 3.4792, 'learning_rate': 1.1783399079973578e-05, 'epoch': 2.57}
Step 333: {'loss': 3.643, 'learning_rate': 2.502187970322657e-05, 'epoch': 2.37}
Step 362: {'loss': 3.9706, 'learning_rate': 1.1395048956986575e-05, 'epoch': 2.57}
Step 334: {'loss': 3.6411, 'learning_rate': 2.4474542382146537e-05, 'epoch': 2.38}
Step 363: {'loss': 3.4283, 'learning_rate': 1.1012819118853147e-05, 'epoch': 2.58}
Step 335: {'loss': 3.5572, 'learning_rate': 2.3932421894989167e-05, 'epoch': 2.38}
Step 364: {'loss': 3.7697, 'learning_rate': 1.0636735967658784e-05, 'epoch': 2.59}
Step 336: {'loss': 3.5796, 'learning_rate': 2.339555568810221e-05, 'epoch': 2.39}
Step 365: {'loss': 3.6495, 'learning_rate': 1.0266825480913611e-05, 'epoch': 2.6}
Step 337: {'loss': 3.5603, 'learning_rate': 2.2863980844900036e-05, 'epoch': 2.4}
Step 366: {'loss': 4.0963, 'learning_rate': 9.903113209758096e-06, 'epoch': 2.6}
Step 338: {'loss': 4.0419, 'learning_rate': 2.2337734083302164e-05, 'epoch': 2.4}
Step 367: {'loss': 4.0732, 'learning_rate': 9.545624277198084e-06, 'epoch': 2.61}
Step 339: {'loss': 3.7602, 'learning_rate': 2.181685175319702e-05, 'epoch': 2.41}
Step 368: {'loss': 3.2284, 'learning_rate': 9.194383376369508e-06, 'epoch': 2.62}
Step 340: {'loss': 3.9638, 'learning_rate': 2.1301369833931117e-05, 'epoch': 2.42}
Step 369: {'loss': 3.7374, 'learning_rate': 8.849414768832687e-06, 'epoch': 2.62}
Step 341: {'loss': 3.6801, 'learning_rate': 2.079132393182378e-05, 'epoch': 2.42}
Step 370: {'loss': 3.3419, 'learning_rate': 8.510742282896544e-06, 'epoch': 2.63}
Step 342: {'loss': 3.3509, 'learning_rate': 2.0286749277707782e-05, 'epoch': 2.43}
Step 371: {'loss': 3.8654, 'learning_rate': 8.178389311972612e-06, 'epoch': 2.64}
Step 343: {'loss': 3.4683, 'learning_rate': 1.9787680724495617e-05, 'epoch': 2.44}
Step 372: {'loss': 4.1685, 'learning_rate': 7.852378812959227e-06, 'epoch': 2.65}
Step 344: {'loss': 3.4165, 'learning_rate': 1.929415274477239e-05, 'epoch': 2.45}
Step 373: {'loss': 3.7534, 'learning_rate': 7.532733304655848e-06, 'epoch': 2.65}
Step 345: {'loss': 3.3516, 'learning_rate': 1.880619942841435e-05, 'epoch': 2.45}
Step 374: {'loss': 3.8149, 'learning_rate': 7.219474866207465e-06, 'epoch': 2.66}
Step 346: {'loss': 3.6832, 'learning_rate': 1.832385448023435e-05, 'epoch': 2.46}
Step 375: {'loss': 3.6331, 'learning_rate': 6.9126251355795864e-06, 'epoch': 2.67}
Step 347: {'loss': 3.589, 'learning_rate': 1.7847151217653624e-05, 'epoch': 2.47}
Step 376: {'loss': 3.7655, 'learning_rate': 6.612205308063646e-06, 'epoch': 2.67}
Step 348: {'loss': 3.7669, 'learning_rate': 1.7376122568400532e-05, 'epoch': 2.47}
Step 377: {'loss': 3.6548, 'learning_rate': 6.318236134812916e-06, 'epoch': 2.68}
Step 349: {'loss': 3.3452, 'learning_rate': 1.6910801068236016e-05, 'epoch': 2.48}
Step 378: {'loss': 3.764, 'learning_rate': 6.030737921409169e-06, 'epoch': 2.69}
Step 350: {'loss': 3.6626, 'learning_rate': 1.6451218858706374e-05, 'epoch': 2.49}
Step 379: {'loss': 3.6713, 'learning_rate': 5.749730526460073e-06, 'epoch': 2.7}
Step 351: {'loss': 3.546, 'learning_rate': 1.5997407684922862e-05, 'epoch': 2.5}
Step 380: {'loss': 3.797, 'learning_rate': 5.475233360227516e-06, 'epoch': 2.7}
Step 352: {'loss': 3.7034, 'learning_rate': 1.5549398893369216e-05, 'epoch': 2.5}
Step 381: {'loss': 3.3301, 'learning_rate': 5.20726538328683e-06, 'epoch': 2.71}
Step 353: {'loss': 3.7146, 'learning_rate': 1.5107223429736272e-05, 'epoch': 2.51}
Step 382: {'loss': 3.5289, 'learning_rate': 4.945845105217117e-06, 'epoch': 2.72}
Step 354: {'loss': 3.9087, 'learning_rate': 1.467091183678444e-05, 'epoch': 2.52}
Step 383: {'loss': 3.4823, 'learning_rate': 4.6909905833226966e-06, 'epoch': 2.72}
Step 355: {'loss': 3.4536, 'learning_rate': 1.4240494252234049e-05, 'epoch': 2.52}
Step 384: {'loss': 4.1878, 'learning_rate': 4.442719421385922e-06, 'epoch': 2.73}
Step 356: {'loss': 3.2884, 'learning_rate': 1.3816000406683604e-05, 'epoch': 2.53}
Step 385: {'loss': 3.5062, 'learning_rate': 4.20104876845111e-06, 'epoch': 2.74}
Step 357: {'loss': 4.1407, 'learning_rate': 1.339745962155613e-05, 'epoch': 2.54}
Step 386: {'loss': 3.6335, 'learning_rate': 3.965995317640025e-06, 'epoch': 2.74}
Step 358: {'loss': 3.4266, 'learning_rate': 1.2984900807073919e-05, 'epoch': 2.55}
Step 387: {'loss': 3.7035, 'learning_rate': 3.7375753049987973e-06, 'epoch': 2.75}
Step 359: {'loss': 3.4996, 'learning_rate': 1.2578352460261456e-05, 'epoch': 2.55}
Step 388: {'loss': 3.5, 'learning_rate': 3.515804508376508e-06, 'epoch': 2.76}
Step 360: {'loss': 3.7685, 'learning_rate': 1.2177842662977135e-05, 'epoch': 2.56}
Step 389: {'loss': 3.6887, 'learning_rate': 3.3006982463352766e-06, 'epoch': 2.77}
Step 361: {'loss': 3.5941, 'learning_rate': 1.1783399079973578e-05, 'epoch': 2.57}
Step 390: {'loss': 3.6704, 'learning_rate': 3.092271377092215e-06, 'epoch': 2.77}
Step 362: {'loss': 3.9287, 'learning_rate': 1.1395048956986575e-05, 'epoch': 2.57}
Step 391: {'loss': 3.7986, 'learning_rate': 2.8905382974930172e-06, 'epoch': 2.78}
Step 363: {'loss': 3.5316, 'learning_rate': 1.1012819118853147e-05, 'epoch': 2.58}
Step 392: {'loss': 3.6811, 'learning_rate': 2.6955129420176196e-06, 'epoch': 2.79}
Step 364: {'loss': 3.3336, 'learning_rate': 1.0636735967658784e-05, 'epoch': 2.59}
Step 393: {'loss': 4.0924, 'learning_rate': 2.5072087818176382e-06, 'epoch': 2.79}
Step 365: {'loss': 3.9333, 'learning_rate': 1.0266825480913611e-05, 'epoch': 2.6}
Step 394: {'loss': 3.8471, 'learning_rate': 2.3256388237858807e-06, 'epoch': 2.8}
Step 366: {'loss': 3.8214, 'learning_rate': 9.903113209758096e-06, 'epoch': 2.6}
Step 395: {'loss': 3.3309, 'learning_rate': 2.150815609657875e-06, 'epoch': 2.81}
Step 367: {'loss': 3.8977, 'learning_rate': 9.545624277198084e-06, 'epoch': 2.61}
Step 396: {'loss': 3.528, 'learning_rate': 1.9827512151456173e-06, 'epoch': 2.82}
Step 368: {'loss': 3.6618, 'learning_rate': 9.194383376369508e-06, 'epoch': 2.62}
Step 397: {'loss': 3.4029, 'learning_rate': 1.8214572491034198e-06, 'epoch': 2.82}
Step 369: {'loss': 3.4661, 'learning_rate': 8.849414768832687e-06, 'epoch': 2.62}
Step 398: {'loss': 3.6889, 'learning_rate': 1.66694485272606e-06, 'epoch': 2.83}
Step 370: {'loss': 3.351, 'learning_rate': 8.510742282896544e-06, 'epoch': 2.63}
Step 399: {'loss': 3.5819, 'learning_rate': 1.5192246987791981e-06, 'epoch': 2.84}
Step 371: {'loss': 3.5955, 'learning_rate': 8.178389311972612e-06, 'epoch': 2.64}
Step 400: {'loss': 3.4926, 'learning_rate': 1.378306990862177e-06, 'epoch': 2.84}
Step 372: {'loss': 3.8033, 'learning_rate': 7.852378812959227e-06, 'epoch': 2.65}
Step 401: {'loss': 3.5426, 'learning_rate': 1.2442014627032316e-06, 'epoch': 2.85}
Step 373: {'loss': 3.2377, 'learning_rate': 7.532733304655848e-06, 'epoch': 2.65}
Step 402: {'loss': 4.0035, 'learning_rate': 1.1169173774871478e-06, 'epoch': 2.86}
Step 374: {'loss': 3.8325, 'learning_rate': 7.219474866207465e-06, 'epoch': 2.66}
Step 403: {'loss': 3.8109, 'learning_rate': 9.964635272153633e-07, 'epoch': 2.87}
Step 375: {'loss': 3.9305, 'learning_rate': 6.9126251355795864e-06, 'epoch': 2.67}
Step 404: {'loss': 3.4564, 'learning_rate': 8.828482320987319e-07, 'epoch': 2.87}
Step 376: {'loss': 3.8343, 'learning_rate': 6.612205308063646e-06, 'epoch': 2.67}
Step 405: {'loss': 3.4928, 'learning_rate': 7.760793399827937e-07, 'epoch': 2.88}
Step 377: {'loss': 4.127, 'learning_rate': 6.318236134812916e-06, 'epoch': 2.68}
Step 406: {'loss': 3.9114, 'learning_rate': 6.761642258056978e-07, 'epoch': 2.89}
Step 378: {'loss': 3.556, 'learning_rate': 6.030737921409169e-06, 'epoch': 2.69}
Step 407: {'loss': 3.6436, 'learning_rate': 5.831097910887873e-07, 'epoch': 2.89}
Step 379: {'loss': 3.6495, 'learning_rate': 5.749730526460073e-06, 'epoch': 2.7}
Step 408: {'loss': 3.9811, 'learning_rate': 4.969224634598591e-07, 'epoch': 2.9}
Step 380: {'loss': 3.3732, 'learning_rate': 5.475233360227516e-06, 'epoch': 2.7}
Step 409: {'loss': 3.7126, 'learning_rate': 4.176081962092182e-07, 'epoch': 2.91}
Step 381: {'loss': 4.1168, 'learning_rate': 5.20726538328683e-06, 'epoch': 2.71}
Step 410: {'loss': 3.7149, 'learning_rate': 3.451724678784518e-07, 'epoch': 2.92}
Step 382: {'loss': 3.8705, 'learning_rate': 4.945845105217117e-06, 'epoch': 2.72}
Step 411: {'loss': 3.7104, 'learning_rate': 2.7962028188198706e-07, 'epoch': 2.92}
Step 383: {'loss': 3.4933, 'learning_rate': 4.6909905833226966e-06, 'epoch': 2.72}
Step 412: {'loss': 3.2915, 'learning_rate': 2.2095616616150115e-07, 'epoch': 2.93}
Step 384: {'loss': 3.2555, 'learning_rate': 4.442719421385922e-06, 'epoch': 2.73}
Step 413: {'loss': 3.7468, 'learning_rate': 1.6918417287318245e-07, 'epoch': 2.94}
Step 385: {'loss': 3.7573, 'learning_rate': 4.20104876845111e-06, 'epoch': 2.74}
Step 414: {'loss': 3.6832, 'learning_rate': 1.2430787810776555e-07, 'epoch': 2.94}
Step 386: {'loss': 3.3491, 'learning_rate': 3.965995317640025e-06, 'epoch': 2.74}
Step 415: {'loss': 3.8497, 'learning_rate': 8.633038164358454e-08, 'epoch': 2.95}
Step 387: {'loss': 3.4938, 'learning_rate': 3.7375753049987973e-06, 'epoch': 2.75}
Step 416: {'loss': 3.5141, 'learning_rate': 5.5254306732444025e-08, 'epoch': 2.96}
Step 388: {'loss': 3.5631, 'learning_rate': 3.515804508376508e-06, 'epoch': 2.76}
Step 417: {'loss': 3.5487, 'learning_rate': 3.1081799918375454e-08, 'epoch': 2.97}
Step 389: {'loss': 3.4407, 'learning_rate': 3.3006982463352766e-06, 'epoch': 2.77}
Step 418: {'loss': 3.4057, 'learning_rate': 1.3814530889433296e-08, 'epoch': 2.97}
Step 390: {'loss': 3.8916, 'learning_rate': 3.092271377092215e-06, 'epoch': 2.77}
Step 419: {'loss': 3.5595, 'learning_rate': 3.453692362309635e-09, 'epoch': 2.98}
Step 391: {'loss': 3.4263, 'learning_rate': 2.8905382974930172e-06, 'epoch': 2.78}
Step 420: {'loss': 3.7989, 'learning_rate': 0.0, 'epoch': 2.99}
Step 420: {'train_runtime': 2638.2374, 'train_samples_per_second': 10.234, 'train_steps_per_second': 0.159, 'total_flos': 0.0, 'train_loss': 5.128861495426723, 'epoch': 2.99}
Step 392: {'loss': 3.631, 'learning_rate': 2.6955129420176196e-06, 'epoch': 2.79}
Step 393: {'loss': 3.3195, 'learning_rate': 2.5072087818176382e-06, 'epoch': 2.79}
Step 394: {'loss': 3.7131, 'learning_rate': 2.3256388237858807e-06, 'epoch': 2.8}
Step 395: {'loss': 3.9698, 'learning_rate': 2.150815609657875e-06, 'epoch': 2.81}
Step 396: {'loss': 3.2774, 'learning_rate': 1.9827512151456173e-06, 'epoch': 2.82}
Step 397: {'loss': 3.604, 'learning_rate': 1.8214572491034198e-06, 'epoch': 2.82}
Step 398: {'loss': 3.8611, 'learning_rate': 1.66694485272606e-06, 'epoch': 2.83}
Step 399: {'loss': 3.5309, 'learning_rate': 1.5192246987791981e-06, 'epoch': 2.84}
Step 400: {'loss': 3.5804, 'learning_rate': 1.378306990862177e-06, 'epoch': 2.84}
Step 401: {'loss': 3.4183, 'learning_rate': 1.2442014627032316e-06, 'epoch': 2.85}
Step 402: {'loss': 3.5539, 'learning_rate': 1.1169173774871478e-06, 'epoch': 2.86}
Step 403: {'loss': 3.6293, 'learning_rate': 9.964635272153633e-07, 'epoch': 2.87}
Step 404: {'loss': 3.7181, 'learning_rate': 8.828482320987319e-07, 'epoch': 2.87}
Step 405: {'loss': 3.57, 'learning_rate': 7.760793399827937e-07, 'epoch': 2.88}
Step 406: {'loss': 3.9483, 'learning_rate': 6.761642258056978e-07, 'epoch': 2.89}
Step 407: {'loss': 3.7702, 'learning_rate': 5.831097910887873e-07, 'epoch': 2.89}
Step 408: {'loss': 3.7945, 'learning_rate': 4.969224634598591e-07, 'epoch': 2.9}
Step 409: {'loss': 3.5167, 'learning_rate': 4.176081962092182e-07, 'epoch': 2.91}
Step 410: {'loss': 3.6546, 'learning_rate': 3.451724678784518e-07, 'epoch': 2.92}
Step 411: {'loss': 3.4239, 'learning_rate': 2.7962028188198706e-07, 'epoch': 2.92}
Step 412: {'loss': 4.0422, 'learning_rate': 2.2095616616150115e-07, 'epoch': 2.93}
Step 413: {'loss': 3.5744, 'learning_rate': 1.6918417287318245e-07, 'epoch': 2.94}
Step 414: {'loss': 3.8367, 'learning_rate': 1.2430787810776555e-07, 'epoch': 2.94}
Step 415: {'loss': 3.4902, 'learning_rate': 8.633038164358454e-08, 'epoch': 2.95}
Step 416: {'loss': 3.6597, 'learning_rate': 5.5254306732444025e-08, 'epoch': 2.96}
Step 417: {'loss': 3.4918, 'learning_rate': 3.1081799918375454e-08, 'epoch': 2.97}
Step 418: {'loss': 3.9922, 'learning_rate': 1.3814530889433296e-08, 'epoch': 2.97}
Step 419: {'loss': 3.3745, 'learning_rate': 3.453692362309635e-09, 'epoch': 2.98}
Step 420: {'loss': 3.7749, 'learning_rate': 0.0, 'epoch': 2.99}
Step 420: {'train_runtime': 2626.8017, 'train_samples_per_second': 10.279, 'train_steps_per_second': 0.16, 'total_flos': 0.0, 'train_loss': 5.17593343598502, 'epoch': 2.99}
