Step 1: {'loss': 16.3228, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.01}
Step 2: {'loss': 15.3585, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.01}
Step 3: {'loss': 21.4648, 'learning_rate': 0.00014285714285714284, 'epoch': 0.02}
Step 4: {'loss': 23.4644, 'learning_rate': 0.00019047619047619048, 'epoch': 0.03}
Step 5: {'loss': 19.1156, 'learning_rate': 0.0002380952380952381, 'epoch': 0.04}
Step 6: {'loss': 18.2486, 'learning_rate': 0.0002857142857142857, 'epoch': 0.04}
Step 7: {'loss': 21.2595, 'learning_rate': 0.0003333333333333333, 'epoch': 0.05}
Step 8: {'loss': 22.7145, 'learning_rate': 0.00038095238095238096, 'epoch': 0.06}
Step 9: {'loss': 25.0539, 'learning_rate': 0.00042857142857142855, 'epoch': 0.06}
Step 10: {'loss': 21.5636, 'learning_rate': 0.0004761904761904762, 'epoch': 0.07}
Step 11: {'loss': 26.1778, 'learning_rate': 0.0005238095238095238, 'epoch': 0.08}
Step 12: {'loss': 16.7568, 'learning_rate': 0.0005714285714285714, 'epoch': 0.09}
Step 13: {'loss': 17.8332, 'learning_rate': 0.0006190476190476191, 'epoch': 0.09}
Step 14: {'loss': 16.2684, 'learning_rate': 0.0006666666666666666, 'epoch': 0.1}
Step 15: {'loss': 15.2269, 'learning_rate': 0.0007142857142857143, 'epoch': 0.11}
Step 16: {'loss': 14.6743, 'learning_rate': 0.0007619047619047619, 'epoch': 0.11}
Step 17: {'loss': 14.0968, 'learning_rate': 0.0008095238095238096, 'epoch': 0.12}
Step 18: {'loss': 13.63, 'learning_rate': 0.0008571428571428571, 'epoch': 0.13}
Step 19: {'loss': 12.7748, 'learning_rate': 0.0009047619047619047, 'epoch': 0.14}
Step 20: {'loss': 14.1806, 'learning_rate': 0.0009523809523809524, 'epoch': 0.14}
Step 21: {'loss': 9.4409, 'learning_rate': 0.001, 'epoch': 0.15}
Step 22: {'loss': 9.0994, 'learning_rate': 0.0010476190476190477, 'epoch': 0.16}
Step 23: {'loss': 8.2435, 'learning_rate': 0.0010952380952380953, 'epoch': 0.16}
Step 24: {'loss': 5.9487, 'learning_rate': 0.0011428571428571427, 'epoch': 0.17}
Step 25: {'loss': 6.6621, 'learning_rate': 0.0011904761904761906, 'epoch': 0.18}
Step 26: {'loss': 5.9537, 'learning_rate': 0.0012380952380952382, 'epoch': 0.18}
Step 27: {'loss': 5.3109, 'learning_rate': 0.0012857142857142859, 'epoch': 0.19}
Step 28: {'loss': 5.0997, 'learning_rate': 0.0013333333333333333, 'epoch': 0.2}
Step 29: {'loss': 4.9344, 'learning_rate': 0.001380952380952381, 'epoch': 0.21}
Step 30: {'loss': 4.4444, 'learning_rate': 0.0014285714285714286, 'epoch': 0.21}
Step 31: {'loss': 4.4864, 'learning_rate': 0.0014761904761904762, 'epoch': 0.22}
Step 32: {'loss': 4.3395, 'learning_rate': 0.0015238095238095239, 'epoch': 0.23}
Step 33: {'loss': 4.0136, 'learning_rate': 0.0015714285714285715, 'epoch': 0.23}
Step 34: {'loss': 4.2325, 'learning_rate': 0.0016190476190476191, 'epoch': 0.24}
Step 35: {'loss': 3.8834, 'learning_rate': 0.0016666666666666668, 'epoch': 0.25}
Step 36: {'loss': 3.9084, 'learning_rate': 0.0017142857142857142, 'epoch': 0.26}
Step 37: {'loss': 3.9758, 'learning_rate': 0.0017619047619047618, 'epoch': 0.26}
Step 38: {'loss': 4.0477, 'learning_rate': 0.0018095238095238095, 'epoch': 0.27}
Step 39: {'loss': 3.959, 'learning_rate': 0.0018571428571428573, 'epoch': 0.28}
Step 40: {'loss': 3.8357, 'learning_rate': 0.0019047619047619048, 'epoch': 0.28}
Step 41: {'loss': 4.0307, 'learning_rate': 0.0019523809523809524, 'epoch': 0.29}
Step 42: {'loss': 4.2256, 'learning_rate': 0.002, 'epoch': 0.3}
Step 43: {'loss': 4.132, 'learning_rate': 0.001999965463076377, 'epoch': 0.31}
Step 44: {'loss': 3.6888, 'learning_rate': 0.0019998618546911056, 'epoch': 0.31}
Step 45: {'loss': 3.5387, 'learning_rate': 0.001999689182000816, 'epoch': 0.32}
Step 46: {'loss': 3.8982, 'learning_rate': 0.001999447456932676, 'epoch': 0.33}
Step 47: {'loss': 3.6694, 'learning_rate': 0.0019991366961835642, 'epoch': 0.33}
Step 48: {'loss': 3.4269, 'learning_rate': 0.0019987569212189223, 'epoch': 0.34}
Step 49: {'loss': 3.702, 'learning_rate': 0.0019983081582712683, 'epoch': 0.35}
Step 50: {'loss': 3.4669, 'learning_rate': 0.001997790438338385, 'epoch': 0.36}
Step 51: {'loss': 3.4416, 'learning_rate': 0.00199720379718118, 'epoch': 0.36}
Step 52: {'loss': 3.3411, 'learning_rate': 0.0019965482753212154, 'epoch': 0.37}
Step 53: {'loss': 3.3678, 'learning_rate': 0.0019958239180379077, 'epoch': 0.38}
Step 54: {'loss': 3.5072, 'learning_rate': 0.0019950307753654017, 'epoch': 0.38}
Step 55: {'loss': 3.2908, 'learning_rate': 0.001994168902089112, 'epoch': 0.39}
Step 56: {'loss': 3.0702, 'learning_rate': 0.001993238357741943, 'epoch': 0.4}
Step 57: {'loss': 3.1442, 'learning_rate': 0.001992239206600172, 'epoch': 0.41}
Step 58: {'loss': 2.9801, 'learning_rate': 0.001991171517679013, 'epoch': 0.41}
Step 59: {'loss': 3.3657, 'learning_rate': 0.0019900353647278463, 'epoch': 0.42}
Step 60: {'loss': 2.8932, 'learning_rate': 0.0019888308262251283, 'epoch': 0.43}
Step 61: {'loss': 3.1504, 'learning_rate': 0.0019875579853729673, 'epoch': 0.43}
Step 62: {'loss': 3.6114, 'learning_rate': 0.0019862169300913783, 'epoch': 0.44}
Step 63: {'loss': 3.7023, 'learning_rate': 0.001984807753012208, 'epoch': 0.45}
Step 64: {'loss': 3.4016, 'learning_rate': 0.0019833305514727396, 'epoch': 0.46}
Step 65: {'loss': 3.3824, 'learning_rate': 0.001981785427508966, 'epoch': 0.46}
Step 66: {'loss': 3.39, 'learning_rate': 0.0019801724878485438, 'epoch': 0.47}
Step 67: {'loss': 3.1752, 'learning_rate': 0.0019784918439034213, 'epoch': 0.48}
Step 68: {'loss': 3.3743, 'learning_rate': 0.0019767436117621414, 'epoch': 0.48}
Step 69: {'loss': 3.4066, 'learning_rate': 0.0019749279121818236, 'epoch': 0.49}
Step 70: {'loss': 3.6814, 'learning_rate': 0.0019730448705798237, 'epoch': 0.5}
Step 71: {'loss': 3.0887, 'learning_rate': 0.00197109461702507, 'epoch': 0.5}
Step 72: {'loss': 3.1917, 'learning_rate': 0.001969077286229078, 'epoch': 0.51}
Step 73: {'loss': 3.5017, 'learning_rate': 0.0019669930175366473, 'epoch': 0.52}
Step 74: {'loss': 3.3948, 'learning_rate': 0.001964841954916235, 'epoch': 0.53}
Step 75: {'loss': 3.3641, 'learning_rate': 0.001962624246950012, 'epoch': 0.53}
Step 76: {'loss': 3.3038, 'learning_rate': 0.0019603400468235998, 'epoch': 0.54}
Step 77: {'loss': 3.1865, 'learning_rate': 0.001957989512315489, 'epoch': 0.55}
Step 78: {'loss': 3.5139, 'learning_rate': 0.001955572805786141, 'epoch': 0.55}
Step 79: {'loss': 3.4682, 'learning_rate': 0.0019530900941667731, 'epoch': 0.56}
Step 80: {'loss': 3.0618, 'learning_rate': 0.0019505415489478291, 'epoch': 0.57}
Step 81: {'loss': 3.5313, 'learning_rate': 0.0019479273461671318, 'epoch': 0.58}
Step 82: {'loss': 3.7688, 'learning_rate': 0.0019452476663977248, 'epoch': 0.58}
Step 83: {'loss': 3.4349, 'learning_rate': 0.0019425026947353992, 'epoch': 0.59}
Step 84: {'loss': 3.3368, 'learning_rate': 0.0019396926207859084, 'epoch': 0.6}
Step 85: {'loss': 3.1807, 'learning_rate': 0.001936817638651871, 'epoch': 0.6}
Step 86: {'loss': 3.1378, 'learning_rate': 0.0019338779469193637, 'epoch': 0.61}
Step 87: {'loss': 3.4675, 'learning_rate': 0.0019308737486442042, 'epoch': 0.62}
Step 88: {'loss': 2.8383, 'learning_rate': 0.0019278052513379254, 'epoch': 0.63}
Step 89: {'loss': 3.2592, 'learning_rate': 0.0019246726669534416, 'epoch': 0.63}
Step 90: {'loss': 3.3228, 'learning_rate': 0.0019214762118704076, 'epoch': 0.64}
Step 91: {'loss': 3.5672, 'learning_rate': 0.001918216106880274, 'epoch': 0.65}
Step 92: {'loss': 3.4552, 'learning_rate': 0.0019148925771710346, 'epoch': 0.65}
Step 93: {'loss': 3.3476, 'learning_rate': 0.0019115058523116733, 'epoch': 0.66}
Step 94: {'loss': 3.1179, 'learning_rate': 0.0019080561662363049, 'epoch': 0.67}
Step 95: {'loss': 3.0001, 'learning_rate': 0.0019045437572280193, 'epoch': 0.68}
Step 96: {'loss': 3.2844, 'learning_rate': 0.001900968867902419, 'epoch': 0.68}
Step 97: {'loss': 3.1845, 'learning_rate': 0.001897331745190864, 'epoch': 0.69}
Step 98: {'loss': 2.808, 'learning_rate': 0.0018936326403234123, 'epoch': 0.7}
Step 99: {'loss': 2.8612, 'learning_rate': 0.0018898718088114688, 'epoch': 0.7}
Step 100: {'loss': 3.044, 'learning_rate': 0.0018860495104301345, 'epoch': 0.71}
Step 101: {'loss': 3.3032, 'learning_rate': 0.0018821660092002643, 'epoch': 0.72}
Step 102: {'loss': 3.1235, 'learning_rate': 0.0018782215733702285, 'epoch': 0.73}
Step 103: {'loss': 3.1463, 'learning_rate': 0.0018742164753973857, 'epoch': 0.73}
Step 104: {'loss': 3.0744, 'learning_rate': 0.0018701509919292613, 'epoch': 0.74}
Step 105: {'loss': 3.1633, 'learning_rate': 0.001866025403784439, 'epoch': 0.75}
Step 106: {'loss': 3.1397, 'learning_rate': 0.001861839995933164, 'epoch': 0.75}
Step 107: {'loss': 3.3341, 'learning_rate': 0.0018575950574776594, 'epoch': 0.76}
Step 108: {'loss': 3.3337, 'learning_rate': 0.0018532908816321556, 'epoch': 0.77}
Step 109: {'loss': 3.3288, 'learning_rate': 0.0018489277657026376, 'epoch': 0.78}
Step 110: {'loss': 3.0823, 'learning_rate': 0.001844506011066308, 'epoch': 0.78}
Step 111: {'loss': 3.0916, 'learning_rate': 0.0018400259231507717, 'epoch': 0.79}
Step 112: {'loss': 3.3743, 'learning_rate': 0.0018354878114129364, 'epoch': 0.8}
Step 113: {'loss': 3.3677, 'learning_rate': 0.0018308919893176396, 'epoch': 0.8}
Step 114: {'loss': 3.1461, 'learning_rate': 0.001826238774315995, 'epoch': 0.81}
Step 115: {'loss': 2.9414, 'learning_rate': 0.0018215284878234641, 'epoch': 0.82}
Step 116: {'loss': 2.9246, 'learning_rate': 0.0018167614551976568, 'epoch': 0.82}
Step 117: {'loss': 3.2574, 'learning_rate': 0.0018119380057158567, 'epoch': 0.83}
Step 118: {'loss': 3.1605, 'learning_rate': 0.001807058472552276, 'epoch': 0.84}
Step 119: {'loss': 3.0468, 'learning_rate': 0.0018021231927550438, 'epoch': 0.85}
Step 120: {'loss': 3.1935, 'learning_rate': 0.0017971325072229226, 'epoch': 0.85}
Step 121: {'loss': 3.2516, 'learning_rate': 0.0017920867606817624, 'epoch': 0.86}
Step 122: {'loss': 3.0823, 'learning_rate': 0.001786986301660689, 'epoch': 0.87}
Step 123: {'loss': 2.9421, 'learning_rate': 0.00178183148246803, 'epoch': 0.87}
Step 124: {'loss': 3.0619, 'learning_rate': 0.0017766226591669784, 'epoch': 0.88}
Step 125: {'loss': 2.9028, 'learning_rate': 0.0017713601915509997, 'epoch': 0.89}
Step 126: {'loss': 2.921, 'learning_rate': 0.001766044443118978, 'epoch': 0.9}
Step 127: {'loss': 2.9734, 'learning_rate': 0.0017606757810501087, 'epoch': 0.9}
Step 128: {'loss': 2.923, 'learning_rate': 0.001755254576178535, 'epoch': 0.91}
Step 129: {'loss': 2.6918, 'learning_rate': 0.0017497812029677341, 'epoch': 0.92}
Step 130: {'loss': 3.4819, 'learning_rate': 0.0017442560394846517, 'epoch': 0.92}
Step 131: {'loss': 3.177, 'learning_rate': 0.0017386794673735857, 'epoch': 0.93}
Step 132: {'loss': 3.2435, 'learning_rate': 0.0017330518718298262, 'epoch': 0.94}
Step 133: {'loss': 3.437, 'learning_rate': 0.0017273736415730487, 'epoch': 0.95}
Step 134: {'loss': 2.9215, 'learning_rate': 0.0017216451688204621, 'epoch': 0.95}
Step 135: {'loss': 2.8286, 'learning_rate': 0.0017158668492597185, 'epoch': 0.96}
Step 136: {'loss': 2.912, 'learning_rate': 0.0017100390820215803, 'epoch': 0.97}
Step 137: {'loss': 3.4309, 'learning_rate': 0.0017041622696523518, 'epoch': 0.97}
Step 138: {'loss': 3.1859, 'learning_rate': 0.0016982368180860727, 'epoch': 0.98}
Step 139: {'loss': 3.3225, 'learning_rate': 0.0016922631366164795, 'epoch': 0.99}
Step 140: {'loss': 3.3729, 'learning_rate': 0.0016862416378687337, 'epoch': 1.0}
Step 141: {'loss': 3.1933, 'learning_rate': 0.0016801727377709192, 'epoch': 1.0}
Step 142: {'loss': 3.2433, 'learning_rate': 0.0016740568555253152, 'epoch': 1.01}
Step 143: {'loss': 2.9588, 'learning_rate': 0.0016678944135794375, 'epoch': 1.02}
Step 144: {'loss': 2.9129, 'learning_rate': 0.0016616858375968595, 'epoch': 1.02}
Step 145: {'loss': 3.1563, 'learning_rate': 0.0016554315564278103, 'epoch': 1.03}
Step 146: {'loss': 2.7561, 'learning_rate': 0.001649132002079552, 'epoch': 1.04}
Step 147: {'loss': 3.1424, 'learning_rate': 0.0016427876096865393, 'epoch': 1.05}
Step 148: {'loss': 3.2165, 'learning_rate': 0.0016363988174803636, 'epoch': 1.05}
Step 149: {'loss': 2.816, 'learning_rate': 0.0016299660667594812, 'epoch': 1.06}
Step 150: {'loss': 3.0797, 'learning_rate': 0.0016234898018587336, 'epoch': 1.07}
Step 151: {'loss': 2.6053, 'learning_rate': 0.0016169704701186527, 'epoch': 1.07}
Step 152: {'loss': 3.0324, 'learning_rate': 0.0016104085218545633, 'epoch': 1.08}
Step 153: {'loss': 3.1917, 'learning_rate': 0.0016038044103254775, 'epoch': 1.09}
Step 154: {'loss': 3.4363, 'learning_rate': 0.0015971585917027862, 'epoch': 1.1}
Step 155: {'loss': 3.1687, 'learning_rate': 0.0015904715250387499, 'epoch': 1.1}
Step 156: {'loss': 3.1014, 'learning_rate': 0.00158374367223479, 'epoch': 1.11}
Step 157: {'loss': 2.9639, 'learning_rate': 0.001576975498009583, 'epoch': 1.12}
Step 158: {'loss': 3.1399, 'learning_rate': 0.0015701674698669619, 'epoch': 1.12}
Step 159: {'loss': 3.0863, 'learning_rate': 0.001563320058063622, 'epoch': 1.13}
Step 160: {'loss': 2.9166, 'learning_rate': 0.0015564337355766411, 'epoch': 1.14}
Step 161: {'loss': 2.8613, 'learning_rate': 0.001549508978070806, 'epoch': 1.14}
Step 162: {'loss': 2.8907, 'learning_rate': 0.0015425462638657594, 'epoch': 1.15}
Step 163: {'loss': 2.9485, 'learning_rate': 0.0015355460739029585, 'epoch': 1.16}
Step 164: {'loss': 2.9693, 'learning_rate': 0.0015285088917124554, 'epoch': 1.17}
Step 165: {'loss': 2.6987, 'learning_rate': 0.001521435203379498, 'epoch': 1.17}
Step 166: {'loss': 3.1317, 'learning_rate': 0.0015143254975109536, 'epoch': 1.18}
Step 167: {'loss': 3.2111, 'learning_rate': 0.0015071802652015592, 'epoch': 1.19}
Step 168: {'loss': 3.0981, 'learning_rate': 0.0015, 'epoch': 1.19}
Step 169: {'loss': 3.041, 'learning_rate': 0.0014927851978748176, 'epoch': 1.2}
Step 170: {'loss': 3.0255, 'learning_rate': 0.0014855363571801522, 'epoch': 1.21}
Step 171: {'loss': 2.9514, 'learning_rate': 0.0014782539786213182, 'epoch': 1.22}
Step 172: {'loss': 3.1782, 'learning_rate': 0.0014709385652202202, 'epoch': 1.22}
Step 173: {'loss': 2.9045, 'learning_rate': 0.0014635906222806056, 'epoch': 1.23}
Step 174: {'loss': 3.1355, 'learning_rate': 0.001456210657353163, 'epoch': 1.24}
Step 175: {'loss': 3.2624, 'learning_rate': 0.0014487991802004624, 'epoch': 1.24}
Step 176: {'loss': 2.9954, 'learning_rate': 0.001441356702761744, 'epoch': 1.25}
Step 177: {'loss': 3.2091, 'learning_rate': 0.0014338837391175581, 'epoch': 1.26}
Step 178: {'loss': 2.9101, 'learning_rate': 0.001426380805454254, 'epoch': 1.27}
Step 179: {'loss': 2.9001, 'learning_rate': 0.001418848420028325, 'epoch': 1.27}
Step 180: {'loss': 3.0394, 'learning_rate': 0.001411287103130612, 'epoch': 1.28}
Step 181: {'loss': 3.0619, 'learning_rate': 0.0014036973770503623, 'epoch': 1.29}
Step 182: {'loss': 2.6996, 'learning_rate': 0.001396079766039157, 'epoch': 1.29}
Step 183: {'loss': 3.0238, 'learning_rate': 0.0013884347962746949, 'epoch': 1.3}
Step 184: {'loss': 2.9685, 'learning_rate': 0.0013807629958244496, 'epoch': 1.31}
Step 185: {'loss': 3.2754, 'learning_rate': 0.001373064894609194, 'epoch': 1.32}
Step 186: {'loss': 2.8963, 'learning_rate': 0.0013653410243663954, 'epoch': 1.32}
Step 187: {'loss': 2.8581, 'learning_rate': 0.0013575919186134863, 'epoch': 1.33}
Step 188: {'loss': 2.7218, 'learning_rate': 0.001349818112611015, 'epoch': 1.34}
Step 189: {'loss': 3.4182, 'learning_rate': 0.0013420201433256688, 'epoch': 1.34}
Step 190: {'loss': 3.1798, 'learning_rate': 0.0013341985493931876, 'epoch': 1.35}
Step 191: {'loss': 3.0911, 'learning_rate': 0.0013263538710811557, 'epoch': 1.36}
Step 192: {'loss': 2.9691, 'learning_rate': 0.0013184866502516845, 'epoch': 1.37}
Step 193: {'loss': 3.518, 'learning_rate': 0.0013105974303239838, 'epoch': 1.37}
Step 194: {'loss': 3.0362, 'learning_rate': 0.0013026867562368261, 'epoch': 1.38}
Step 195: {'loss': 2.923, 'learning_rate': 0.0012947551744109042, 'epoch': 1.39}
Step 196: {'loss': 2.7329, 'learning_rate': 0.0012868032327110904, 'epoch': 1.39}
Step 197: {'loss': 2.9079, 'learning_rate': 0.0012788314804085903, 'epoch': 1.4}
Step 198: {'loss': 2.7366, 'learning_rate': 0.0012708404681430053, 'epoch': 1.41}
Step 199: {'loss': 3.1284, 'learning_rate': 0.0012628307478842952, 'epoch': 1.42}
Step 200: {'loss': 2.8371, 'learning_rate': 0.0012548028728946547, 'epoch': 1.42}
Step 201: {'loss': 3.1206, 'learning_rate': 0.0012467573976902935, 'epoch': 1.43}
Step 202: {'loss': 3.4851, 'learning_rate': 0.001238694878003138, 'epoch': 1.44}
Step 203: {'loss': 2.9959, 'learning_rate': 0.0012306158707424402, 'epoch': 1.44}
Step 204: {'loss': 3.1587, 'learning_rate': 0.0012225209339563144, 'epoch': 1.45}
Step 205: {'loss': 3.1064, 'learning_rate': 0.0012144106267931876, 'epoch': 1.46}
Step 206: {'loss': 2.6776, 'learning_rate': 0.0012062855094631777, 'epoch': 1.46}
Step 207: {'loss': 2.862, 'learning_rate': 0.0011981461431993976, 'epoch': 1.47}
Step 208: {'loss': 3.0512, 'learning_rate': 0.0011899930902191903, 'epoch': 1.48}
Step 209: {'loss': 3.0591, 'learning_rate': 0.0011818269136852908, 'epoch': 1.49}
Step 210: {'loss': 3.396, 'learning_rate': 0.0011736481776669307, 'epoch': 1.49}
Step 211: {'loss': 2.7165, 'learning_rate': 0.0011654574471008713, 'epoch': 1.5}
Step 212: {'loss': 3.0209, 'learning_rate': 0.0011572552877523853, 'epoch': 1.51}
Step 213: {'loss': 3.2942, 'learning_rate': 0.0011490422661761743, 'epoch': 1.51}
Step 214: {'loss': 2.8959, 'learning_rate': 0.0011408189496772368, 'epoch': 1.52}
Step 215: {'loss': 2.9918, 'learning_rate': 0.0011325859062716794, 'epoch': 1.53}
Step 216: {'loss': 3.0363, 'learning_rate': 0.0011243437046474854, 'epoch': 1.54}
Step 217: {'loss': 3.0893, 'learning_rate': 0.0011160929141252303, 'epoch': 1.54}
Step 218: {'loss': 3.101, 'learning_rate': 0.0011078341046187588, 'epoch': 1.55}
Step 219: {'loss': 2.8475, 'learning_rate': 0.0010995678465958167, 'epoch': 1.56}
Step 220: {'loss': 3.0436, 'learning_rate': 0.0010912947110386483, 'epoch': 1.56}
Step 221: {'loss': 3.0587, 'learning_rate': 0.0010830152694045552, 'epoch': 1.57}
Step 222: {'loss': 3.2376, 'learning_rate': 0.0010747300935864243, 'epoch': 1.58}
Step 223: {'loss': 3.1951, 'learning_rate': 0.0010664397558732244, 'epoch': 1.59}
Step 224: {'loss': 2.9319, 'learning_rate': 0.0010581448289104759, 'epoch': 1.59}
Step 225: {'loss': 2.6741, 'learning_rate': 0.0010498458856606971, 'epoch': 1.6}
Step 226: {'loss': 3.0369, 'learning_rate': 0.0010415434993638268, 'epoch': 1.61}
Step 227: {'loss': 3.4592, 'learning_rate': 0.0010332382434976267, 'epoch': 1.61}
Step 228: {'loss': 3.296, 'learning_rate': 0.001024930691738073, 'epoch': 1.62}
Step 229: {'loss': 3.1867, 'learning_rate': 0.0010166214179197265, 'epoch': 1.63}
Step 230: {'loss': 2.7819, 'learning_rate': 0.0010083109959960971, 'epoch': 1.64}
Step 231: {'loss': 3.2867, 'learning_rate': 0.001, 'epoch': 1.64}
Step 232: {'loss': 2.9024, 'learning_rate': 0.0009916890040039031, 'epoch': 1.65}
Step 233: {'loss': 2.98, 'learning_rate': 0.0009833785820802738, 'epoch': 1.66}
Step 234: {'loss': 3.1307, 'learning_rate': 0.0009750693082619273, 'epoch': 1.66}
Step 235: {'loss': 3.1138, 'learning_rate': 0.0009667617565023734, 'epoch': 1.67}
Step 236: {'loss': 3.258, 'learning_rate': 0.0009584565006361734, 'epoch': 1.68}
Step 237: {'loss': 2.7441, 'learning_rate': 0.0009501541143393028, 'epoch': 1.69}
Step 238: {'loss': 3.0879, 'learning_rate': 0.0009418551710895242, 'epoch': 1.69}
Step 239: {'loss': 3.249, 'learning_rate': 0.0009335602441267759, 'epoch': 1.7}
Step 240: {'loss': 2.8799, 'learning_rate': 0.0009252699064135758, 'epoch': 1.71}
Step 241: {'loss': 2.9548, 'learning_rate': 0.0009169847305954447, 'epoch': 1.71}
Step 242: {'loss': 3.2575, 'learning_rate': 0.0009087052889613518, 'epoch': 1.72}
Step 243: {'loss': 3.208, 'learning_rate': 0.0009004321534041835, 'epoch': 1.73}
Step 244: {'loss': 3.433, 'learning_rate': 0.0008921658953812415, 'epoch': 1.74}
Step 245: {'loss': 2.9891, 'learning_rate': 0.0008839070858747696, 'epoch': 1.74}
Step 246: {'loss': 2.9593, 'learning_rate': 0.0008756562953525152, 'epoch': 1.75}
Step 247: {'loss': 3.2468, 'learning_rate': 0.0008674140937283207, 'epoch': 1.76}
Step 248: {'loss': 2.7046, 'learning_rate': 0.0008591810503227634, 'epoch': 1.76}
Step 249: {'loss': 3.0398, 'learning_rate': 0.0008509577338238254, 'epoch': 1.77}
Step 250: {'loss': 3.0026, 'learning_rate': 0.0008427447122476148, 'epoch': 1.78}
Step 251: {'loss': 3.1524, 'learning_rate': 0.0008345425528991288, 'epoch': 1.78}
Step 252: {'loss': 3.3818, 'learning_rate': 0.0008263518223330697, 'epoch': 1.79}
Step 253: {'loss': 3.0549, 'learning_rate': 0.0008181730863147093, 'epoch': 1.8}
Step 254: {'loss': 2.9473, 'learning_rate': 0.0008100069097808103, 'epoch': 1.81}
Step 255: {'loss': 2.9136, 'learning_rate': 0.0008018538568006026, 'epoch': 1.81}
Step 256: {'loss': 2.987, 'learning_rate': 0.0007937144905368226, 'epoch': 1.82}
Step 257: {'loss': 2.9424, 'learning_rate': 0.0007855893732068124, 'epoch': 1.83}
Step 258: {'loss': 3.17, 'learning_rate': 0.0007774790660436857, 'epoch': 1.83}
Step 259: {'loss': 2.9752, 'learning_rate': 0.0007693841292575599, 'epoch': 1.84}
Step 260: {'loss': 2.8732, 'learning_rate': 0.0007613051219968623, 'epoch': 1.85}
Step 261: {'loss': 3.0531, 'learning_rate': 0.0007532426023097063, 'epoch': 1.86}
Step 262: {'loss': 2.8687, 'learning_rate': 0.0007451971271053455, 'epoch': 1.86}
Step 263: {'loss': 2.9148, 'learning_rate': 0.0007371692521157047, 'epoch': 1.87}
Step 264: {'loss': 2.5152, 'learning_rate': 0.000729159531856995, 'epoch': 1.88}
Step 265: {'loss': 2.8994, 'learning_rate': 0.0007211685195914096, 'epoch': 1.88}
Step 266: {'loss': 3.113, 'learning_rate': 0.0007131967672889101, 'epoch': 1.89}
Step 267: {'loss': 2.7828, 'learning_rate': 0.0007052448255890957, 'epoch': 1.9}
Step 268: {'loss': 2.9283, 'learning_rate': 0.0006973132437631742, 'epoch': 1.91}
Step 269: {'loss': 2.9771, 'learning_rate': 0.0006894025696760162, 'epoch': 1.91}
Step 270: {'loss': 3.0579, 'learning_rate': 0.0006815133497483157, 'epoch': 1.92}
Step 271: {'loss': 2.9347, 'learning_rate': 0.0006736461289188444, 'epoch': 1.93}
Step 272: {'loss': 3.0681, 'learning_rate': 0.0006658014506068125, 'epoch': 1.93}
Step 273: {'loss': 2.9481, 'learning_rate': 0.0006579798566743314, 'epoch': 1.94}
Step 274: {'loss': 2.8661, 'learning_rate': 0.0006501818873889855, 'epoch': 1.95}
Step 275: {'loss': 2.5209, 'learning_rate': 0.0006424080813865139, 'epoch': 1.96}
Step 276: {'loss': 2.9014, 'learning_rate': 0.000634658975633605, 'epoch': 1.96}
Step 277: {'loss': 3.1338, 'learning_rate': 0.000626935105390806, 'epoch': 1.97}
Step 278: {'loss': 2.6955, 'learning_rate': 0.0006192370041755506, 'epoch': 1.98}
Step 279: {'loss': 2.6145, 'learning_rate': 0.0006115652037253053, 'epoch': 1.98}
Step 280: {'loss': 2.8151, 'learning_rate': 0.0006039202339608432, 'epoch': 1.99}
Step 281: {'loss': 2.923, 'learning_rate': 0.0005963026229496378, 'epoch': 2.0}
Step 282: {'loss': 2.9282, 'learning_rate': 0.0005887128968693887, 'epoch': 2.01}
Step 283: {'loss': 3.2884, 'learning_rate': 0.0005811515799716753, 'epoch': 2.01}
Step 284: {'loss': 3.0376, 'learning_rate': 0.0005736191945457463, 'epoch': 2.02}
Step 285: {'loss': 2.9605, 'learning_rate': 0.0005661162608824419, 'epoch': 2.03}
Step 286: {'loss': 3.1202, 'learning_rate': 0.000558643297238256, 'epoch': 2.03}
Step 287: {'loss': 2.8785, 'learning_rate': 0.0005512008197995379, 'epoch': 2.04}
Step 288: {'loss': 2.7923, 'learning_rate': 0.000543789342646837, 'epoch': 2.05}
Step 289: {'loss': 2.8124, 'learning_rate': 0.0005364093777193943, 'epoch': 2.06}
Step 290: {'loss': 3.0381, 'learning_rate': 0.0005290614347797802, 'epoch': 2.06}
Step 291: {'loss': 2.8175, 'learning_rate': 0.0005217460213786822, 'epoch': 2.07}
Step 292: {'loss': 3.1191, 'learning_rate': 0.0005144636428198478, 'epoch': 2.08}
Step 293: {'loss': 2.751, 'learning_rate': 0.0005072148021251821, 'epoch': 2.08}
Step 294: {'loss': 3.1026, 'learning_rate': 0.0005000000000000002, 'epoch': 2.09}
Step 295: {'loss': 3.251, 'learning_rate': 0.000492819734798441, 'epoch': 2.1}
Step 296: {'loss': 2.6827, 'learning_rate': 0.00048567450248904653, 'epoch': 2.1}
Step 297: {'loss': 2.7164, 'learning_rate': 0.000478564796620502, 'epoch': 2.11}
Step 298: {'loss': 3.1745, 'learning_rate': 0.0004714911082875446, 'epoch': 2.12}
Step 299: {'loss': 3.5812, 'learning_rate': 0.00046445392609704164, 'epoch': 2.13}
Step 300: {'loss': 2.9131, 'learning_rate': 0.00045745373613424067, 'epoch': 2.13}
Step 301: {'loss': 3.2709, 'learning_rate': 0.000450491021929194, 'epoch': 2.14}
Step 302: {'loss': 2.7575, 'learning_rate': 0.00044356626442335935, 'epoch': 2.15}
Step 303: {'loss': 3.0761, 'learning_rate': 0.00043667994193637795, 'epoch': 2.15}
Step 304: {'loss': 2.7156, 'learning_rate': 0.00042983253013303827, 'epoch': 2.16}
Step 305: {'loss': 2.9854, 'learning_rate': 0.000423024501990417, 'epoch': 2.17}
Step 306: {'loss': 3.0839, 'learning_rate': 0.00041625632776521037, 'epoch': 2.18}
Step 307: {'loss': 2.6478, 'learning_rate': 0.00040952847496125033, 'epoch': 2.18}
Step 308: {'loss': 2.9254, 'learning_rate': 0.00040284140829721405, 'epoch': 2.19}
Step 309: {'loss': 2.6815, 'learning_rate': 0.0003961955896745224, 'epoch': 2.2}
Step 310: {'loss': 2.979, 'learning_rate': 0.00038959147814543693, 'epoch': 2.2}
Step 311: {'loss': 2.8436, 'learning_rate': 0.0003830295298813475, 'epoch': 2.21}
Step 312: {'loss': 2.7318, 'learning_rate': 0.0003765101981412665, 'epoch': 2.22}
Step 313: {'loss': 3.0791, 'learning_rate': 0.0003700339332405187, 'epoch': 2.23}
Step 314: {'loss': 3.0639, 'learning_rate': 0.00036360118251963647, 'epoch': 2.23}
Step 315: {'loss': 3.1228, 'learning_rate': 0.0003572123903134606, 'epoch': 2.24}
Step 316: {'loss': 3.3298, 'learning_rate': 0.0003508679979204481, 'epoch': 2.25}
Step 317: {'loss': 3.1488, 'learning_rate': 0.00034456844357218973, 'epoch': 2.25}
Step 318: {'loss': 3.0131, 'learning_rate': 0.00033831416240314084, 'epoch': 2.26}
Step 319: {'loss': 2.6804, 'learning_rate': 0.0003321055864205628, 'epoch': 2.27}
Step 320: {'loss': 2.818, 'learning_rate': 0.00032594314447468453, 'epoch': 2.28}
Step 321: {'loss': 3.0995, 'learning_rate': 0.0003198272622290804, 'epoch': 2.28}
Step 322: {'loss': 3.2762, 'learning_rate': 0.0003137583621312665, 'epoch': 2.29}
Step 323: {'loss': 2.4052, 'learning_rate': 0.00030773686338352046, 'epoch': 2.3}
Step 324: {'loss': 2.7672, 'learning_rate': 0.00030176318191392726, 'epoch': 2.3}
Step 325: {'loss': 2.9466, 'learning_rate': 0.00029583773034764826, 'epoch': 2.31}
Step 326: {'loss': 2.8806, 'learning_rate': 0.0002899609179784197, 'epoch': 2.32}
Step 327: {'loss': 2.9294, 'learning_rate': 0.0002841331507402816, 'epoch': 2.33}
Step 328: {'loss': 2.9064, 'learning_rate': 0.0002783548311795379, 'epoch': 2.33}
Step 329: {'loss': 2.9545, 'learning_rate': 0.00027262635842695125, 'epoch': 2.34}
Step 330: {'loss': 2.8082, 'learning_rate': 0.0002669481281701739, 'epoch': 2.35}
Step 331: {'loss': 2.9808, 'learning_rate': 0.00026132053262641465, 'epoch': 2.35}
Step 332: {'loss': 3.2091, 'learning_rate': 0.0002557439605153483, 'epoch': 2.36}
Step 333: {'loss': 3.2664, 'learning_rate': 0.0002502187970322657, 'epoch': 2.37}
Step 334: {'loss': 2.8863, 'learning_rate': 0.0002447454238214654, 'epoch': 2.38}
Step 335: {'loss': 2.741, 'learning_rate': 0.00023932421894989165, 'epoch': 2.38}
Step 336: {'loss': 2.9055, 'learning_rate': 0.0002339555568810221, 'epoch': 2.39}
Step 337: {'loss': 2.6611, 'learning_rate': 0.00022863980844900034, 'epoch': 2.4}
Step 338: {'loss': 2.8501, 'learning_rate': 0.00022337734083302164, 'epoch': 2.4}
Step 339: {'loss': 3.0479, 'learning_rate': 0.0002181685175319702, 'epoch': 2.41}
Step 340: {'loss': 3.1026, 'learning_rate': 0.00021301369833931117, 'epoch': 2.42}
Step 341: {'loss': 3.1602, 'learning_rate': 0.0002079132393182378, 'epoch': 2.42}
Step 342: {'loss': 3.1611, 'learning_rate': 0.00020286749277707784, 'epoch': 2.43}
Step 343: {'loss': 2.9075, 'learning_rate': 0.00019787680724495617, 'epoch': 2.44}
Step 344: {'loss': 2.7698, 'learning_rate': 0.00019294152744772387, 'epoch': 2.45}
Step 345: {'loss': 3.1482, 'learning_rate': 0.0001880619942841435, 'epoch': 2.45}
Step 346: {'loss': 3.1653, 'learning_rate': 0.00018323854480234347, 'epoch': 2.46}
Step 347: {'loss': 3.0789, 'learning_rate': 0.00017847151217653624, 'epoch': 2.47}
Step 348: {'loss': 3.1366, 'learning_rate': 0.00017376122568400532, 'epoch': 2.47}
Step 349: {'loss': 2.6285, 'learning_rate': 0.00016910801068236014, 'epoch': 2.48}
Step 350: {'loss': 2.6978, 'learning_rate': 0.00016451218858706373, 'epoch': 2.49}
Step 351: {'loss': 2.7841, 'learning_rate': 0.0001599740768492286, 'epoch': 2.5}
Step 352: {'loss': 2.8662, 'learning_rate': 0.00015549398893369216, 'epoch': 2.5}
Step 353: {'loss': 2.9403, 'learning_rate': 0.0001510722342973627, 'epoch': 2.51}
Step 354: {'loss': 3.0672, 'learning_rate': 0.00014670911836784438, 'epoch': 2.52}
Step 355: {'loss': 2.7846, 'learning_rate': 0.00014240494252234048, 'epoch': 2.52}
Step 356: {'loss': 2.8891, 'learning_rate': 0.00013816000406683605, 'epoch': 2.53}
Step 357: {'loss': 2.7858, 'learning_rate': 0.0001339745962155613, 'epoch': 2.54}
Step 358: {'loss': 2.4, 'learning_rate': 0.0001298490080707392, 'epoch': 2.55}
Step 359: {'loss': 3.214, 'learning_rate': 0.00012578352460261455, 'epoch': 2.55}
Step 360: {'loss': 2.9221, 'learning_rate': 0.00012177842662977134, 'epoch': 2.56}
Step 361: {'loss': 2.9565, 'learning_rate': 0.00011783399079973578, 'epoch': 2.57}
Step 362: {'loss': 2.9943, 'learning_rate': 0.00011395048956986576, 'epoch': 2.57}
Step 363: {'loss': 2.5841, 'learning_rate': 0.00011012819118853145, 'epoch': 2.58}
Step 364: {'loss': 3.0695, 'learning_rate': 0.00010636735967658784, 'epoch': 2.59}
Step 365: {'loss': 2.8649, 'learning_rate': 0.00010266825480913611, 'epoch': 2.6}
Step 366: {'loss': 3.6565, 'learning_rate': 9.903113209758097e-05, 'epoch': 2.6}
Step 367: {'loss': 2.9018, 'learning_rate': 9.545624277198084e-05, 'epoch': 2.61}
Step 368: {'loss': 3.0, 'learning_rate': 9.194383376369509e-05, 'epoch': 2.62}
Step 369: {'loss': 2.8898, 'learning_rate': 8.849414768832687e-05, 'epoch': 2.62}
Step 370: {'loss': 2.58, 'learning_rate': 8.510742282896544e-05, 'epoch': 2.63}
Step 371: {'loss': 2.8348, 'learning_rate': 8.178389311972611e-05, 'epoch': 2.64}
Step 372: {'loss': 2.9894, 'learning_rate': 7.852378812959226e-05, 'epoch': 2.65}
Step 373: {'loss': 2.6399, 'learning_rate': 7.532733304655848e-05, 'epoch': 2.65}
Step 374: {'loss': 2.9795, 'learning_rate': 7.219474866207464e-05, 'epoch': 2.66}
Step 375: {'loss': 2.7328, 'learning_rate': 6.912625135579587e-05, 'epoch': 2.67}
Step 376: {'loss': 2.7191, 'learning_rate': 6.612205308063646e-05, 'epoch': 2.67}
Step 377: {'loss': 2.8098, 'learning_rate': 6.318236134812916e-05, 'epoch': 2.68}
Step 378: {'loss': 3.0354, 'learning_rate': 6.0307379214091684e-05, 'epoch': 2.69}
Step 379: {'loss': 3.0391, 'learning_rate': 5.749730526460073e-05, 'epoch': 2.7}
Step 380: {'loss': 3.0894, 'learning_rate': 5.475233360227516e-05, 'epoch': 2.7}
Step 381: {'loss': 2.851, 'learning_rate': 5.20726538328683e-05, 'epoch': 2.71}
Step 382: {'loss': 2.8486, 'learning_rate': 4.945845105217117e-05, 'epoch': 2.72}
Step 383: {'loss': 2.6081, 'learning_rate': 4.6909905833226964e-05, 'epoch': 2.72}
Step 384: {'loss': 2.7847, 'learning_rate': 4.4427194213859215e-05, 'epoch': 2.73}
Step 385: {'loss': 2.7829, 'learning_rate': 4.20104876845111e-05, 'epoch': 2.74}
Step 386: {'loss': 2.803, 'learning_rate': 3.965995317640026e-05, 'epoch': 2.74}
Step 387: {'loss': 3.0081, 'learning_rate': 3.737575304998797e-05, 'epoch': 2.75}
Step 388: {'loss': 2.6565, 'learning_rate': 3.5158045083765075e-05, 'epoch': 2.76}
Step 389: {'loss': 2.8015, 'learning_rate': 3.300698246335277e-05, 'epoch': 2.77}
Step 390: {'loss': 3.1585, 'learning_rate': 3.092271377092215e-05, 'epoch': 2.77}
Step 391: {'loss': 2.574, 'learning_rate': 2.8905382974930172e-05, 'epoch': 2.78}
Step 392: {'loss': 2.8571, 'learning_rate': 2.6955129420176194e-05, 'epoch': 2.79}
Step 393: {'loss': 2.6991, 'learning_rate': 2.5072087818176382e-05, 'epoch': 2.79}
Step 394: {'loss': 3.1548, 'learning_rate': 2.3256388237858805e-05, 'epoch': 2.8}
Step 395: {'loss': 3.2335, 'learning_rate': 2.1508156096578746e-05, 'epoch': 2.81}
Step 396: {'loss': 2.6055, 'learning_rate': 1.982751215145617e-05, 'epoch': 2.82}
Step 397: {'loss': 2.9352, 'learning_rate': 1.82145724910342e-05, 'epoch': 2.82}
Step 398: {'loss': 2.6519, 'learning_rate': 1.66694485272606e-05, 'epoch': 2.83}
Step 399: {'loss': 2.9972, 'learning_rate': 1.519224698779198e-05, 'epoch': 2.84}
Step 400: {'loss': 3.013, 'learning_rate': 1.378306990862177e-05, 'epoch': 2.84}
Step 401: {'loss': 2.8314, 'learning_rate': 1.2442014627032316e-05, 'epoch': 2.85}
Step 402: {'loss': 2.8785, 'learning_rate': 1.1169173774871477e-05, 'epoch': 2.86}
Step 403: {'loss': 3.2837, 'learning_rate': 9.964635272153633e-06, 'epoch': 2.87}
Step 404: {'loss': 2.8888, 'learning_rate': 8.828482320987319e-06, 'epoch': 2.87}
Step 405: {'loss': 3.0134, 'learning_rate': 7.760793399827936e-06, 'epoch': 2.88}
Step 406: {'loss': 2.6855, 'learning_rate': 6.761642258056977e-06, 'epoch': 2.89}
Step 407: {'loss': 2.9166, 'learning_rate': 5.831097910887873e-06, 'epoch': 2.89}
Step 408: {'loss': 2.9927, 'learning_rate': 4.9692246345985906e-06, 'epoch': 2.9}
Step 409: {'loss': 2.6327, 'learning_rate': 4.176081962092182e-06, 'epoch': 2.91}
Step 410: {'loss': 3.0779, 'learning_rate': 3.451724678784518e-06, 'epoch': 2.92}
Step 411: {'loss': 2.9511, 'learning_rate': 2.7962028188198706e-06, 'epoch': 2.92}
Step 412: {'loss': 3.1379, 'learning_rate': 2.2095616616150117e-06, 'epoch': 2.93}
Step 413: {'loss': 3.122, 'learning_rate': 1.6918417287318244e-06, 'epoch': 2.94}
Step 414: {'loss': 2.9075, 'learning_rate': 1.2430787810776556e-06, 'epoch': 2.94}
Step 415: {'loss': 2.9372, 'learning_rate': 8.633038164358453e-07, 'epoch': 2.95}
Step 416: {'loss': 2.8903, 'learning_rate': 5.525430673244403e-07, 'epoch': 2.96}
Step 417: {'loss': 2.6369, 'learning_rate': 3.1081799918375455e-07, 'epoch': 2.97}
Step 418: {'loss': 3.1963, 'learning_rate': 1.3814530889433296e-07, 'epoch': 2.97}
Step 419: {'loss': 2.8506, 'learning_rate': 3.453692362309635e-08, 'epoch': 2.98}
Step 420: {'loss': 2.5137, 'learning_rate': 0.0, 'epoch': 2.99}
Step 420: {'train_runtime': 2367.4408, 'train_samples_per_second': 11.405, 'train_steps_per_second': 0.177, 'total_flos': 0.0, 'train_loss': 3.8869009863762627, 'epoch': 2.99}
